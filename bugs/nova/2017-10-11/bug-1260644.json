{
    "status": "Invalid", 
    "last_updated": "2014-09-16 00:17:09.352513+00:00", 
    "description": "In the grenade test [0] for a bp I'm working on, ServerRescueTestXML rescue_unrescue test failed because the VM did not get into RESCUE state in time. It seems that the test is flacky.\n\nFrom the tempest log [1] I see the sequence VM ACTIVE, RESCUE issues, WAIT, timeout, DELETE VM.\n\nFrom the nova cpu log [1], following request ID: req-6c20654c-c00c-4932-87ad-8cfec9866399, I see that the RESCUE RCP is received immediately by n-cpu, however then the requests starves for 3 minutes waiting for a  \"compute_resources\" lock.\n\nThe VM is then deleted by the test and when nova tries to process the RESCUE it throws and exception as the VM is not there:\n\nbc-b27a-83c39b7566c8] Traceback (most recent call last):\nbc-b27a-83c39b7566c8]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2664, in rescue_instance\nbc-b27a-83c39b7566c8]     rescue_image_meta, admin_password)\nbc-b27a-83c39b7566c8]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 2109, in rescue\nbc-b27a-83c39b7566c8]     write_to_disk=True)\nbc-b27a-83c39b7566c8]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3236, in to_xml\nbc-b27a-83c39b7566c8]     libvirt_utils.write_to_file(xml_path, xml)\nbc-b27a-83c39b7566c8]   File \"/opt/stack/new/nova/nova/virt/libvirt/utils.py\", line 494, in write_to_file\nbc-b27a-83c39b7566c8]     with open(path, 'w') as f:\nbc-b27a-83c39b7566c8] IOError: [Errno 2] No such file or directory: u'/opt/stack/data/nova/instances/a5099beb-f4a2-47bc-b27a-83c39b7566c8/libvirt.xml'\nbc-b27a-83c39b7566c8]\n\nThere may be a problem in nova as well, as RESCUE is held for 3 minutes waiting on a lock.\n\n[0] https://review.openstack.org/#/c/60434/\n[1] http://logs.openstack.org/34/60434/5/check/check-grenade-dsvm/1d2852d/logs/tempest.txt.gz\n[2] http://logs.openstack.org/34/60434/5/check/check-grenade-dsvm/1d2852d/logs/new/screen-n-cpu.txt.gz?", 
    "tags": [
        "gate-failure"
    ], 
    "importance": "High", 
    "heat": 20, 
    "link": "https://bugs.launchpad.net/nova/+bug/1260644", 
    "owner": "None", 
    "id": 1260644, 
    "index": 1349, 
    "created": "2013-12-13 09:06:46.189386+00:00", 
    "title": "ServerRescueTest may fail due to RESCUE taking too long", 
    "comments": [
        {
            "content": "In the grenade test [0] for a bp I'm working on, ServerRescueTestXML rescue_unrescue test failed because the VM did not get into RESCUE state in time. It seems that the test is flacky.\n\nFrom the tempest log [1] I see the sequence VM ACTIVE, RESCUE issues, WAIT, timeout, DELETE VM.\n\nFrom the nova cpu log [1], following request ID: req-6c20654c-c00c-4932-87ad-8cfec9866399, I see that the RESCUE RCP is received immediately by n-cpu, however then the requests starves for 3 minutes waiting for a  \"compute_resources\" lock.\n\nThe VM is than deleted by the test and when nova tries to process the RESCUE it throws and exception as the VM is not there:\n\nbc-b27a-83c39b7566c8] Traceback (most recent call last):\nbc-b27a-83c39b7566c8]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2664, in rescue_instance\nbc-b27a-83c39b7566c8]     rescue_image_meta, admin_password)\nbc-b27a-83c39b7566c8]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 2109, in rescue\nbc-b27a-83c39b7566c8]     write_to_disk=True)\nbc-b27a-83c39b7566c8]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3236, in to_xml\nbc-b27a-83c39b7566c8]     libvirt_utils.write_to_file(xml_path, xml)\nbc-b27a-83c39b7566c8]   File \"/opt/stack/new/nova/nova/virt/libvirt/utils.py\", line 494, in write_to_file\nbc-b27a-83c39b7566c8]     with open(path, 'w') as f:\nbc-b27a-83c39b7566c8] IOError: [Errno 2] No such file or directory: u'/opt/stack/data/nova/instances/a5099beb-f4a2-47bc-b27a-83c39b7566c8/libvirt.xml'\nbc-b27a-83c39b7566c8] \n\nThere may be a problem in nova as well, as RESCUE is held for 3 minutes waiting on a lock.\n\n[0] https://review.openstack.org/#/c/60434/\n[1] http://logs.openstack.org/34/60434/5/check/check-grenade-dsvm/1d2852d/logs/tempest.txt.gz\n[2] http://logs.openstack.org/34/60434/5/check/check-grenade-dsvm/1d2852d/logs/new/screen-n-cpu.txt.gz?", 
            "date_created": "2013-12-13 09:06:46.189386+00:00", 
            "author": "https://api.launchpad.net/1.0/~andrea-frittoli"
        }, 
        {
            "content": "This looks like the root cause is Nova exploding on the transition. I'm going to mark the Tempest side invalid.", 
            "date_created": "2013-12-13 13:48:19.642986+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "Hit it here also:\n\nhttp://logs.openstack.org/98/55798/12/check/check-grenade-dsvm/1d928a5/console.html\n\nAnything we can use for an e-r query to identify this?", 
            "date_created": "2013-12-13 23:56:20.118436+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I see this in the nova compute log when I hit the failure:\n\n2013-12-13 22:37:58.043 WARNING nova.virt.libvirt.driver [req-0b016f8d-41e1-4d02-aed3-669f9ac86c25 tempest.scenario.manager-tempest-1268694175-user tempest.scenario.manager-tempest-1268694175-tenant] [instance: 41ea1271-84f4-4d25-91e2-4a545480c1f7] File injection into a boot from volume instance is not supported\n\n2013-12-13 22:37:58.046 WARNING nova.virt.disk.api [req-0b016f8d-41e1-4d02-aed3-669f9ac86c25 tempest.scenario.manager-tempest-1268694175-user tempest.scenario.manager-tempest-1268694175-tenant] Ignoring error injecting data into image ([Errno 2] No such file or directory: '/opt/stack/data/nova/instances/41ea1271-84f4-4d25-91e2-4a545480c1f7/disk')\n\n2013-12-13 22:38:09.969 ERROR nova.compute.manager [req-c9e27115-7a1b-4a38-b0d8-84a66437470f ServerRescueTestXML-tempest-1077445745-user ServerRescueTestXML-tempest-1077445745-tenant] [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095] Error trying to Rescue Instance\n\nSeems that we could write an e-r query on \"Error trying to Rescue Instance\".  I ran that in a query and got 9 hits in the last 7 days:\n\nhttp://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwiRXJyb3IgdHJ5aW5nIHRvIFJlc2N1ZSBJbnN0YW5jZVwiIEFORCBmaWxlbmFtZTpcImxvZ3Mvc2NyZWVuLW4tY3B1LnR4dFwiIiwiZmllbGRzIjpbXSwib2Zmc2V0IjowLCJ0aW1lZnJhbWUiOiI2MDQ4MDAiLCJncmFwaG1vZGUiOiJjb3VudCIsInRpbWUiOnsidXNlcl9pbnRlcnZhbCI6MH0sInN0YW1wIjoxMzg3MDU0NTE5MDAxfQ==\n\nThe problem is 8 out of the 9 times it fails, it's failing due to a libvirt connection reset.  In only one case did I see this:\n\nIOError: [Errno 2] No such file or directory: u'/opt/stack/data/nova/instances/5a9b502f-7e4b-422a-9813-ff39666c73dc/libvirt.xml'\n\nAnd that was in a check-tempest-dsvm-postgres-full build, so we can't filter on it just happening with the grenade test.\n\nIf we had multi-line/doc query support with elastic recheck we could combine those two messages for a pretty solid query, but that isn't supported yet.", 
            "date_created": "2013-12-14 20:58:44.931575+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Hmm, actually when I expand the logs it looks like when I hit this failure it was due to the libvirt connection getting reset also:\n\n2013-12-13 22:38:09.969 ERROR nova.compute.manager [req-c9e27115-7a1b-4a38-b0d8-84a66437470f ServerRescueTestXML-tempest-1077445745-user ServerRescueTestXML-tempest-1077445745-tenant] [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095] Error trying to Rescue Instance\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095] Traceback (most recent call last):\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2664, in rescue_instance\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]     rescue_image_meta, admin_password)\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 2086, in rescue\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]     unrescue_xml = self._get_existing_domain_xml(instance, network_info)\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 1272, in _get_existing_domain_xml\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]     xml = virt_dom.XMLDesc(0)\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 179, in doit\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 139, in proxy_call\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]     rv = execute(f,*args,**kwargs)\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 77, in tworker\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]     rv = meth(*args,**kwargs)\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 381, in XMLDesc\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095]     if ret is None: raise libvirtError ('virDomainGetXMLDesc() failed', dom=self)\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095] libvirtError: Unable to read from monitor: Connection reset by peer\n2013-12-13 22:38:09.969 10037 TRACE nova.compute.manager [instance: 1a65dda0-a949-414c-a43c-51bc60cd7095] \n2013-12-13 22:38:10.137 ERROR nova.openstack.common.rpc.amqp [req-c9e27115-7a1b-4a38-b0d8-84a66437470f ServerRescueTestXML-tempest-1077445745-user ServerRescueTestXML-tempest-1077445745-tenant] Exception during message handling\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp Traceback (most recent call last):\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/openstack/common/rpc/amqp.py\", line 461, in _process_data\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     **args)\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/openstack/common/rpc/dispatcher.py\", line 172, in dispatch\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     result = getattr(proxyobj, method)(ctxt, **kwargs)\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/exception.py\", line 90, in wrapped\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     payload)\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     six.reraise(self.type_, self.value, self.tb)\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/exception.py\", line 73, in wrapped\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     return f(self, context, *args, **kw)\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 248, in decorated_function\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     pass\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     six.reraise(self.type_, self.value, self.tb)\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 234, in decorated_function\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     return function(self, context, *args, **kwargs)\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 299, in decorated_function\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     function(self, context, *args, **kwargs)\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2670, in rescue_instance\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp     reason=_(\"Driver Error: %s\") % unicode(e))\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp InstanceNotRescuable: Instance 1a65dda0-a949-414c-a43c-51bc60cd7095 cannot be rescued: Driver Error: Unable to read from monitor: Connection reset by peer\n2013-12-13 22:38:10.137 10037 TRACE nova.openstack.common.rpc.amqp \n\nSo maybe this bug is just a dupe of another because I thought we already had one tracking random libvirt connection drops.\n\nLooks like that's bug 1255624.", 
            "date_created": "2013-12-14 21:06:32.204101+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "From Andrea's grenade failure logs, it's actually not due to the libvirt connection reset, it's due to the domain xml not being found, so this is a valid unique bug (apart from bug 1255624).\n\n2013-12-12 19:17:31.244 10417 TRACE nova.openstack.common.rpc.amqp InstanceNotRescuable: Instance a5099beb-f4a2-47bc-b27a-83c39b7566c8 cannot be rescued: Driver Error: [Errno 2] No such file or directory: u'/opt/stack/data/nova/instances/a5099beb-f4a2-47bc-b27a-83c39b7566c8/libvirt.xml'", 
            "date_created": "2013-12-14 21:12:48.539829+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "We should be able to write an e-r query on this:\n\nmessage:\"cannot be rescued: Driver Error: [Errno 2] No such file or directory:\" AND filename:\"logs/screen-n-cpu.txt\"\n\nThat has both the 'cannot be rescued' piece and IOError pieces I was looking for to make this a unique query.\n\nThere is 1 hit in the last 7 days:\n\nhttp://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwiY2Fubm90IGJlIHJlc2N1ZWQ6IERyaXZlciBFcnJvcjogW0Vycm5vIDJdIE5vIHN1Y2ggZmlsZSBvciBkaXJlY3Rvcnk6XCIgQU5EIGZpbGVuYW1lOlwibG9ncy9zY3JlZW4tbi1jcHUudHh0XCIiLCJmaWVsZHMiOltdLCJvZmZzZXQiOjAsInRpbWVmcmFtZSI6IjYwNDgwMCIsImdyYXBobW9kZSI6ImNvdW50IiwidGltZSI6eyJ1c2VyX2ludGVydmFsIjowfSwic3RhbXAiOjEzODcwNTU2MjA0MjZ9\n\nThat's in a non-grenade test, probably because of the path to the log filename.  Maybe I can correct that with an OR in the query.", 
            "date_created": "2013-12-14 21:15:43.653906+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Proposed an elastic-recheck query here: https://review.openstack.org/#/c/62192/", 
            "date_created": "2013-12-14 21:23:53.369661+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Matt, thanks for your investigation on this. \n\nIn my understanding the sequence of events from the nova logs is the following:\n- n-cpu starts processing RESCUE request \n- it waits 3 minutes+ for a lock compute_resources to become available - this could be a consequence of bug 1255624\n- meanwhile the timeout in the test expires, and the test proceeds to delete the test VM (just a guess)\n- the deletion of the VM is processed by n-cpu\n- the execution of RESCUE resumes, it assumes that the VM is still in the same state, no noticing that it has been deleted already. This it hits the issue with the domain file not found.\n\nSo perhaps the additional error message in this case, compared to bug 1255624, is due to a race condition where the test deleted the VM successfully before RESCUE could resume. ", 
            "date_created": "2013-12-15 21:18:37.933739+00:00", 
            "author": "https://api.launchpad.net/1.0/~andrea-frittoli"
        }, 
        {
            "content": " No hits in a while looks like this resolved itself or the fingerprint is out of date.", 
            "date_created": "2014-08-30 00:01:56.441387+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }
    ]
}