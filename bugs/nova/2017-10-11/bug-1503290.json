{
    "status": "Invalid", 
    "last_updated": "2016-01-18 20:59:40.954945+00:00", 
    "description": "http://logs.openstack.org/10/230510/2/gate/gate-grenade-dsvm/e796b39/logs/new/screen-n-cpu.txt.gz?level=TRACE#_2015-10-06_05_39_36_682\n\n2015-10-06 05:39:36.682 ERROR nova.compute.manager [req-03e13a69-3da6-4bc6-bcab-3b2a3fe4d236 tempest-ServersTestManualDisk-1771971010 tempest-ServersTestManualDisk-1239478904] [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959] Build of instance 816e60bb-0085-4b0b-9a00-dbd24c339959 aborted: Failure prepping block device.\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959] Traceback (most recent call last):\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1906, in _do_build_and_run_instance\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     filter_properties)\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2034, in _build_and_run_instance\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     'create.error', fault=e)\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 195, in __exit__\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     six.reraise(self.type_, self.value, self.tb)\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1999, in _build_and_run_instance\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     block_device_mapping) as resources:\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     return self.gen.next()\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2165, in _build_resources\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     reason=msg)\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959] BuildAbortException: Build of instance 816e60bb-0085-4b0b-9a00-dbd24c339959 aborted: Failure prepping block device.\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959] \n\n\n\nhttp://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwiX2RvX2J1aWxkX2FuZF9ydW5faW5zdGFuY2VcIiBBTkQgbWVzc2FnZTpcImFib3J0ZWQ6IEZhaWx1cmUgcHJlcHBpbmcgYmxvY2sgZGV2aWNlXCIgQU5EIHRhZ3M6XCJzY3JlZW4tbi1jcHUudHh0XCIiLCJmaWVsZHMiOltdLCJvZmZzZXQiOjAsInRpbWVmcmFtZSI6IjYwNDgwMCIsImdyYXBobW9kZSI6ImNvdW50IiwidGltZSI6eyJ1c2VyX2ludGVydmFsIjowfSwic3RhbXAiOjE0NDQxMzg1OTE3NjV9\n\n7 hits in 7 days, check and gate, all failures, master branch only.", 
    "tags": [
        "volumes"
    ], 
    "importance": "High", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1503290", 
    "owner": "None", 
    "id": 1503290, 
    "index": 1821, 
    "created": "2015-10-06 13:39:03.885235+00:00", 
    "title": "grenade failures on mitaka side with failure prepping block device due to RPC timeout", 
    "comments": [
        {
            "content": "http://logs.openstack.org/10/230510/2/gate/gate-grenade-dsvm/e796b39/logs/new/screen-n-cpu.txt.gz?level=TRACE#_2015-10-06_05_39_36_682\n\n2015-10-06 05:39:36.682 ERROR nova.compute.manager [req-03e13a69-3da6-4bc6-bcab-3b2a3fe4d236 tempest-ServersTestManualDisk-1771971010 tempest-ServersTestManualDisk-1239478904] [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959] Build of instance 816e60bb-0085-4b0b-9a00-dbd24c339959 aborted: Failure prepping block device.\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959] Traceback (most recent call last):\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1906, in _do_build_and_run_instance\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     filter_properties)\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2034, in _build_and_run_instance\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     'create.error', fault=e)\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 195, in __exit__\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     six.reraise(self.type_, self.value, self.tb)\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1999, in _build_and_run_instance\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     block_device_mapping) as resources:\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     return self.gen.next()\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2165, in _build_resources\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959]     reason=msg)\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959] BuildAbortException: Build of instance 816e60bb-0085-4b0b-9a00-dbd24c339959 aborted: Failure prepping block device.\n2015-10-06 05:39:36.682 5634 ERROR nova.compute.manager [instance: 816e60bb-0085-4b0b-9a00-dbd24c339959] \n\n\n\nhttp://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwiX2RvX2J1aWxkX2FuZF9ydW5faW5zdGFuY2VcIiBBTkQgbWVzc2FnZTpcImFib3J0ZWQ6IEZhaWx1cmUgcHJlcHBpbmcgYmxvY2sgZGV2aWNlXCIgQU5EIHRhZ3M6XCJzY3JlZW4tbi1jcHUudHh0XCIiLCJmaWVsZHMiOltdLCJvZmZzZXQiOjAsInRpbWVmcmFtZSI6IjYwNDgwMCIsImdyYXBobW9kZSI6ImNvdW50IiwidGltZSI6eyJ1c2VyX2ludGVydmFsIjowfSwic3RhbXAiOjE0NDQxMzg1OTE3NjV9\n\n7 hits in 7 days, check and gate, all failures, master branch only.", 
            "date_created": "2015-10-06 13:39:03.885235+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I'm wondering if this is related to the recent devstack change on master which dropped conductor workers from $nproc (8) to 2.", 
            "date_created": "2015-10-06 13:46:00.551697+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Looking at dstat around 05:39:36 when we had the messaging timeout, cinder is doing a lot of work, not conductor, so we're probably timing out waiting for a response from cinder-api for something, like initializing a connection.\n\nhttp://logs.openstack.org/10/230510/2/gate/gate-grenade-dsvm/e796b39/logs/new/screen-dstat.txt.gz\n\nNote that right before this failures we're running test_volume_boot_pattern which is a boot from volume test:\n\nhttp://logs.openstack.org/10/230510/2/gate/gate-grenade-dsvm/e796b39/logs/new/screen-n-cpu.txt.gz?level=TRACE#_2015-10-06_05_39_33_329\n\nSo around the time that we timeout prepping block devices for one instance, we're attaching a newly created volume to another instance in a concurrently running test.", 
            "date_created": "2015-10-06 14:10:33.690523+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "There is a lock being held in c-vol that is taking awhile, 16 seconds in one case, I'm not sure if that's a lot or not:\n\nhttp://logs.openstack.org/10/230510/2/gate/gate-grenade-dsvm/e796b39/logs/new/screen-c-vol.txt.gz#_2015-10-06_05_40_15_936\n\n2015-10-06 05:40:15.936 DEBUG oslo_concurrency.lockutils [req-6b402bc1-3c24-47f8-be65-609bfb98c8fd tempest-TestVolumeBootPatternV2-836916434] Lock \"35fbbb48-90a3-45e2-9275-d66c9b8e9b2b-delete_snapshot\" released by \"cinder.volume.manager._run_flow_locked\" :: held 16.103s inner /usr/local/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py:265", 
            "date_created": "2015-10-06 14:15:52.772679+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Cinder is not involved here, we're hitting the rpc timeout when calling instance.save() in nova.compute.manager _build_resources here:\n\n            LOG.debug('Start building block device mappings for instance.',\n                      instance=instance)\n            instance.vm_state = vm_states.BUILDING\n            instance.task_state = task_states.BLOCK_DEVICE_MAPPING\n            instance.save()\n\nAnd conductor is in bad shape:\n\nhttp://logs.openstack.org/10/230510/2/gate/gate-grenade-dsvm/e796b39/logs/new/screen-n-cond.txt.gz?level=TRACE\n\nWhen we failed, we're falling in between:\n\nhttp://logs.openstack.org/10/230510/2/gate/gate-grenade-dsvm/e796b39/logs/new/screen-n-cond.txt.gz#_2015-10-06_05_39_34_313\n\nAnd\n\nhttp://logs.openstack.org/10/230510/2/gate/gate-grenade-dsvm/e796b39/logs/new/screen-n-cond.txt.gz#_2015-10-06_05_39_43_085\n\nWhen nothing is happening.", 
            "date_created": "2015-10-06 14:52:25.453576+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "The lock part is caused by the fact we're locking source snapshot deletion while we're creating a volume from it. I don't think it is the root of the problem. I'd rather look at it from other side - it's taking us 16 seconds to create a volume from snapshot. Why? Is it the cause of the timeout?\n\nFrom logs for this particular request (6b402bc1-3c24-47f8-be65-609bfb98c8fd) it looks like this dd is taking the most time: http://logs.openstack.org/10/230510/2/gate/gate-grenade-dsvm/e796b39/logs/new/screen-c-vol.txt.gz#_2015-10-06_05_40_00_759", 
            "date_created": "2015-10-06 14:54:18.389830+00:00", 
            "author": "https://api.launchpad.net/1.0/~michal-dulko-f"
        }, 
        {
            "content": "Maybe this could be related to bug 1446583.", 
            "date_created": "2015-10-06 15:10:40.105279+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "It might be related to bug 1318721", 
            "date_created": "2015-10-06 21:23:05.861770+00:00", 
            "author": "https://api.launchpad.net/1.0/~chuckcarmack75"
        }, 
        {
            "content": "This isn't showing up anymore and bug 1446583 is fixed so I'm assuming it was related to that.", 
            "date_created": "2016-01-18 20:59:40.334900+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }
    ]
}