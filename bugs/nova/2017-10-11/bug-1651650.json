{
    "status": "Fix Released", 
    "last_updated": "2017-01-27 00:51:16.534073+00:00", 
    "description": "Observed several failure in citrix xenserver CI for this test case:\ntempest.api.compute.servers.test_server_rescue\n\nSee there are timeout waiting for vif:\n\n$ grep 'Timeout waiting for vif plugging callbac' screen-n-cpu.txt.gz\n2016-12-20 10:58:52.036 4528 WARNING nova.virt.xenapi.vmops [req-ff027cef-59be-4326-95e1-065f68077d63 tempest-ServerRescueTestJSON-1293983176 tempest-ServerRescueTestJSON-1293983176] [instance: 28b094ee-c571-4083-b72b-5ea78f1f4291] Timeout waiting for vif plugging callback\n\nFor rescue, it seems shouldn't wait for this event as this port should be active at the rescuing start.\nBut observed:\nneutron service reported the 2nd vif-plugin event:\n\n\n2016-12-20 10:52:31.689 712 DEBUG neutron.notifiers.nova [-] Sending events: [{'status': 'completed', 'tag': u'52d79a78-7205-4e69-8005-76a3cebbf267', 'name': 'network-vif-plugged', 'server_uuid': u'28b094ee-c571-4083-b72b-5ea78f1f4291'}] send_events /opt/stack/new/neutron/neutron/notifiers/nova.py:248\n\n2016-12-20 10:53:45.179 712 DEBUG neutron.notifiers.nova [-] Sending events: [{'status': 'completed', 'tag': u'52d79a78-7205-4e69-8005-76a3cebbf267', 'name': 'network-vif-plugged', 'server_uuid': u'28b094ee-c571-4083-b72b-5ea78f1f4291'}] send_events /opt/stack/new/neutron/neutron/notifiers/nova.py:248\n\n\nAnd nova attempts to wait for this event after the 2nd event sent out; so it won't catch the 2nd event at all:\n2016-12-20 10:53:46.326 4528 DEBUG nova.virt.xenapi.vmops [req-ff027cef-59be-4326-95e1-065f68077d63 tempest-ServerRescueTestJSON-1293983176 tempest-ServerRescueTestJSON-1293983176] wait for instance event:[('network-vif-plugged', u'52d79a78-7205-4e69-8005-76a3cebbf267')] _spawn /opt/stack/new/nova/nova/virt/xenapi/vmops.py:599", 
    "tags": [
        "neutron", 
        "rescue", 
        "testing", 
        "xenserver"
    ], 
    "importance": "Medium", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1651650", 
    "owner": "https://api.launchpad.net/1.0/~huan-xie", 
    "id": 1651650, 
    "index": 4712, 
    "created": "2016-12-21 06:18:16.380517+00:00", 
    "title": "XenAPI: server rescue test sometime failed with timeout waiting for vif plugging ", 
    "comments": [
        {
            "content": "Observed several failure in citrix xenserver CI for this test case:\ntempest.api.compute.servers.test_server_rescue\n\nSee there are timeout waiting for vif:\n\n$ grep 'Timeout waiting for vif plugging callbac' screen-n-cpu.txt.gz\n2016-12-20 10:58:52.036 4528 WARNING nova.virt.xenapi.vmops [req-ff027cef-59be-4326-95e1-065f68077d63 tempest-ServerRescueTestJSON-1293983176 tempest-ServerRescueTestJSON-1293983176] [instance: 28b094ee-c571-4083-b72b-5ea78f1f4291] Timeout waiting for vif plugging callback\n\nFor rescue, it seems shouldn't wait for this event as this port should be active at the rescuing start.\nBut observed:\nneutron service reported the 2nd vif-plugin event:\n\n\n2016-12-20 10:52:31.689 712 DEBUG neutron.notifiers.nova [-] Sending events: [{'status': 'completed', 'tag': u'52d79a78-7205-4e69-8005-76a3cebbf267', 'name': 'network-vif-plugged', 'server_uuid': u'28b094ee-c571-4083-b72b-5ea78f1f4291'}] send_events /opt/stack/new/neutron/neutron/notifiers/nova.py:248\n\n2016-12-20 10:53:45.179 712 DEBUG neutron.notifiers.nova [-] Sending events: [{'status': 'completed', 'tag': u'52d79a78-7205-4e69-8005-76a3cebbf267', 'name': 'network-vif-plugged', 'server_uuid': u'28b094ee-c571-4083-b72b-5ea78f1f4291'}] send_events /opt/stack/new/neutron/neutron/notifiers/nova.py:248\n\n\nAnd nova attempts to wait for this event after the 2nd event sent out; so it won't catch the 2nd event at all:\n2016-12-20 10:53:46.326 4528 DEBUG nova.virt.xenapi.vmops [req-ff027cef-59be-4326-95e1-065f68077d63 tempest-ServerRescueTestJSON-1293983176 tempest-ServerRescueTestJSON-1293983176] wait for instance event:[('network-vif-plugged', u'52d79a78-7205-4e69-8005-76a3cebbf267')] _spawn /opt/stack/new/nova/nova/virt/xenapi/vmops.py:599", 
            "date_created": "2016-12-21 06:18:16.380517+00:00", 
            "author": "https://api.launchpad.net/1.0/~wjh-fresh"
        }, 
        {
            "content": "The libvirt driver uses a vifs_already_plugged boolean that it uses to determine if it should wait for vif plug callback events from neutron:\n\nhttps://github.com/openstack/nova/blob/a74d3ae4e815e3727961ef67bd801dada0267a0b/nova/virt/libvirt/driver.py#L5004\n\nSo for cases like spawn (create a new server), that's False, but for things like migrate, resume, and reboot, it's False to indicate that the vifs are already plugged and we shouldn't wait for events. Perhaps similar logic needs to be built into the xenapi driver.\n\nI don't see the libvirt driver needing to deal with this at all for rescue, however.", 
            "date_created": "2016-12-29 21:19:22.927528+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "It does look like during the rescue flow for creating a new VM it does create new VIFs from the same network info and plug them into the new rescue VM. Maybe the issue is that neutron things the VIFs are already plugged and therefore doesn't send the event?", 
            "date_created": "2016-12-29 21:30:40.571541+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "@Matt, you are right, it should not wait for vif plug event. I've checked the code and found with XenServer driver, most of the time, it will not wait for that event, see https://github.com/openstack/nova/blob/master/nova/virt/xenapi/vmops.py#L593 will try to get event to wait, and when rescue the VM, it use the same Port(neutron side), so the vif's status is ACTIVE, so it won't wait for event https://github.com/openstack/nova/blob/master/nova/virt/xenapi/vmops.py#L641\n\nBut I found there is a problem in creating VIF, it will always delete the VIF and create new one https://github.com/openstack/nova/blob/master/nova/virt/xenapi/vif.py#L324, which will cause neutron side change the Port(VIF)'s status, then in virt/xenapi/vmops.py:_get_neutron_events() found the status is not ACTIVE and will wait for vif_plug_event()\n\nI've made a patch for this problem https://review.openstack.org/#/c/413469/", 
            "date_created": "2017-01-03 01:23:43.592708+00:00", 
            "author": "https://api.launchpad.net/1.0/~huan-xie"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/413469\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=2207dcf560413b213a8fb3737bb4b0923dcd96e0\nSubmitter: Jenkins\nBranch:    master\n\ncommit 2207dcf560413b213a8fb3737bb4b0923dcd96e0\nAuthor: Huan Xie <email address hidden>\nDate:   Tue Dec 20 23:26:49 2016 -0800\n\n    XenAPI: Fix vif plug problem during VM rescue/unrescue\n    \n    During VM rescue tests, we found nova xenserver driver failed due\n    to waiting vif-plug-event from neutron timeout. when checking\n    nova and neutron logs, we found there are several mistakes in\n    nova driver:\n    (1) After several rounds of rescuing/unrescuing, it will wait for\n    vif-plug-event, but actually, it shouldn't wait for such event\n    (2) Checking neutron log, we found the port status sometimes will\n    change during rescuing/unrescuing, which also shouldn't happen\n    (3) Checking nova related code, we found each time when booting a\n    VM, it will delete and create the tap device, which is used by\n    neutron security group, this delete/re-create action will cause\n    the port status change which shouldn't be changed.\n    (4) When adding/deleting security groups to VM's port, it will\n    trigger the port status change, e.g. from ACTIVE to BUILDING, but\n    under rescue scenario, we also depends on VIF's status to determine\n    whether waiting for vif plug event is not appropriate.\n    \n    This patch is to fix the above problem and there is another patch\n    to enable the exclude rescue tests to test this fix\n    https://review.openstack.org/#/c/416197/\n    \n    Closes-Bug: #1651650\n    \n    Change-Id: I32c66733330bc9877caea7e2a2290c02b3906708\n", 
            "date_created": "2017-01-18 23:47:22.820687+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 15.0.0.0b3 development milestone.", 
            "date_created": "2017-01-27 00:51:15.353573+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}