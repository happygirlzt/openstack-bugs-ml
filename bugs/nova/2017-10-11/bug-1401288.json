{
    "status": "Expired", 
    "last_updated": "2016-07-05 09:55:26.641843+00:00", 
    "description": "I get a \"Failure prepping block device\" error whenever I create an instance with a volume or just a volume. It has been happening a few times after setup, then I was able to create an instance once, now it again occurs every time. I tried at least 10 times with various configurations (empty volume, from image), also tried rebooting in between.\n\nI run RDO Juno, CentOS 7, XFS + MD-RAID1. It is a fresh installation, I didn't really change much other than adding a few images.\n\nSSH access can be provided for debugging purposes.\n\nRelevant nova-compute log: https://gist.githubusercontent.com/jgillich/fac1667fac71f5f459a6/raw/2794e3434f39d0333e70145a30a5c18ebbe34db5/gistfile1.txt", 
    "tags": [
        "volumes"
    ], 
    "importance": "Undecided", 
    "heat": 70, 
    "link": "https://bugs.launchpad.net/nova/+bug/1401288", 
    "owner": "None", 
    "id": 1401288, 
    "index": 5316, 
    "created": "2014-12-10 22:14:27.705404+00:00", 
    "title": "'Failure prepping block device' error when creating volumes", 
    "comments": [
        {
            "content": "I get a \"Failure prepping block device\" error whenever I create an instance with a volume or just a volume. It has been happening a few times after setup, then I was able to create an instance once, now it again occurs every time. I tried at least 10 times with various configurations (empty volume, from image), also tried rebooting in between.\n\nI run RDO Juno, CentOS 7, XFS + MD-RAID1. It is a fresh installation, I didn't really change much other than adding a few images.\n\nSSH access can be provided for debugging purposes.\n\nRelevant nova-compute log:\n\n2014-12-10 22:25:20.978 3841 AUDIT nova.compute.manager [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Starting instance...\n2014-12-10 22:25:21.133 3841 AUDIT nova.compute.claims [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Attempting claim: memory 512 MB, disk 5 GB\n2014-12-10 22:25:21.133 3841 AUDIT nova.compute.claims [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Total memory: 7716 MB, used: 6656.00 MB\n2014-12-10 22:25:21.134 3841 AUDIT nova.compute.claims [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] memory limit: 11574.00 MB, free: 4918.00 MB\n2014-12-10 22:25:21.134 3841 AUDIT nova.compute.claims [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Total disk: 922 GB, used: 60.00 GB\n2014-12-10 22:25:21.134 3841 AUDIT nova.compute.claims [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] disk limit not specified, defaulting to unlimited\n2014-12-10 22:25:21.158 3841 AUDIT nova.compute.claims [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Claim successful\n2014-12-10 22:25:21.500 3841 INFO nova.scheduler.client.report [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] Compute_service record updated for ('openstack.localdomain', 'openstack.localdomain')\n2014-12-10 22:25:21.703 3841 INFO nova.scheduler.client.report [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] Compute_service record updated for ('openstack.localdomain', 'openstack.localdomain')\n2014-12-10 22:25:22.001 3841 AUDIT nova.virt.block_device [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Booting with volume None at /dev/vda\n2014-12-10 22:25:22.002 3841 WARNING nova.volume.cinder [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] Cinder V1 API is deprecated as of the Juno release, and Nova is still configured to use it. Enable the V2 API in Cinder and set cinder_catalog_info in nova.conf to use it.\n2014-12-10 22:25:22.808 3841 INFO nova.scheduler.client.report [-] Compute_service record updated for ('openstack.localdomain', 'openstack.localdomain')\n2014-12-10 22:25:23.626 3841 WARNING nova.compute.manager [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] Volume id: b9642e1b-a964-41da-a722-521b96cec023 finished being created but was not set as 'available'\n2014-12-10 22:25:23.811 3841 ERROR nova.compute.manager [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Instance failed block device setup\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Traceback (most recent call last):\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 1818, in _prep_block_device\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     do_check_attach=do_check_attach) +\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/virt/block_device.py\", line 407, in attach_block_devices\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     map(_log_and_attach, block_device_mapping)\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/virt/block_device.py\", line 405, in _log_and_attach\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     bdm.attach(*attach_args, **attach_kwargs)\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/virt/block_device.py\", line 339, in attach\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     do_check_attach=do_check_attach)\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/virt/block_device.py\", line 46, in wrapped\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     ret_val = method(obj, context, *args, **kwargs)\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/virt/block_device.py\", line 229, in attach\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     volume_api.check_attach(context, volume, instance=instance)\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/volume/cinder.py\", line 305, in check_attach\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     raise exception.InvalidVolume(reason=msg)\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] InvalidVolume: Invalid volume: status must be 'available'\n2014-12-10 22:25:23.811 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] \n2014-12-10 22:25:23.827 3841 ERROR nova.compute.manager [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Failure prepping block device\n2014-12-10 22:25:23.827 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Traceback (most recent call last):\n2014-12-10 22:25:23.827 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 2206, in _build_resources\n2014-12-10 22:25:23.827 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     block_device_mapping)\n2014-12-10 22:25:23.827 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 1846, in _prep_block_device\n2014-12-10 22:25:23.827 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     raise exception.InvalidBDM()\n2014-12-10 22:25:23.827 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] InvalidBDM: Block Device Mapping is Invalid.\n2014-12-10 22:25:23.827 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] \n2014-12-10 22:25:23.943 3841 INFO nova.scheduler.client.report [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] Compute_service record updated for ('openstack.localdomain', 'openstack.localdomain')\n2014-12-10 22:25:23.953 3841 ERROR nova.compute.manager [req-62588275-2fdb-4257-ba95-050b6c68c2e6 None] [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Build of instance 74998751-c233-45d2-8582-2dfdaa7cdb90 aborted: Failure prepping block device.\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] Traceback (most recent call last):\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 2014, in do_build_and_run_instance\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     filter_properties)\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 2117, in _build_and_run_instance\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     'create.error', fault=e)\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/openstack/common/excutils.py\", line 82, in __exit__\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     six.reraise(self.type_, self.value, self.tb)\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 2091, in _build_and_run_instance\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     block_device_mapping) as resources:\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib64/python2.7/contextlib.py\", line 17, in __enter__\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     return self.gen.next()\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 2228, in _build_resources\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90]     reason=msg)\n2014-12-10 22:25:23.953 3841 TRACE nova.compute.manager [instance: 74998751-c233-45d2-8582-2dfdaa7cdb90] BuildAbortException: Build of instance 74998751-c233-45d2-8582-2dfdaa7cdb90 aborted: Failure prepping block device.", 
            "date_created": "2014-12-10 22:14:27.705404+00:00", 
            "author": "https://api.launchpad.net/1.0/~jgillich"
        }, 
        {
            "content": "I've tried another operating system (Fedora 21), another file system (ext4), and a completely different machine; still get this error. The only thing that these had in common are the hard disks, two WD Red. No (other) issues with the disks so far, but I need to make a few more tests to be sure.", 
            "date_created": "2014-12-16 13:31:33.533120+00:00", 
            "author": "https://api.launchpad.net/1.0/~jgillich"
        }, 
        {
            "content": "I've seen the same issue in Juno. What did work for me was the following: \n\n1. Create a volume manually using cinder and specificy an image to be copied into the volume. Let's name this newly created volume ubuntu14_04_volume \n2. Create a snapshot of the volume ubuntu_14_04_volume\n3. Launch a new instance specifying instance boot source: Volume snapshot creates new volume\n\nThis way I was able to still achieve the same, similar affect. \n\nPossible issue: Maybe a timeout happened while downloading the image to RBD and nova doesn't wait long enough for larger images? Or when Ceph is on a slow network.", 
            "date_created": "2015-02-02 06:49:09.056117+00:00", 
            "author": "https://api.launchpad.net/1.0/~sammiestoel"
        }, 
        {
            "content": "Update: I'm positive that the volume which was created by Boot from image(Creates new volume) is still in downloading state, while nova thinks there was a timeout, the image was infact still being downloaded. Nova shouldn't have a hard timeout if the image is still being downloaded. The current default hard timeout is too low. Any place to configure this?", 
            "date_created": "2015-02-02 06:50:58.250824+00:00", 
            "author": "https://api.launchpad.net/1.0/~sammiestoel"
        }, 
        {
            "content": "Same problem on our installation (Juno, Centos7, ext4).", 
            "date_created": "2015-02-11 06:19:57.099310+00:00", 
            "author": "https://api.launchpad.net/1.0/~bernd-vogt"
        }, 
        {
            "content": "Same problem on installation (Juno, Ubuntu 14.04)", 
            "date_created": "2015-02-11 19:03:35.204808+00:00", 
            "author": "https://api.launchpad.net/1.0/~vallard"
        }, 
        {
            "content": "Confirming same problem in Ubuntu 14.04 and Juno combination", 
            "date_created": "2015-04-03 01:51:21.729964+00:00", 
            "author": "https://api.launchpad.net/1.0/~ethode"
        }, 
        {
            "content": "I get the same error, however on cinder volume logs I saw:\n\nImageUnacceptable: Image 2963117e-3616-4b8a-b97f-97b30963b670 is unacceptable: Size is 8GB and doesn't fit in a volume of size 5GB.\n\nIt seems that the qcow2 image I was using, uncompressed was using 8G, if I am not mistaken. Increasing the device volume from 5G to 10G got me past this error.", 
            "date_created": "2015-04-09 06:47:56.285405+00:00", 
            "author": "https://api.launchpad.net/1.0/~revin"
        }, 
        {
            "content": "I am seeing the same error on Ubuntu 14-04 Juno and ceph Friefly.\n\nMy understanding is that since I'm using ceph for nova, glance and cinder that I shouldn't have any timeout issues.\n\nHowever I ran into this issue while diagnosing another issue in our environment which is that spinning up instances from images takes on the order of minutes and is dependent on the size of the image.\n\nThis should not be happening since the instance ephemeral volumes should be cloned within ceph which takes less than a second.\n\nCreating a volume from an image and then booting from the instance does the same thing.\n\nI am also seeing the same behavior as Sam Stoelinga (sammiestoel)  reported above where if you make a volume snapshot of the volume (once it finished downloading) and boot from that then it does make a clone in ceph and it does boot rapidly.\nUnfortunately, that scenario isn't feasible in our environment since volumes and volume snapshots are not shareable between tenants.\n\nIn summary:\n\nBooting an instance from an image .\nBooting an instance from a volume created from an image via the --block-device source=image option to nova boot\n\nBoth make a full copy not a COW clone of the image.\n\nBooting an instance from a volume snapshot does operate correctly.\n\n\n\n\n\n \n", 
            "date_created": "2015-06-10 16:54:53.783602+00:00", 
            "author": "https://api.launchpad.net/1.0/~darbymorrison"
        }, 
        {
            "content": "There are 2 nova.conf options which can almost be used to fix this issue:\n\n1) [xenserver]\nblock_device_creation_timeout = 10 (IntOpt) Time to wait for a block device to be created\n\nShould work if you're using Xen. This is also true of the option to disable nova image caching.\n\n2) [DEFAULT]\ninstance_build_timeout = 0 (IntOpt) Amount of time in seconds an instance can be in BUILD before going into ERROR status.Set to 0 to disable.\n\nAlmost what i was looking for, but the instance build failed while in \"Mapping Block Device\" since it takes too long for the image to load onto a volume.\n\n", 
            "date_created": "2015-06-10 22:59:13.195248+00:00", 
            "author": "https://api.launchpad.net/1.0/~darbymorrison"
        }, 
        {
            "content": "I am having this issue currently using Netapp as backend on Ubuntu 14.04 LTS, version Kilo.  Have yet to find any answers but will update here if I do.", 
            "date_created": "2015-08-01 06:03:28.321833+00:00", 
            "author": "https://api.launchpad.net/1.0/~jwitko1"
        }, 
        {
            "content": "I am using redhat 7, and I am also seeing issue, same tests I conducted..", 
            "date_created": "2015-08-18 11:21:58.414454+00:00", 
            "author": "https://api.launchpad.net/1.0/~pzanwar"
        }, 
        {
            "content": "And I am using Juno distribution", 
            "date_created": "2015-08-18 11:22:49.643511+00:00", 
            "author": "https://api.launchpad.net/1.0/~pzanwar"
        }, 
        {
            "content": "My observation to this is, and I am using netapp cdot backend. Whenever cache image file doesn't exist for source image, netapp will try prepare that first and then add volume. If I change size of destination volume, cache image file will be redone, and it takes longer than nova timeout for accessing boot volume, and it errors out. Image cache file can be created manually, copying image file from Glace directory to volume directory, and name it like netapp expects cache-img-* ", 
            "date_created": "2015-08-18 11:44:14.123271+00:00", 
            "author": "https://api.launchpad.net/1.0/~pzanwar"
        }, 
        {
            "content": "I'm seeing this issue using Kilo on Ubuntu 14.04. For me the cause of this error was slightly different. I'm posting in case anyone else comes here with the same cause:\nhttp://paste.openstack.org/show/474506/\n\nI was creating an instance by passing an image ID and telling nova to create a volume from it. Before nova finished setting up the instance I was invalidating the user's keystone token. When nova made the API call to Cinder (using the user's token) for creating the volume. The token was no longer valid, causing my stack trace. Hopefully you folks were not making the same silly mistake I was :p\n", 
            "date_created": "2015-09-28 20:58:57.259930+00:00", 
            "author": "https://api.launchpad.net/1.0/~sergio-martins"
        }, 
        {
            "content": "We can also set the value of \"hw_disk_discard\"  to unmap in nova.conf. \n\nDetails can be found at:\nhttp://specs.openstack.org/openstack/nova-specs/specs/juno/implemented/libvirt-disk-discard-option.html ", 
            "date_created": "2016-06-29 01:43:39.007362+00:00", 
            "author": "https://api.launchpad.net/1.0/~double12gzh"
        }, 
        {
            "content": "\nThis is an automated cleanup. This bug report has been closed because it\nis older than 18 months and there is no open code change to fix this.\nAfter this time it is unlikely that the circumstances which lead to\nthe observed issue can be reproduced.\n\nIf you can reproduce the bug, please:\n* reopen the bug report (set to status \"New\")\n* AND add the detailed steps to reproduce the issue (if applicable)\n* AND leave a comment \"CONFIRMED FOR: <RELEASE_NAME>\"\n  Only still supported release names are valid (LIBERTY, MITAKA, OCATA, NEWTON).\n  Valid example: CONFIRMED FOR: LIBERTY\n", 
            "date_created": "2016-07-05 09:55:26.059452+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }
    ]
}