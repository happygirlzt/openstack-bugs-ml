{
    "status": "Won't Fix", 
    "last_updated": "2014-09-18 20:39:19.645362+00:00", 
    "description": "When using Nova baremetal the IPMI power commands are still proving to be too fast. I routinely get stack traces that look like this when deleting baremetal instances:\n\n2 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] ProcessExecutionError: Unexpected error while running command.\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] Command: ipmitool -I lanplus -H 10.1.8.23 -U ooo-dev -f /tmp/tmpMa8D4u power status\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] Exit code: 1\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] Stdout: ''\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] Stderr: 'Error in open session response message : insufficient resources for session\\n\\nError: Unable to establish IPMI v2 / RMCP+ session\\nUnable to get Chassis Power Status\\n'\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce]\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.931 5112 ERROR oslo.messaging.rpc.dispatcher [-] Exception during message handling: Unexpected error while running command.\n\n----\n\nThe root cause seems to be in the _power_off routine which repeatedly calls \"power status\" to determine if the instance has properly powered down after issuing the \"power off\". Once this fails simply resetting the instance state and retrying the delete again usually fixes the issue.\n\nOn the CLI the same commands always seem to work as well.\n\nIt does seem like our retry code is still too aggressive and we need to wait longer for each IPMI retry.", 
    "tags": [], 
    "importance": "High", 
    "heat": 12, 
    "link": "https://bugs.launchpad.net/nova/+bug/1291991", 
    "owner": "https://api.launchpad.net/1.0/~dan-prince", 
    "id": 1291991, 
    "index": 1430, 
    "created": "2014-03-13 13:20:43.763565+00:00", 
    "title": "ipmi cmds run too fast, cause BMC to run out of resources", 
    "comments": [
        {
            "content": "When using Nova baremetal the IPMI power commands are still proving to be too fast. I routinely get stack traces that look like this when deleting baremetal instances:\n\n2 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] ProcessExecutionError: Unexpected error while running command.\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] Command: ipmitool -I lanplus -H 10.1.8.23 -U ooo-dev -f /tmp/tmpMa8D4u power status\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] Exit code: 1\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] Stdout: ''\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce] Stderr: 'Error in open session response message : insufficient resources for session\\n\\nError: Unable to establish IPMI v2 / RMCP+ session\\nUnable to get Chassis Power Status\\n'\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.351 5112 TRACE nova.compute.manager [instance: 032250f7-3255-47f5-b866-35687dcd14ce]\nMar 12 10:39:33 undercloud-undercloud-7be7u2y6y5cz nova-compute[5112]: 2014-03-12 10:39:33.931 5112 ERROR oslo.messaging.rpc.dispatcher [-] Exception during message handling: Unexpected error while running command.\n\n----\n\nThe root cause seems to be in the _power_off routine which repeatedly calls \"power status\" to determine if the instance has properly powered down after issuing the \"power off\". Once this fails simply resetting the instance state and retrying the delete again usually fixes the issue.\n\nOn the CLI the same commands always seem to work as well.\n\nIt does seem like our retry code is still too aggressive and we need to wait longer for each IPMI retry.", 
            "date_created": "2014-03-13 13:20:43.763565+00:00", 
            "author": "https://api.launchpad.net/1.0/~dan-prince"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/80397", 
            "date_created": "2014-03-13 20:37:21.598256+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/80400", 
            "date_created": "2014-03-13 20:53:12.257102+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/82668", 
            "date_created": "2014-03-24 23:30:21.202275+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/82668\nCommitted: https://git.openstack.org/cgit/openstack/ironic/commit/?id=a6146ed69159bef7eec917f5efa71bc6dcbc7f7c\nSubmitter: Jenkins\nBranch:    master\n\ncommit a6146ed69159bef7eec917f5efa71bc6dcbc7f7c\nAuthor: Dan Prince <email address hidden>\nDate:   Thu Mar 13 16:52:19 2014 -0400\n\n    Run ipmi power status less aggressively\n    \n    Ironic runs IPMI 'power status' in a loop until the desired state is\n    reached. Running repeated IPMI commands in a tight loop (1 second sleep)\n    seems to occasionally cause 'insufficient resources' errors with some\n    hardware types.\n    \n    In this commit we update the IPMI retry timer to use a\n    DynamicLoopingCall which can wait longer for each retry of the power\n    status command. We increase the wait time exponentially\n    between each call, until the total time would exceed the max retry time\n    on the next iteration.\n    \n    This patch also removes the spurious initial 'power status' call which\n    preceeded the 'power on' or 'power off' call without any gap. Since\n    Ironic has a periodic task to sync the power state, it is safe to assume\n    that the hardware's current power state is already known and does not\n    need to be verified inside the set_power_state method.\n    \n    As part of this change we also increase the default IPMI retry_timeout\n    config to 60 seconds.\n    \n    Co-authored-by: Dan Prince <email address hidden>\n    \n    Change-Id: Ie0e29239592bb64c7a10ecedae299df2c5053359\n    Closes-bug: #1291991\n", 
            "date_created": "2014-03-25 22:18:42.641241+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "I attempted to apply the proposed patch by Dan Prince into the Icehouse codebase that still uses Nova Baremetal, and it did not solve the issue. I was still running into the issue when using DynamicLoopingCall, but only against certain DRAC firmware.\n\nDRAC 7 1.40.40 - Not affected\nDRAC 7 1.45.45 - Not affected\nDRAC 7 1.57.57 - Affected, even after applying patch\n\nI have attached a shell script that triggers the bug. This is an attempt to duplicate what happens with DynamicLoopingCall, although my understanding of DynamicLoopingCall may be incorrect (does it double the backoff time, or just increase it?) It is called with:\n$ ./power.sh <username> <password> <ipaddr> off\n\nI only ran into this bug when turning the hosts off, they were less sensitive when powering on. When powering off, this shell script (which introduces a 1 second longer delay each time) will trigger the bug about 2 out of 3 runs.\n\nMy concern is that we may not have fixed the issue by changing from FixedIntervalLoopingCall to DynamicLoopingCall in Ironic, if the bug is still triggered sometimes. Perhaps we need logic to accept the \"insufficient resources\" error as transient, and retry rather than error out.", 
            "date_created": "2014-09-18 20:39:17.520057+00:00", 
            "author": "https://api.launchpad.net/1.0/~dsneddon"
        }
    ]
}