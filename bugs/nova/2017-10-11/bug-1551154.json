{
    "status": "Expired", 
    "last_updated": "2017-09-24 04:17:39.095788+00:00", 
    "description": "Scenario:\n----------------\n1. Create a VM with SRIOV port --> the vNIC state should be UP\n2. On the VM host, shutdown the PF (i.e. ifconfig ens1f1 down) --> The vNIC state should be DOWN\n3. Create a snapshot of this suboptimal VM\n\nExpected behavior:\n--------------------------------\nSnapshot creation process begins, after a while the snapshot succeeds, VM should be up without the vNIC (if the PF is still down)\n\nActual behavior:\n---------------------------\nSnapshot creation process begins, after a while the snapshot fails and is deleted. The VM is up without the vNIC (since the PF is still down)\n\nAnalysis:\n---------------\nFrom nova-compute.log\n\n2016-02-29 07:04:05.205 34455 WARNING nova.virt.libvirt.driver [req-3f00299f-1c82-4bb4-9283-81dc1d11383d 6dc69ac7e48549e0a6f0577e870a096e 7e5da331cb6342fca3688ea4b4df01f4 - - -] Performing standard snap\nshot because direct snapshot failed: Image cd938ad4-6e0a-46f3-bc1c-d94644b3fef5 is unacceptable: direct_snapshot() is not implemented\n2016-02-29 07:07:43.834 34455 ERROR oslo_messaging.rpc.dispatcher [req-3f00299f-1c82-4bb4-9283-81dc1d11383d 6dc69ac7e48549e0a6f0577e870a096e 7e5da331cb6342fca3688ea4b4df01f4 - - -] Exception during mess\nage handling: internal error: Unable to configure VF 62 of PF 'ens1f1' because the PF is not online. Please change host network config to put the PF online.\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher Traceback (most recent call last):\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/oslo_messaging/rpc/dispatcher.py\", line 142, in _dispatch_and_reply\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     executor_callback))\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/oslo_messaging/rpc/dispatcher.py\", line 186, in _dispatch\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     executor_callback)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/oslo_messaging/rpc/dispatcher.py\", line 130, in _do_dispatch\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     result = func(ctxt, **new_args)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 6917, in snapshot_instance\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     return self.manager.snapshot_instance(ctxt, image_id, instance)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/exception.py\", line 88, in wrapped\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     payload)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/exception.py\", line 71, in wrapped\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     return f(self, context, *args, **kw)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 341, in decorated_function\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     LOG.warning(msg, e, instance_uuid=instance_uuid)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 312, in decorated_function\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 369, in decorated_function\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     kwargs['instance'], e, sys.exc_info())\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 357, in decorated_function\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 417, in decorated_function\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     instance=instance)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 407, in decorated_function\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     *args, **kwargs)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 3297, in snapshot_instance\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     task_states.IMAGE_SNAPSHOT)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 3327, in _snapshot_instance\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     update_task_state)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 1471, in snapshot\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     update_task_state)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 1507, in _generic_snapshot\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     instance)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 1487, in _snapshot_domain\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     self._attach_sriov_ports(context, instance, new_dom)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 3092, in _attach_sriov_ports\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     dom.attachDevice(cfg.to_xml())\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 183, in doit\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 141, in proxy_call\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     rv = execute(f, *args, **kwargs)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 122, in execute\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     six.reraise(c, e, tb)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 80, in tworker\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     rv = meth(*args, **kwargs)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 530, in attachDevice\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher     if ret == -1: raise libvirtError ('virDomainAttachDevice() failed', dom=self)\n2016-02-29 07:07:43.834 34455 TRACE oslo_messaging.rpc.dispatcher libvirtError: internal error: Unable to configure VF 62 of PF 'ens1f1' because the PF is not online. Please change host network config to put the PF online.\n\nAfter a short conversation in #openstack-nova the initial conclusion was that probably the snapshot process shouldn't fail.\n\nNOTE: This was observed in Kilo but it doesn't seem like the exception handling in the code changed until Mitaka.\n\nFurther analysis (trying to fix the issue locally):\n------------------------------------------------------------------------\nLooking at libvirt's code (virnetdev.c) it seems that there's no way to workaround this problem (attaching to an offline PF, though configuration of VLAN and MAC is possible):\n\nstatic int\nvirNetDevReplaceVfConfig(const char *pflinkdev, int vf,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0const virMacAddr *macaddress,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0int vlanid,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0const char *stateDir)\n{\n...\n\u00a0\u00a0\u00a0\u00a0/* Assure that PF is online prior to twiddling with the VF.  It\n\u00a0\u00a0\u00a0\u00a0\u00a0* *should* be, but if the PF isn't online the changes made to the\n\u00a0\u00a0\u00a0\u00a0\u00a0* VF via the PF won't take effect, yet there will be no error\n\u00a0\u00a0\u00a0\u00a0\u00a0* reported. In the case that it isn't online, fail and report the\n\u00a0\u00a0\u00a0\u00a0\u00a0* error, since setting an unconfigured interface online\n\u00a0\u00a0\u00a0\u00a0\u00a0* automatically turns on IPv6 autoconfig, which may not be what\n\u00a0\u00a0\u00a0\u00a0\u00a0* the admin expects, so we want them to explicitly enable the PF\n\u00a0\u00a0\u00a0\u00a0\u00a0* in the host system network config.\n\u00a0\u00a0\u00a0\u00a0\u00a0*/\n\u00a0\u00a0\u00a0\u00a0if (virNetDevGetOnline(pflinkdev, &pfIsOnline) < 0)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0goto cleanup;\n\u00a0\u00a0\u00a0\u00a0if (!pfIsOnline) {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0virReportError(VIR_ERR_INTERNAL_ERROR,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0_(\"Unable to configure VF %d of PF '%s' \"\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"because the PF is not online. Please \"\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"change host network config to put the \"\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"PF online.\"),\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0vf, pflinkdev);\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0goto cleanup;\n\u00a0\u00a0\u00a0\u00a0}\n...\n\n(from http://libvirt.org/git/?p=libvirt.git;a=blob;f=src/util/virnetdev.c)\n\nIntroducing the following change to libvirt.py (the \"Manually written part of python bindings for libvirt\"):\n--- /usr/lib64/python2.7/site-packages/libvirt.py\t2016-02-29 09:20:34.734195406 +0000\n+++ /usr/lib64/python2.7/site-packages/libvirt.py.patched\t2016-02-29 09:20:26.068155372 +0000\n@@ -527,7 +527,7 @@\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0into S4 state (also known as hibernation) unless you also modify the\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0persistent domain definition. \"\"\"\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ret = libvirtmod.virDomainAttachDevice(self._o, xml)\n-        if ret == -1: raise libvirtError ('virDomainAttachDevice() failed', dom=self)\n+        #if ret == -1: raise libvirtError ('virDomainAttachDevice() failed', dom=self)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return ret\n\n\u00a0\u00a0\u00a0\u00a0\u00a0def attachDeviceFlags(self, xml, flags=0):\n@@ -1056,7 +1056,7 @@\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0If the VIR_DOMAIN_START_FORCE_BOOT flag is set, then any managed save\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0file for this domain is discarded, and the domain boots from scratch. \"\"\"\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ret = libvirtmod.virDomainCreateWithFlags(self._o, flags)\n-        if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n+        #if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return ret\n\nSolved the issue and the behavior returned to be as expected.\n\nThe fix should be in the snapshot failure code (and not in the libvirt.py of course...)", 
    "tags": [
        "compute", 
        "libvirt", 
        "pci", 
        "snapshot", 
        "sriov"
    ], 
    "importance": "Medium", 
    "heat": 12, 
    "link": "https://bugs.launchpad.net/nova/+bug/1551154", 
    "owner": "None", 
    "id": 1551154, 
    "index": 4461, 
    "created": "2016-02-29 10:09:04.512470+00:00", 
    "title": "Snapshot of VM with SRIOV port fails if host PF is down", 
    "comments": [
        {
            "content": "Scenario:\n----------------\n1. Create a VM with SRIOV port --> the vNIC state should be UP\n2. On the VM host, shutdown the PF (i.e. ifconfig ens1f1 down) --> The vNIC state should be DOWN\n3. Create a snapshot of this suboptimal VM\n\nExpected behavior:\n--------------------------------\nSnapshot creation process begins, after a while the snapshot succeeds, VM should be up without the vNIC (if the PF is still down)\n\nActual behavior:\n---------------------------\nSnapshot creation process begins, after a while the snapshot fails and is deleted. The VM is up without the vNIC (since the PF is still down)\n\nAnalysis:\n---------------\nFrom nova-compute.log\n\n2016-02-29 07:21:51.578 34455 ERROR nova.compute.manager [req-00a47655-f6c8-4e53-913f-bef0c61100d0 6dc69ac7e48549e0a6f0577e870a096e 7e5da331cb6342fca3688ea4b4df01f4 - - -] [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b] Instance failed to spawn\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b] Traceback (most recent call last):\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 2480, in _build_resource\ns\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     yield resources\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 2352, in _build_and_run_\ninstance\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     block_device_info=block_device_info)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 2463, in spawn\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     block_device_info=block_device_info)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 4588, in _create_domain_and_network\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     power_on=power_on)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 4519, in _create_domain\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     LOG.error(err)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     six.reraise(self.type_, self.value, self.tb)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 4509, in _create_domain\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     domain.createWithFlags(launch_flags)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 183, in doit\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 141, in proxy_call\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     rv = execute(f, *args, **kwargs)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 122, in execute\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     six.reraise(c, e, tb)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 80, in tworker\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     rv = meth(*args, **kwargs)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 1059, in createWithFlags\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n2016-02-29 07:21:51.578 34455 TRACE nova.compute.manager [instance: 14a17ed9-8cbd-44f0-9cf6-a93b71de474b] libvirtError: internal error: Unable to configure VF 62 of PF 'ens1f1' because the PF is not online. Please change host network config to put the PF online.\n\n\nAfter a short conversation in #openstack-nova the initial conclusion was that probably the snapshot process shouldn't fail.\n\nFurther analysis (trying to fix the issue locally):\n------------------------------------------------------------------------\nLooking at libvirt's code (virnetdev.c) it seems that there's no way to workaround this problem (attaching to an offline PF, though configuration of VLAN and MAC is possible):\n\nstatic int\nvirNetDevReplaceVfConfig(const char *pflinkdev, int vf,\n                         const virMacAddr *macaddress,\n                         int vlanid,\n                         const char *stateDir)\n{\n...\n    /* Assure that PF is online prior to twiddling with the VF.  It\n     * *should* be, but if the PF isn't online the changes made to the\n     * VF via the PF won't take effect, yet there will be no error\n     * reported. In the case that it isn't online, fail and report the\n     * error, since setting an unconfigured interface online\n     * automatically turns on IPv6 autoconfig, which may not be what\n     * the admin expects, so we want them to explicitly enable the PF\n     * in the host system network config.\n     */\n    if (virNetDevGetOnline(pflinkdev, &pfIsOnline) < 0)\n       goto cleanup;\n    if (!pfIsOnline) {\n        virReportError(VIR_ERR_INTERNAL_ERROR,\n                       _(\"Unable to configure VF %d of PF '%s' \"\n                         \"because the PF is not online. Please \"\n                         \"change host network config to put the \"\n                         \"PF online.\"),\n                       vf, pflinkdev);\n        goto cleanup;\n    }\n...\n\n(from http://libvirt.org/git/?p=libvirt.git;a=blob;f=src/util/virnetdev.c)\n\nIntroducing the following change to libvirt.py (the \"Manually written part of python bindings for libvirt\"):\n--- /usr/lib64/python2.7/site-packages/libvirt.py\t2016-02-29 09:20:34.734195406 +0000\n+++ /usr/lib64/python2.7/site-packages/libvirt.py.patched\t2016-02-29 09:20:26.068155372 +0000\n@@ -527,7 +527,7 @@\n         into S4 state (also known as hibernation) unless you also modify the\n         persistent domain definition. \"\"\"\n         ret = libvirtmod.virDomainAttachDevice(self._o, xml)\n-        if ret == -1: raise libvirtError ('virDomainAttachDevice() failed', dom=self)\n+        #if ret == -1: raise libvirtError ('virDomainAttachDevice() failed', dom=self)\n         return ret\n\n     def attachDeviceFlags(self, xml, flags=0):\n@@ -1056,7 +1056,7 @@\n         If the VIR_DOMAIN_START_FORCE_BOOT flag is set, then any managed save\n         file for this domain is discarded, and the domain boots from scratch. \"\"\"\n         ret = libvirtmod.virDomainCreateWithFlags(self._o, flags)\n-        if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n+        #if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n         return ret\n\n\nSolved the issue and the behavior returned to be as expected.\n\nThe fix should be in the snapshot failure code (and not in the libvirt.py of course...)", 
            "date_created": "2016-02-29 10:09:04.512470+00:00", 
            "author": "https://api.launchpad.net/1.0/~david-edery"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/287515", 
            "date_created": "2016-03-02 23:47:47.924831+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Michael Still (<email address hidden>) on branch: master\nReview: https://review.openstack.org/287515\nReason: This patch has been sitting unchanged for more than 12 weeks. I am therefore going to abandon it to keep the nova review queue sane. Please feel free to restore the change if you're still working on it.", 
            "date_created": "2016-11-30 02:44:48.657543+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "There are no currently open reviews on this bug, changing the status back to the previous state and unassigning. If there are active reviews related to this bug, please include links in comments. ", 
            "date_created": "2017-06-27 19:25:18.225481+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "This is a pretty old bug, can we get confirmation that it's still an issue?", 
            "date_created": "2017-07-25 14:17:58.476678+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "[Expired for OpenStack Compute (nova) because there has been no activity for 60 days.]", 
            "date_created": "2017-09-24 04:17:36.631502+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ]
}