{
    "status": "Fix Released", 
    "last_updated": "2015-04-30 09:10:56.820712+00:00", 
    "description": "We have deployed OpenStack Icehouse with Legacy Networking setup and we are building our instances on shared storage (NFS). We want to protect VMs when a host (compute node) fails. When we use Nova Evacuate API with \"--on-shared-storage\" option two issues happens:\n1- Sometimes the evacuated VM will come up on new host but it will be re-built from the base image. \n2- Sometimes the instance will not come up at all. For this case if we use \"nova reboot --hard <VM>\" the VM will come up on the new host.", 
    "tags": [
        "compute"
    ], 
    "importance": "High", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1362244", 
    "owner": "https://api.launchpad.net/1.0/~jichenjc", 
    "id": 1362244, 
    "index": 1587, 
    "created": "2014-08-27 16:23:20.976638+00:00", 
    "title": "Issues with Nova Evacuate API", 
    "comments": [
        {
            "content": "We have deployed OpenStack Icehouse with Legacy Networking setup and we are building our instances on shared storage (NFS). We want to protect VMs when a host (compute node) fails. When we use Nova Evacuate API with \"--on-shared-storage\" option two issues happens:\n1- Sometimes the evacuated VM will come up on new host but it will be re-built from the base image. \n2- Sometimes the instance will not come up at all. For this case if we use \"nova reboot --hard <VM>\" the VM will come up on the new host.", 
            "date_created": "2014-08-27 16:23:20.976638+00:00", 
            "author": "https://api.launchpad.net/1.0/~mhormati"
        }, 
        {
            "content": "Hi, thanks for your bug report. We need additional information to help diagnose the issue.\r\n\r\nOn 1, what is the behavior you expect when the VM comes up on the new host, other than being rebuilt from the base image?\r\n\r\nOn 2, can you check in the nova-compute.log on the origin host and the new host to look for ERROR messages related to the migrated VM? There should be messages there that indicate what went wrong so we can pinpoint the problem.", 
            "date_created": "2014-09-04 19:52:48.196721+00:00", 
            "author": "https://api.launchpad.net/1.0/~melwitt"
        }, 
        {
            "content": "We are seeing this issue as well.  However, we always see the original disk on shared storage being deleted and recreated.\n\nI found a section in the nova\\compute\\manager.py file\nwhere it looks like the \"recreate\" flag is not being passed down to the driver level.\nIf I add the recreate variable to the dictionary, the evacuate always completes successfully\nand preserves the user data.  \n\n\n~2539\n           kwargs = dict(\n                context=context,\n                instance=instance,\n                image_meta=image_meta,\n                injected_files=files,\n                admin_password=new_pass,\n                bdms=bdms,\n                detach_block_devices=detach_block_devices,\n                attach_block_devices=self._prep_block_device,\n                block_device_info=block_device_info,\n                network_info=network_info,\n                preserve_ephemeral=preserve_ephemeral)\n            try:\n                self.driver.rebuild(**kwargs)\n            except NotImplementedError:\n                # NOTE(rpodolyaka): driver doesn't provide specialized version\n                # of rebuild, fall back to the default implementation\n                self._rebuild_default_impl(**kwargs)\n            instance.power_state = self._get_power_state(context, instance)\n    ", 
            "date_created": "2014-09-09 22:08:27.230462+00:00", 
            "author": "https://api.launchpad.net/1.0/~aaron-smith"
        }, 
        {
            "content": "@Aaron Thanks for confirming this bug and sharing your finding!", 
            "date_created": "2014-09-10 04:38:10.684406+00:00", 
            "author": "https://api.launchpad.net/1.0/~melwitt"
        }, 
        {
            "content": "I submitted a patch for this bug and add recreate flag\n\nhowever, I am not sure whether it can fix the problem pointed by original bug description \nbecause the 'recreate' flag not passed lead to the instance will always be destroyed (recreate always False)\nnot sure this will lead to problem or not , I don't have NFS env so I only use Partial bug not Close bug here\n\nif not recreate:\n            self.driver.destroy(context, instance, network_info,\n                                block_device_info=block_device_info)", 
            "date_created": "2014-09-23 14:35:49.095135+00:00", 
            "author": "https://api.launchpad.net/1.0/~jichenjc"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/123454", 
            "date_created": "2014-09-23 14:39:42.448812+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Actually the rebuild_instance in compute manager check the shared storage https://github.com/openstack/nova/blob/454760d46cbda1f8677a3d8caa5bb47e43f6d9cf/nova/compute/manager.py#L2718\n\nbut it just print a log, didn't use that variable doing anything.", 
            "date_created": "2014-09-24 07:39:10.854360+00:00", 
            "author": "https://api.launchpad.net/1.0/~xuhj"
        }, 
        {
            "content": "commit 91d3272b975572d9866b7d959547e438142dc4fb fixed this problem \r\nso marked Fix committed here", 
            "date_created": "2014-11-14 08:45:01.051572+00:00", 
            "author": "https://api.launchpad.net/1.0/~jichenjc"
        }, 
        {
            "content": "Change abandoned by jichenjc (<email address hidden>) on branch: master\nReview: https://review.openstack.org/123454\nReason: fix already committed", 
            "date_created": "2014-11-14 08:45:43.675003+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}