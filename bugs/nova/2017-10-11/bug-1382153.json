{
    "status": "Expired", 
    "last_updated": "2016-07-05 09:53:49.599864+00:00", 
    "description": "All nova conductor worker process attempts to join to the service on the same host. It does not seams required.\nIf you have 48 conductor worker on a node, it means it tries to maintain the membership with all 48 worker.\n\nSince the workers are started almost at the same time, it means 48 burst update attempt close to each other.\n\nThe situation even worse with zk driver,  it does not works with multiple workers >1 , because all worker thread inherited the same zookeeper connection from it's parent.  (4096 connection allowed from the same ip on my zk servers)\n(The api service does not do status report, so it can work with multiple workers)\n\nThe  \"lsof -P |grep cond | grep 2181\"  indicates all conductor worker uses the same tcp source port  --> the same socket inherited.", 
    "tags": [], 
    "importance": "Undecided", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1382153", 
    "owner": "None", 
    "id": 1382153, 
    "index": 5221, 
    "created": "2014-10-16 18:03:14.618433+00:00", 
    "title": "n-cond shoul not joining to servicegroup an all worker", 
    "comments": [
        {
            "content": "All nova conductor worker process attempts to join to the service on the same host. It does not seams required.\nIf you have 48 conductor worker on a node, it means it tries to maintain the membership with all 48 worker.\n\nSince the workers are started almost at the same time, it means 48 burst update attempt close to each other.\n\nThe situation even worse with zk driver,  it does not works with multiple workers >1 , because all worker thread inherited the same zookeeper connection from it's parent.  (4096 connection allowed from the same ip on my zk servers)\n(The api service does not do status report, so it can work with multiple workers)\n\nThe  \"lsof -P |grep cond | grep 2181\"  indicates all conductor worker uses the same tcp source port  --> the same socket inherited.", 
            "date_created": "2014-10-16 18:03:14.618433+00:00", 
            "author": "https://api.launchpad.net/1.0/~afazekas"
        }, 
        {
            "content": "Looks like this is in nova/service.py and not just the conductor.", 
            "date_created": "2014-10-17 22:00:51.407486+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "I can confirm, that I have the similar problem but with more significant consequences.\nTested on ubuntu 14.04 with zookeeper 3.4.5, trying to run nova-conductor (with 2 workers) ends that any of them isn't registered in zookeeper (and namespace isn't created).\nI reported another bug because I believe it's more important that just multiple registration and is only related to zk driver and  effects are worse than overuse of resources.\n\nLink to bug:\n\nhttps://bugs.launchpad.net/nova/+bug/1389782\n", 
            "date_created": "2014-11-05 17:00:59.162835+00:00", 
            "author": "https://api.launchpad.net/1.0/~pawel-palucki"
        }, 
        {
            "content": "I have found another bug related to this one. When zookeeper driver is used (and we mitigate problem from previous comment) each process tries to register itself multiple times but without success: \n\nhttps://bugs.launchpad.net/nova/+bug/1390511", 
            "date_created": "2014-11-07 16:00:22.213958+00:00", 
            "author": "https://api.launchpad.net/1.0/~pawel-palucki"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/133479", 
            "date_created": "2014-11-10 13:48:20.702496+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/133500", 
            "date_created": "2014-11-10 15:24:09.773583+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/133500\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=e61bf70146c47a99394a143c598ebd73409eca47\nSubmitter: Jenkins\nBranch:    master\n\ncommit e61bf70146c47a99394a143c598ebd73409eca47\nAuthor: Pawel Palucki <email address hidden>\nDate:   Fri Nov 7 14:41:49 2014 +0100\n\n    Fix conductor processes race trying to join servicegroup (zk driver)\n    \n    When conductor is run in multi process manner and zk (zookeeper) driver\n    is used as servicegroup driver, there is a problem because each process\n    tries to manage own Membership object to the same zookeeper path.\n    \n    This ends with raising exceptions:\n    \n    RuntimeError: Duplicated membership name /servicegroups/conductor/MEMBER_ID\n    \n    Zookeeper driver uses Membership (evzookeeper) class with path related\n    to service type and AFAIK it isn't correct that many process will be\n    responsible for the same ephemeral node. From my research it is not\n    supported but evzookeeper (Membership class) - so we can ignore the\n    exception or give each process his own node.\n    \n    If we ignore exception (silent it) and when first registered process dies\n    and the ephemeral node disappears, another process will create it. It will\n    work but hides the information about overall structure of services and\n    also causes that each process endlessly will be trying to create a node\n    (sending invalid create node requests to zookeeper). IMO is not a clean solution.\n    \n    So there is another solution that each process has its own node. This\n    fix does that.\n    \n    The best unique identifier for process is pid, so the chosen solution,\n    reorganizes the structure of zookeeper tree by adding one more level\n    with process ids.\n    \n    The zookeeper tree before looks like this:\n    \n    /servicesgroups/SERVICE/MEMBER\n    \n    and after path will look like this:\n    \n    /servicegroups/SERVICE/MEMBER/PID\n    eg.\n    /servicegroups/conductor/foo/12345\n    \n    This solution also assumes, that servicegroup driver will not check existence of\n    member node, but existence of subnodes (pids) - which corresponds to existence\n    of processes of given service.\n    \n    In general we will have more granular information about whole system -\n    for exmaple we can check number of processes of given service on each node.\n    \n    To answer the question: is service on given node works, we have to check\n    number of ephemeral \"pids\" nodes in get_all() method.\n    \n    Closes-bug: #1390511\n    \n    Related-bug: #1389782\n    Related-bug: #1382153\n    \n    Change-Id: I478845b6921dcfb9e9af5a45283a8569051b4f4f\n", 
            "date_created": "2015-01-29 21:49:28.495550+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/133479\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=afe86b6f29033a472cab1b52dd0724bb3c6dfb82\nSubmitter: Jenkins\nBranch:    master\n\ncommit afe86b6f29033a472cab1b52dd0724bb3c6dfb82\nAuthor: Michal Dulko <email address hidden>\nDate:   Wed Feb 4 12:44:12 2015 +0100\n\n    Fix conductor servicegroup joining when zk driver is used\n    \n    When conductor is run as multiprocess (default for multi core system) and\n    zk (zookeeper) is used as servicegroup_driver then conductor is unable to join\n    servicegroup because of shared zookeeper handle (and probably socket)\n    between parent and children processes.\n    \n    It's found the problem lies in zookeeper c library implementation.\n    Proof can be seen in related bug #1389782.\n    \n    This fix follows the idea used by memcache and db driver that\n    servicegroup_api._driver object is used in lazy manner.\n    This means that like connection to memcache and session to database,\n    zookeeper handle (zk session in driver) isn't created until required by\n    worker (child process).\n    \n    Additional note: before fix, during Service object creation the\n    prefix in zookeeper was created. That was the probably reason the session was\n    established so early. In my opinion the eagerness of this is not necessary\n    and namespace can be created by child process as well.\n    \n    Closes-Bug: #1389782\n    \n    Related-bug: #1390511\n    Related-bug: #1382153\n    \n    Change-Id: I9b386ef1f9268d19d04879ec89e5684170f3862a\n", 
            "date_created": "2015-02-06 18:37:50.772035+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "\nThis is an automated cleanup. This bug report has been closed because it\nis older than 18 months and there is no open code change to fix this.\nAfter this time it is unlikely that the circumstances which lead to\nthe observed issue can be reproduced.\n\nIf you can reproduce the bug, please:\n* reopen the bug report (set to status \"New\")\n* AND add the detailed steps to reproduce the issue (if applicable)\n* AND leave a comment \"CONFIRMED FOR: <RELEASE_NAME>\"\n  Only still supported release names are valid (LIBERTY, MITAKA, OCATA, NEWTON).\n  Valid example: CONFIRMED FOR: LIBERTY\n", 
            "date_created": "2016-07-05 09:53:49.165350+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }
    ]
}