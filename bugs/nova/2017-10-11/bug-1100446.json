{
    "status": "Fix Released", 
    "last_updated": "2013-04-11 19:54:20.152044+00:00", 
    "description": "A  VM transits  from BUILD to ACTIVE status can take 26 second with libvirt/qemu.\n\nThis transition is critical in the gate system's performance too.\n\nhttps://github.com/openstack/nova/blob/c215b5ec79516111456dfc2a63fa0facf5946ab0/nova/virt/libvirt/driver.py#L365\nThis call should replaced to something cheaper,  Like LibVirt Version (or Hostname query .)\nOr by an something even cheaper solution.\n\nNote:\nThe one minute periodical status update also leads to this expensive call. I do not think the architecture changes frequently.\nConsider query it only on service start-up.\n\nIf you just use the getCapabilies only at startup, you can reduce the ~26 second to ~13 second!\n\nIf your qemu supports multiple architecture it is much slower, and by fixing this issue,  you can have even greater performance.\n\nYou can see the executions done by the libvirtd by this.  \nstrace -Ff -p <libvirtd_pid> -e execve\n\nYou will see several hundred/ or thousands(multi arch) of similar execve lines: \n\n29010 +++ exited with 0 +++\n5382  --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=29010, si_status=0, si_utime=1, si_stime=0} ---\n29011 execve(\"/usr/bin/qemu-system-x86_64\", [\"/usr/bin/qemu-system-x86_64\", \"-device\", \"?\", \"-device\", \"pci-assign,?\", \"-device\", \"virtio-blk-pci,?\", \"-device\", \"virtio-net-pci,?\", \"-device\", \"scsi-disk,?\"], [/* 2 vars */]) = 0\n29011 +++ exited with 0 +++\n5382  --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=29011, si_status=0, si_utime=1, si_stime=0} ---\n29012 execve(\"/usr/bin/qemu-system-x86_64\", [\"/usr/bin/qemu-system-x86_64\", \"-cpu\", \"?\"], [/* 2 vars */]) = 0\n29012 +++ exited with 0 +++\n5382  --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=29012, si_status=0, si_utime=1, si_stime=0} ---\n29013 execve(\"/usr/bin/qemu-system-x86_64\", [\"/usr/bin/qemu-system-x86_64\", \"-help\"], [/* 2 vars */]) = 0\n29013 +++ exited with 0 +++\n5382  --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=29013, si_status=0, si_utime=1, si_stime=0} ---\n29014 execve(\"/usr/bin/qemu-system-x86_64\", [\"/usr/bin/qemu-system-x86_64\", \"-device\", \"?\", \"-device\", \"pci-assign,?\", \"-device\", \"virtio-blk-pci,?\", \"-device\", \"virtio-net-pci,?\", \"-device\", \"scsi-disk,?\"], [/* 2 vars */]) = 0\n29014 +++ exited with 0 +++\n\n(you can add a -ttt argument for time measurement )", 
    "tags": [
        "folsom-backport-potential"
    ], 
    "importance": "High", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1100446", 
    "owner": "https://api.launchpad.net/1.0/~vishvananda", 
    "id": 1100446, 
    "index": 929, 
    "created": "2013-01-16 20:14:31.460956+00:00", 
    "title": "libvirt driver connection validation causes unnecessary process execution with libvirt/qemu", 
    "comments": [
        {
            "content": "A  VM transits  from BUILD to ACTIVE status can take 26 second with libvirt/qemu.\n\nThis transition is critical in the gate system's performance too.\n\nhttps://github.com/openstack/nova/blob/c215b5ec79516111456dfc2a63fa0facf5946ab0/nova/virt/libvirt/driver.py#L365\nThis call should replaced to something cheaper,  Like LibVirt Version (or Hostname query .)\nOr by an something even cheaper solution.\n\nNote:\nThe one minute periodical status update also leads to this expensive call. I do not think the architecture changes frequently.\nConsider query it only on service start-up.\n\nIf you just use the getCapabilies only at startup, you can reduce the ~26 second to ~13 second!\n\nIf your qemu supports multiple architecture it is much slower, and by fixing this issue,  you can have even greater performance.\n\nYou can see the executions done by the libvirtd by this.  \nstrace -Ff -p <libvirtd_pid> -e execve\n\nYou will see several hundred/ or thousands(multi arch) of similar execve lines: \n\n29010 +++ exited with 0 +++\n5382  --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=29010, si_status=0, si_utime=1, si_stime=0} ---\n29011 execve(\"/usr/bin/qemu-system-x86_64\", [\"/usr/bin/qemu-system-x86_64\", \"-device\", \"?\", \"-device\", \"pci-assign,?\", \"-device\", \"virtio-blk-pci,?\", \"-device\", \"virtio-net-pci,?\", \"-device\", \"scsi-disk,?\"], [/* 2 vars */]) = 0\n29011 +++ exited with 0 +++\n5382  --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=29011, si_status=0, si_utime=1, si_stime=0} ---\n29012 execve(\"/usr/bin/qemu-system-x86_64\", [\"/usr/bin/qemu-system-x86_64\", \"-cpu\", \"?\"], [/* 2 vars */]) = 0\n29012 +++ exited with 0 +++\n5382  --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=29012, si_status=0, si_utime=1, si_stime=0} ---\n29013 execve(\"/usr/bin/qemu-system-x86_64\", [\"/usr/bin/qemu-system-x86_64\", \"-help\"], [/* 2 vars */]) = 0\n29013 +++ exited with 0 +++\n5382  --- SIGCHLD {si_signo=SIGCHLD, si_code=CLD_EXITED, si_pid=29013, si_status=0, si_utime=1, si_stime=0} ---\n29014 execve(\"/usr/bin/qemu-system-x86_64\", [\"/usr/bin/qemu-system-x86_64\", \"-device\", \"?\", \"-device\", \"pci-assign,?\", \"-device\", \"virtio-blk-pci,?\", \"-device\", \"virtio-net-pci,?\", \"-device\", \"scsi-disk,?\"], [/* 2 vars */]) = 0\n29014 +++ exited with 0 +++\n\n(you can add a -ttt argument for time measurement )", 
            "date_created": "2013-01-16 20:14:31.460956+00:00", 
            "author": "https://api.launchpad.net/1.0/~afazekas"
        }, 
        {
            "content": "This seems like a huge performance win.", 
            "date_created": "2013-01-17 00:31:06.673886+00:00", 
            "author": "https://api.launchpad.net/1.0/~vishvananda"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/19880", 
            "date_created": "2013-01-17 00:58:21.301762+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "What version of libvirt are you using which exhibits this behaviour ?  Libvirt will cache the results of querying QEMU so repeated calls to getCapabilities should not cause any problems, unless you have a fairly old libvirt.", 
            "date_created": "2013-01-17 09:24:03.100086+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "Known affected libvirt versions are:  0.9.8 and 0.9.11.8.\n\nProbably the 0.10.2 is not affected (it tested with kvm , not with the soft emu).\n\ngetCapabilities transfers more data than the LibVersion query anyway, so the validation should be changed anyway.\n\ngetCapabilities probably  does not have significant/measurable performance impact in the periodic status updates.", 
            "date_created": "2013-01-17 10:32:10.727049+00:00", 
            "author": "https://api.launchpad.net/1.0/~afazekas"
        }, 
        {
            "content": "Also what version of QEMU / KVM are involved & what emulators are installed", 
            "date_created": "2013-01-17 11:02:58.962803+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "Using systemtap I counted & timed the libvirt API calls that Nova is making. On Fedora 18 with qemu 1.2.0 and libvirt 1.0.0, I get the following (nb times are cumulative execution time for all counted API calls, in milliseconds)\n\nCurrent code, during startup\n                                                                                                         \nauth_list:66 count=2 time=2                                                                              \nauth_polkit:70 count=2 time=33                                                                           \nopen:1 count=2 time=14                                                                                   \nget_lib_version:157 count=1 time=1                                                                       \nget_capabilities:7 count=57 time=393                                                                     \nnum_of_domains:51 count=7 time=8                                                                         \nnum_of_defined_domains:25 count=2 time=2                                                                 \ndomain_lookup_by_name:23 count=1 time=0                                                                  \nnode_get_info:6 count=15 time=25                                                                         \nget_type:3 count=2 time=2                                                                                \nget_version:4 count=5 time=5                                                                             \nget_hostname:59 count=5 time=5       \n\nClearly there are far too many calls to getCapabilities here, but it is still only 400ms total time on my machine\n\nJust changing getCapablities to getLibVersion in the test connection code changes the results to look like\n\nauth_list:66 count=2 time=2                                                                              \nauth_polkit:70 count=2 time=29                                                                           \nopen:1 count=2 time=13                                                                                   \nget_lib_version:157 count=49 time=59                                                                     \nnum_of_domains:51 count=7 time=8                                                                         \nnum_of_defined_domains:25 count=2 time=2                                                                 \ndomain_lookup_by_name:23 count=1 time=1                                                                  \nnode_get_info:6 count=15 time=26                                                                         \nget_capabilities:7 count=9 time=64                                                                       \nget_type:3 count=2 time=2                                                                                \nget_version:4 count=5 time=6                                                                             \nget_hostname:59 count=5 time=6                                                                           \n\nSo as expected, there are far fewer calls to getCapabilities now, and correspondingly large number to getLibVersion(). Approx 300ms has been removed.\n\nLooking at the periodic task, the current code results in\n\nget_capabilities:7 count=22 time=126                                                                     \nnode_get_info:6 count=6 time=8                                                                           \nnum_of_domains:51 count=3 time=3                                                                         \nget_version:4 count=2 time=2                                                                             \nget_hostname:59 count=2 time=2                                                                           \nnum_of_defined_domains:25 count=1 time=1                                                                 \n                                                         \n\nwhile the change to getLibVersion results in\n\nget_lib_version:157 count=19 time=20                                                                     \nnode_get_info:6 count=6 time=8                                                                           \nnum_of_domains:51 count=3 time=3                                                                         \nget_capabilities:7 count=3 time=17                                                                       \nget_version:4 count=2 time=2                                                                             \nget_hostname:59 count=2 time=2                                                                           \nnum_of_defined_domains:25 count=1 time=1                                                                 \n\n", 
            "date_created": "2013-01-17 11:08:02.800026+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "I'm bumping up the priority of this one. The devstack on qemu in our CI environment would get dramatically faster with this change. That's Ubuntu 12.04 using qemu (no kvm acceleration, as it's running in kvm or xen guests).\n\nIt was a very good find by Attila, and something I'd like to see us get in soon.", 
            "date_created": "2013-01-17 12:44:45.537203+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/19880\nCommitted: http://github.com/openstack/nova/commit/ec3d7e4cb882eff42fa8f1e5f8f52723fb909b0e\nSubmitter: Jenkins\nBranch:    master\n\ncommit ec3d7e4cb882eff42fa8f1e5f8f52723fb909b0e\nAuthor: Vishvananda Ishaya <email address hidden>\nDate:   Wed Jan 16 16:50:47 2013 -0800\n\n    libvirt: Optimize test_connection and capabilities\n    \n    The getCapabilities call can be very slow so it is not a good choice\n    for testing the libvirt connection. This patch switches to\n    getLibVersion and also caches the result of getCapabilities so it\n    doesn't need to be requested every time. Note that this means that\n    nova-compute will need to be restarted if the capaabilities of the\n    host changes. This is an acceptable risk because capabilities\n    changes should be very rare and nova-compute should be restarted\n    if libvirt is restarted or reinstalled.\n    \n    This simple change lowers boot time in my devstack install from\n    22 seconds down to 8 seconds!\n    \n    Fixes bug 1100446\n    \n    Change-Id: I1b5072a906b19c6130957cf255e8d35b20990828\n", 
            "date_created": "2013-01-17 18:49:04.676262+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/folsom\nReview: https://review.openstack.org/23304", 
            "date_created": "2013-03-01 17:24:39.030095+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/23304\nCommitted: http://github.com/openstack/nova/commit/f8c5492bef9e6057f4bd3cdc0b94e5bff4d7e5d8\nSubmitter: Jenkins\nBranch:    stable/folsom\n\ncommit f8c5492bef9e6057f4bd3cdc0b94e5bff4d7e5d8\nAuthor: Vishvananda Ishaya <email address hidden>\nDate:   Wed Jan 16 16:50:47 2013 -0800\n\n    libvirt: Optimize test_connection and capabilities\n    \n    The getCapabilities call can be very slow so it is not a good choice\n    for testing the libvirt connection. This patch switches to\n    getLibVersion and also caches the result of getCapabilities so it\n    doesn't need to be requested every time. Note that this means that\n    nova-compute will need to be restarted if the capaabilities of the\n    host changes. This is an acceptable risk because capabilities\n    changes should be very rare and nova-compute should be restarted\n    if libvirt is restarted or reinstalled.\n    \n    This simple change lowers boot time in my devstack install from\n    22 seconds down to 8 seconds!\n    \n    Fixes bug 1100446\n    (cherry picked from commit ec3d7e4cb882eff42fa8f1e5f8f52723fb909b0e)\n    \n    Conflicts:\n    \tnova/virt/libvirt/driver.py\n    \n    Change-Id: I3adbb48a2859a54ed93503f26de684acbd157841\n", 
            "date_created": "2013-03-26 02:20:48.507675+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}