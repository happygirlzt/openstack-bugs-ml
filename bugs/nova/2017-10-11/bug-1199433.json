{
    "status": "Fix Released", 
    "last_updated": "2017-02-21 03:13:51.072416+00:00", 
    "description": "Using devstack with and the 'VIRT_DRIVER=fake' option,\n\n\"nova boot --flavor=m1.tiny --image=c483232b-398a-4d7f-8a34-fabeb25aa3c1 --num-instances 50 test\" causes all instances to fail but\n\n\"nova boot --flavor=m1.tiny --image=c483232b-398a-4d7f-8a34-fabeb25aa3c1  justone\" works\n\nrelevant stack traces:\n\nhttp://paste.openstack.org/show/39824/", 
    "tags": [
        "network"
    ], 
    "importance": "High", 
    "heat": 20, 
    "link": "https://bugs.launchpad.net/nova/+bug/1199433", 
    "owner": "https://api.launchpad.net/1.0/~vishvananda", 
    "id": 1199433, 
    "index": 1153, 
    "created": "2013-07-09 16:15:03.174379+00:00", 
    "title": "nova boot --num-instances=50 times out ", 
    "comments": [
        {
            "content": "\nUsing devstack with and the 'VIRT_DRIVER=fake' option, \n\n\"nova boot --flavor=m1.tiny --image=c483232b-398a-4d7f-8a34-fabeb25aa3c1 --num-instances 50 test\" causes all instances to fail but \n\n\"nova boot --flavor=m1.tiny --image=c483232b-398a-4d7f-8a34-fabeb25aa3c1  justone\" works\n\nrelevant stack traces:\n\nhttp://paste.openstack.org/show/39824/", 
            "date_created": "2013-07-09 16:15:03.174379+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "The main reason in wrong configuration. You should overwrite rpc_response_timeout option in nova.conf. By default it is equal to 60. But if you get Timeout error in rpc code you should increase this value. rpc_response_timeout=180 should resolve this trouble.", 
            "date_created": "2013-07-15 11:58:33.999064+00:00", 
            "author": "https://api.launchpad.net/1.0/~sshturm"
        }, 
        {
            "content": "Shturm,  the slow RPC is a sign of an underlying issue.   And if we think RPC should be set higher then the default should be higher.  for rpc_ressponse_time the same issue will exist if I try to spin up 150 instances.", 
            "date_created": "2013-07-15 17:24:42.636967+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Joe, i think we shouldn't change default value for this option, because  there a lot of configurations of OpenStack. we can not have universal value for this option for any count of booted instances. Also  there was a bug https://bugs.launchpad.net/nova/+bug/1199433 which shows another side of this problem. So, user should decide this trouble by configuring his own service.\n", 
            "date_created": "2013-07-16 07:15:44.342943+00:00", 
            "author": "https://api.launchpad.net/1.0/~sshturm"
        }, 
        {
            "content": "Svetlana,\n\nthe link you included was to this bug.   the issue here is not the RPC timeout  but that something running on nova-compute is so slow that it cannot handle 50 concurrent requests in a reasonable timeframe.  This bug points to an underlying performance issue that will force deployers to run extra nova-network nodes.\n\nI don't think the RPC timeout should have to be a value that any cloud operator should have to tweak (there may be a few specific exceptions to this).  If they have to change it we are saying nova barely works and you have to adjust the timeout to get around very serious performance issues.    A proper solution would be to identify the root cause why 'allocate_for_instance' does not scale.", 
            "date_created": "2013-07-16 17:24:55.777666+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Joe, \n\n\nAs we are working in python we have only one thread, so you should run a lot of nova networks processes and conductors to scale this. \n\nI have the same problems when I was deploying OpenStack Grizzly on 80 nodes. \n\nWe have only 1 control node with:\nnova.network + scheduler + conductor + compute.api + mysql\n\nAnd when we were trying to run 100 instances it takes about 20 minutes.\n\nBut then I run on control node\n3 networks, 3 conductors, 2 schedulers change mysql default connection limit\nAnd it took only 2 minutes to run 100 instances (so it was good enough for us)\n\n\nSo I think this is not bug in OpenStack. It seems like wrong deployment. \n", 
            "date_created": "2013-07-17 07:16:56.837223+00:00", 
            "author": "https://api.launchpad.net/1.0/~boris-42"
        }, 
        {
            "content": "Boris, \n\nNeither of those boot times should be considered acceptable.  As a project we should always be trying to identify and remove any performance/scale bottlenecks.  It may be that for some reason this issue isn't easily solvable and should be marked as won't fix.   But first we need to find the root cause.\n\nAccepting nova is just slow and requires many processes, without knowing the reason why  is accepting our failures.", 
            "date_created": "2013-07-17 17:26:15.859566+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Joe, agreed. I think we need to do some profiling into nova-network to figure out where the actual hangup is here. Boris' configuration suggests that it's not something external to nova-network, if adding more instances on the same machine fixes the problem. I think we should have a better assessment made before H-3 and have this fixed, mitigated, or documented with a workaround by Havana.", 
            "date_created": "2013-07-17 17:35:21.091139+00:00", 
            "author": "https://api.launchpad.net/1.0/~danms"
        }, 
        {
            "content": "I did some basic profiling of nova network's shell outs it does ~25 or so and take over 4 seconds just to shell out\n\nhttp://paste.openstack.org/show/40715/", 
            "date_created": "2013-07-17 18:02:01.730182+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "It looks like the issue is how related to how long we hold locks for,  So the queue for a lock can become very long.\n\nhttp://paste.openstack.org/show/40747/\n\n\n00:07 < dansmith> if we do eight seconds of work for each, then you're pretty much \n                  getting what you'd expect\n00:08 < jog0> right\n00:08 < jog0> my guess is we are locking too coarsly\n00:09 < dansmith> so, that's probably true,\n00:09 < dansmith> but there has to be some schedule-able point inside the current lock \n                  to make that pay off\n00:09 < dansmith> since we're not really multi-threaded here, we're not blocking other \n                  work by holding a lock unless we're doing nothing for part of the time\n00:09 < jog0> right\n00:10 < dansmith> so unless the ip/iptables/etc binaries are really taking that long to \n                  do their work (I don't think they are) then maybe it's all just silly \n                  setup and teardown or something,\n00:10 < jog0> does \" ip addr show dev eth1 scope global\"need to be ina lock?\n00:10 < dansmith> which means that's the thing to optimize and not necessarily \n                  restructuring all the network code to lock more finely\n", 
            "date_created": "2013-07-18 00:13:50.617424+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Looks like the issue is rootwrap:\n\nvagrant@precise64:/opt/stack/nova$ time sudo nova-rootwrap /etc/nova/rootwrap.conf iptables-save -c\n\n<snip>\n\nreal    0m0.352s\nuser    0m0.268s\nsys     0m0.072s\n\n\nvagrant@precise64:/opt/stack/nova$ time sudo  iptables-save -c\n\n<snip>\n\nreal    0m0.025s\nuser    0m0.012s\nsys     0m0.012s\n\n", 
            "date_created": "2013-07-18 00:18:37.955892+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "When removing rootwrap from the equation everything becomes about 4x faster.\n\nTo explain the issue in a a different way: \n\n:/opt/stack/nova$ time sudo nova-rootwrap /etc/nova/rootwrap.conf ls \n/usr/local/bin/nova-rootwrap: Unauthorized command: ls (no filter matched)\n\nreal    0m0.254s\nuser    0m0.180s\nsys     0m0.068s\n", 
            "date_created": "2013-07-18 00:46:31.924468+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "After further investigation it looks like the issue is entry points.  In devstack when I make  nova/openstack/common/rootwrap/cmd.py an empty file it still   takes 0.201 seconds to run nova-rootwrap.\n", 
            "date_created": "2013-07-18 22:42:28.349103+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "In Devstack:\n\nvagrant@precise64:/opt/stack/nova$ time python -c \"import pkg_resources\"\n\nreal    0m0.286s\nuser    0m0.240s\nsys     0m0.044s\n", 
            "date_created": "2013-07-19 18:16:37.241068+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Note that nova-rootwrap isn't the only thing to blame when an RPC times out. There are _many_ parts of OpenStack that don't scale. Infact, I wrote a very long article about the situation here: http://blog.gridcentric.com/bid/318277/Boosting-OpenStack-s-Parallel-Performance.", 
            "date_created": "2013-07-25 21:31:22.027121+00:00", 
            "author": "https://api.launchpad.net/1.0/~pete5"
        }, 
        {
            "content": "Even with https://review.openstack.org/#/c/38000/\n\nrootwrap is too slow to do nova boot --num-instances=50 in a standard devstack enviornment:\n\n$ time sudo nova-rootwrap /etc/nova/rootwrap.conf iptables-save -c \n\n<snip>\n\nreal    0m0.154s\nuser    0m0.084s\nsys     0m0.056s\n\nvs:\n$ time sudo iptables-save -c \n\nreal    0m0.040s\nuser    0m0.020s\nsys     0m0.008s", 
            "date_created": "2013-08-01 04:57:53.657068+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "When swapping rootwrap out with just sudo,  when I run 'nova boot --num-instances=200' only once instance times out while waiting for a nova-network RPC response.", 
            "date_created": "2013-08-01 06:23:49.740546+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Although the slow rootwrap hits neutron as well, when launching 100 VMs there are no RPC timeouts.  So fixing this would just make neutron faster and not fix any failures.\n\nIt looks like this has been a big issue for people in the past as there is a retry option to get around the issue, CONF.network_allocate_retries is set to 0 by default but can be set higher to cause network.api.allocate_for_instance to retry (the command that times out due to the rootwrap overhead combined with global locks).\n", 
            "date_created": "2013-08-03 04:13:30.475805+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/40688", 
            "date_created": "2013-08-07 18:06:38.782970+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/40688\nCommitted: http://github.com/openstack/nova/commit/176c483cdf2bc8eff7cfff4a9b0ac0dd98239da1\nSubmitter: Jenkins\nBranch:    master\n\ncommit 176c483cdf2bc8eff7cfff4a9b0ac0dd98239da1\nAuthor: Vishvananda Ishaya <email address hidden>\nDate:   Wed Aug 7 11:02:59 2013 -0700\n\n    Fix simultaneous timeout with smart iptables usage\n    \n    Simultaneous boots were getting timeouts in allocate_for_network.\n    This was due to our inefficient use of iptables where we attempt\n    to recreate the same rules over and over using initialize_gateway,\n    plug, and restart_dhcp.\n    \n    This patch makes the iptables code a little bit smarter by only\n    shelling out if the rule list has changed. Note that there is\n    a small difference in the interpretation of duplicate rules.\n    Previously, the last copy of the rule would win whereas now\n    the first copy of the rule will win. Multiple copies of the same\n    rule were never supported. This means the only thing that one\n    needs to remember is it is necessary to remove a rule and re-add\n    it if you want to move it later in the list.\n    \n    Fixes bug 1199433\n    \n    Change-Id: I9920f8d6aa269d9b3bfd88a8dbbb00f859deb158\n", 
            "date_created": "2013-08-10 00:00:40.659111+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/grizzly\nReview: https://review.openstack.org/41451", 
            "date_created": "2013-08-12 15:34:12.921358+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/41451\nCommitted: http://github.com/openstack/nova/commit/d2c1098ddf1373398b46870002b8125501804a20\nSubmitter: Jenkins\nBranch:    stable/grizzly\n\ncommit d2c1098ddf1373398b46870002b8125501804a20\nAuthor: Vishvananda Ishaya <email address hidden>\nDate:   Wed Aug 7 11:02:59 2013 -0700\n\n    Fix simultaneous timeout with smart iptables usage\n    \n    Simultaneous boots were getting timeouts in allocate_for_network.\n    This was due to our inefficient use of iptables where we attempt\n    to recreate the same rules over and over using initialize_gateway,\n    plug, and restart_dhcp.\n    \n    This patch makes the iptables code a little bit smarter by only\n    shelling out if the rule list has changed. Note that there is\n    a small difference in the interpretation of duplicate rules.\n    Previously, the last copy of the rule would win whereas now\n    the first copy of the rule will win. Multiple copies of the same\n    rule were never supported. This means the only thing that one\n    needs to remember is it is necessary to remove a rule and re-add\n    it if you want to move it later in the list.\n    \n    Fixes bug 1199433\n    \n    Change-Id: I9920f8d6aa269d9b3bfd88a8dbbb00f859deb158\n    (cherry picked from commit 176c483cdf2bc8eff7cfff4a9b0ac0dd98239da1)\n", 
            "date_created": "2013-08-26 10:16:22.094579+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Unclear to me where this has ended up from an oslo perspective\n\nDo we need a separate \"rootwrap is slow?\" bug report?", 
            "date_created": "2013-10-08 20:15:34.340906+00:00", 
            "author": "https://api.launchpad.net/1.0/~markmc"
        }, 
        {
            "content": "This has been fixed. Mordred added a pbr patch to speed rootwrap ( and the startup time of all Openstack binaries). Now the biggest overheard is python startup time. But that is small enough that things are working now.", 
            "date_created": "2013-10-08 20:24:56.726038+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }
    ]
}