{
    "status": "Fix Released", 
    "last_updated": "2013-04-04 11:07:53.104242+00:00", 
    "description": "I'm seeing the following stack trace occur frequently in Nova compute.log when running test suites. The exception seems to occur when instances are terminated. I've seen it both on SmokeStack and again today it happened to me when running the latest Grizzly trunk code manually to investigate the issue further (Git Hash 36b8525).\n\n2012-10-09 13:24:56 AUDIT nova.compute.manager [req-4909f79a-f35a-4590-88fc-5a94ad6fc9fc aff1b54efbbf4a56b88d6d92790190d0 df64b634751947d5b0fbd813f813d5e7] [instance: 5420df8c-b1ad-4373-bc6f-c2088325ad89] Terminating instance\n2012-10-09 13:25:00 ERROR nova.manager [-] Error during ComputeManager.update_available_resource: Unable to read from monitor: Connection reset by peer\n2012-10-09 13:25:00 TRACE nova.manager Traceback (most recent call last):\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/manager.py\", line 175, in periodic_tasks\n2012-10-09 13:25:00 TRACE nova.manager     task(self, context)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 2804, in update_available_resource\n2012-10-09 13:25:00 TRACE nova.manager     self.resource_tracker.update_available_resource(context)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/utils.py\", line 760, in inner\n2012-10-09 13:25:00 TRACE nova.manager     retval = f(*args, **kwargs)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/compute/resource_tracker.py\", line 390, in update_available_resource\n2012-10-09 13:25:00 TRACE nova.manager     resources = self.driver.get_available_resource()\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 2220, in get_available_resource\n2012-10-09 13:25:00 TRACE nova.manager     'disk_available_least': self.get_disk_available_least()}\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 2712, in get_disk_available_least\n2012-10-09 13:25:00 TRACE nova.manager     self.get_instance_disk_info(i_name))\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 2659, in get_instance_disk_info\n2012-10-09 13:25:00 TRACE nova.manager     xml = virt_dom.XMLDesc(0)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 187, in doit\n2012-10-09 13:25:00 TRACE nova.manager     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 147, in proxy_call\n2012-10-09 13:25:00 TRACE nova.manager     rv = execute(f,*args,**kwargs)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 76, in tworker\n2012-10-09 13:25:00 TRACE nova.manager     rv = meth(*args,**kwargs)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 381, in XMLDesc\n2012-10-09 13:25:00 TRACE nova.manager     if ret is None: raise libvirtError ('virDomainGetXMLDesc() failed', dom=self)\n2012-10-09 13:25:00 TRACE nova.manager libvirtError: Unable to read from monitor: Connection reset by peer\n2012-10-09 13:25:00 TRACE nova.manager\n2012-10-09 13:25:00 INFO nova.virt.libvirt.driver [-] [instance: 5420df8c-b1ad-4373-bc6f-c2088325ad89] Instance destroyed successfully.", 
    "tags": [], 
    "importance": "High", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1064581", 
    "owner": "https://api.launchpad.net/1.0/~hzwangpan", 
    "id": 1064581, 
    "index": 846, 
    "created": "2012-10-09 18:20:16.688394+00:00", 
    "title": "instance destroy causes libvirtError: Unable to read from monitor", 
    "comments": [
        {
            "content": "I'm seeing the following stack trace occur frequently in Nova compute.log when running test suites. The exception seems to occur when instances are terminated. I've seen it both on SmokeStack and again today it happened to me when running the latest Grizzly trunk code manually to investigate the issue further (Git Hash 36b8525).\n\n2012-10-09 13:24:56 AUDIT nova.compute.manager [req-4909f79a-f35a-4590-88fc-5a94ad6fc9fc aff1b54efbbf4a56b88d6d92790190d0 df64b634751947d5b0fbd813f813d5e7] [instance: 5420df8c-b1ad-4373-bc6f-c2088325ad89] Terminating instance\n2012-10-09 13:25:00 ERROR nova.manager [-] Error during ComputeManager.update_available_resource: Unable to read from monitor: Connection reset by peer\n2012-10-09 13:25:00 TRACE nova.manager Traceback (most recent call last):\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/manager.py\", line 175, in periodic_tasks\n2012-10-09 13:25:00 TRACE nova.manager     task(self, context)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 2804, in update_available_resource\n2012-10-09 13:25:00 TRACE nova.manager     self.resource_tracker.update_available_resource(context)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/utils.py\", line 760, in inner\n2012-10-09 13:25:00 TRACE nova.manager     retval = f(*args, **kwargs)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/compute/resource_tracker.py\", line 390, in update_available_resource\n2012-10-09 13:25:00 TRACE nova.manager     resources = self.driver.get_available_resource()\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 2220, in get_available_resource\n2012-10-09 13:25:00 TRACE nova.manager     'disk_available_least': self.get_disk_available_least()}\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 2712, in get_disk_available_least\n2012-10-09 13:25:00 TRACE nova.manager     self.get_instance_disk_info(i_name))\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 2659, in get_instance_disk_info\n2012-10-09 13:25:00 TRACE nova.manager     xml = virt_dom.XMLDesc(0)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 187, in doit\n2012-10-09 13:25:00 TRACE nova.manager     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 147, in proxy_call\n2012-10-09 13:25:00 TRACE nova.manager     rv = execute(f,*args,**kwargs)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 76, in tworker\n2012-10-09 13:25:00 TRACE nova.manager     rv = meth(*args,**kwargs)\n2012-10-09 13:25:00 TRACE nova.manager   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 381, in XMLDesc\n2012-10-09 13:25:00 TRACE nova.manager     if ret is None: raise libvirtError ('virDomainGetXMLDesc() failed', dom=self)\n2012-10-09 13:25:00 TRACE nova.manager libvirtError: Unable to read from monitor: Connection reset by peer\n2012-10-09 13:25:00 TRACE nova.manager\n2012-10-09 13:25:00 INFO nova.virt.libvirt.driver [-] [instance: 5420df8c-b1ad-4373-bc6f-c2088325ad89] Instance destroyed successfully.", 
            "date_created": "2012-10-09 18:20:16.688394+00:00", 
            "author": "https://api.launchpad.net/1.0/~dan-prince"
        }, 
        {
            "content": "> 2012-10-09 13:25:00 TRACE nova.manager libvirtError: Unable to read from monitor: Connection reset by peer\n\nThis indicates that QEMU shutdown while libvirt was talking to its monitor, to fullfill the virDomainGetXMLDesc() API call. \n\nThis obviously happened because another thread was destroying that instance while the stats collection thread was working.\n\nI guess the stats collection thread needs to deal with the possibility that a VM can disappear while its talking to it instead of throwing the exception", 
            "date_created": "2012-10-11 14:37:15.163741+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/19287", 
            "date_created": "2013-01-09 12:00:23.677122+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/19287\nCommitted: http://github.com/openstack/nova/commit/67376d34ed6bf68b15ac87ef444887cbc27dc6b0\nSubmitter: Jenkins\nBranch:    master\n\ncommit 67376d34ed6bf68b15ac87ef444887cbc27dc6b0\nAuthor: Wangpan <email address hidden>\nDate:   Wed Jan 9 19:33:43 2013 +0800\n\n    Map libvirt error to InstanceNotFound in get_instance_disk_info\n    \n    When getting instance disk info, the instance may be destroyed/deleted, and a\n    libvirtError will be raised in XMLDesc method, so catching and mapping it to\n    InstanceNotFound and the caller can handle it correctly.\n    \n    Fixes bug #1064581\n    \n    Change-Id: I07fed3e82e10dad4cb84ae5c8650ada351c24e78\n", 
            "date_created": "2013-01-23 18:37:17.639314+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}