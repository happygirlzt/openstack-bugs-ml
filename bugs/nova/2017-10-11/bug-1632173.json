{
    "status": "Expired", 
    "last_updated": "2017-02-08 04:17:49.610113+00:00", 
    "description": "Hi,\n\nI am upgrading from Juno to Kilo and from that to Liberty.\n\nI understand I need to nova-manage db migrate_flavor_data before upgrading from Kilo to Liberty to let VMs that were spawned while the system was in Juno to flavor migrate to Kilo.\n\nDepending on the number of computes, complete upgrade can potentially be spanned for longer duration, days if not months.\n\nWhile migrate_flavor_data seem to flavor migrate meta data of the VMs that were spawned before upgrade procedure, it doesn't seem to flavor migrate for the VMs that were spawned during the upgrade procedure more specifically after openstack controller upgrade and before compute upgrade. Am I missing something here or is it by intention?\n\nSince, the compute upgrade procedure could last for days, would it be practical to block spawning work load VMs for that long duration? Otherwise, next upgrade will fail right?\n\nthanks\n\n>> While migrate_flavor_data seem to flavor migrate meta data of the VMs\n>> that were spawned before upgrade procedure, it doesn't seem to flavor\n>> migrate for the VMs that were spawned during the upgrade procedure more\n>> specifically after openstack controller upgrade and before compute\n>> upgrade. Am I missing something here or is it by intention?\n\n>You can run the flavor migration as often as you need, and can certainly\n>run it after your last compute is upgraded before you start to move into\n>liberty.\n>\n>--Dan\n\n\nThanks Dan for your response. While I do run that before I start my move to liberty, what I see is that it doesn't seem to flavor migrate meta data for the VMs that are spawned after controller upgrade from juno to kilo and before all computes upgraded from juno to kilo. The current work around is to delete those VMs that are spawned after controller upgrade and before all computes upgrade, and then initiate liberty upgrade. Then it works fine.\n\nDan Smith <email address hidden>\n\t\nAug 31\n\t\nto me, openstack-dev\n> Thanks Dan for your response. While I do run that before I start my\n> move to liberty, what I see is that it doesn't seem to flavor migrate\n> meta data for the VMs that are spawned after controller upgrade from\n> juno to kilo and before all computes upgraded from juno to kilo. The\n> current work around is to delete those VMs that are spawned after\n> controller upgrade and before all computes upgrade, and then initiate\n> liberty upgrade. Then it works fine.\n\nI can't think of any reason why that would be, or why it would be a\nproblem. Instances created after the controllers are upgraded should not\nhave old-style flavor info, so they need not be touched by the migration\ncode.\n\nMaybe filing a bug is in order describing what you see?\n\n\nHi,\n\nI did some investigation last week, why this was happening before I file the bug. Here are my observations and I would like to work on it. Any guidance is appreciated.\n\n\nUpgrade procedure:\nIn my setup I have openstack controller on one node, neutron on another node and rest of the nodes are computes. Assume they are running juno. As the first step,\na) Bringup up a new openstack node in kilo\nb) Migrate database from juno to kilo.\nc) Run xxx manage db sync commands.\nd) Set upgrade levels to juno\ne) Migrate neutron and computes to the newer controller.\n\nsecond step.\na) Upgrade neutron, and then start compute upgrades one at a time.\n\nthird step,\na) Finalize the upgrade by clearing upgrade levels and restarting services.\nb) Issue migrate flavor data command.\n\nThis procedure is openstack side by side upgraded and neutron and computes inplace upgraded.\n\nIssue:\nVMs spawned after step1 and during step2 are not flavor migrated. So, migration to liberty was failing.\n\nInvestigation:\nflavor migrate command filters instance uuids in nova.instance_extra table whose 'flavor' column is NULL and fill in with the necessary flavor information and delete those respective rows from the nova.instance_system_metadata associated with that VM.\nFor the VMs spawned after the first step and before step2, this flavor information in nova.instance_extra and also respective flavor information in nova.instance_system_metadata table.\nSince the filter looks for 'flavor ' column as NULL, these instances are not caught to delete entries in nova.instance_system_metadata. And presence of this data is failing nova db sync while migrating to liberty.\n\nPossible Solutions:\nI feel we should broaden the filter so that instances spawned after step1 and during step 2 are also accounted for data translation. As a quick verification, I tried this by having no filer and it worked. I know filter give efficiency, but would it matter in this context or should we broaden the filter?\n\nPlease let me know if I am going in the right direction.\n\nthanks", 
    "tags": [
        "upgrades"
    ], 
    "importance": "Undecided", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1632173", 
    "owner": "None", 
    "id": 1632173, 
    "index": 6475, 
    "created": "2016-10-11 01:52:30.007087+00:00", 
    "title": "migrate_flavor_data doesn't flavor migrate meta data of VMs spawned during upgrade", 
    "comments": [
        {
            "content": "Hi,\n\nI am upgrading from Juno to Kilo and from that to Liberty.\n\nI understand I need to nova-manage db migrate_flavor_data before upgrading from Kilo to Liberty to let VMs that were spawned while the system was in Juno to flavor migrate to Kilo.\n\nDepending on the number of computes, complete upgrade can potentially be spanned for longer duration, days if not months.\n\nWhile migrate_flavor_data seem to flavor migrate meta data of the VMs that were spawned before upgrade procedure, it doesn't seem to flavor migrate for the VMs that were spawned during the upgrade procedure more specifically after openstack controller upgrade and before compute upgrade. Am I missing something here or is it by intention?\n\nSince, the compute upgrade procedure could last for days, would it be practical to block spawning work load VMs for that long duration? Otherwise, next upgrade will fail right?\n\nthanks\n\n>> While migrate_flavor_data seem to flavor migrate meta data of the VMs\n>> that were spawned before upgrade procedure, it doesn't seem to flavor\n>> migrate for the VMs that were spawned during the upgrade procedure more\n>> specifically after openstack controller upgrade and before compute\n>> upgrade. Am I missing something here or is it by intention?\n\n>You can run the flavor migration as often as you need, and can certainly\n>run it after your last compute is upgraded before you start to move into\n>liberty.\n>\n>--Dan\n\n\nThanks Dan for your response. While I do run that before I start my move to liberty, what I see is that it doesn't seem to flavor migrate meta data for the VMs that are spawned after controller upgrade from juno to kilo and before all computes upgraded from juno to kilo. The current work around is to delete those VMs that are spawned after controller upgrade and before all computes upgrade, and then initiate liberty upgrade. Then it works fine.\n\nDan Smith <email address hidden>\n\t\nAug 31\n\t\nto me, openstack-dev\n> Thanks Dan for your response. While I do run that before I start my\n> move to liberty, what I see is that it doesn't seem to flavor migrate\n> meta data for the VMs that are spawned after controller upgrade from\n> juno to kilo and before all computes upgraded from juno to kilo. The\n> current work around is to delete those VMs that are spawned after\n> controller upgrade and before all computes upgrade, and then initiate\n> liberty upgrade. Then it works fine.\n\nI can't think of any reason why that would be, or why it would be a\nproblem. Instances created after the controllers are upgraded should not\nhave old-style flavor info, so they need not be touched by the migration\ncode.\n\nMaybe filing a bug is in order describing what you see?\n\n\nHi,\n\nI did some investigation last week, why this was happening before I file the bug. Here are my observations and I would like to work on it. Any guidance is appreciated.\n\n\nUpgrade procedure:\nIn my setup I have openstack controller on one node, neutron on another node and rest of the nodes are computes. Assume they are running juno. As the first step,\na) Bringup up a new openstack node in kilo\nb) Migrate database from juno to kilo.\nc) Run xxx manage db sync commands.\nd) Set upgrade levels to juno\ne) Migrate neutron and computes to the newer controller.\n\nsecond step.\na) Upgrade neutron, and then start compute upgrades one at a time.\n\nthird step,\na) Finalize the upgrade by clearing upgrade levels and restarting services.\nb) Issue migrate flavor data command.\n\nThis procedure is openstack side by side upgraded and neutron and computes inplace upgraded.\n\nIssue:\nVMs spawned after step1 and during step2 are not flavor migrated. So, migration to liberty was failing.\n\nInvestigation:\nflavor migrate command filters instance uuids in nova.instance_extra table whose 'flavor' column is NULL and fill in with the necessary flavor information and delete those respective rows from the nova.instance_system_metadata associated with that VM.\nFor the VMs spawned after the first step and before step2, this flavor information in nova.instance_extra and also respective flavor information in nova.instance_system_metadata table.\nSince the filter looks for 'flavor ' column as NULL, these instances are not caught to delete entries in nova.instance_system_metadata. And presence of this data is failing nova db sync while migrating to liberty.\n\nPossible Solutions:\nI feel we should broaden the filter so that instances spawned after step1 and during step 2 are also accounted for data translation. As a quick verification, I tried this by having no filer and it worked. I know filter give efficiency, but would it matter in this context or should we broaden the filter?\n\nPlease let me know if I am going in the right direction.\n\nthanks", 
            "date_created": "2016-10-11 01:52:30.007087+00:00", 
            "author": "https://api.launchpad.net/1.0/~sureshk"
        }, 
        {
            "content": "This is for some really old code at this point, but as I said, I'm not sure how this could happen. This bug really needs more detail like what fails exactly, as well as maybe some dumps of the affected instances from the database, etc.", 
            "date_created": "2016-12-09 17:45:12.478238+00:00", 
            "author": "https://api.launchpad.net/1.0/~danms"
        }, 
        {
            "content": "[Expired for OpenStack Compute (nova) because there has been no activity for 60 days.]", 
            "date_created": "2017-02-08 04:17:46.126567+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ]
}