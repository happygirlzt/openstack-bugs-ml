{
    "status": "Opinion", 
    "last_updated": "2017-07-25 15:45:59.870302+00:00", 
    "description": "Description\n===========\npci_passthrough_whitelist = {\"address\": \"0000:0a:00.1\", \"physical_network\": \"physnet1\"}\nIf a nova-compute supports multi nodes. The nodes's pci address maybe repeat.\nSo format above can not describe the situation.\n\nOpenstack architecture is supporting mapping a nova-compute to multi node.\nFor drivers listed in Openstack community code, there is only vmware driver supporting it .\nBut there are many other hypervisor products which based on KVM/Xen/PowerVM. They do enhancement On KVM/Xen/PowerVM and provide managebility and develop their drivers supporting mapping a nova-compute to multi node.\nWhen customers want to build a cloud and make a decision on how to choose cloud products and hypervisor products, they maybe choose hypervisor beyond KVM/Xen/PowerVM. So openstack cloud products should regard sr-iov working with multi-node.\n\n\n\nSteps to reproduce\n==================\n1.Configure nova-compute mappint to multi node.\n2.there are two node whic have same pci_address\n3.pci_passthrough_whitelist can not describe the situation\n\nExpected result\n===============\nNone\n\nSuggest Solution\n=============\npci_passthrough_whitelist = {\"address\": \"0000:0a:00.1\", \"node\": \"xxxx\", \"physical_network\": \"physnet1\"}\nwe add node description in pci_passthrough_whitelist.\nwhen nova-compute process pci_passthrough_whitelist per node, ResourceTracker and PciDeviceStats just process own node's pci_passthrough_whitelist.\nPciDeviceSpec doesn't need to add \"Node\" item. We will pop \"Node\" of pci_passthrough_whitelist.\nThe \"Node\" is for selection per node.", 
    "tags": [
        "pci", 
        "vmware", 
        "whitelist"
    ], 
    "importance": "Wishlist", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1612029", 
    "owner": "None", 
    "id": 1612029, 
    "index": 1816, 
    "created": "2016-08-11 02:43:15.014933+00:00", 
    "title": "[vmware] [sr-iov] pci passthrough whitelist doesn't support mult node", 
    "comments": [
        {
            "content": "Description\n===========\npci_passthrough_whitelist = {\"address\": \"0000:0a:00.1\", \"physical_network\": \"physnet1\"}\nIf a nova-compute supports multi nodes. The nodes's pci address maybe repeat.\nSo format above can not describe the situation.\n\n\nSteps to reproduce\n==================\nNone\n\nExpected result\n===============\nNone\n\nSuggest Solution\n=============\npci_passthrough_whitelist = {\"address\": \"0000:0a:00.1\", \"node\": \"xxxx\", \"physical_network\": \"physnet1\"}\nwe add node description in pci_passthrough_whitelist.\nwhen nova-compute process pci_passthrough_whitelist per node, ResourceTracker and PciDeviceStats just process own node's pci_passthrough_whitelist. \nPciDeviceSpec doesn't need to add \"Node\" item. We will pop \"Node\" of pci_passthrough_whitelist.\nThe \"Node\" is for selection per node.", 
            "date_created": "2016-08-11 02:43:15.014933+00:00", 
            "author": "https://api.launchpad.net/1.0/~guoyongxhzhf"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/354557", 
            "date_created": "2016-08-12 07:17:17.009882+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Michael Still (<email address hidden>) on branch: master\nReview: https://review.openstack.org/354557\nReason: This patch has been sitting unchanged for more than 12 weeks. I am therefore going to abandon it to keep the nova review queue sane. Please feel free to restore the change if you're still working on it.", 
            "date_created": "2016-12-06 20:09:44.970646+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "\nThere are no currently open reviews on this bug, changing\nthe status back to the previous state and unassigning. If\nthere are active reviews related to this bug, please include\nlinks in comments.\n", 
            "date_created": "2017-06-23 12:44:19.225170+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "Probably needs to come in as spec as this requires work outside of the virt driver", 
            "date_created": "2017-07-25 15:45:59.180649+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }
    ]
}