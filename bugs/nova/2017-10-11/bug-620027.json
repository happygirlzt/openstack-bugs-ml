{
    "status": "Invalid", 
    "last_updated": "2011-01-05 13:08:03.324916+00:00", 
    "description": "I noticed that service.py under nova/volume contains this flag:\n\nflags.DEFINE_string('storage_dev', '/dev/sdb', 'Physical device to use for volumes')\n\nmy host does not have a /dev/sdb, so vgcreate in _init_volume_group(self) fails and consequently lvcreate in _create_lv fails too. It seems that no exeption is reported in the log file. Shouldn't storage_dev be /dev/loop0 or any other free loop device chosen by losetup passed by $NOVA_VOLUME_ARGS?\n\nThanks,\nArmando\n\n", 
    "tags": [], 
    "importance": "Undecided", 
    "heat": 8, 
    "link": "https://bugs.launchpad.net/nova/+bug/620027", 
    "owner": "None", 
    "id": 620027, 
    "index": 1919, 
    "created": "2010-08-18 18:22:07.071723+00:00", 
    "title": "vgcreate/lvcreate in volume/service.py fail and go undetected", 
    "comments": [
        {
            "content": "I noticed that service.py under nova/volume contains this flag: \n\nflags.DEFINE_string('storage_dev', '/dev/sdb', 'Physical device to use for volumes') \n\nmy host does not have a /dev/sdb, so vgcreate in _init_volume_group(self) fails and consequently lvcreate in _create_lv fails too. It seems that no exeption is reported in the log file. Shouldn't storage_dev be /dev/loop0?\n\nThanks,\nArmando", 
            "date_created": "2010-08-18 18:22:07.071723+00:00", 
            "author": "https://api.launchpad.net/1.0/~armando-migliaccio"
        }, 
        {
            "content": "You can pass in a flag for a different storage device -->\n./nova-volume --nodaemon --verbose --storage_dev=/dev/loop0\nor in /etc/nova/nova-volume.conf:\n--storage_dev=/dev/loop0\n\nAlso, if you just make sure that the volume group already exists, it will\nwork.  The group should be called 'nova-volumes'.  You can also specify a\ndifferent volume group name with a flag\n--volume_group=vgfoo\n\nVish\n\nOn Wed, Aug 18, 2010 at 11:46 AM, Armando Migliaccio <\n<email address hidden>> wrote:\n\n> ** Description changed:\n>\n>  I noticed that service.py under nova/volume contains this flag:\n>\n>  flags.DEFINE_string('storage_dev', '/dev/sdb', 'Physical device to use\n>  for volumes')\n>\n>  my host does not have a /dev/sdb, so vgcreate in\n>  _init_volume_group(self) fails and consequently lvcreate in _create_lv\n>  fails too. It seems that no exeption is reported in the log file.\n> - Shouldn't storage_dev be /dev/loop0?\n> + Shouldn't storage_dev be /dev/loop0 or any other free loop device chosen\n> + by losetup?\n>\n>  Thanks,\n>  Armando\n>\n> ** Description changed:\n>\n>  I noticed that service.py under nova/volume contains this flag:\n>\n>  flags.DEFINE_string('storage_dev', '/dev/sdb', 'Physical device to use\n>  for volumes')\n>\n>  my host does not have a /dev/sdb, so vgcreate in\n>  _init_volume_group(self) fails and consequently lvcreate in _create_lv\n>  fails too. It seems that no exeption is reported in the log file.\n>   Shouldn't storage_dev be /dev/loop0 or any other free loop device chosen\n> - by losetup?\n> + by losetup passed by $NOVA_VOLUME_ARGS?\n>\n>  Thanks,\n>  Armando\n>\n> --\n> vgcreate/lvcreate in volume/service.py fail and go undetected\n> https://bugs.launchpad.net/bugs/620027\n> You received this bug notification because you are a member of Nova\n> Bugs, which is subscribed to OpenStack Compute (nova).\n>\n> Status in OpenStack Compute (Nova): New\n>\n> Bug description:\n> I noticed that service.py under nova/volume contains this flag:\n>\n> flags.DEFINE_string('storage_dev', '/dev/sdb', 'Physical device to use for\n> volumes')\n>\n> my host does not have a /dev/sdb, so vgcreate in _init_volume_group(self)\n> fails and consequently lvcreate in _create_lv fails too. It seems that no\n> exeption is reported in the log file. Shouldn't storage_dev be /dev/loop0 or\n> any other free loop device chosen by losetup passed by $NOVA_VOLUME_ARGS?\n>\n> Thanks,\n> Armando\n>\n>\n>\n>\n>\n", 
            "date_created": "2010-08-18 20:32:06+00:00", 
            "author": "https://api.launchpad.net/1.0/~vishvananda"
        }, 
        {
            "content": "you are right, if you make sure that the volume group already exists, the volume creation does work. However, I went back to my config and saw that I do pass the flag storage_dev=/dev/loop0 on the command line. I also noticed that I do not pass the --nodaemon switch. \n\nWhen I launch nova-volume without --nodaemon 'vgcreate' does not seem to get called. Is that possible? Instead when I launch nova-volume with the --nodaemon, vgcreate does get called. I did instrument the code and compared the log output in the two cases (latest lines of the logs are interesting):\n\n**** NOVA-VOLUME WITHOUT --NODAEMON SWITCH ****\nStarting Nova Volume\nDEBUG:root:Full set of FLAGS:\nDEBUG:root:help : None\nDEBUG:root:storage_availability_zone : nova\nDEBUG:root:volume_topic : volume\nDEBUG:root:verbose : True\nDEBUG:root:encrypted : None\nDEBUG:root:compute_topic : compute\nDEBUG:root:default_kernel : aki-11111\nDEBUG:root:report_profile : None\nDEBUG:root:rabbit_password : guest\nDEBUG:root:syslog : None\nDEBUG:root:prefix : nova-volume\nDEBUG:root:vpn_key_suffix : -key\nDEBUG:root:ec2_url : http://localhost:8773/services/Cloud\nDEBUG:root:originalname : None\nDEBUG:root:rundir : .\nDEBUG:root:profiler : hotshot\nDEBUG:root:uid : None\nDEBUG:root:connection_type : libvirt\nDEBUG:root:fake_rabbit : False\nDEBUG:root:s3_port : 3333\nDEBUG:root:help_reactors : None\nDEBUG:root:rabbit_host : 10.70.177.14\nDEBUG:root:source : None\nDEBUG:root:process_pool_size : 4\nDEBUG:root:umask : None\nDEBUG:root:nothotshot : None\nDEBUG:root:debug : False\nDEBUG:root:fake_storage : False\nDEBUG:root:redis_db : 0\nDEBUG:root:gid : None\nDEBUG:root:volume_group : nova-volumes\nDEBUG:root:reactor : None\nDEBUG:root:pidfile : /home/openstack/openstack/nova-volume.pid\nDEBUG:root:savestats : None\nDEBUG:root:rabbit_userid : guest\nDEBUG:root:storage_dev : /dev/loop0\nDEBUG:root:file : twistd.tap\nDEBUG:root:default_instance_type : m1.small\nDEBUG:root:report_interval : 10\nDEBUG:root:blades_per_shelf : 16\nDEBUG:root:node_availability_zone : nova\nDEBUG:root:version : None\nDEBUG:root:aoe_eth_dev : eth0\nDEBUG:root:auth_token_ttl : 3600\nDEBUG:root:rabbit_port : 5672\nDEBUG:root:chroot : None\nDEBUG:root:profile : None\nDEBUG:root:euid : None\nDEBUG:root:vpn_image_id : ami-CLOUDPIPE\nDEBUG:root:logfile : nova-volume.log\nDEBUG:root:nodaemon : None\nDEBUG:root:b : None\nDEBUG:root:last_shelf_id : 149\nDEBUG:root:no_save : True\nDEBUG:root:aoe_export_dir : /var/lib/vblade-persist/vblades\nDEBUG:root:rabbit_virtual_host : /\nDEBUG:root:node_name : phantom\nDEBUG:root:redis_host : 127.0.0.1\nDEBUG:root:spew : None\nDEBUG:root:r : None\nDEBUG:root:default_image : ami-11111\nDEBUG:root:control_exchange : nova\nDEBUG:root:default_ramdisk : ari-11111\nDEBUG:root:redis_port : 6379\nDEBUG:root:s3_host : 127.0.0.1\nDEBUG:root:python : /home/openstack/openstack/nova/trunk/bin/nova-volume\nDEBUG:root:first_shelf_id : 140\nDEBUG:root:fake_network : False\nDEBUG:root:network_topic : network\nWARNING:root:Starting volume node\nDEBUG:root:*** before_pvcreate ***\nDEBUG:root:Executing: sudo ['pvcreate', '/dev/loop0']:\nDEBUG:root:>> execute\nDEBUG:root:<< execute\nDEBUG:root:exe output: <Deferred at 0xa700dec  current result: <Deferred at 0xa700e2c>>\n\nThe last few lines are logging messages I added in _init_volume_group, simple_execute and execute. If I execute vgdislay on the shell I get nothing.\n\n**** NOVA-VOLUME WITH --NODAEMON SWITCH ****\n\nStarting Nova Volume\nDEBUG:root:Full set of FLAGS:\nDEBUG:root:help : None\nDEBUG:root:storage_availability_zone : nova\nDEBUG:root:volume_topic : volume\nDEBUG:root:verbose : True\nDEBUG:root:encrypted : None\nDEBUG:root:compute_topic : compute\nDEBUG:root:default_kernel : aki-11111\nDEBUG:root:report_profile : None\nDEBUG:root:rabbit_password : guest\nDEBUG:root:syslog : None\nDEBUG:root:prefix : nova-volume\nDEBUG:root:vpn_key_suffix : -key\nDEBUG:root:ec2_url : http://localhost:8773/services/Cloud\nDEBUG:root:originalname : None\nDEBUG:root:rundir : .\nDEBUG:root:profiler : hotshot\nDEBUG:root:uid : None\nDEBUG:root:connection_type : libvirt\nDEBUG:root:fake_rabbit : False\nDEBUG:root:s3_port : 3333\nDEBUG:root:help_reactors : None\nDEBUG:root:rabbit_host : 127.0.0.1\nDEBUG:root:source : None\nDEBUG:root:process_pool_size : 4\nDEBUG:root:umask : None\nDEBUG:root:nothotshot : None\nDEBUG:root:debug : False\nDEBUG:root:fake_storage : False\nDEBUG:root:redis_db : 0\nDEBUG:root:gid : None\nDEBUG:root:volume_group : nova-volumes\nDEBUG:root:reactor : None\nDEBUG:root:pidfile : /home/openstack/openstack/nova-volume.pid\nDEBUG:root:savestats : None\nDEBUG:root:rabbit_userid : guest\nDEBUG:root:storage_dev : /dev/loop0\nDEBUG:root:file : twistd.tap\nDEBUG:root:default_instance_type : m1.small\nDEBUG:root:report_interval : 10\nDEBUG:root:blades_per_shelf : 16\nDEBUG:root:node_availability_zone : nova\nDEBUG:root:version : None\nDEBUG:root:aoe_eth_dev : eth0\nDEBUG:root:auth_token_ttl : 3600\nDEBUG:root:rabbit_port : 5672\nDEBUG:root:chroot : None\nDEBUG:root:profile : None\nDEBUG:root:euid : None\nDEBUG:root:vpn_image_id : ami-CLOUDPIPE\nDEBUG:root:logfile : -\nDEBUG:root:nodaemon : True\nDEBUG:root:b : None\nDEBUG:root:last_shelf_id : 149\nDEBUG:root:no_save : True\nDEBUG:root:aoe_export_dir : /var/lib/vblade-persist/vblades\nDEBUG:root:rabbit_virtual_host : /\nDEBUG:root:node_name : phantom\nDEBUG:root:redis_host : 127.0.0.1\nDEBUG:root:spew : None\nDEBUG:root:r : None\nDEBUG:root:default_image : ami-11111\nDEBUG:root:control_exchange : nova\nDEBUG:root:default_ramdisk : ari-11111\nDEBUG:root:redis_port : 6379\nDEBUG:root:s3_host : 10.70.177.40\nDEBUG:root:python : /home/openstack/openstack/nova/trunk/bin/nova-volume\nDEBUG:root:first_shelf_id : 140\nDEBUG:root:fake_network : False\nDEBUG:root:network_topic : network\nWARNING:root:Starting volume node\nDEBUG:root:*** before_pvcreate ***\nDEBUG:root:Executing: sudo ['pvcreate', '/dev/loop0']:\nDEBUG:root:>> execute\nDEBUG:root:<< execute\nDEBUG:root:exe output: <Deferred at 0x8f89dec  current result: <Deferred at 0x8f89e2c>>\n2010-08-19 10:17:06+0100 [-] Log opened.\n2010-08-19 10:17:06+0100 [-] twistd 10.0.0 (/usr/bin/python 2.6.5) starting up.\n2010-08-19 10:17:06+0100 [-] reactor class: twisted.internet.selectreactor.SelectReactor.\nDEBUG:root:*** after_pvcreate ***\n2010-08-19 10:17:06+0100 [-] (root): DEBUG *** after_pvcreate ***\nDEBUG:root:Executing: sudo ['vgcreate', 'nova-volumes', '/dev/loop0']:\n2010-08-19 10:17:06+0100 [-] (root): DEBUG Executing: sudo ['vgcreate', 'nova-volumes', '/dev/loop0']:\nDEBUG:root:>> execute\n2010-08-19 10:17:06+0100 [-] (root): DEBUG >> execute\nDEBUG:root:<< execute\n2010-08-19 10:17:06+0100 [-] (root): DEBUG << execute\nDEBUG:root:exe output: <Deferred at 0x8fa608c  current result: <Deferred at 0x8fa660c>>\n2010-08-19 10:17:06+0100 [-] (root): DEBUG exe output: <Deferred at 0x8fa608c  current result: <Deferred at 0x8fa660c>>\nDEBUG:root:***after vgcreate ***\n2010-08-19 10:17:06+0100 [-] (root): DEBUG ***after vgcreate ***\n\nvgdisplay says:\n\n  --- Volume group ---\n  VG Name               nova-volumes\n  System ID\n  Format                lvm2\n  Metadata Areas        1\n  Metadata Sequence No  1\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                0\n  Open LV               0\n  Max PV                0\n  Cur PV                1\n  Act PV                1\n  VG Size               10.00 GiB\n  PE Size               4.00 MiB\n  Total PE              2559\n  Alloc PE / Size       0 / 0\n  Free  PE / Size       2559 / 10.00 GiB\n  VG UUID               xiORYR-dJ0P-pu2e-QiDx-nstm-PwWh-7HuJHZ\n\nHope this help\n", 
            "date_created": "2010-08-19 09:18:03.883276+00:00", 
            "author": "https://api.launchpad.net/1.0/~armando-migliaccio"
        }, 
        {
            "content": "pvcreate is immediately followed by vgcreate in the code (though both are deferreds).  So if pvcreate is being called but vgcreate is not, then it sounds like pvcreate is raising an exception.\n\nI would feel that any errors should be logged, and indeed, looking at the code, I don't see how an error is not being logged.  Does anything get printed on stdout/stderr by nova-volume (particularly in the --nodaemon case?)\n\nYou might try merging my branch which checks the results of spawned processes:\nbzr merge lp:~justin-fathomdb/nova/check-subprocess-exit-code\n\nI don't think that will give you a better error message (though it might!), but what it will do is not treat messages on stderr as being failures.  For instance (speculating), perhaps the first time you call pvcreate it loads a kernel module, which prints a message on stderr, which causes a failure the first time you run it (only).\n\nUnfortunately, it looks like our twisted module calls into twistd.runApp, which appears to be an undocumented twisted function (http://twistedmatrix.com/trac/wiki/UndocumentedScripts).  Any Twisted people able to comment on why no error is being logged when exceptions are thrown at startup?", 
            "date_created": "2010-08-19 10:24:55.710387+00:00", 
            "author": "https://api.launchpad.net/1.0/~justin-fathomdb"
        }, 
        {
            "content": "in the --nodaemon case nova-volume works like a charm, it creates both the physical volume and the volume group. It's the case without the --nodaemon switch that has troubles...the difference between the two pvcreate outputs:\n\n*** WITH --nodaemon switch ***\n\n  --- Physical volume ---\n  PV Name               /dev/loop0\n  VG Name               nova-volumes\n  PV Size               10.00 GiB / not usable 4.00 MiB\n  Allocatable           yes\n  PE Size               4.00 MiB\n  Total PE              2559\n  Free PE               2559\n  Allocated PE          0\n  PV UUID               5AKxZf-9TlO-3CSF-8UoG-GHzF-v910-CqIsEg\n\n*** WITHOUT --nodaemon switch ***\n  \"/dev/loop0\" is a new physical volume of \"10.00 GiB\"\n  --- NEW Physical volume ---\n  PV Name               /dev/loop0\n  VG Name\n  PV Size               10.00 GiB\n  Allocatable           NO\n  PE Size               0\n  Total PE              0\n  Free PE               0\n  Allocated PE          0\n  PV UUID               FWH78L-I3b2-eMS6-hE43-V7dp-t1Fb-ksNDTI\n\nIt looks like that pvcreate fails silently...but I don't see any messages in /var/log/syslog or /var/log/messages. Any clues?", 
            "date_created": "2010-08-19 12:16:33.518603+00:00", 
            "author": "https://api.launchpad.net/1.0/~armando-migliaccio"
        }, 
        {
            "content": "Other than the earlier suggestions (merge in the error checking branch)...\n\nWhat perplexes me is that it looks like pvcreate is succeeding in both cases, because a PV appears to be created.\n\nIf it's not dependent on the order in which you run the commands, then perhaps it's a permissions problem?  (I wonder if the sudo is causing trouble).  Who are you running this as?  Can you try running as root (e.g. sudo bash beforehand).\n\nAlso, I noticed you seem to have uid and gid flags... do you by any chance have ~soren/nova/derootification merged in?  Are you running off a clean trunk?", 
            "date_created": "2010-08-19 13:02:47.526529+00:00", 
            "author": "https://api.launchpad.net/1.0/~justin-fathomdb"
        }, 
        {
            "content": "I am running off a clean trunk (the latest) and as root. I also tried to merge ~justin-fathomdb/nova/check-subprocess-exit-code and ~justin-fathomdb/nova/check-subprocess-exit-code but I haven't got any better error messages. I still experience the same issue, which is the volume group is not created at initialization, if nova-volume runs as daemon. \n\nif the physical volume/volume group already exist, pvcreate and vgcreate both fail with exit code 5 (I see that if I launch the commands from the shell), this means that also nova-volume incur in this error, however the log does not trace any of that.", 
            "date_created": "2010-08-19 14:35:18.825879+00:00", 
            "author": "https://api.launchpad.net/1.0/~armando-migliaccio"
        }, 
        {
            "content": "Inspired by that exit code 5 comment, would it be correct to rephrase the bug as \"if the PV / VG already exists, the storage manager fails to launch\"?  Or are you deleting the PV/VG in between runs?\n\nThe \"if it already exists\" bug probably exists, even if it isn't your problem here.\n\nWhat I may do is fix the \"if it already exists\" bug, and add more logging of the stdout/stderr/exit code in case of problems (which I'll have to look at anyway as part of the bug fix.)\n\nBut do please let me know whether you're cleaning up the PV/VG in between (sounds like you probably are...)", 
            "date_created": "2010-08-19 15:21:20.089992+00:00", 
            "author": "https://api.launchpad.net/1.0/~justin-fathomdb"
        }, 
        {
            "content": "I am deleting PV/VG in between runs. \n\nself.stderr.write() and self.stdout.write() do not write on my console in either mode (daemon, nodaemon) so I replaced them with log traces and I managed to see that when nova-volume runs in daemon mode vgcreate does not get called at all! Is it possible that the process.simple_execute call gets lost somehow in the call chain?", 
            "date_created": "2010-08-19 16:24:33.148606+00:00", 
            "author": "https://api.launchpad.net/1.0/~armando-migliaccio"
        }, 
        {
            "content": "by the way, with your changes I can see in the log that the pvcreate call fails in the \"if it already exists\" case, but that (as you pointed out) is not the problem here. It's just this oddity about the daemon mode, which might potentially affect every other service! ", 
            "date_created": "2010-08-19 16:29:19.817942+00:00", 
            "author": "https://api.launchpad.net/1.0/~armando-migliaccio"
        }, 
        {
            "content": "It would be great to figure out why this is happening but ultimately It\nmight be better if nova volume didn't go around creating volume groups at\nall and just checked to make sure the right one exists.\n\nOn Aug 19, 2010 9:35 AM, \"Armando Migliaccio\" <email address hidden>\nwrote:\n> by the way, with your changes I can see in the log that the pvcreate\n> call fails in the \"if it already exists\" case, but that (as you pointed\n> out) is not the problem here. It's just this oddity about the daemon\n> mode, which might potentially affect every other service!\n>\n> --\n> vgcreate/lvcreate in volume/service.py fail and go undetected\n> https://bugs.launchpad.net/bugs/620027\n> You received this bug notification because you are a member of Nova\n> Bugs, which is subscribed to OpenStack Compute (nova).\n>\n> Status in OpenStack Compute (Nova): New\n>\n> Bug description:\n> I noticed that service.py under nova/volume contains this flag:\n>\n> flags.DEFINE_string('storage_dev', '/dev/sdb', 'Physical device to use for\nvolumes')\n>\n> my host does not have a /dev/sdb, so vgcreate in _init_volume_group(self)\nfails and consequently lvcreate in _create_lv fails too. It seems that no\nexeption is reported in the log file. Shouldn't storage_dev be /dev/loop0 or\nany other free loop device chosen by losetup passed by $NOVA_VOLUME_ARGS?\n>\n> Thanks,\n> Armando\n>\n>\n>\n>\n", 
            "date_created": "2010-08-19 17:05:59+00:00", 
            "author": "https://api.launchpad.net/1.0/~vishvananda"
        }, 
        {
            "content": "This may be an unrelated problem, but there is a particularly nasty issue\nwith LVM interacting with AoE.  The various LV commands will hang trying to\nstat orphaned aoe devices.  And they hang badly in a system call and can't\nbe killed.  The best solution is to add something to LVM config so it\ndoesn't try to stat the aoe devices.  My Filter looks like so in\n/etc/lvm/lvm.conf:\n\n    filter = [ \"r|/dev/etherd/.*|\", \"r|/dev/block/.*|\", \"a/.*/\" ]\n\n\n\nOn Thu, Aug 19, 2010 at 9:29 AM, Armando Migliaccio <\n<email address hidden>> wrote:\n\n> by the way, with your changes I can see in the log that the pvcreate\n> call fails in the \"if it already exists\" case, but that (as you pointed\n> out) is not the problem here. It's just this oddity about the daemon\n> mode, which might potentially affect every other service!\n>\n> --\n> vgcreate/lvcreate in volume/service.py fail and go undetected\n> https://bugs.launchpad.net/bugs/620027\n> You received this bug notification because you are a member of Nova\n> Bugs, which is subscribed to OpenStack Compute (nova).\n>\n> Status in OpenStack Compute (Nova): New\n>\n> Bug description:\n> I noticed that service.py under nova/volume contains this flag:\n>\n> flags.DEFINE_string('storage_dev', '/dev/sdb', 'Physical device to use for\n> volumes')\n>\n> my host does not have a /dev/sdb, so vgcreate in _init_volume_group(self)\n> fails and consequently lvcreate in _create_lv fails too. It seems that no\n> exeption is reported in the log file. Shouldn't storage_dev be /dev/loop0 or\n> any other free loop device chosen by losetup passed by $NOVA_VOLUME_ARGS?\n>\n> Thanks,\n> Armando\n>\n>\n>\n>\n>\n", 
            "date_created": "2010-08-19 18:02:40+00:00", 
            "author": "https://api.launchpad.net/1.0/~vishvananda"
        }, 
        {
            "content": "I commented out the pvcreate command under _init_volume_group\n\ndef _init_volume_group(self):\n        if FLAGS.fake_storage:\n            return\n        #yield process.simple_execute(\n        #        \"sudo pvcreate %s\" % (FLAGS.storage_dev))\n        yield process.simple_execute(\n                \"sudo vgcreate %s %s\" % (FLAGS.volume_group,\n                                         FLAGS.storage_dev))\n\nand let nova-volume create the group and the physical disk in one go. The command's output looks like below:\n\nNo physical volume label read from /dev/loop0\n  Physical volume \"/dev/loop0\" successfully created\n  Volume group \"nova-volumes\" successfully created\n\nwhen I run nova-volume as daemon I finally get the volume group created!! I know it does not sound like a bug fix, but commenting pvcreate out does circumvent the problem. \n\nIf vgcreate takes care of the \"pvcreation\" too, would it make sense to have just one simple_execute call?", 
            "date_created": "2010-08-20 19:16:48.305191+00:00", 
            "author": "https://api.launchpad.net/1.0/~armando-migliaccio"
        }, 
        {
            "content": "Ping on this bug.  Where are we with this.  Vish, Justin, has anything been fixed in this regard?  Is the bug valid?  Trying to do a little maintenance on outstanding bugs...thanks.", 
            "date_created": "2010-10-06 01:43:05.137623+00:00", 
            "author": "https://api.launchpad.net/1.0/~jaypipes"
        }, 
        {
            "content": "<a bit of housekeeping> After the eventlet merge and the latest developments on the nova branch, I think this bug report no longer applies", 
            "date_created": "2011-01-05 13:08:02.372770+00:00", 
            "author": "https://api.launchpad.net/1.0/~armando-migliaccio"
        }
    ]
}