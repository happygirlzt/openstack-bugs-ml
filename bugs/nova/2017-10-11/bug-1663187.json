{
    "status": "Invalid", 
    "last_updated": "2017-02-16 12:56:38.457400+00:00", 
    "description": "logs at\n\nhttp://logs.openstack.org/periodic/periodic-tripleo-ci-centos-7-ovb-updates/024c997/console.html#_2017-02-09_08_41_30_014769\n\nshow the error\n\"No valid host was found\"\n\nThe deployment completed and updated successfully", 
    "tags": [
        "ci"
    ], 
    "importance": "Undecided", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1663187", 
    "owner": "https://api.launchpad.net/1.0/~juan-osorio-robles", 
    "id": 1663187, 
    "index": 6668, 
    "created": "2017-02-09 09:54:42.527884+00:00", 
    "title": "Nova Placement API on IPv6 unreachable from compute nodes", 
    "comments": [
        {
            "content": "logs at \n\nhttp://logs.openstack.org/periodic/periodic-tripleo-ci-centos-7-ovb-updates/024c997/console.html#_2017-02-09_08_41_30_014769\n\nshow the error \n\"No valid host was found\"\n\nHe deployment completed and updated successfully", 
            "date_created": "2017-02-09 09:54:42.527884+00:00", 
            "author": "https://api.launchpad.net/1.0/~gcerami"
        }, 
        {
            "content": "overcloud nova conductor logs at\n\nhttp://logs.openstack.org/periodic/periodic-tripleo-ci-centos-7-ovb-updates/024c997/logs/overcloud-controller-0/var/log/nova/nova-conductor.txt.gz#_2017-02-09_08_39_51_132\n\nshows the full error, but I don't see any root cause\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager [req-ef5efb8e-c34a-4a61-85e5-823333b66161 - - - - -] Failed to schedule instances\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager Traceback (most recent call last):\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/nova/conductor/manager.py\", line 866, in schedule_and_build_instances\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     request_specs[0].to_legacy_filter_properties_dict())\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/nova/conductor/manager.py\", line 597, in _schedule_instances\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     hosts = self.scheduler_client.select_destinations(context, spec_obj)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/nova/scheduler/utils.py\", line 371, in wrapped\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     return func(*args, **kwargs)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/nova/scheduler/client/__init__.py\", line 51, in select_destinations\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     return self.queryclient.select_destinations(context, spec_obj)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/nova/scheduler/client/__init__.py\", line 37, in __run_method\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     return getattr(self.instance, __name)(*args, **kwargs)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/nova/scheduler/client/query.py\", line 32, in select_destinations\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     return self.scheduler_rpcapi.select_destinations(context, spec_obj)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/nova/scheduler/rpcapi.py\", line 129, in select_destinations\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     return cctxt.call(ctxt, 'select_destinations', **msg_args)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/oslo_messaging/rpc/client.py\", line 169, in call\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     retry=self.retry)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/oslo_messaging/transport.py\", line 97, in _send\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     timeout=timeout, retry=retry)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/oslo_messaging/_drivers/amqpdriver.py\", line 458, in send\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     retry=retry)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/oslo_messaging/_drivers/amqpdriver.py\", line 449, in _send\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     raise result\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager NoValidHost_Remote: No valid host was found. There are not enough hosts available.\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager Traceback (most recent call last):\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager \n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/oslo_messaging/rpc/server.py\", line 218, in inner\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     return func(*args, **kwargs)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager \n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/nova/scheduler/manager.py\", line 98, in select_destinations\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     dests = self.driver.select_destinations(ctxt, spec_obj)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager \n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager   File \"/usr/lib/python2.7/site-packages/nova/scheduler/filter_scheduler.py\", line 79, in select_destinations\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager     raise exception.NoValidHost(reason=reason)\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager \n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager NoValidHost: No valid host was found. There are not enough hosts available.\n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager \n2017-02-09 08:39:51.132 243236 ERROR nova.conductor.manager \n", 
            "date_created": "2017-02-09 13:13:31.693666+00:00", 
            "author": "https://api.launchpad.net/1.0/~gcerami"
        }, 
        {
            "content": "I investigated this one and it happens for all ovb-updates job. I'm almost sure it's related to IPv6.\n\nNova Placement API that runs on the controller in WSGi with Apache is binded on IPv6 interface, but somehow the nova-compute process fails to reach the service:\nhttp://logs.openstack.org/95/414395/5/check-tripleo/gate-tripleo-ci-centos-7-ovb-updates/0e8a0f5/logs/overcloud-novacompute-0/var/log/nova/nova-compute.txt.gz#_2017-02-11_19_16_11_161\n\n\"Placement API service is not responding\".\nThis error is related to networking and this is not about Keystone authorization or anything else.\n\nWe need to investigate if Compute node can reach this service by using the public endpoint (ipv6), otherwise we might need to run this service on ipv4 by using internal endpoint. I'm testing that on https://review.openstack.org/#/c/432761/", 
            "date_created": "2017-02-12 14:04:45.079846+00:00", 
            "author": "https://api.launchpad.net/1.0/~emilienm"
        }, 
        {
            "content": "I confirm https://review.openstack.org/#/c/432761/ helps to fix Ipv6 deployments. Now I'm not sure if whether or not I took the right approach. Help is welcome!", 
            "date_created": "2017-02-12 16:24:15.882674+00:00", 
            "author": "https://api.launchpad.net/1.0/~emilienm"
        }, 
        {
            "content": "Seems to me that this is also a nova issue, as the interface to be used should be configurable.", 
            "date_created": "2017-02-13 05:48:51.209623+00:00", 
            "author": "https://api.launchpad.net/1.0/~juan-osorio-robles"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/432855", 
            "date_created": "2017-02-13 06:03:22.885170+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Juan Antonio Osorio Robles (<email address hidden>) on branch: master\nReview: https://review.openstack.org/432855", 
            "date_created": "2017-02-13 06:06:52.508495+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Somebody had uploaded a fix before me: https://review.openstack.org/#/c/426163/6", 
            "date_created": "2017-02-13 06:07:18.322168+00:00", 
            "author": "https://api.launchpad.net/1.0/~juan-osorio-robles"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/432864", 
            "date_created": "2017-02-13 06:22:01.237340+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "There is presumably something more weird going on than the endpoint simply not being reachable, let's try a different one. Because the placement API only exposes itself as a wsgi application, any problems with reaching it are either with how it has been listed in keystone or how the wsgi server (in this case apache with mod wsgi) has been configured, both of which are entirely in the domain (in this case) of the puppet files. So something is weird with how the network is setup, and working around that seems like it is just hiding a bug or at least a misunderstanding of how the network is configured. Is the goal that the n-cpu and nova-scheduler hosting boxes can reach the IPV6 network?\n\n\nIn any case, this patch which you may already know about may be helpful: https://review.openstack.org/#/c/426163/", 
            "date_created": "2017-02-13 11:38:07.943975+00:00", 
            "author": "https://api.launchpad.net/1.0/~cdent"
        }, 
        {
            "content": "Change abandoned by Emilien Macchi (<email address hidden>) on branch: master\nReview: https://review.openstack.org/432761\nReason: https://review.openstack.org/#/c/432864/", 
            "date_created": "2017-02-13 12:09:54.378181+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "I suspect the reason this breaks on our ipv6 jobs is that our compute nodes are not directly connected to the public network.  I think we get away with it on ipv4 because we have forwarding rules set up on the undercloud that indirectly allows the compute nodes access to the public api endpoints, but I suspect those rules don't allow ipv4 to ipv6 forwarding.  Also, that forwarding is not a requirement and it's not something we should rely on because it sends all of that traffic over the provisioning network.\n\nSo I think on the tripleo side we just need to make use of the new nova option and move placement to the internal network so the compute nodes have direct access.", 
            "date_created": "2017-02-13 16:32:18.785020+00:00", 
            "author": "https://api.launchpad.net/1.0/~bnemec"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/432864\nCommitted: https://git.openstack.org/cgit/openstack/tripleo-heat-templates/commit/?id=ca843e18824f8ff5bfe2f576ad2afb894a16d2f4\nSubmitter: Jenkins\nBranch:    master\n\ncommit ca843e18824f8ff5bfe2f576ad2afb894a16d2f4\nAuthor: Juan Antonio Osorio Robles <email address hidden>\nDate:   Mon Feb 13 08:20:16 2017 +0200\n\n    Configure the placement API's interface to use the internal endpoint\n    \n    Due to the keystoneauth library's defaults, it uses the public interface\n    currently. This is not desirable in most cases (specially when using\n    network isolation); so we set it to use the internal one.\n    \n    Change-Id: Ic222a2b734f4d512349fd8556aa2864b13a1eb07\n    Depends-On: I1c7fd3a32d04e2fafb3820d1c1f221f45c613c83\n    Closes-Bug: #1663187\n", 
            "date_created": "2017-02-14 00:38:28.373266+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/tripleo-heat-templates 6.0.0.0rc1 release candidate.", 
            "date_created": "2017-02-16 12:56:36.922831+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}