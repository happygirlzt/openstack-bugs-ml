{
    "status": "Fix Released", 
    "last_updated": "2016-11-17 13:11:57.270156+00:00", 
    "description": "nova master\ndevstack multinode with 2 compute nodes\n1. booting vm with direct port\n2. nova migrate 128a2ba4-fb6e-49f4-a6e0-45cde1c60215\n3. nova resize-confirm 128a2ba4-fb6e-49f4-a6e0-45cde1c60215\n4. nova migrate 128a2ba4-fb6e-49f4-a6e0-45cde1c60215\n5. nova resize-confirm 128a2ba4-fb6e-49f4-a6e0-45cde1c60215\n\nThe second migration failed with this error:\n\n2016-09-12 13:12:45.750 8388 DEBUG oslo_concurrency.lockutils [req-a4a0126a-215a-489a-b043-ad38d3b5e28d - -] Lock \"compute_resources\" released by \"nova.compute.resource_tracker._update_available_resource\" :: held 0.143s inner /usr/lib/python2.7/site-packages/oslo_concurrency/lockutils.py:282\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager [req-a4a0126a-215a-489a-b043-ad38d3b5e28d - -] Error updating resources for node r-dcs224.mtr.labs.mlnx.\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager Traceback (most recent call last):\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/compute/manager.py\", line 6408, in update_available_resource_for_node\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     rt.update_available_resource(context)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/compute/resource_tracker.py\", line 526, in update_available_resource\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     self._update_available_resource(context, resources)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/usr/lib/python2.7/site-packages/oslo_concurrency/lockutils.py\", line 271, in inner\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     return f(*args, **kwargs)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/compute/resource_tracker.py\", line 580, in _update_available_resource\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     self.pci_tracker.clean_usage(instances, migrations, orphans)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/pci/manager.py\", line 326, in clean_usage\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     self._free_device(dev)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/pci/manager.py\", line 270, in _free_device\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     freed_devs = dev.free(instance)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/objects/pci_device.py\", line 397, in free\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     hopestatus=ok_statuses)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager PciDeviceInvalidStatus: PCI device 3:0000:03:00.5 is available instead of ('allocated', 'claimed')\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager\n2016-09-12 13:12:46.220 8388 DEBUG oslo_service.periodic_task [req-a4a0126a-215a-489a-b043-ad38d3b5e28d - -] Running periodic task ComputeManager._sync_scheduler_instance_info run_periodic_tasks /usr/lib/python2.7/site-packages/oslo_service/periodic_task.py:215", 
    "tags": [
        "compute", 
        "newton-backport-potential", 
        "pci", 
        "resize"
    ], 
    "importance": "Medium", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1622854", 
    "owner": "https://api.launchpad.net/1.0/~berrange", 
    "id": 1622854, 
    "index": 4624, 
    "created": "2016-09-13 06:33:06.575510+00:00", 
    "title": "pci: double pci migration is putting vm in ERROR", 
    "comments": [
        {
            "content": "nova master\ndevstack multinode with 2 compute nodes\n1. booting vm with direct port\n2. nova migrate 128a2ba4-fb6e-49f4-a6e0-45cde1c60215\n3. nova resize-confirm 128a2ba4-fb6e-49f4-a6e0-45cde1c60215\n4. nova migrate 128a2ba4-fb6e-49f4-a6e0-45cde1c60215\n5. nova resize-confirm 128a2ba4-fb6e-49f4-a6e0-45cde1c60215\n\nThe second migration failed with this error:\n\n2016-09-12 13:12:45.750 8388 DEBUG oslo_concurrency.lockutils [req-a4a0126a-215a-489a-b043-ad38d3b5e28d - -] Lock \"compute_resources\" released by \"nova.compute.resource_tracker._update_available_resource\" :: held 0.143s inner /usr/lib/python2.7/site-packages/oslo_concurrency/lockutils.py:282\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager [req-a4a0126a-215a-489a-b043-ad38d3b5e28d - -] Error updating resources for node r-dcs224.mtr.labs.mlnx.\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager Traceback (most recent call last):\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/compute/manager.py\", line 6408, in update_available_resource_for_node\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     rt.update_available_resource(context)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/compute/resource_tracker.py\", line 526, in update_available_resource\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     self._update_available_resource(context, resources)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/usr/lib/python2.7/site-packages/oslo_concurrency/lockutils.py\", line 271, in inner\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     return f(*args, **kwargs)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/compute/resource_tracker.py\", line 580, in _update_available_resource\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     self.pci_tracker.clean_usage(instances, migrations, orphans)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/pci/manager.py\", line 326, in clean_usage\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     self._free_device(dev)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/pci/manager.py\", line 270, in _free_device\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     freed_devs = dev.free(instance)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager   File \"/.autodirect/mtrswgwork/moshele/openstack/nova/nova/objects/pci_device.py\", line 397, in free\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager     hopestatus=ok_statuses)\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager PciDeviceInvalidStatus: PCI device 3:0000:03:00.5 is available instead of ('allocated', 'claimed')\n2016-09-12 13:12:45.750 8388 ERROR nova.compute.manager\n2016-09-12 13:12:46.220 8388 DEBUG oslo_service.periodic_task [req-a4a0126a-215a-489a-b043-ad38d3b5e28d - -] Running periodic task ComputeManager._sync_scheduler_instance_info run_periodic_tasks /usr/lib/python2.7/site-packages/oslo_service/periodic_task.py:215", 
            "date_created": "2016-09-13 06:33:06.575510+00:00", 
            "author": "https://api.launchpad.net/1.0/~moshele"
        }, 
        {
            "content": "So, it's a regression, it's why I added the newton RC potential tag. That said, discussing with Moshe on IRC, maybe it's okay to just not block RC1 for that bug, and ask for rather a backport.\n", 
            "date_created": "2016-09-13 10:03:38.255207+00:00", 
            "author": "https://api.launchpad.net/1.0/~sylvain-bauza"
        }, 
        {
            "content": "I thought migration with PCI devices attached didn't work before Newton, so is this really a regression from Mitaka?", 
            "date_created": "2016-09-13 15:15:50.361097+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "@Matt, \nIt is just regression for newton ", 
            "date_created": "2016-11-02 08:53:07.730755+00:00", 
            "author": "https://api.launchpad.net/1.0/~moshele"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/369180\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=6689c96cdfaa148037dc5df2baa058b09a075ec7\nSubmitter: Jenkins\nBranch:    master\n\ncommit 6689c96cdfaa148037dc5df2baa058b09a075ec7\nAuthor: Moshe Levi <email address hidden>\nDate:   Tue Sep 13 09:30:59 2016 +0300\n\n    pci: remove pci device from claims and allocations when freeing it\n    \n    In drop_move_claim we call free pci device when we need to drop a\n    specific device from the src/dest node. This is done by calling\n    pci manager free_device. The current code just update the device\n    status to available in database but doesn't remove it from the\n    pci manager claims and allocations lists. This patch adds the\n    removal as well.\n    \n    Closes-Bug: #1622854\n    \n    Change-Id: If1cd6f3a635759cd55d116a34ca164630c61e085\n", 
            "date_created": "2016-11-03 17:20:03.570985+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 15.0.0.0b1 development milestone.", 
            "date_created": "2016-11-17 13:11:56.492402+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}