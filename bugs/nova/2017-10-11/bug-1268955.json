{
    "status": "Fix Released", 
    "last_updated": "2016-08-16 05:09:39.858826+00:00", 
    "description": "Environment\n==========\n- Xen Server 6.2\n- OpenStack Havana installed with Packstack\n- Neutron OVS agent using VLAN\n\nFrom time to time, when an instance is started, it fails to get network connectivity. As a result the instance cannot get its IP address from DHCP and it remains unreachable.\n\nAfter further investigation, it appears that the OVS agent running on the compute node is updating the wrong OVS port because on startup, 2 ports exist for the same instance: vifX.0 and tapX.0. The agent updates whatever port is returned in first position (see logs below). Note that the tapX.0 port is only transient and disappears after a few seconds.\n\nWorkaround\n==========\n\nManually update the OVS port on dom0:\n\n$ ovs-vsctl set Port vif17.0 tag=1\n\nOVS Agent logs\n============\n\n2014-01-14 14:15:11.382 18268 DEBUG neutron.agent.linux.utils [-] Running command: ['/usr/bin/neutron-rootwrap-xen-dom0', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=2', '--', '--columns=external_ids,name,ofport', 'find', 'Interface', 'external_ids:iface-id=\"98679ab6-b879-4b1b-a524-01696959d468\"'] execute /usr/lib/python2.6/site-packages/neutron/agent/linux/utils.py:43\n2014-01-14 14:15:11.403 18268 DEBUG qpid.messaging.io.raw [-] SENT[3350c68]: '\\x0f\\x01\\x00\\x19\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\n\\x01\\x00\\x07\\x00\\x010\\x00\\x00\\x00\\x00\\x01\\x0f\\x00\\x00\\x1a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\n\\x01\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x81' writeable /usr/lib/python2.6/site-packages/qpid/messaging/driver.py:480\n2014-01-14 14:15:11.649 18268 DEBUG neutron.agent.linux.utils [-]\nCommand: ['/usr/bin/neutron-rootwrap-xen-dom0', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=2', '--', '--columns=external_ids,name,ofport', 'find', 'Interface', 'external_ids:iface-id=\"98679ab6-b879-4b1b-a524-01696959d468\"']\nExit code: 0\nStdout: 'external_ids        : {attached-mac=\"fa:16:3e:46:1e:91\", iface-id=\"98679ab6-b879-4b1b-a524-01696959d468\", iface-status=active, xs-network-uuid=\"b2bf90df-be17-a4ff-5c1e-3d69851f508a\", xs-vif-uuid=\"2d2718d8-6064-e734-2737-cdcb4e06efc4\", xs-vm-uuid=\"7f7f1918-3773-d97c-673a-37843797f70a\"}\\nname                : \"tap29.0\"\\nofport              : 52\\n\\nexternal_ids        : {attached-mac=\"fa:16:3e:46:1e:91\", iface-id=\"98679ab6-b879-4b1b-a524-01696959d468\", iface-status=inactive, xs-network-uuid=\"b2bf90df-be17-a4ff-5c1e-3d69851f508a\", xs-vif-uuid=\"2d2718d8-6064-e734-2737-cdcb4e06efc4\", xs-vm-uuid=\"7f7f1918-3773-d97c-673a-37843797f70a\"}\\nname                : \"vif29.0\"\\nofport              : 51\\n\\n'\nStderr: '' execute /usr/lib/python2.6/site-packages/neutron/agent/linux/utils.py:60\n2014-01-14 14:15:11.650 18268 INFO neutron.plugins.openvswitch.agent.ovs_neutron_agent [-] Port 98679ab6-b879-4b1b-a524-01696959d468 updated. Details: {u'admin_state_up': True, u'network_id': u'ad37f107-074b-4c58-8f36-4705533afb8d', u'segmentation_id': 100, u'physical_network': u'default', u'device': u'98679ab6-b879-4b1b-a524-01696959d468', u'port_id': u'98679ab6-b879-4b1b-a524-01696959d468', u'network_type': u'vlan'}\n2014-01-14 14:15:11.650 18268 DEBUG neutron.agent.linux.utils [-] Running command: ['/usr/bin/neutron-rootwrap-xen-dom0', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=2', 'set', 'Port', 'tap29.0', 'tag=1'] execute /usr/lib/python2.6/site-packages/neutron/agent/linux/utils.py:43\n2014-01-14 14:15:11.913 18268 DEBUG neutron.agent.linux.utils [-]\nCommand: ['/usr/bin/neutron-rootwrap-xen-dom0', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=2', 'set', 'Port', 'tap29.0', 'tag=1']\nExit code: 0\nStdout: '\\n'\nStderr: '' execute /usr/lib/python2.6/site-packages/neutron/agent/linux/utils.py:60", 
    "tags": [
        "ovs", 
        "xenserver"
    ], 
    "importance": "Undecided", 
    "heat": 24, 
    "link": "https://bugs.launchpad.net/nova/+bug/1268955", 
    "owner": "None", 
    "id": 1268955, 
    "index": 4468, 
    "created": "2014-01-14 13:17:28.153932+00:00", 
    "title": "OVS agent updates the wrong port when using XenAPI + Neutron with HVM or PVHVM", 
    "comments": [
        {
            "content": "Environment\n==========\n- Xen Server 6.2\n- OpenStack Havana installed with Packstack\n- Neutron OVS agent using VLAN\n\nFrom time to time, when an instance is started, it fails to get network connectivity. As a result the instance cannot get its IP address from DHCP and it remains unreachable.\n\nAfter further investigation, it appears that the OVS agent running on the compute node is updating the wrong OVS port because on startup, 2 ports exist for the same instance: vifX.0 and tapX.0. The agent updates whatever port is returned in first position (see logs below). Note that the tapX.0 port is only transient and disappears after a few seconds.\n\nWorkaround\n==========\n\nManually update the OVS port on dom0:\n\n$ ovs-vsctl set Port vif17.0 tag=1\n\nOVS Agent logs\n============\n\n2014-01-14 14:15:11.382 18268 DEBUG neutron.agent.linux.utils [-] Running command: ['/usr/bin/neutron-rootwrap-xen-dom0', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=2', '--', '--columns=external_ids,name,ofport', 'find', 'Interface', 'external_ids:iface-id=\"98679ab6-b879-4b1b-a524-01696959d468\"'] execute /usr/lib/python2.6/site-packages/neutron/agent/linux/utils.py:43\n2014-01-14 14:15:11.403 18268 DEBUG qpid.messaging.io.raw [-] SENT[3350c68]: '\\x0f\\x01\\x00\\x19\\x00\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x04\\n\\x01\\x00\\x07\\x00\\x010\\x00\\x00\\x00\\x00\\x01\\x0f\\x00\\x00\\x1a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\n\\x01\\x00\\x00\\x08\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x81' writeable /usr/lib/python2.6/site-packages/qpid/messaging/driver.py:480\n2014-01-14 14:15:11.649 18268 DEBUG neutron.agent.linux.utils [-]\nCommand: ['/usr/bin/neutron-rootwrap-xen-dom0', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=2', '--', '--columns=external_ids,name,ofport', 'find', 'Interface', 'external_ids:iface-id=\"98679ab6-b879-4b1b-a524-01696959d468\"']\nExit code: 0\nStdout: 'external_ids        : {attached-mac=\"fa:16:3e:46:1e:91\", iface-id=\"98679ab6-b879-4b1b-a524-01696959d468\", iface-status=active, xs-network-uuid=\"b2bf90df-be17-a4ff-5c1e-3d69851f508a\", xs-vif-uuid=\"2d2718d8-6064-e734-2737-cdcb4e06efc4\", xs-vm-uuid=\"7f7f1918-3773-d97c-673a-37843797f70a\"}\\nname                : \"tap29.0\"\\nofport              : 52\\n\\nexternal_ids        : {attached-mac=\"fa:16:3e:46:1e:91\", iface-id=\"98679ab6-b879-4b1b-a524-01696959d468\", iface-status=inactive, xs-network-uuid=\"b2bf90df-be17-a4ff-5c1e-3d69851f508a\", xs-vif-uuid=\"2d2718d8-6064-e734-2737-cdcb4e06efc4\", xs-vm-uuid=\"7f7f1918-3773-d97c-673a-37843797f70a\"}\\nname                : \"vif29.0\"\\nofport              : 51\\n\\n'\nStderr: '' execute /usr/lib/python2.6/site-packages/neutron/agent/linux/utils.py:60\n2014-01-14 14:15:11.650 18268 INFO neutron.plugins.openvswitch.agent.ovs_neutron_agent [-] Port 98679ab6-b879-4b1b-a524-01696959d468 updated. Details: {u'admin_state_up': True, u'network_id': u'ad37f107-074b-4c58-8f36-4705533afb8d', u'segmentation_id': 100, u'physical_network': u'default', u'device': u'98679ab6-b879-4b1b-a524-01696959d468', u'port_id': u'98679ab6-b879-4b1b-a524-01696959d468', u'network_type': u'vlan'}\n2014-01-14 14:15:11.650 18268 DEBUG neutron.agent.linux.utils [-] Running command: ['/usr/bin/neutron-rootwrap-xen-dom0', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=2', 'set', 'Port', 'tap29.0', 'tag=1'] execute /usr/lib/python2.6/site-packages/neutron/agent/linux/utils.py:43\n2014-01-14 14:15:11.913 18268 DEBUG neutron.agent.linux.utils [-]\nCommand: ['/usr/bin/neutron-rootwrap-xen-dom0', '/etc/neutron/rootwrap.conf', 'ovs-vsctl', '--timeout=2', 'set', 'Port', 'tap29.0', 'tag=1']\nExit code: 0\nStdout: '\\n'\nStderr: '' execute /usr/lib/python2.6/site-packages/neutron/agent/linux/utils.py:60", 
            "date_created": "2014-01-14 13:17:28.153932+00:00", 
            "author": "https://api.launchpad.net/1.0/~simon-pasquier"
        }, 
        {
            "content": "I just realized that this is because I'm using HVM instances. In that case, Xen Server creates 1 vif and 1 tap and it deletes the tap interface if the domU is able to load the virtualized Xen driver for the NIC.\nSee http://lists.xen.org/archives/html/xen-devel/2011-12/msg02085.html", 
            "date_created": "2014-01-14 13:58:20.261359+00:00", 
            "author": "https://api.launchpad.net/1.0/~simon-pasquier"
        }, 
        {
            "content": "Can this happen only on initial VM creation or is it possible during every startup?\n\nHave you been able to isolate which file contains the errant code?\n\nAs I see it, these are the candidates (my nodes are Debian 7.3, so slightly different locations):\n/usr/share/pyshared/neutron/agent/linux/utils.py\n/usr/share/pyshared/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py\n/usr/bin/neutron-rootwrap-xen-dom0\n/etc/xapi.d/plugins/netwrap in dom0\n\nSomething is possibly using too loose a filtering method when selecting which interface to tag.", 
            "date_created": "2014-02-13 05:01:36.133788+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "The issue might happen every time the instance starts.\n\nAFAIU, there is no problem with the neutron OVS agent code. The issue is that the command executed by OVSBridge.get_vif_port_by_id() method [1] returns 2 rows. In all other cases (KVM, Xen PV, ...), this command returns only one row because there is only one port matching a given \"external_ids:iface-id\". The get_vif_port_by_id() method is called by the OVS agent on every added or updated port [2].\n\n[1] https://github.com/openstack/neutron/blob/aa85a97ca2dcb06996ed133d864705f1dca722b1/neutron/agent/linux/ovs_lib.py#L379\n[2] https://github.com/openstack/neutron/blob/aa85a97ca2dcb06996ed133d864705f1dca722b1/neutron/plugins/openvswitch/agent/ovs_neutron_agent.py#L934", 
            "date_created": "2014-02-13 08:49:04.848097+00:00", 
            "author": "https://api.launchpad.net/1.0/~simon-pasquier"
        }, 
        {
            "content": "This also appears to affect Debian VMs created from the package openstack-debian-image. It appears that it starts out in HVM mode and then switches to PV drivers mid-way through boot, manifesting with an untagged OVS port in dom0. If I restart the OVS agent that manages OVS ports in dom0, the tag gets placed properly. By then, it's too late for dhcp and cloud-init, so the VM never gets network or metadata.\n\nI suspect that it's because the flags supplied with the image in glance aren't set properly, but I'm still investigating. I thought I remembered reading that you can set something in glance along with the image to define the target hypervisor and virtualization method.", 
            "date_created": "2014-02-13 21:34:09.146420+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "I'm checking to see if adding metadata to the image resolves the issue. It doesn't \"fix\" the bug, but it's a much more viable workaround than manually updating the OVS port tag on every creation/reboot. I'll report back soon.\nhttp://docs.openstack.org/image-guide/content/image-metadata.html", 
            "date_created": "2014-02-13 22:23:48.814801+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "VM image properties do not seem to make a difference. Some \"nova boot\" commands result in the OVS port in dom0 getting the proper tag (everything works) and some show the results detailed in this bug report (dhcp and metadata retrieval fail due to missing VLAN tag on OVS port in dom0).", 
            "date_created": "2014-02-13 23:18:40.767466+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "I did note, however, that restarting the VM or restarting the OVS agent plugin that works in dom0 applies the proper tags at that moment. VM creation (vs reboot) still experiences the same issue for the same reasons outlined above (HVM to PV change).", 
            "date_created": "2014-02-13 23:25:47.590369+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "I guess the issue with Debian Wheezy (7.3) is that it uses a PVHVM kernel. PVHVM seems to be subject to this issue as well. Debian being incapable of running on OpenStack if XenServer is the hypervisor seems like a pretty big issue. Not to mention Windows. It makes OpenStack with XenServer practically unusable with neutron and VLANs.\n\nI'm not a coder. I can look around in code and get a general idea what is happening, but I wouldn't know how to trace or patch this issue. How do we get someone with skills to look at this issue?", 
            "date_created": "2014-02-13 23:59:36.147106+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "It's just random dumb luck when the OVS port gets tagged on VM reboot.\n\nDebian 7.3 VM OVS ports in dom0 at creation or boot/reboot (ovs-vsctl show):\n        Port \"tap33.0\"\n            Interface \"tap33.0\"\n        Port \"vif33.0\"\n            Interface \"vif33.0\"\n\nAfter some time has elapsed (a few seconds), that changes to:\n        Port \"vif33.0\"\n            tag: 5\n            Interface \"vif33.0\"\nor\n        Port \"vif33.0\"\n            Interface \"vif33.0\"\n\ndepending on which of the two initial ports got the tag.\n\nConsidering that conventional linux kernel wisdom of the day is that PVHVM is better than straight PV and most distributions are working to utilize upstream built-in PVHVM support, this bug affects pretty much every new operating system. The only ones immune are older operating systems that are still using the paradigm of strictly PV. Strictly PV isn't even available in the kernel packages for Debian 7 (wheezy) like it was in Debian 6 (squeeze) or Debian 5 (lenny).", 
            "date_created": "2014-02-14 01:38:37.043102+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "@Andrew\n\nWhat you described in the previous comment is exactly what I explained in the original description. I'll try to propose a fix in the next weeks.", 
            "date_created": "2014-02-14 08:30:23.746908+00:00", 
            "author": "https://api.launchpad.net/1.0/~simon-pasquier"
        }, 
        {
            "content": "@Simon\n\nI thought it worthwhile to demonstrate that the failure mode for PVHVM was the same as HVM. PVHVM is becoming ubiquitous in the Linux world since it is more performant than plain PV or plain HVM. It's also how the mainline Linux kernel supports Xen. Nobody even makes PV only Linux kernels any more unless they're done directly from xensource.\n\nI'm going to be examining a potential temporary workaround. Since the timing of the call to get_vif_port_by_id() method can impact whether it gets one or two rows in response, I'm looking into inserting a delay of a few seconds just before that call. I know it's not a real fix, but it's a possible workaround that I think I can muddle through with my limited knowledge of python.", 
            "date_created": "2014-02-14 18:42:37.333694+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "Workaround (not a real fix!):\nOn the node with the OVS agent controlling network in dom0 in /usr/share/pyshared/neutron/agent/linux/ovs_lib.py\n\nadd to the top near the other import statements:\nimport time\n\nChange this:\n    def get_vif_port_by_id(self, port_id):\n         args = ['--', '--columns=external_ids,name,ofport',\n                'find', 'Interface',\n                'external_ids:iface-id=\"%s\"' % port_id]\n        result = self.run_vsctl(args)\n\nto this:\n    def get_vif_port_by_id(self, port_id):\n        time.sleep(8)\n        args = ['--', '--columns=external_ids,name,ofport',\n                'find', 'Interface',\n                'external_ids:iface-id=\"%s\"' % port_id]\n        result = self.run_vsctl(args)\n\n\nOn my system, the tap interface has a life of 5 to 6 seconds at current load levels (mostly idle). If the sleep is 10 seconds, it interferes with the DHCP request emitted from within the VM, so I split the difference and set it to 8 seconds. Obviously, this will vary by machine and load levels, so it is by no means adequate as a real fix. It just increases the success rate of getting the tag on the proper port in dom0 before DHCP sends its first request from within the VM. A side effect is that it takes that number of seconds longer before networking is functional again when restarting the OVS agent that controls dom0.", 
            "date_created": "2014-02-14 21:07:47.750433+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "@Andrew\n\nI've modified the title of the bug to mention that it would happen with PVHVM too.", 
            "date_created": "2014-02-17 09:59:24.175105+00:00", 
            "author": "https://api.launchpad.net/1.0/~simon-pasquier"
        }, 
        {
            "content": "Will the following touch the code path for this bug as well?\nhttps://review.openstack.org/#/c/66375/", 
            "date_created": "2014-02-18 01:11:17.159164+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "This also badly affects HVM instances where both the vif and the tap interface remain instead of one of the two being removed. You can see from the following output from \"ovs-vsctl show\" (trimmed and grouped for easier reading) that it is indeterminate which of the vif or tap will get the tag.\n\n        Port \"tap81.0\"\n            tag: 3\n            Interface \"tap81.0\"\n        Port \"vif81.0\"\n            Interface \"vif81.0\"\n\n        Port \"tap81.1\"\n            Interface \"tap81.1\"\n        Port \"vif81.1\"\n            tag: 2\n            Interface \"vif81.1\"\n\n        Port \"tap81.2\"\n            Interface \"tap81.2\"\n        Port \"vif81.2\"\n            tag: 4\n            Interface \"vif81.2\"\n\n        Port \"tap81.3\"\n            Interface \"tap81.3\"\n        Port \"vif81.3\"\n            tag: 5\n            Interface \"vif81.3\"\n", 
            "date_created": "2014-02-25 23:11:04.941317+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "Yes, the review you mentioned in comment #14 would probably fix the issue when only the vif interface remains. In which case would the vif and tap interfaces remain together?", 
            "date_created": "2014-02-26 09:26:03.376327+00:00", 
            "author": "https://api.launchpad.net/1.0/~simon-pasquier"
        }, 
        {
            "content": "An HVM domU without any PV drivers keeps the tap *and* vif interfaces.\n\nXenServer provides both tap and vif interfaces to an HVM domU. If the HVM domU employs PV drivers, activating the PV drivers tells XenServer to rip out the tap interfaces and keep the vif interfaces. If no PV drivers are employed in the HVM domU, the tap interfaces are used by the domU and XenServer continues to supply the vif interfaces \"just in case\" the domU installs PV drivers later.\n\nUnfortunately, in this situation, my workaround does not correct the problem. Sometimes the vif gets the tag and sometimes the tap gets the tag. For an HVM domU without PV drivers, the network interface inside the domU can only pass traffic if the tap interface gets the tag. It is extremely \"lucky\" when multiple interfaces of such a domU get tags on all the tap interfaces all at the same time.", 
            "date_created": "2014-02-26 22:30:28.866841+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "https://review.openstack.org/#/c/66375/\nactually makes the problem worse and it's about to be merged. With those patches, no ports get tags now. I think this comment is key in the new ovs_lib.py in get_vif_port_by_id():\n# We won't deal with the possibility of ovs-vsctl return multiple\n# rows since the interface identifier is unique\n\nIt typifies the current thinking, which incorrect in the case of XenServer. How do we get them to change course on this?", 
            "date_created": "2014-02-28 03:16:14.371231+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "https://review.openstack.org/#/c/66375/\napparently requires other changes and silently crashed the ovs agent with no message to the log. That's why no tags were applied. I'm in the process of tracking down where the error messages might have landed to see what went wrong.", 
            "date_created": "2014-02-28 04:10:54.911995+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "There were no messages in any logs about why the ovs agent crashed, so I've rolled back the changes from https://review.openstack.org/#/c/66375/\n\nShort of doing a git pull and building everything from source, I think I'm SOL until I see it come down the pipeline for Debian packages.", 
            "date_created": "2014-02-28 05:02:44.856095+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "Thanks for the deep dive, Andrew :)\n\nFWIW, the comment you mentioned (\"We won't deal with the possibility of ovs-vsctl return multiple rows since the interface identifier is unique\") only states something that was already true before (eg Havana code). For reference, here is the associated commit => https://github.com/openstack/neutron/commit/3d24fe5710cbea6d7d1f88c3476f4a856347ab5e", 
            "date_created": "2014-02-28 09:16:18.090614+00:00", 
            "author": "https://api.launchpad.net/1.0/~simon-pasquier"
        }, 
        {
            "content": "From a XenServer perspective, I think the right answer is that both ports must be tagged.  I'd love some input from the Neutron guys around this.  The rationale is that the two interfaces are actually the same from the VMs perspective - it can only use one of them and will negotiate up to the PV interface if it can.\n\nHVM and PVHVM are effectively the same in this case as they are both using an HVM container and negotiate around the use of PV drivers.\n\nWe might also fix it by only tagging the tap port, then watching in dom0 for this going away and tagging the corresponding vif - but that might be racy since I think the driver negotiation doesn't have a hook that we could grab on to.", 
            "date_created": "2014-02-28 10:23:34.555449+00:00", 
            "author": "https://api.launchpad.net/1.0/~bob-ball"
        }, 
        {
            "content": "I like tagging both the vif and tap. It feels safe with less chance for odd corner cases.", 
            "date_created": "2014-02-28 20:44:23.758043+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "I don't think tagging them both is going to work. I've tried it by manually tagging the tap port when the vif port already has the tag. No go. I suspect it's because they both have the same MAC address.", 
            "date_created": "2014-03-09 19:50:32.055618+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "Simon,\nCan you add the tag havana-backport-potential to this bug report? It doesn't look like I have sufficient rights to do so or I'm missing something. I'd like to avoid upgrading to icehouse to get this fixed if I can avoid it.", 
            "date_created": "2014-03-13 00:17:10.379798+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "Andrew,\nThis is done. I notice that you removed your previous comment saying that tagging the 2 interfaces didn't work. Does it mean that it works indeed?", 
            "date_created": "2014-03-13 11:23:04.545593+00:00", 
            "author": "https://api.launchpad.net/1.0/~simon-pasquier"
        }, 
        {
            "content": "I don't know if it works. My previous test results were invalidated. I had done a re-install and defined the networks within the web gui (horizon) on the re-install versus defining the networks from command line previously. That caused the wrong physnet to be attached to the network definitions, resulting in a lack of proper OVS flow definition which caused *nothing* to work, no matter whether tags were there or not. I discovered this after making my comment and thought it prudent to retract the comment until I could retest.", 
            "date_created": "2014-03-13 19:32:47.814554+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "Our workaround so far has been to restart the \"neutron-plugin-openvswitch-agent\" service in the compute node after every VM reboot/start.\n\nAny progress on a real fix? Our clients don't have access to the \"neutron-plugin-openvswitch-agent\" service directly, so they have to open a support ticket with our staff every time they reboot/start any VM. As you can imagine, it's a royal pain for everyone and downright problematic when dealing with third parties that don't realize they need to schedule the reboot of the VM with our support staff.", 
            "date_created": "2014-05-06 01:45:56.688816+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "I think this will not be fixed in Havana.\nI wonder if Icehouse works fine for the described case.", 
            "date_created": "2014-06-16 11:03:15.884011+00:00", 
            "author": "https://api.launchpad.net/1.0/~enikanorov"
        }, 
        {
            "content": "Eugene,\nIt's a crying shame that it won't be fixed in Havana. The process to go from Havana to Icehouse is so frigging onerous you'd have to be high to attempt it. It's only practical to do a completely fresh install, but who has duplicate clusters sitting around to do those types of transitions with production systems?! Bovine feces!", 
            "date_created": "2014-07-19 00:06:12.262593+00:00", 
            "author": "https://api.launchpad.net/1.0/~andykinney"
        }, 
        {
            "content": "I can confirm that that problem remains in 2014.2.1. A race condition exists that if both the tap and vif device exists, there is a chance that ovs will try to add the tag the tap port.", 
            "date_created": "2015-02-26 18:53:48.501232+00:00", 
            "author": "https://api.launchpad.net/1.0/~h-thomas-carroll"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/233498", 
            "date_created": "2015-10-12 06:07:43.935746+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/237900", 
            "date_created": "2015-10-21 06:59:35.573415+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Jianghua Wang (<email address hidden>) on branch: master\nReview: https://review.openstack.org/233498\nReason: design changed; the new patch set is: https://review.openstack.org/#/c/237900/", 
            "date_created": "2015-10-21 07:06:55.257132+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Jianghua Wang (<email address hidden>) on branch: master\nReview: https://review.openstack.org/237900\nReason: After some discussion, it's not a good solution by tracking two ports in neutron. it's thought that may break the neutron design. So we will go with the solution with change in nova to add a interim bridge between VM and the integration bridge. So in the world of neutron, it need only monitor the patch port connecting the interim bridge to the integration bridge. In this way, the switch over case between active and inactive port is transparent to neutron. \n  So this patch set will be abandoned and the new solution will be covered by https://review.openstack.org/#/c/242846/\n  Thanks all.", 
            "date_created": "2015-11-10 01:58:22.934934+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "I've developed a work around that works at least for my environment. Note that I have security groups disabled. Following ovs-xapi-sync that copies external_ids between vif and taps, neutron-ovs-tag-sync monitors the ovsdb for changes to Port. tag and copies the tag from vifx to tapx and vice versa. In dom0, copy the script to dom0's /usr/share/openvswitch/scripts and execute it using\n\nPYTHONPATH=/usr/share/openvswitch/python /usr/share/openvswitch/scripts/neutron-ovs-tag-sync --log-file --pidfile --detach --monitor unix:/var/run/openvswitch/db.sock\n\nA startup script will be necessary to start the script after a reboot", 
            "date_created": "2016-01-12 21:06:39.893109+00:00", 
            "author": "https://api.launchpad.net/1.0/~h-thomas-carroll"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 14.0.0.0b2 development milestone.", 
            "date_created": "2016-07-14 13:01:04.321555+00:00", 
            "author": "https://api.launchpad.net/1.0/~doug-hellmann"
        }
    ]
}