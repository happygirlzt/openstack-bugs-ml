{
    "status": "Fix Released", 
    "last_updated": "2013-04-04 10:54:50.245724+00:00", 
    "description": "on most of the xen deploy's I've seen, the 'root_device_name' attribute on the instance is None, and instance_block_mapping will short-circuit the return path with-out evaluating bdms.\n\nThis is the attach request, after do_reserve has already returned the selected \"mountpoint\" (it's not really a *mount* is it?).\n\n2012-10-04 23:07:49 DEBUG nova.openstack.common.rpc.amqp [-] received {u'_context_roles': [u'admin'], u'_context_request_id': u'req-45592fb5-143b-4f40-a168-d1ff0c0c0aa4', u'_context_quota_class': None, u'_context_project_name': u'openStackCastleLab', u'_context_service_catalog': None, u'_context_user_name': u'clayg', u'_context_auth_token': '<SANITIZED>', u'args': {u'mountpoint': u'/dev/xvdb', u'instance': {u'vm_state': u'active', u'availability_zone': None, u'terminated_at': None, u'ephemeral_gb': 0, u'instance_type_id': 1, u'user_data': None, u'vm_mode': u'xen', u'deleted_at': None, u'reservation_id': u'r-pax0p2jn', u'id': 1, u'security_groups': [{u'deleted_at': None, u'user_id': u'ed4bd089a2f449dca0828a2c42dbfb77', u'name': u'default', u'deleted': False, u'created_at': u'2012-10-04T01:29:31.000000', u'updated_at': None, u'rules': [], u'project_id': u'3f4884d9c31d4393a11158e09b816a5b', u'id': 1, u'description': u'default'}], u'disable_terminate': False, u'user_id': u'ed4bd089a2f449dca0828a2c42dbfb77', u'uuid': u'6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca', u'server_name': None, u'default_swap_device': None, u'info_cache': {u'instance_uuid': u'6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca', u'deleted': False, u'created_at': u'2012-10-04T01:29:31.000000', u'updated_at': u'2012-10-04T01:29:34.000000', u'network_info': u'[{\"network\": {\"bridge\": \"xenbr0\", \"subnets\": [{\"ips\": [{\"meta\": {}, \"version\": 4, \"type\": \"fixed\", \"floating_ips\": [], \"address\": \"10.127.0.130\"}], \"version\": 4, \"meta\": {}, \"dns\": [{\"meta\": {}, \"version\": 4, \"type\": \"dns\", \"address\": \"10.6.23.4\"}, {\"meta\": {}, \"version\": 4, \"type\": \"dns\", \"address\": \"10.6.23.5\"}], \"routes\": [], \"cidr\": \"10.127.0.0/24\", \"gateway\": {\"meta\": {}, \"version\": 4, \"type\": \"gateway\", \"address\": \"10.127.0.1\"}}, {\"ips\": [], \"version\": null, \"meta\": {}, \"dns\": [], \"routes\": [], \"cidr\": null, \"gateway\": {\"meta\": {}, \"version\": null, \"type\": \"gateway\", \"address\": null}}], \"meta\": {\"tenant_id\": null}, \"id\": \"130460c1-8dd6-45d0-94bb-870777dc1f21\", \"label\": \"public\"}, \"meta\": {}, \"id\": \"0b8f347d-b301-439e-8b88-274a43f7cc2e\", \"address\": \"fa:16:3e:2a:89:f7\"}]', u'deleted_at': None, u'id': 1}, u'hostname': u'test01', u'launched_on': u'localhost.localdomain', u'display_description': u'test01', u'key_data': None, u'kernel_id': u'', u'power_state': 1, u'default_ephemeral_device': None, u'progress': 100, u'project_id': u'3f4884d9c31d4393a11158e09b816a5b', u'launched_at': u'2012-10-04T01:34:19.000000', u'scheduled_at': u'2012-10-04T01:29:31.000000', u'ramdisk_id': u'', u'access_ip_v6': None, u'access_ip_v4': None, u'deleted': False, u'key_name': None, u'updated_at': u'2012-10-04T01:35:30.000000', u'host': u'localhost.localdomain', u'display_name': u'test01', u'task_state': None, u'shutdown_terminate': False, u'architecture': None, u'root_gb': 40, u'locked': False, u'name': u'instance-6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca', u'created_at': u'2012-10-04T01:29:31.000000', u'launch_index': 0, u'metadata': [], u'memory_mb': 4096, u'instance_type': {u'disabled': False, u'root_gb': 40, u'deleted_at': None, u'name': u'm1.medium', u'deleted': False, u'created_at': None, u'ephemeral_gb': 0, u'updated_at': None, u'memory_mb': 4096, u'vcpus': 2, u'swap': 0, u'rxtx_factor': 1.0, u'is_public': True, u'flavorid': u'3', u'vcpu_weight': None, u'id': 1}, u'vcpus': 2, u'image_ref': u'6a86087a-2c71-4f50-90ae-1b884eb6bb22', u'root_device_name': None, u'auto_disk_config': None, u'os_type': None, u'config_drive': u''}, u'volume_id': u'bf5ddd27-6f8e-427b-b0a1-e66ad67c6bce'}, u'_context_instance_lock_checked': False, u'_context_is_admin': True, u'version': u'2.0', u'_context_project_id': u'3f4884d9c31d4393a11158e09b816a5b', u'_context_timestamp': u'2012-10-04T23:07:49.337942', u'_context_read_deleted': u'no', u'_context_user_id': u'ed4bd089a2f449dca0828a2c42dbfb77', u'method': u'attach_volume', u'_context_remote_address': u'10.6.61.108'} from (pid=4897) _safe_log /opt/nova/nova/openstack/common/rpc/common.py:195\n\nEven though this instance already had a \"auto device_name\" volume attached, the do_reserve is returning/attach call is sending:\n\n'mountpoint': u'/dev/xvdb'\n\nAnd the problem seems to mostly be the instance has:\n\n'root_device_name': None\n\nWhich unsurprisingly leads to a traceback:\n\n2012-10-04 23:08:59 ERROR nova.virt.xenapi.volumeops [req-c6af01f8-1d42-4f93-ada0-4fc217c56bdc ed4bd089a2f449dca0828a2c42dbfb77 3f4884d9c31d4393a11158e09b816a5b] ['DEVICE_ALREADY_EXISTS', '1']\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops Traceback (most recent call last):\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/opt/nova/nova/virt/xenapi/volumeops.py\", line 178, in attach_volume\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     dev_number, bootable=False)\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/opt/nova/nova/virt/xenapi/vm_utils.py\", line 332, in create_vbd\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     vbd_ref = session.call_xenapi('VBD.create', vbd_rec)\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/opt/nova/nova/virt/xenapi/driver.py\", line 714, in call_xenapi\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     return session.xenapi_request(method, args)\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/usr/local/lib/python2.6/dist-packages/XenAPI.py\", line 133, in xenapi_request\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     result = _parse_result(getattr(self, methodname)(*full_params))\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/usr/local/lib/python2.6/dist-packages/XenAPI.py\", line 203, in _parse_result\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     raise Failure(result['ErrorDescription'])\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops Failure: ['DEVICE_ALREADY_EXISTS', '1']\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops\n\nThere's some more in the error handling:\n\n2012-10-04 23:09:00 ERROR nova.compute.manager [req-c6af01f8-1d42-4f93-ada0-4fc217c56bdc ed4bd089a2f449dca0828a2c42dbfb77 3f4884d9c31d4393a11158e09b816a5b] [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca] Failed to attach volume 8d8b78b8-bff3-48fe-be34-a3d589076028 at /dev/xvdb\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca] Traceback (most recent call last):\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]   File \"/opt/nova/nova/compute/manager.py\", line 2001, in _attach_volume\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]     mountpoint)\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]   File \"/opt/nova/nova/virt/xenapi/driver.py\", line 381, in attach_volume\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]     mountpoint)\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]   File \"/opt/nova/nova/virt/xenapi/volumeops.py\", line 183, in attach_volume\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]     ' instance %(instance_name)s') % locals())\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca] Exception: Unable to use SR OpaqueRef:fd0c55a7-7584-2907-4791-654dd06428ed for instance instance-6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]", 
    "tags": [
        "attach", 
        "verification-needed", 
        "volume", 
        "xen"
    ], 
    "importance": "Medium", 
    "heat": 14, 
    "link": "https://bugs.launchpad.net/nova/+bug/1061944", 
    "owner": "https://api.launchpad.net/1.0/~clay-gerrard", 
    "id": 1061944, 
    "index": 3089, 
    "created": "2012-10-04 23:15:58.446856+00:00", 
    "title": "xen volume auto device selection always picks xvdb", 
    "comments": [
        {
            "content": "on most of the xen deploy's I've seen, the 'root_device_name' attribute on the instance is None, and instance_block_mapping short-circuit the return path with-out evaluating bdms.\n\nThis is the attach request, after do_reserve has already returned the selected \"mountpoint\" (it's not really a *mount* is it?).\n\n2012-10-04 23:07:49 DEBUG nova.openstack.common.rpc.amqp [-] received {u'_context_roles': [u'admin'], u'_context_request_id': u'req-45592fb5-143b-4f40-a168-d1ff0c0c0aa4', u'_context_quota_class': None, u'_context_project_name': u'openStackCastleLab', u'_context_service_catalog': None, u'_context_user_name': u'clayg', u'_context_auth_token': '<SANITIZED>', u'args': {u'mountpoint': u'/dev/xvdb', u'instance': {u'vm_state': u'active', u'availability_zone': None, u'terminated_at': None, u'ephemeral_gb': 0, u'instance_type_id': 1, u'user_data': None, u'vm_mode': u'xen', u'deleted_at': None, u'reservation_id': u'r-pax0p2jn', u'id': 1, u'security_groups': [{u'deleted_at': None, u'user_id': u'ed4bd089a2f449dca0828a2c42dbfb77', u'name': u'default', u'deleted': False, u'created_at': u'2012-10-04T01:29:31.000000', u'updated_at': None, u'rules': [], u'project_id': u'3f4884d9c31d4393a11158e09b816a5b', u'id': 1, u'description': u'default'}], u'disable_terminate': False, u'user_id': u'ed4bd089a2f449dca0828a2c42dbfb77', u'uuid': u'6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca', u'server_name': None, u'default_swap_device': None, u'info_cache': {u'instance_uuid': u'6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca', u'deleted': False, u'created_at': u'2012-10-04T01:29:31.000000', u'updated_at': u'2012-10-04T01:29:34.000000', u'network_info': u'[{\"network\": {\"bridge\": \"xenbr0\", \"subnets\": [{\"ips\": [{\"meta\": {}, \"version\": 4, \"type\": \"fixed\", \"floating_ips\": [], \"address\": \"10.127.0.130\"}], \"version\": 4, \"meta\": {}, \"dns\": [{\"meta\": {}, \"version\": 4, \"type\": \"dns\", \"address\": \"10.6.23.4\"}, {\"meta\": {}, \"version\": 4, \"type\": \"dns\", \"address\": \"10.6.23.5\"}], \"routes\": [], \"cidr\": \"10.127.0.0/24\", \"gateway\": {\"meta\": {}, \"version\": 4, \"type\": \"gateway\", \"address\": \"10.127.0.1\"}}, {\"ips\": [], \"version\": null, \"meta\": {}, \"dns\": [], \"routes\": [], \"cidr\": null, \"gateway\": {\"meta\": {}, \"version\": null, \"type\": \"gateway\", \"address\": null}}], \"meta\": {\"tenant_id\": null}, \"id\": \"130460c1-8dd6-45d0-94bb-870777dc1f21\", \"label\": \"public\"}, \"meta\": {}, \"id\": \"0b8f347d-b301-439e-8b88-274a43f7cc2e\", \"address\": \"fa:16:3e:2a:89:f7\"}]', u'deleted_at': None, u'id': 1}, u'hostname': u'test01', u'launched_on': u'localhost.localdomain', u'display_description': u'test01', u'key_data': None, u'kernel_id': u'', u'power_state': 1, u'default_ephemeral_device': None, u'progress': 100, u'project_id': u'3f4884d9c31d4393a11158e09b816a5b', u'launched_at': u'2012-10-04T01:34:19.000000', u'scheduled_at': u'2012-10-04T01:29:31.000000', u'ramdisk_id': u'', u'access_ip_v6': None, u'access_ip_v4': None, u'deleted': False, u'key_name': None, u'updated_at': u'2012-10-04T01:35:30.000000', u'host': u'localhost.localdomain', u'display_name': u'test01', u'task_state': None, u'shutdown_terminate': False, u'architecture': None, u'root_gb': 40, u'locked': False, u'name': u'instance-6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca', u'created_at': u'2012-10-04T01:29:31.000000', u'launch_index': 0, u'metadata': [], u'memory_mb': 4096, u'instance_type': {u'disabled': False, u'root_gb': 40, u'deleted_at': None, u'name': u'm1.medium', u'deleted': False, u'created_at': None, u'ephemeral_gb': 0, u'updated_at': None, u'memory_mb': 4096, u'vcpus': 2, u'swap': 0, u'rxtx_factor': 1.0, u'is_public': True, u'flavorid': u'3', u'vcpu_weight': None, u'id': 1}, u'vcpus': 2, u'image_ref': u'6a86087a-2c71-4f50-90ae-1b884eb6bb22', u'root_device_name': None, u'auto_disk_config': None, u'os_type': None, u'config_drive': u''}, u'volume_id': u'bf5ddd27-6f8e-427b-b0a1-e66ad67c6bce'}, u'_context_instance_lock_checked': False, u'_context_is_admin': True, u'version': u'2.0', u'_context_project_id': u'3f4884d9c31d4393a11158e09b816a5b', u'_context_timestamp': u'2012-10-04T23:07:49.337942', u'_context_read_deleted': u'no', u'_context_user_id': u'ed4bd089a2f449dca0828a2c42dbfb77', u'method': u'attach_volume', u'_context_remote_address': u'10.6.61.108'} from (pid=4897) _safe_log /opt/nova/nova/openstack/common/rpc/common.py:195\n\nEven though this instance already had a \"auto device_name\" volume attached, the do_reserve is returning/attach call is sending:\n\n'mountpoint': u'/dev/xvdb'\n\nAnd the problem seems to mostly be the instance has:\n\n'root_device_name': None\n\nWhich unsurprisingly leads to a traceback:\n\n2012-10-04 23:08:59 ERROR nova.virt.xenapi.volumeops [req-c6af01f8-1d42-4f93-ada0-4fc217c56bdc ed4bd089a2f449dca0828a2c42dbfb77 3f4884d9c31d4393a11158e09b816a5b] ['DEVICE_ALREADY_EXISTS', '1']\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops Traceback (most recent call last):\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/opt/nova/nova/virt/xenapi/volumeops.py\", line 178, in attach_volume\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     dev_number, bootable=False)\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/opt/nova/nova/virt/xenapi/vm_utils.py\", line 332, in create_vbd\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     vbd_ref = session.call_xenapi('VBD.create', vbd_rec)\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/opt/nova/nova/virt/xenapi/driver.py\", line 714, in call_xenapi\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     return session.xenapi_request(method, args)\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/usr/local/lib/python2.6/dist-packages/XenAPI.py\", line 133, in xenapi_request\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     result = _parse_result(getattr(self, methodname)(*full_params))\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops   File \"/usr/local/lib/python2.6/dist-packages/XenAPI.py\", line 203, in _parse_result\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops     raise Failure(result['ErrorDescription'])\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops Failure: ['DEVICE_ALREADY_EXISTS', '1']\n2012-10-04 23:08:59 TRACE nova.virt.xenapi.volumeops\n\nThere's some more in the error handling:\n\n2012-10-04 23:09:00 ERROR nova.compute.manager [req-c6af01f8-1d42-4f93-ada0-4fc217c56bdc ed4bd089a2f449dca0828a2c42dbfb77 3f4884d9c31d4393a11158e09b816a5b] [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca] Failed to attach volume 8d8b78b8-bff3-48fe-be34-a3d589076028 at /dev/xvdb\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca] Traceback (most recent call last):\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]   File \"/opt/nova/nova/compute/manager.py\", line 2001, in _attach_volume\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]     mountpoint)\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]   File \"/opt/nova/nova/virt/xenapi/driver.py\", line 381, in attach_volume\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]     mountpoint)\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]   File \"/opt/nova/nova/virt/xenapi/volumeops.py\", line 183, in attach_volume\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]     ' instance %(instance_name)s') % locals())\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca] Exception: Unable to use SR OpaqueRef:fd0c55a7-7584-2907-4791-654dd06428ed for instance instance-6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca\n2012-10-04 23:09:00 TRACE nova.compute.manager [instance: 6819fd4d-e1db-4cdf-86f3-3cb8594eb1ca]", 
            "date_created": "2012-10-04 23:15:58.446856+00:00", 
            "author": "https://api.launchpad.net/1.0/~clay-gerrard"
        }, 
        {
            "content": "", 
            "date_created": "2012-10-04 23:15:58.446856+00:00", 
            "author": "https://api.launchpad.net/1.0/~clay-gerrard"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/14068", 
            "date_created": "2012-10-05 00:00:49.337327+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/14068\nCommitted: http://github.com/openstack/nova/commit/07845ad68f83952bbae36b4b115ff6c433e81fa3\nSubmitter: Jenkins\nBranch:    master\n\ncommit 07845ad68f83952bbae36b4b115ff6c433e81fa3\nAuthor: Clay Gerrard <email address hidden>\nDate:   Thu Oct 4 18:50:39 2012 -0500\n\n    Always use bdm in instance_block_mapping on Xen\n    \n    It doesn't seem that Xen will set the 'root_device_name' property on\n    instances.  This is causing instance_block_mapping to return early\n    without evaluating the bdm before returning the list of device_names\n    in use.  I'm not sure why instance_block_mapping does this\n    (optimization?) but on Xen at least it seems that it should not.\n    \n    Added a check for Xen compute_driver flag in instance_block_mapping to\n    \"guess\" the root_device_name (similarlly to what is done in\n    compute.utils for swap and ephemeral).\n    \n    fixes bug #1061944\n    \n    Change-Id: If5b1a2b7377232c78f0629a3624552ecf6ceb0ee\n", 
            "date_created": "2012-10-05 06:05:42.853242+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Note: backport also needs https://review.openstack.org/#/c/14991/", 
            "date_created": "2012-10-29 20:01:38.763513+00:00", 
            "author": "https://api.launchpad.net/1.0/~vishvananda"
        }, 
        {
            "content": "Fix proposed to branch: stable/folsom\nReview: https://review.openstack.org/16713", 
            "date_created": "2012-11-22 00:44:17.622048+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/16713\nCommitted: http://github.com/openstack/nova/commit/a369303b93500694b22b7d49785b47dcd734acf4\nSubmitter: Jenkins\nBranch:    stable/folsom\n\ncommit a369303b93500694b22b7d49785b47dcd734acf4\nAuthor: Clay Gerrard <email address hidden>\nDate:   Thu Oct 4 18:50:39 2012 -0500\n\n    Always use bdm in instance_block_mapping on Xen\n    \n    It doesn't seem that Xen will set the 'root_device_name' property on\n    instances.  This is causing instance_block_mapping to return early\n    without evaluating the bdm before returning the list of device_names\n    in use.  I'm not sure why instance_block_mapping does this\n    (optimization?) but on Xen at least it seems that it should not.\n    \n    Added a check for Xen compute_driver flag in instance_block_mapping to\n    \"guess\" the root_device_name (similarlly to what is done in\n    compute.utils for swap and ephemeral).\n    \n    fixes bug #1061944\n    \n    Change-Id: If5b1a2b7377232c78f0629a3624552ecf6ceb0ee\n    (cherry picked from commit 07845ad68f83952bbae36b4b115ff6c433e81fa3)\n", 
            "date_created": "2012-11-27 02:27:25.071526+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Hello clayg, or anyone else affected,\n\nAccepted nova into quantal-proposed. The package will build now and be available at http://launchpad.net/ubuntu/+source/nova/2012.2.1+stable-20121212-a99a802e-0ubuntu1 in a few hours, and then in the -proposed repository.\n\nPlease help us by testing this new package.  See https://wiki.ubuntu.com/Testing/EnableProposed for documentation how to enable and use -proposed.  Your feedback will aid us getting this update out to other Ubuntu users.\n\nIf this package fixes the bug for you, please add a comment to this bug, mentioning the version of the package you tested, and change the tag from verification-needed to verification-done. If it does not fix the bug for you, please add a comment stating that, and change the tag to verification-failed.  In either case, details of your testing will help us make a better decision.\n\nFurther information regarding the verification process can be found at https://wiki.ubuntu.com/QATeam/PerformingSRUVerification .  Thank you in advance!", 
            "date_created": "2012-12-28 16:26:59.536003+00:00", 
            "author": "https://api.launchpad.net/1.0/~clint-fewbar"
        }, 
        {
            "content": "This bug was fixed in the package nova - 2012.2.1+stable-20121212-a99a802e-0ubuntu1\n\n---------------\nnova (2012.2.1+stable-20121212-a99a802e-0ubuntu1) quantal-proposed; urgency=low\n\n  * Ubuntu updates:\n    - debian/control: Ensure novaclient is upgraded with nova,\n      require python-keystoneclient >= 1:2.9.0. (LP: #1073289)\n    - d/p/avoid_setuptools_git_dependency.patch: Refresh.\n  * Dropped patches, applied upstream:\n    - debian/patches/CVE-2012-5625.patch: [a99a802]\n  * Resynchronize with stable/folsom (b55014ca) (LP: #1085255):\n    - [a99a802] create_lvm_image allocates dirty blocks (LP: #1070539)\n    - [670b388] RPC exchange name defaults to 'openstack' (LP: #1083944)\n    - [3ede373] disassociate_floating_ip with multi_host=True fails\n      (LP: #1074437)\n    - [22d7c3b] libvirt imagecache should handle shared image storage\n      (LP: #1075018)\n    - [e787786] Detached and deleted RBD volumes remain associated with insance\n      (LP: #1083818)\n    - [9265eb0] live_migration missing migrate_data parameter in Hyper-V driver\n      (LP: #1066513)\n    - [3d99848] use_single_default_gateway does not function correctly\n      (LP: #1075859)\n    - [65a2d0a] resize does not migrate DHCP host information (LP: #1065440)\n    - [102c76b] Nova backup image fails (LP: #1065053)\n    - [48a3521] Fix config-file overrides for nova-dhcpbridge\n    - [69663ee] Cloudpipe in Folsom: no such option: cnt_vpn_clients\n      (LP: #1069573)\n    - [6e47cc8] DisassociateAddress can cause Internal Server Error\n      (LP: #1080406)\n    - [22c3d7b] API calls to dis-associate an auto-assigned floating IP should\n      return proper warning (LP: #1061499)\n    - [bd11d15] libvirt: if exception raised during volume_detach, volume state\n      is inconsistent (LP: #1057756)\n    - [dcb59c3] admin can't describe all images in ec2 api (LP: #1070138)\n    - [78de622] Incorrect Exception raised during Create server when metadata\n      over 255 characters  (LP: #1004007)\n    - [c313de4] Fixed IP isn't released before updating DHCP host file\n      (LP: #1078718)\n    - [f4ab42d] Enabling Return Reservation ID with XML create server request\n      returns no body  (LP: #1061124)\n    - [3db2a38] 'BackupCreate' should accept rotation parameter greater than or\n      equal to zero (LP: #1071168)\n    - [f7e5dde] libvirt reboot sometimes fails to reattach volumes\n      (LP: #1073720)\n    - [ff776d4] libvirt: detaching volume may fail while terminating other\n      instances on the same host concurrently (LP: #1060836)\n    - [85a8bc2] Used instance uuid rather than id in remove-fixed-ip\n    - [42a85c0] Fix error on invalid delete_on_termination value\n    - [6a17579] xenapi migrations fail w/ swap (LP: #1064083)\n    - [97649b8] attach-time field for volumes is not updated for detach volume\n      (LP: #1056122)\n    - [8f6a718] libvirt: rebuild is not using kernel and ramdisk associated with\n      the new image (LP: #1060925)\n    - [fbe835f] live-migration and volume host assignement (LP: #1066887)\n    - [c2a9150] typo prevents volume_tmp_dir flag from working (LP: #1071536)\n    - [93efa21] Instances deleted during spawn leak network allocations\n      (LP: #1068716)\n    - [ebabd02] After restarting an instance volume is lost (LP: #1071069)\n    - [a369303] xen volume auto device selection always picks xvdb\n      (LP: #1061944)\n    - [8d1095c] Calls to to_xml() to generate XML for a soft deleted flavor fail\n      (LP: #1073736)\n    - [1857821] nova-manage doesn't validate the key value supplied to update\n      the quota (LP: #1064359)\n    - [6ae32f0] Compute manager doesn't update 'host' field when it tries to run\n      a VM (LP: #1073600)\n    - [284f6ea] Host field set too early during builds (LP: #1060255)\n    - [395511f] finish_resize failures result in NoneType exception\n      (LP: #1071595)\n    - [85ccf80] confirm_resize mgr call requires admin context (LP: #1071600)\n    - [2dceffa] Only return the last N lines of the console log (LP: #1081436)\n    - [9c7a711] console auth does not work with memcache, unicode error\n      (LP: #1057279)\n    - [b27f7ef] disk path not exists when using LXC with libvirt_images_type=lvm\n      (LP: #1079113)\n    - [1351c6b] nova-api now requires quantumclient (LP: #1070509)\n    - [612f404] nova-api now requires quantumclient (LP: #1070509)\n    - [7e8a166] nova-compute (folsom) fails to start, compute_driver is None\n      (LP: #1081836)\n    - [182ca80] Nova API does not work with QuantumV2 API subclasses\n      (LP: #1070045)\n    - [55d1412] 413 error code doesn't always provide Retry-After (LP: #1079387)\n    - [1581505] Snapshotting LXC instance fails (LP: #1058273)\n    - [197398f] Stop network.api import on network import\n    - [b874d21] Scheduler Race Condition at high volume (LP: #1073956)\n    - [3316e1f] Nic Ordering not guaranteed with Quantum API (LP: #1064524)\n    - [ab7e37e] Stable oslo (aka common) update\n    - [3f7788c] update nova to report quantum floating IPs (LP: #1023169)\n    - [d3fd05b] metadata service throws 500 - NoSuchOptError (LP: #1063851)\n    - [97542c9] libvirt imagecache still runs even if disabled (LP: #1075017)\n    - [b31f528] OS API: XML Namespace Handling Broken (LP: #887191)\n    - [76b44d9] nova-api crashes if it is run with nobody account.\n      (LP: #1073858)\n    - [d59f6ad] nova-compute will assign the same device name if volume-attach\n      continuously  (LP: #1062033)\n    - [8e11181] Nova does not delete the LV on LVM backed VMs (LP: #1078085)\n    - [9bf2c6a] Fixed instance deletion issue from Nova API.\n    - [c0e1247] forget to release resource when terminate an instance from a\n      failed compute node (LP: #1067214)\n    - [49397a4] ensure_default_security_group() does not call sgh (LP: #1050982)\n    - [47ff8a5] trigger_instance[add/remove]_security_group_refresh are never\n      called (LP: #1057069)\n    - [c9cade2] Resource reservation isn't rolled back properly for certain\n      failures during Instance Create (LP: #1065092)\n    - [34c3845] Resource tracker uses regex DB query too often (LP: #1060363)\n    - [92eddd2] Logging CPU incompatibility when attempting live migration fails\n      (LP: #1076308)\n    - [8b4896b] hostname in metadata ends with . if dhcp_domain flag is empty\n      (LP: #1064713)\n    - [ded0473] deletes fail when instance in RESIZED (LP: #1056601)\n    - [d015be5] libvirt: cannot detach volume from stopped domain (LP: #1057730)\n    - [d5888f1] Resizing a Xen instance with attached volumes fails\n      (LP: #1028092)\n    - [fb88827] resize leave leftover libvirt configs (LP: #1015731)\n    - [5ccd691] nova-network cannot re-generate MAC address if collision happen\n      (LP: #1059366)\n    - [e3d7f8c] After folsom upgrade, instances can no longer access existing\n      volumes. (LP: #1065702)\n    - [804f858] Jenkins jobs fail because of incompatibility between sqlalchemy-\n      migrate and the newest sqlalchemy-0.8.0b1 (LP: #1073569)\n    - [f67a5f9] block device mappings for deleted instances are leaked\n      (LP: #1069099)\n    - [32d8722] volume and snapshot IDs do not correctly map to UUIDs after\n      folsom upgrade (LP: #1065785)\n    - [9613643] Xenserver cannot boot vm_mode=xen type images (LP: #1055431)\n    - [863c767] Cloudpipe extension xml serialization doesn't return the\n      instance(s) data (LP: #1056242)\n    - [724adcf] deleting security group does not mark rules as deleted\n      (LP: #1056380)\n    - [84a996c] IP Protocol for security group should be returned in lower case\n      to be compliant with the ec2 api (LP: #1057196)\n    - [e1ed06a] db tests fail with sqlalchemy 0.7.4 (LP: #1057145)\n    - [bddb06d] Fail to boot raw image on XenServer (LP: #1055413)\n    - [d4d1665] Add SIGPIPE handler to subprocess execution in rootwrap and\n      utils.execute (LP: #1053364)\n    - [0af4dd0] libvirt: concurrent detach_volume and terminate fails\n      (LP: #1057719)\n    - [ebbfa9e] Instances in vm state DELETED are preventing compute restart\n      (LP: #1053441)\n    - [db516a2] ComputeManager does not provide block_device_info on destroy\n      call in revert_resize (LP: #1056285)\n    - [4223ebf] Set defaultbranch in .gitreview to stable/folsom\n    - [eee4dbb] do_refresh_security_group_rules in nova.virt.firewall is very\n      slow (LP: #1062314)\n    - [b7e509a] Set read_deleted='yes' for instance_id_mappings.\n    - [9e20735] Tests fail on 32bit machines (_get_hash_str is platform\n      dependent) (LP: #1050359)\n -- Adam Gandelman <email address hidden>   Wed, 12 Dec 2012 16:27:51 -0400", 
            "date_created": "2013-01-29 13:10:46.783756+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ]
}