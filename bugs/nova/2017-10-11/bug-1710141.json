{
    "status": "In Progress", 
    "last_updated": "2017-08-23 00:12:19.103714+00:00", 
    "description": "Seen here:\n\nhttp://logs.openstack.org/54/487954/12/check/gate-tempest-dsvm-ironic-ipa-wholedisk-bios-agent_ipmitool-tinyipa-ubuntu-xenial-nv/041c03a/logs/screen-n-cpu.txt.gz#_Aug_09_19_31_21_450705\n\nAug 09 19:31:21.450705 ubuntu-xenial-internap-mtl01-10351013 nova-compute[19132]: WARNING nova.scheduler.client.report [None req-9db22a6d-e88a-42b0-879e-8fe523dcc664 None None] [req-2eead243-5e63-4dd0-a208-4ceed95478ff] We cannot delete inventory 'VCPU, MEMORY_MB, DISK_GB' for resource provider 38b274b2-2e37-4c23-ad6f-d86c1f0a0e3f because the inventory is in use.\n\nAs soon as an ironic node has an instance built on it, the node state is ACTIVE which means that this method returns True:\n\nhttps://github.com/openstack/nova/blob/c2d33c3271370358d48553233b41bf9119d834fb/nova/virt/ironic/driver.py#L176\n\nSaying the node is unavailable, because it's wholly consumed I guess.\n\nThat's used here:\n\nhttps://github.com/openstack/nova/blob/c2d33c3271370358d48553233b41bf9119d834fb/nova/virt/ironic/driver.py#L324\n\nAnd that's checked here when reporting inventory to the resource tracker:\n\nhttps://github.com/openstack/nova/blob/c2d33c3271370358d48553233b41bf9119d834fb/nova/virt/ironic/driver.py#L741\n\nWhich then tries to delete the inventory for the node resource provider in placement, which fails because it's already got an instance running on it that is consuming inventory:\n\nhttp://logs.openstack.org/54/487954/12/check/gate-tempest-dsvm-ironic-ipa-wholedisk-bios-agent_ipmitool-tinyipa-ubuntu-xenial-nv/041c03a/logs/screen-n-cpu.txt.gz#_Aug_09_19_31_21_450705\n\nAug 09 19:31:21.391146 ubuntu-xenial-internap-mtl01-10351013 nova-compute[19132]: INFO nova.scheduler.client.report [None req-9db22a6d-e88a-42b0-879e-8fe523dcc664 None None] Compute node 38b274b2-2e37-4c23-ad6f-d86c1f0a0e3f reported no inventory but previous inventory was detected. Deleting existing inventory records.\nAug 09 19:31:21.450705 ubuntu-xenial-internap-mtl01-10351013 nova-compute[19132]: WARNING nova.scheduler.client.report [None req-9db22a6d-e88a-42b0-879e-8fe523dcc664 None None] [req-2eead243-5e63-4dd0-a208-4ceed95478ff] We cannot delete inventory 'VCPU, MEMORY_MB, DISK_GB' for resource provider 38b274b2-2e37-4c23-ad6f-d86c1f0a0e3f because the inventory is in use.\n\nThis is also bad because if the node was updated with a resource_class, that resource class won't be automatically created in Placement here:\n\nhttps://github.com/openstack/nova/blob/c2d33c3271370358d48553233b41bf9119d834fb/nova/scheduler/client/report.py#L789\n\nBecause the driver didn't report it in the get_inventory method.\n\nAnd that has an impact on this code to migrate instance.flavor.extra_specs to have custom resource class overrides from ironic nodes that now have a resource_class set:\n\nhttps://review.openstack.org/#/c/487954/\n\nSo we've got a bit of a chicken and egg problem here.\n\nManually testing the ironic flavor migration code hits this problem, as seen here:\n\nhttp://paste.openstack.org/show/618160/", 
    "tags": [
        "in-stable-pike", 
        "ironic", 
        "placement"
    ], 
    "importance": "High", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1710141", 
    "owner": "https://api.launchpad.net/1.0/~divius", 
    "id": 1710141, 
    "index": 2127, 
    "created": "2017-08-11 11:47:52.057083+00:00", 
    "title": "Continual warnings in n-cpu logs about being unable to delete inventory for an ironic node with an instance on it", 
    "comments": [
        {
            "content": "Seen here:\n\nhttp://logs.openstack.org/54/487954/12/check/gate-tempest-dsvm-ironic-ipa-wholedisk-bios-agent_ipmitool-tinyipa-ubuntu-xenial-nv/041c03a/logs/screen-n-cpu.txt.gz#_Aug_09_19_31_21_450705\n\nAug 09 19:31:21.450705 ubuntu-xenial-internap-mtl01-10351013 nova-compute[19132]: WARNING nova.scheduler.client.report [None req-9db22a6d-e88a-42b0-879e-8fe523dcc664 None None] [req-2eead243-5e63-4dd0-a208-4ceed95478ff] We cannot delete inventory 'VCPU, MEMORY_MB, DISK_GB' for resource provider 38b274b2-2e37-4c23-ad6f-d86c1f0a0e3f because the inventory is in use.\n\nAs soon as an ironic node has an instance built on it, the node state is ACTIVE which means that this method returns True:\n\nhttps://github.com/openstack/nova/blob/c2d33c3271370358d48553233b41bf9119d834fb/nova/virt/ironic/driver.py#L176\n\nSaying the node is unavailable, because it's wholly consumed I guess.\n\nThat's used here:\n\nhttps://github.com/openstack/nova/blob/c2d33c3271370358d48553233b41bf9119d834fb/nova/virt/ironic/driver.py#L324\n\nAnd that's checked here when reporting inventory to the resource tracker:\n\nhttps://github.com/openstack/nova/blob/c2d33c3271370358d48553233b41bf9119d834fb/nova/virt/ironic/driver.py#L741\n\nWhich then tries to delete the inventory for the node resource provider in placement, which fails because it's already got an instance running on it that is consuming inventory:\n\nhttp://logs.openstack.org/54/487954/12/check/gate-tempest-dsvm-ironic-ipa-wholedisk-bios-agent_ipmitool-tinyipa-ubuntu-xenial-nv/041c03a/logs/screen-n-cpu.txt.gz#_Aug_09_19_31_21_450705\n\nAug 09 19:31:21.391146 ubuntu-xenial-internap-mtl01-10351013 nova-compute[19132]: INFO nova.scheduler.client.report [None req-9db22a6d-e88a-42b0-879e-8fe523dcc664 None None] Compute node 38b274b2-2e37-4c23-ad6f-d86c1f0a0e3f reported no inventory but previous inventory was detected. Deleting existing inventory records.\nAug 09 19:31:21.450705 ubuntu-xenial-internap-mtl01-10351013 nova-compute[19132]: WARNING nova.scheduler.client.report [None req-9db22a6d-e88a-42b0-879e-8fe523dcc664 None None] [req-2eead243-5e63-4dd0-a208-4ceed95478ff] We cannot delete inventory 'VCPU, MEMORY_MB, DISK_GB' for resource provider 38b274b2-2e37-4c23-ad6f-d86c1f0a0e3f because the inventory is in use.\n\nThis is also bad because if the node was updated with a resource_class, that resource class won't be automatically created in Placement here:\n\nhttps://github.com/openstack/nova/blob/c2d33c3271370358d48553233b41bf9119d834fb/nova/scheduler/client/report.py#L789\n\nBecause the driver didn't report it in the get_inventory method.\n\nAnd that has an impact on this code to migrate instance.flavor.extra_specs to have custom resource class overrides from ironic nodes that now have a resource_class set:\n\nhttps://review.openstack.org/#/c/487954/\n\nSo we've got a bit of a chicken and egg problem here.\n\nManually testing the ironic flavor migration code hits this problem, as seen here:\n\nhttp://paste.openstack.org/show/618160/", 
            "date_created": "2017-08-11 11:47:52.057083+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "One question is, why don't we report inventory for an ACTIVE node? If the inventory is 1 but an instance is also allocating that 1 of whatever resource class, then isn't that sufficient? In other words, if an instance is consuming all of the node inventory, that should take the node out of scheduling decisions for building new instances, which is also how things work for regular compute nodes for building VMs.", 
            "date_created": "2017-08-11 12:11:17.800092+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "If we're just fixing the warnings, then this isn't pike-rc-potential for rc2, we could just fix the warnings issue and backport to stable/pike and stable/ocata since it's not a regression in pike.", 
            "date_created": "2017-08-11 12:45:07.926138+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Patch is at https://review.openstack.org/492964", 
            "date_created": "2017-08-11 15:31:39.102810+00:00", 
            "author": "https://api.launchpad.net/1.0/~vdrok"
        }, 
        {
            "content": "Fix proposed to branch: stable/pike\nReview: https://review.openstack.org/494216", 
            "date_created": "2017-08-16 13:57:42.799589+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/492964\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=9ed692bf8c84e0a702536101cd6cb084d33e1c26\nSubmitter: Jenkins\nBranch:    master\n\ncommit 9ed692bf8c84e0a702536101cd6cb084d33e1c26\nAuthor: Dmitry Tantsur <email address hidden>\nDate:   Fri Aug 11 13:52:02 2017 +0200\n\n    Fix reporting inventory for provisioned nodes in the Ironic driver\n    \n    Currently we report the full inventory for available nodes, and an empty\n    inventory for nodes that are deployed to or otherwise unavailable.\n    \n    Reporting an empty inventory for deployed nodes has 2 bad consequences:\n    1. Nova tries deleting the inventory for Placement, which fails, because\n       the resources are still in use. This results in nasty warnings.\n    2. When adding a resource class to a deployed node, it does not get into\n       inventory, and thus does not get to Placement. It results in an error\n       later on, when the custom resource class is not found.\n    \n    This patch fixes the latter problem by\n    1. Always reporting the custom resource class for deployed nodes, if present.\n    2. Reporting VCPUS/memory/disk in exactly the same amount, as it is configured\n       in the ironic node's properties.\n    \n    As a side effect, the warnings are no longer shown for deployed nodes.\n    They still appear, however, for nodes during cleaning.\n    \n    Partial-Bug: #1710141\n    Change-Id: I2fd1e4a95f000da19864e75299afa51527697101\n", 
            "date_created": "2017-08-16 15:23:06.952641+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/494216\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=c92337bdf80fea4c0a8ebb433bacec4cc07f7a94\nSubmitter: Jenkins\nBranch:    stable/pike\n\ncommit c92337bdf80fea4c0a8ebb433bacec4cc07f7a94\nAuthor: Dmitry Tantsur <email address hidden>\nDate:   Fri Aug 11 13:52:02 2017 +0200\n\n    Fix reporting inventory for provisioned nodes in the Ironic driver\n    \n    Currently we report the full inventory for available nodes, and an empty\n    inventory for nodes that are deployed to or otherwise unavailable.\n    \n    Reporting an empty inventory for deployed nodes has 2 bad consequences:\n    1. Nova tries deleting the inventory for Placement, which fails, because\n       the resources are still in use. This results in nasty warnings.\n    2. When adding a resource class to a deployed node, it does not get into\n       inventory, and thus does not get to Placement. It results in an error\n       later on, when the custom resource class is not found.\n    \n    This patch fixes the latter problem by\n    1. Always reporting the custom resource class for deployed nodes, if present.\n    2. Reporting VCPUS/memory/disk in exactly the same amount, as it is configured\n       in the ironic node's properties.\n    \n    As a side effect, the warnings are no longer shown for deployed nodes.\n    They still appear, however, for nodes during cleaning.\n    \n    Partial-Bug: #1710141\n    Change-Id: I2fd1e4a95f000da19864e75299afa51527697101\n    (cherry picked from commit 9ed692bf8c84e0a702536101cd6cb084d33e1c26)\n", 
            "date_created": "2017-08-16 23:44:24.520175+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}