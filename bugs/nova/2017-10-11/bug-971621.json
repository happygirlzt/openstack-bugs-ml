{
    "status": "Fix Released", 
    "last_updated": "2012-10-11 19:44:16.820757+00:00", 
    "description": "When I launch more than one LXC instance, and I try to delete one (the first one for example), the wrong rootfs is umounted and disconnected from its nbd device (the last one for example).\n\nE.g.\n\nBefore:\n\nname        status   nbd   --> rootfs_path                    veth_if --> IP      cgroup\n---------------------------------------------------------------------------------------\ninstance1   ACTIVE   nbd15 --> .../instance-00000001/rootfs   veth0   --> 10.0.0.2   V\ninstance2   ACTIVE   nbd14 --> .../instance-00000002/rootfs   veth1   --> 10.0.0.3   V\ninstance3   ACTIVE   nbd13 --> .../instance-00000003/rootfs   veth2   --> 10.0.0.4   V\n\nnova delete instance1\n\nAfter:\n\nname        status   nbd   --> rootfs_path                    veth_if --> IP      cgroup\n---------------------------------------------------------------------------------------\ninstance1   SHUTOFF  nbd15 --> .../instance-00000001/rootfs   X       --> X          X\ninstance2   ACTIVE   nbd14 --> .../instance-00000002/rootfs   veth1   --> 10.0.0.3   V\ninstance3   SHUTOFF  X     --> X                              veth2   --> 10.0.0.4   X\n\nSpecifications:\n\n- Host OS: ubuntu precise beta2\n- Guest OS: ubuntu precise beta2 cloud image (from http://cloud-images.ubuntu.com/precise/current/precise-server-cloudimg-amd64.tar.gz)\n- OpenStack version: 2012.1 (essex)\n- Virtualization: LXC (LinuX Container)", 
    "tags": [
        "lxc", 
        "verification-done"
    ], 
    "importance": "High", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/971621", 
    "owner": "https://api.launchpad.net/1.0/~p-draigbrady", 
    "id": 971621, 
    "index": 655, 
    "created": "2012-04-02 15:16:28.880615+00:00", 
    "title": "nova delete lxc-instance umounts the wrong rootfs", 
    "comments": [
        {
            "content": "When I launch more than one LXC instance, and I try to delete one (the first one for example), the wrong rootfs is umounted and disconnected from its nbd device (the last one for example).\n\nE.g.\n\nBefore:\n\nname        status   nbd   --> rootfs_path                    veth_if --> IP         cgroup\n----------------------------------------------------------------------------------------------------------------------------\ninstance1   ACTIVE   nbd15 --> .../instance-00000001/rootfs   veth0   --> 10.0.0.2   V   \ninstance2   ACTIVE   nbd14 --> .../instance-00000002/rootfs   veth1   --> 10.0.0.3   V  \ninstance3   ACTIVE   nbd13 --> .../instance-00000003/rootfs   veth2   --> 10.0.0.4   V   \n\nnova delete instance1\n\nAfter:\n\nname        status   nbd   --> rootfs_path                    veth_if --> IP         cgroup\n----------------------------------------------------------------------------------------------------------------------------\ninstance1   SHUTOFF  nbd15 --> .../instance-00000001/rootfs   X       --> X          X   \ninstance2   ACTIVE   nbd14 --> .../instance-00000002/rootfs   veth1   --> 10.0.0.3   V  \ninstance3   ACTIVE   X     --> X                              veth2   --> 10.0.0.4   V   \n\nSpecifications:\n\n- Host: KVM VM\n- Host OS: ubuntu precise beta2 cloud image (from http://cloud-images.ubuntu.com/precise/current/precise-server-cloudimg-amd64.tar.gz)\n- Guest OS: ubuntu precise beta2 cloud image (from http://cloud-images.ubuntu.com/precise/current/precise-server-cloudimg-amd64.tar.gz)\n- OpenStack version: folsom-1 (but probably exact same behavior with essex-rc1) from github master branch with devstack \n- Virtualization: LXC (LinuX Container)", 
            "date_created": "2012-04-02 15:16:28.880615+00:00", 
            "author": "https://api.launchpad.net/1.0/~dodeeric"
        }, 
        {
            "content": "This problem happens with:\n\na) qcow2 root disk images (nbd block devices) ==> As described above\n\ndisk: qcow2 format\n\ninstance1 .../instance-00000001/disk --> nbd15 --> .../instance-00000001/rootfs\ninstance2 .../instance-00000002/disk --> nbd14 --> .../instance-00000002/rootfs\ninstance3 .../instance-00000003/disk --> nbd13 --> .../instance-00000003/rootfs\n\nbut also with:\n\nb) raw root disk images (loop block devices)\n\nnova.conf: use_cow_images=False\n\ndisk: raw format\n\ninstance1 .../instance-00000001/disk --> loop0 --> .../instance-00000001/rootfs\ninstance2 .../instance-00000002/disk --> loop1 --> .../instance-00000002/rootfs\ninstance3 .../instance-00000003/disk --> loop2 --> .../instance-00000003/rootfs", 
            "date_created": "2012-04-06 14:28:18.846008+00:00", 
            "author": "https://api.launchpad.net/1.0/~dodeeric"
        }, 
        {
            "content": "Traces:\n\nnova delete i1 (uuid: 9b1... / veth0 / loop0 / instance-0000000a)\n\nName   IP    veth   loop   rootfs   uuid\n--------------------------------------------\ni1     4.3   0      0      i-a      9b1...\ni2     4.4   1      1      i-b      af2...\n\nNOK: loop1 is umounted/disconneced!!!\n\nAMQP: req-d29...\n\nuser_uuid: cad... (dodeeric)\nproject_uuid: c1a... (lc2)\n\n-----\n\nOK (i-a / instance-0000000a):\n\n2012-04-07 10:26:52 INFO nova.virt.libvirt.connection [req-d29c2ab4-cd57-4121-93c2-27e9d56cf1fb cadc85c18c6\na4aee928c19653f48dd45 c1ab5bc8097b48278ef41db02ecf82eb] [instance: 9b1533e4-f973-43ef-a1b5-96ce52ae5db1] Deleting instance files /var/lib/nova/instances/instance-0000000a\n\nNOK (loop1):\n\n2012-04-07 10:26:52 DEBUG nova.utils [req-d29c2ab4-cd57-4121-93c2-27e9d56cf1fb cadc85c18c6a4aee928c19653f48\ndd45 c1ab5bc8097b48278ef41db02ecf82eb] Running cmd (subprocess): sudo nova-rootwrap umount /dev/loop1 from \n(pid=31501) execute /usr/lib/python2.7/dist-packages/nova/utils.py:219\n\n2012-04-07 10:26:52 DEBUG nova.utils [req-d29c2ab4-cd57-4121-93c2-27e9d56cf1fb cadc85c18c6a4aee928c19653f48\ndd45 c1ab5bc8097b48278ef41db02ecf82eb] Running cmd (subprocess): sudo nova-rootwrap losetup --detach /dev/l\noop1 from (pid=31501) execute /usr/lib/python2.7/dist-packages/nova/utils.py:219", 
            "date_created": "2012-04-07 09:43:28.002398+00:00", 
            "author": "https://api.launchpad.net/1.0/~dodeeric"
        }, 
        {
            "content": "To summarize the bug: when you delete a LXC instance, it always umount the rootfs of the latest LXC instance!\n\nExample:\n\nWe have three running LXC instances:\n\ni1 ../instance-00000001/rootfs\ni2 ../instance-00000002/rootfs\ni3 ../instance-00000003/rootfs\n\nIf you run:\n\n$ nova delete i3 ==> will umount ../instance-00000003/rootfs ==> OK\n\nthen:\n\n$ nova delete i2 ==> will umount ../instance-00000003/rootfs ==> NOK\n\nthen:\n\n$ nova delete i1 ==> will umount ../instance-00000003/rootfs ==> NOK", 
            "date_created": "2012-04-07 18:26:22.725118+00:00", 
            "author": "https://api.launchpad.net/1.0/~dodeeric"
        }, 
        {
            "content": "This should be an issue once the instances have been converted to uuids in nova/virt/libvirt/driver.py", 
            "date_created": "2012-07-12 13:15:02.136854+00:00", 
            "author": "https://api.launchpad.net/1.0/~zulcss"
        }, 
        {
            "content": "On 07/12/2012 03:15 PM, Chuck Short wrote:\n> This should be an issue once the instances have been converted to uuids\n> in nova/virt/libvirt/driver.py\nThanks for the hint, Chuck! Will look that way.\n\n", 
            "date_created": "2012-07-12 13:49:34+00:00", 
            "author": "https://api.launchpad.net/1.0/~al-maisan"
        }, 
        {
            "content": "Just getting to this now.\n\nHmm, this is quite awkward.\nThere are 3 cases to consider for correctly cleaning up the LXC mount dirs\n\n1. Multiple LXC instances (the orig bug)\nvirt/driver.py stores a global object tracking the mount,\nand so will always clean the last LXC instance created.\n\nNow you could let the operating system maintain state and just\n`umount /the/lxc/instance/mount/dir`. \nUnfortunately a simple umount wont suffice because\ndepending on the mount method we may need to\n`fuesrmount -u` or cleaup nbd devices etc.\nSo we'd need to store some state as to the\ntype of mount we performed.\nNow maybe things could be arranged so that `umount ...` always works,\nthough that seems invasive and hacky at first glance.\n\n2. Now because these are long lived mounts, nova could be restarted,\nrequiring state info for the umount to be maintained outside of nova.\nWe'd have to be careful to create this atomically, i.e. as a transaction\naround the mount operation.\n\n3. If the system is restarted, then the mounts would be too,\nand so the persisted mount information should be ignored.\n", 
            "date_created": "2012-07-31 15:44:44.117387+00:00", 
            "author": "https://api.launchpad.net/1.0/~p-draigbrady"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/10655", 
            "date_created": "2012-08-01 14:50:17.486500+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/10655\nCommitted: http://github.com/openstack/nova/commit/a5184d5dbf67630dac3abb69b1678b60807cfce7\nSubmitter: Jenkins\nBranch:    master\n\ncommit a5184d5dbf67630dac3abb69b1678b60807cfce7\nAuthor: P\u00e1draig Brady <email address hidden>\nDate:   Wed Aug 1 14:26:54 2012 +0100\n\n    fix unmounting of LXC containers\n    \n    There were two issues here.\n    \n    1. There was a global object stored for all instances,\n    thus the last mounted instance was always unmounted.\n    \n    2. Even if there was only a single LXC instance in use,\n    the global object would be lost on restart of Nova.\n    \n    Therefore we reset the internal state for the mount object,\n    by passing in the mount point to destroy_container(),\n    and querying the device in use for that mount point.\n    \n    Fixes bug: 971621\n    Change-Id: I5442442f00d93f5e8b82f492d62918419db5cd3b\n", 
            "date_created": "2012-08-04 03:50:23.594947+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/essex\nReview: https://review.openstack.org/10962", 
            "date_created": "2012-08-07 14:24:52.349492+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/10962\nCommitted: http://github.com/openstack/nova/commit/272b98d718a68f5f714543ed2948d49ffe052ca5\nSubmitter: Jenkins\nBranch:    stable/essex\n\ncommit 272b98d718a68f5f714543ed2948d49ffe052ca5\nAuthor: P\u00e1draig Brady <email address hidden>\nDate:   Tue Aug 7 15:17:08 2012 +0100\n\n    fix unmounting of LXC containers\n    \n    There were two issues here.\n    \n    1. There was a global object stored for all instances,\n    thus the last mounted instance was always unmounted.\n    \n    2. Even if there was only a single LXC instance in use,\n    the global object would be lost on restart of Nova.\n    \n    Therefore we reset the internal state for the mount object,\n    by passing in the mount point to destroy_container(),\n    and querying the device in use for that mount point.\n    \n    Fixes bug: 971621\n    Change-Id: I5442442f00d93f5e8b82f492d62918419db5cd3b\n    Cherry-picked: a5184d5dbf67630dac3abb69b1678b60807cfce7\n", 
            "date_created": "2012-08-21 14:47:38.295322+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Please find the attached test log from the Ubuntu Server Team's CI infrastructure.  As part of the verification process for this bug, Nova has been deployed and configured across multiple nodes using precise-proposed as an installation source.  After successful bring-up and configuration of the cluster, a number of exercises and smoke tests have be invoked to ensure the updated package did not introduce any regressions. A number of test iterations were carried out to catch any possible transient errors.\n\nPlease Note the list of installed packages at the top and bottom of the report.\n\nFor records of upstream test coverage of this update, please see the Jenkins links in the comments of the relevant  upstream code-review(s):\n\nTrunk review: https://review.openstack.org/10655\nStable review: https://review.openstack.org/10962\n\nAs per the provisional Micro Release Exception granted to this package by the Technical Board, we hope this contributes toward verification of this update.", 
            "date_created": "2012-08-30 07:34:47.517787+00:00", 
            "author": "https://api.launchpad.net/1.0/~gandelman-a"
        }, 
        {
            "content": "Test coverage log.", 
            "date_created": "2012-08-30 07:34:49.699485+00:00", 
            "author": "https://api.launchpad.net/1.0/~gandelman-a"
        }, 
        {
            "content": "This bug was fixed in the package nova - 2012.1.3+stable-20120827-4d2a4afe-0ubuntu1\n\n---------------\nnova (2012.1.3+stable-20120827-4d2a4afe-0ubuntu1) precise-proposed; urgency=low\n\n  * New upstream snapshot, fixes FTBFS in -proposed. (LP: #1041120)\n  * Resynchronize with stable/essex (4d2a4afe):\n    - [5d63601] Inappropriate exception handling on kvm live/block migration\n      (LP: #917615)\n    - [ae280ca] Deleted floating ips can cause instance delete to fail\n      (LP: #1038266)\n\nnova (2012.1.3+stable-20120824-86fb7362-0ubuntu1) precise-proposed; urgency=low\n\n  * New upstream snapshot. (LP: #1041120)\n  * Dropped, superseded by new snapshot:\n    - debian/patches/CVE-2012-3447.patch: [d9577ce]\n    - debian/patches/CVE-2012-3371.patch: [25f5bd3]\n    - debian/patches/CVE-2012-3360+3361.patch: [b0feaff]\n  * Resynchronize with stable/essex (86fb7362):\n    - [86fb736] Libvirt driver reports incorrect error when volume-detach fails\n      (LP: #1029463)\n    - [272b98d] nova delete lxc-instance umounts the wrong rootfs (LP: #971621)\n    - [09217ab] Block storage connections are NOT restored on system reboot\n      (LP: #1036902)\n    - [d9577ce] CVE-2012-3361 not fully addressed (LP: #1031311)\n    - [e8ef050] pycrypto is unused and the existing code is potentially insecure\n      to use (LP: #1033178)\n    - [3b4ac31] cannot umount guestfs  (LP: #1013689)\n    - [f8255f3] qpid_heartbeat setting in ineffective (LP: #1030430)\n    - [413c641] Deallocation of fixed IP occurs before security group refresh\n      leading to potential security issue in error / race conditions\n      (LP: #1021352)\n    - [219c5ca] Race condition in network/deallocate_for_instance() leads to\n      security issue (LP: #1021340)\n    - [f2bc403] cleanup_file_locks does not remove stale sentinel files\n      (LP: #1018586)\n    - [4c7d671] Deleting Flavor currently in use by instance creates error\n      (LP: #994935)\n    - [7e88e39] nova testsuite errors on newer versions of python-boto (e.g.\n      2.5.2) (LP: #1027984)\n    - [80d3026] NoMoreFloatingIps: Zero floating ips available after repeatedly\n      creating and destroying instances over time (LP: #1017418)\n    - [4d74631] Launching with source groups under load produces lazy load error\n      (LP: #1018721)\n    - [08e5128] API 'v1.1/{tenant_id}/os-hosts' does not return a list of hosts\n      (LP: #1014925)\n    - [801b94a] Restarting nova-compute removes ip packet filters (LP: #1027105)\n    - [f6d1f55] instance live migration should create virtual_size disk image\n      (LP: #977007)\n    - [4b89b4f] [nova][volumes] Exceeding volumes, gigabytes and floating_ips\n      quotas returns general uninformative HTTP 500 error (LP: #1021373)\n    - [6e873bc] [nova][volumes] Exceeding volumes, gigabytes and floating_ips\n      quotas returns general uninformative HTTP 500 error (LP: #1021373)\n    - [7b215ed] Use default qemu-img cluster size in libvirt connection driver\n    - [d3a87a2] Listing flavors with marker set returns 400 (LP: #956096)\n    - [cf6a85a] nova-rootwrap hardcodes paths instead of using\n      /sbin:/usr/sbin:/usr/bin:/bin (LP: #1013147)\n    - [2efc87c] affinity filters don't work if scheduler_hints is None\n      (LP: #1007573)\n    - [48e5f46] metadata injection is broken in xen (LP: #1022036)\n    - [25f5bd3] scheduler hang (DOS) possible with\n      DifferentHostFilter/SameHostFilter  (LP: #1017795)\n    - [1c1b858] cannot umount guestfs  (LP: #1013689)\n    - [835ba4f] not able to get host total memory in xen with libvirt\n      (LP: #1004298)\n    - [00e5104] Call to network_get_all_by_uuids missing 'db' (LP: #986922)\n    - [4c49df7] [nova][volumes] Exceeding volumes, gigabytes and floating_ips\n      quotas returns general uninformative HTTP 500 error (LP: #1021373)\n    - [19631f3] [nova][volumes] Exceeding volumes quotas logs\n      \"VolumeSizeTooLarge\" instead of \"VolumeLimitExceeded\"  (LP: #1020634)\n    - [b0feaff] Remote arbitrary file corruption / creation flaw via injected\n      files (LP: #1015531)\n    - [3cb6e57] NoMoreFixedIps: Zero fixed ips available. Nova seems leaking\n      them. (LP: #1014769)\n    - [5d8431b] ram_allocation_ratio does not work (LP: #1016273)\n    - [410060f] test_get_console_output_file requires sudo NOPASSWD\n      (LP: #992805)\n    - [33c2575] Stop/start a KVM instance with volumes attached produces an\n      error state (LP: #1013782)\n    - [6c01c01] Backport tox settings to unbreak jenkins jobs.\n    - [344125f] Set defaultbranch in .gitreview to stable/essex\n    - [9b789be] floating ips are not disassociated from instances on deletion\n      (LP: #997763)\n    - [d89c2f3] qpid timeout causing compute service to crash (LP: #999698)\n    - [caae0e9] floating ips do not display in 'nova list' after association to\n      instance (LP: #939122)\n    - [1dc9f19] impl_qpid doesn't ACK messages (LP: #1012374)\n    - [bc621bc] Restarting nova-network removes ip packet filters\n      (LP: #1000853)\n    - [7870157] Add caching to openstack.common.cfg\n    - [27133ee] Firewall rules from nova-compute are not refreshed after host\n      reboot (LP: #985162)\n    - [3ee026e] Source group based security group rule without protocol and port\n      causes failures (LP: #1010514)\n    - [f0a9f47] [SRU] dns_domains table mysql charset is 'latin1'. Should be\n      'utf8' (LP: #993663)\n    - [cc8fd97] euca-describe-keypair NonExistent returns 200 (LP: #1006664)\n    - [9f9e9da] Security groups fail to be set correctly if incorrect case is\n      used for protocol specification (LP: #985184)\n -- Adam Gandelman <email address hidden>   Mon, 27 Aug 2012 14:50:40 -0700", 
            "date_created": "2012-09-03 15:18:08.793162+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }, 
        {
            "content": "The verification of this Stable Release Update has completed successfully and the package has now been released to -updates.  Subsequently, the Ubuntu Stable Release Updates Team is being unsubscribed and will not receive messages about this bug report.  In the event that you encounter a regression using the package from -updates please report a new bug using ubuntu-bug and tag the bug report regression-update so we can easily find any regresssions.", 
            "date_created": "2012-09-03 15:22:12.309136+00:00", 
            "author": "https://api.launchpad.net/1.0/~clint-fewbar"
        }
    ]
}