{
    "status": "Fix Released", 
    "last_updated": "2015-12-03 21:35:05.274208+00:00", 
    "description": "nova version: 1:2014.2.1-0ubuntu1~cloud0\n\nState to reproduce:\n1. Boot instance from image\n2. Delete image\n3. Stop nova-compute\n4. Remove /var/lib/nova/instances/_base/*\n5. start nova-compute\n6. Try to rescue instance (nova rescue image)\n\nNova-compute will fail with few  traces (see below) and instance get strange state:\n\nnova show 290ab4b7-7225-4b74-853a-d342974a2080\n+--------------------------------------+----------------------------------------------------------+\n| Property                             | Value                                                    |\n+--------------------------------------+----------------------------------------------------------+\n| OS-DCF:diskConfig                    | AUTO                                                     |\n| OS-EXT-AZ:availability_zone          | nova                                                     |\n| OS-EXT-SRV-ATTR:host                 | pp3                                                      |\n| OS-EXT-SRV-ATTR:hypervisor_hostname  | pp3                                                      |\n| OS-EXT-SRV-ATTR:instance_name        | instance-000000f6                                        |\n| OS-EXT-STS:power_state               | 1                                                        |\n| OS-EXT-STS:task_state                | -                                                        |\n| OS-EXT-STS:vm_state                  | active                                                   |\n| OS-SRV-USG:launched_at               | 2015-02-05T14:15:30.000000                               |\n| OS-SRV-USG:terminated_at             | -                                                        |\n(skip)\n\nAfter that it is impossible to unrescue instance  (Cannot 'unrescue' while instance is in vm_state active) or hard-reset (nothing happens).\n\nOnly nova reset-state helps.\n\nExpected behavior: set it to ERROR state or, better, to reject rescue if no image found.\n\nTraces:\n\n2015-02-05 15:59:41.973 7281 INFO nova.virt.libvirt.driver [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Instance failed to shutdown in 60 seconds.\n2015-02-05 15:59:42.363 7281 DEBUG nova.virt.driver [-] Emitting event <LifecycleEvent: 1423148382.36, 290ab4b7-7225-4b74-853a-d342974a2080 => Stopped> emit_event /usr/lib/python2.7/dist-packages/nova/virt/driver.py:1298\n2015-02-05 15:59:42.364 7281 INFO nova.compute.manager [-] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] VM Stopped (Lifecycle Event)\n2015-02-05 15:59:42.366 7281 INFO nova.virt.libvirt.driver [-] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Instance destroyed successfully.\n2015-02-05 15:59:42.368 7281 INFO nova.virt.libvirt.driver [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Creating image\n2015-02-05 15:59:42.369 7281 DEBUG nova.openstack.common.processutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf chown 106 /var/lib/nova/instances/290ab4b7-7225-4b74-853a-d342974a2080/console.log execute /usr/lib/python2.7/dist-packages/nova/openstack/common/processutils.py:161\n2015-02-05 15:59:42.389 7281 DEBUG nova.compute.manager [-] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Synchronizing instance power state after lifecycle event \"Stopped\"; current vm_state: active, current task_state: rescuing, current DB power_state: 1, VM power_state: 4 handle_lifecycle_event /usr/lib/python2.7/dist-packages/nova/compute/manager.py:1111\n2015-02-05 15:59:42.405 7281 DEBUG nova.openstack.common.processutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] Result was 0 execute /usr/lib/python2.7/dist-packages/nova/openstack/common/processutils.py:195\n2015-02-05 15:59:42.406 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Created new semaphore \"70a880bdefde82d942a92de4c180c202e6090dd6\" internal_lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:206\n2015-02-05 15:59:42.406 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Acquired semaphore \"70a880bdefde82d942a92de4c180c202e6090dd6\" lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:229\n2015-02-05 15:59:42.406 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Attempting to grab external lock \"70a880bdefde82d942a92de4c180c202e6090dd6\" external_lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:178\n2015-02-05 15:59:42.406 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Got file lock \"/var/lib/nova/instances/locks/nova-70a880bdefde82d942a92de4c180c202e6090dd6\" acquire /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:93\n2015-02-05 15:59:42.407 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Got semaphore / lock \"fetch_func_sync\" inner /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:271\n2015-02-05 15:59:42.407 7281 DEBUG glanceclient.common.http [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] curl -i -X GET -H 'User-Agent: python-glanceclient' -H 'Content-Type: application/octet-stream' -H 'Accept-Encoding: gzip, deflate' -H 'Accept: */*' -H 'X-Auth-Token: ***' http://gi.controller:9292/v1/images/a58da6f6-cea3-4b3a-bdd0-30aefcdb37cf log_curl_request /usr/lib/python2.7/dist-packages/glanceclient/common/http.py:119\n2015-02-05 15:59:42.417 7281 INFO nova.compute.manager [-] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] During sync_power_state the instance has a pending task (rescuing). Skip.\n2015-02-05 15:59:42.515 7281 ERROR glanceclient.common.http [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Request returned failure status 404.\n2015-02-05 15:59:42.515 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Released file lock \"/var/lib/nova/instances/locks/nova-70a880bdefde82d942a92de4c180c202e6090dd6\" release /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:115\n2015-02-05 15:59:42.515 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Releasing semaphore \"70a880bdefde82d942a92de4c180c202e6090dd6\" lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:238\n2015-02-05 15:59:42.516 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Semaphore / lock released \"fetch_func_sync\" inner /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:275\n2015-02-05 15:59:42.516 7281 ERROR nova.compute.manager [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Error trying to Rescue Instance\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Traceback (most recent call last):\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 3277, in rescue_instance\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     rescue_image_meta, admin_password)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 2569, in rescue\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     admin_pass=rescue_password)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 3005, in _create_image\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     project_id=instance['project_id'])\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/imagebackend.py\", line 208, in cache\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     *args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/imagebackend.py\", line 410, in create_image\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     prepare_template(target=base, max_size=size, *args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py\", line 272, in inner\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     return f(*args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/imagebackend.py\", line 198, in fetch_func_sync\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     fetch_func(target=target, *args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/utils.py\", line 452, in fetch_image\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     max_size=max_size)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/images.py\", line 79, in fetch_to_raw\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     max_size=max_size)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/images.py\", line 73, in fetch\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     IMAGE_API.download(context, image_href, dest_path=path)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/image/api.py\", line 178, in download\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     dst_path=dest_path)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/image/glance.py\", line 359, in download\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     _reraise_translated_image_exception(image_id)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/image/glance.py\", line 357, in download\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     image_chunks = self._client.call(context, 1, 'data', image_id)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/image/glance.py\", line 232, in call\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     return getattr(client.images, method)(*args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/glanceclient/v1/images.py\", line 142, in data\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     % urlparse.quote(str(image_id)))\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/glanceclient/common/http.py\", line 253, in get\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     return self._request('GET', url, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/glanceclient/common/http.py\", line 221, in _request\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     raise exc.from_response(resp, resp.content)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080] ImageNotFound: Image a58da6f6-cea3-4b3a-bdd0-30aefcdb37cf could not be found.\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]\n2015-02-05 15:59:42.649 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Created new semaphore \"compute_resources\" internal_lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:206\n2015-02-05 15:59:42.650 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Acquired semaphore \"compute_resources\" lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:229\n2015-02-05 15:59:42.650 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Got semaphore / lock \"update_usage\" inner /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:271\n2015-02-05 15:59:42.671 7281 INFO nova.scheduler.client.report [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] Compute_service record updated for ('pp3', 'pp3')\n2015-02-05 15:59:42.671 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Releasing semaphore \"compute_resources\" lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:238\n2015-02-05 15:59:42.672 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Semaphore / lock released \"update_usage\" inner /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:275\n2015-02-05 15:59:42.672 7281 ERROR oslo.messaging.rpc.dispatcher [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Exception during message handling: Instance 290ab4b7-7225-4b74-853a-d342974a2080 cannot be rescued: Driver Error: Image a58da6f6-cea3-4b3a-bdd0-30aefcdb37cf could not be found.\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher Traceback (most recent call last):\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 134, in _dispatch_and_reply\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     incoming.message))\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 177, in _dispatch\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return self._do_dispatch(endpoint, method, ctxt, args)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 123, in _do_dispatch\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     result = getattr(endpoint, method)(ctxt, **new_args)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 419, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 88, in wrapped\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     payload)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/excutils.py\", line 82, in __exit__\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 71, in wrapped\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return f(self, context, *args, **kw)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 303, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     pass\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/excutils.py\", line 82, in __exit__\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 289, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 353, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 331, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     kwargs['instance'], e, sys.exc_info())\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/excutils.py\", line 82, in __exit__\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 319, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 3283, in rescue_instance\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     reason=_(\"Driver Error: %s\") % unicode(e))\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher InstanceNotRescuable: Instance 290ab4b7-7225-4b74-853a-d342974a2080 cannot be rescued: Driver Error: Image a58da6f6-cea3-4b3a-bdd0-30aefcdb37cf could not be found.", 
    "tags": [], 
    "importance": "Low", 
    "heat": 12, 
    "link": "https://bugs.launchpad.net/nova/+bug/1418590", 
    "owner": "https://api.launchpad.net/1.0/~mriedem", 
    "id": 1418590, 
    "index": 250, 
    "created": "2015-02-05 15:12:04.044665+00:00", 
    "title": "Instance is left in ACTIVE state even if rescue fails", 
    "comments": [
        {
            "content": "State to reproduce:\n1. Boot instance from image\n2. Delete image\n3. Stop nova-compute\n4. Remove /var/lib/nova/instances/_base/*\n5. start nova-compute\n6. Try to rescue instance (nova rescue image)\n\nNova-compute will fail with few  traces (see below) and instance get strange state:\n\nnova show 290ab4b7-7225-4b74-853a-d342974a2080\n+--------------------------------------+----------------------------------------------------------+\n| Property                             | Value                                                    |\n+--------------------------------------+----------------------------------------------------------+\n| OS-DCF:diskConfig                    | AUTO                                                     |\n| OS-EXT-AZ:availability_zone          | nova                                                     |\n| OS-EXT-SRV-ATTR:host                 | pp3                                                      |\n| OS-EXT-SRV-ATTR:hypervisor_hostname  | pp3                                                      |\n| OS-EXT-SRV-ATTR:instance_name        | instance-000000f6                                        |\n| OS-EXT-STS:power_state               | 1                                                        |\n| OS-EXT-STS:task_state                | -                                                        |\n| OS-EXT-STS:vm_state                  | active                                                   |\n| OS-SRV-USG:launched_at               | 2015-02-05T14:15:30.000000                               |\n| OS-SRV-USG:terminated_at             | -                                                        |\n(skip)\n\nAfter that it is impossible to unrescue instance  (Cannot 'unrescue' while instance is in vm_state active) or hard-reset (nothing happens).\n\nOnly nova reset-state helps.\n\nExpected behavior: set it to ERROR state.\n\nTraces:\n\n2015-02-05 15:59:41.973 7281 INFO nova.virt.libvirt.driver [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Instance failed to shutdown in 60 seconds.\n2015-02-05 15:59:42.363 7281 DEBUG nova.virt.driver [-] Emitting event <LifecycleEvent: 1423148382.36, 290ab4b7-7225-4b74-853a-d342974a2080 => Stopped> emit_event /usr/lib/python2.7/dist-packages/nova/virt/driver.py:1298\n2015-02-05 15:59:42.364 7281 INFO nova.compute.manager [-] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] VM Stopped (Lifecycle Event)\n2015-02-05 15:59:42.366 7281 INFO nova.virt.libvirt.driver [-] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Instance destroyed successfully.\n2015-02-05 15:59:42.368 7281 INFO nova.virt.libvirt.driver [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Creating image\n2015-02-05 15:59:42.369 7281 DEBUG nova.openstack.common.processutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf chown 106 /var/lib/nova/instances/290ab4b7-7225-4b74-853a-d342974a2080/console.log execute /usr/lib/python2.7/dist-packages/nova/openstack/common/processutils.py:161\n2015-02-05 15:59:42.389 7281 DEBUG nova.compute.manager [-] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Synchronizing instance power state after lifecycle event \"Stopped\"; current vm_state: active, current task_state: rescuing, current DB power_state: 1, VM power_state: 4 handle_lifecycle_event /usr/lib/python2.7/dist-packages/nova/compute/manager.py:1111\n2015-02-05 15:59:42.405 7281 DEBUG nova.openstack.common.processutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] Result was 0 execute /usr/lib/python2.7/dist-packages/nova/openstack/common/processutils.py:195\n2015-02-05 15:59:42.406 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Created new semaphore \"70a880bdefde82d942a92de4c180c202e6090dd6\" internal_lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:206\n2015-02-05 15:59:42.406 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Acquired semaphore \"70a880bdefde82d942a92de4c180c202e6090dd6\" lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:229\n2015-02-05 15:59:42.406 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Attempting to grab external lock \"70a880bdefde82d942a92de4c180c202e6090dd6\" external_lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:178\n2015-02-05 15:59:42.406 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Got file lock \"/var/lib/nova/instances/locks/nova-70a880bdefde82d942a92de4c180c202e6090dd6\" acquire /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:93\n2015-02-05 15:59:42.407 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Got semaphore / lock \"fetch_func_sync\" inner /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:271\n2015-02-05 15:59:42.407 7281 DEBUG glanceclient.common.http [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] curl -i -X GET -H 'User-Agent: python-glanceclient' -H 'Content-Type: application/octet-stream' -H 'Accept-Encoding: gzip, deflate' -H 'Accept: */*' -H 'X-Auth-Token: ***' http://gi.controller:9292/v1/images/a58da6f6-cea3-4b3a-bdd0-30aefcdb37cf log_curl_request /usr/lib/python2.7/dist-packages/glanceclient/common/http.py:119\n2015-02-05 15:59:42.417 7281 INFO nova.compute.manager [-] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] During sync_power_state the instance has a pending task (rescuing). Skip.\n2015-02-05 15:59:42.515 7281 ERROR glanceclient.common.http [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Request returned failure status 404.\n2015-02-05 15:59:42.515 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Released file lock \"/var/lib/nova/instances/locks/nova-70a880bdefde82d942a92de4c180c202e6090dd6\" release /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:115\n2015-02-05 15:59:42.515 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Releasing semaphore \"70a880bdefde82d942a92de4c180c202e6090dd6\" lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:238\n2015-02-05 15:59:42.516 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Semaphore / lock released \"fetch_func_sync\" inner /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:275\n2015-02-05 15:59:42.516 7281 ERROR nova.compute.manager [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Error trying to Rescue Instance\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080] Traceback (most recent call last):\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 3277, in rescue_instance\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     rescue_image_meta, admin_password)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 2569, in rescue\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     admin_pass=rescue_password)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 3005, in _create_image\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     project_id=instance['project_id'])\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/imagebackend.py\", line 208, in cache\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     *args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/imagebackend.py\", line 410, in create_image\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     prepare_template(target=base, max_size=size, *args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py\", line 272, in inner\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     return f(*args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/imagebackend.py\", line 198, in fetch_func_sync\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     fetch_func(target=target, *args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/utils.py\", line 452, in fetch_image\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     max_size=max_size)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/images.py\", line 79, in fetch_to_raw\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     max_size=max_size)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/virt/images.py\", line 73, in fetch\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     IMAGE_API.download(context, image_href, dest_path=path)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/image/api.py\", line 178, in download\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     dst_path=dest_path)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/image/glance.py\", line 359, in download\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     _reraise_translated_image_exception(image_id)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/image/glance.py\", line 357, in download\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     image_chunks = self._client.call(context, 1, 'data', image_id)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/nova/image/glance.py\", line 232, in call\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     return getattr(client.images, method)(*args, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/glanceclient/v1/images.py\", line 142, in data\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     % urlparse.quote(str(image_id)))\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/glanceclient/common/http.py\", line 253, in get\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     return self._request('GET', url, **kwargs)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]   File \"/usr/lib/python2.7/dist-packages/glanceclient/common/http.py\", line 221, in _request\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080]     raise exc.from_response(resp, resp.content)\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080] ImageNotFound: Image a58da6f6-cea3-4b3a-bdd0-30aefcdb37cf could not be found.\n2015-02-05 15:59:42.516 7281 TRACE nova.compute.manager [instance: 290ab4b7-7225-4b74-853a-d342974a2080] \n2015-02-05 15:59:42.649 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Created new semaphore \"compute_resources\" internal_lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:206\n2015-02-05 15:59:42.650 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Acquired semaphore \"compute_resources\" lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:229\n2015-02-05 15:59:42.650 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Got semaphore / lock \"update_usage\" inner /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:271\n2015-02-05 15:59:42.671 7281 INFO nova.scheduler.client.report [req-af7026f3-4d85-4899-8452-2b69a3e66123 None] Compute_service record updated for ('pp3', 'pp3')\n2015-02-05 15:59:42.671 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Releasing semaphore \"compute_resources\" lock /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:238\n2015-02-05 15:59:42.672 7281 DEBUG nova.openstack.common.lockutils [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Semaphore / lock released \"update_usage\" inner /usr/lib/python2.7/dist-packages/nova/openstack/common/lockutils.py:275\n2015-02-05 15:59:42.672 7281 ERROR oslo.messaging.rpc.dispatcher [req-af7026f3-4d85-4899-8452-2b69a3e66123 ] Exception during message handling: Instance 290ab4b7-7225-4b74-853a-d342974a2080 cannot be rescued: Driver Error: Image a58da6f6-cea3-4b3a-bdd0-30aefcdb37cf could not be found.\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher Traceback (most recent call last):\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 134, in _dispatch_and_reply\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     incoming.message))\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 177, in _dispatch\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return self._do_dispatch(endpoint, method, ctxt, args)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 123, in _do_dispatch\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     result = getattr(endpoint, method)(ctxt, **new_args)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 419, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 88, in wrapped\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     payload)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/excutils.py\", line 82, in __exit__\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 71, in wrapped\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return f(self, context, *args, **kw)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 303, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     pass\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/excutils.py\", line 82, in __exit__\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 289, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 353, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 331, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     kwargs['instance'], e, sys.exc_info())\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/excutils.py\", line 82, in __exit__\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 319, in decorated_function\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 3283, in rescue_instance\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher     reason=_(\"Driver Error: %s\") % unicode(e))\n2015-02-05 15:59:42.672 7281 TRACE oslo.messaging.rpc.dispatcher InstanceNotRescuable: Instance 290ab4b7-7225-4b74-853a-d342974a2080 cannot be rescued: Driver Error: Image a58da6f6-cea3-4b3a-bdd0-30aefcdb37cf could not be found.", 
            "date_created": "2015-02-05 15:12:04.044665+00:00", 
            "author": "https://api.launchpad.net/1.0/~george-shuklin"
        }, 
        {
            "content": "My current idea is to stop using cached images at all for the rescue and check if image exists before doing anything bad with instance.\n\nIn my current implementation attempt to rescue instance with deleted image will not stop instance and log error: \n\nImage cad7e9e6-930c-4622-bbd4-b3af79f66914 found but deleted, unable to use it for rescue instance 8f021338-233e-4f4e-937a-596358e487c4.", 
            "date_created": "2015-02-11 17:31:03.542908+00:00", 
            "author": "https://api.launchpad.net/1.0/~george-shuklin"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/154991", 
            "date_created": "2015-02-11 18:28:25.339568+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Why would you remove /var/lib/nova/instances/_base/* ?", 
            "date_created": "2015-02-11 22:25:50.485645+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Which virt driver are you using?", 
            "date_created": "2015-02-11 22:31:20.403552+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Hello. We using qemu/kvm with raw disks. Normally, disk (qcow) will be irreversibly damaged if someone removes _base, but for the raw disks all stuff in _base is formality. We placing it on slow HDD raid0 (VS normal raid with SSD for instance disks), so losing HDD with _base's is normal case for us. In case of IO errors we're just replacing HDD, remounting _base, restarting nova-compute  and continue to work without any problems. But 'rescue' has a problem (and I'm now in the process of Jenkins fight for fix).", 
            "date_created": "2015-02-11 22:49:00.990256+00:00", 
            "author": "https://api.launchpad.net/1.0/~george-shuklin"
        }, 
        {
            "content": "OK. I found some problems with my ideas: If instance have _base, it still can be rescued even if image is deleted. I'll think about this on second part.\n\nFor now I'll set instance in ERROR if rescue was failed.  (Bugreport says 'instance broken, but status is ACTIVE'). ", 
            "date_created": "2015-02-11 23:57:57.150027+00:00", 
            "author": "https://api.launchpad.net/1.0/~george-shuklin"
        }, 
        {
            "content": "Change abandoned by George Shuklin (<email address hidden>) on branch: master\nReview: https://review.openstack.org/154991\nReason: Sorry, I found it is not good - it will silently rejects to rescue instances with existing _base and deleted image.", 
            "date_created": "2015-02-11 23:59:55.263184+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/155120", 
            "date_created": "2015-02-12 00:21:11.331332+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Sorry, I've lost context of the fix, upstream is way to ahead.", 
            "date_created": "2015-06-23 09:13:58.208087+00:00", 
            "author": "https://api.launchpad.net/1.0/~george-shuklin"
        }, 
        {
            "content": "Solving an inconsistency: The bug is 'In Progress' but without an assignee. I set the status back to the last known status before the change to 'In Progress'. \n\nFeel free to assign the bug to yourself. If you do so, please set it to 'In Progress'.", 
            "date_created": "2015-07-14 15:01:47.912613+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "Did you configure the rescue image in nova.conf. rescue operation is to get the ERROR prone instance disks to be added as secondary disks to the new instance which is going to be created by the rescue operation. \n\nPlease clarify if I am wrong", 
            "date_created": "2015-08-19 11:31:28.837820+00:00", 
            "author": "https://api.launchpad.net/1.0/~amritgeo"
        }, 
        {
            "content": "I am looking forward to work on this bug please assign it to me", 
            "date_created": "2015-09-19 01:34:39.402198+00:00", 
            "author": "https://api.launchpad.net/1.0/~khushbuparakh"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/155120\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=a9e4e2c9a5aaa4d675057790816aa395bc27e9bc\nSubmitter: Jenkins\nBranch:    master\n\ncommit a9e4e2c9a5aaa4d675057790816aa395bc27e9bc\nAuthor: George Shuklin <email address hidden>\nDate:   Fri May 1 17:57:00 2015 +0300\n\n    If rescue failed set instance to ERROR\n    \n    The compute API will allow attempting to rescue an instance that is in\n    active/stopped/error state.  The compute manager will power off the instance\n    before calling driver.rescue.\n    \n    If the rescue call fails in the virt driver, we should set the instance\n    to ERROR state since we (1) know the instance is definitely not active since\n    the compute manager powered it off and (2) we don't know what failed in the\n    virt driver, so punting and putting the instance into ERROR state is better\n    than leaving it broken and not signaling that with the vm_state.\n    \n    Co-Authored-By: Matt Riedemann <email address hidden>\n    \n    Closes-Bug: 1418590\n    Change-Id: Ia1054d3f9193f876803f8b5a26d00bd9d5d66c12\n", 
            "date_created": "2015-10-06 14:49:49.455590+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 13.0.0.0b1 development milestone.", 
            "date_created": "2015-12-02 16:18:20.439209+00:00", 
            "author": "https://api.launchpad.net/1.0/~ttx"
        }
    ]
}