{
    "status": "Fix Released", 
    "last_updated": "2015-10-15 08:49:10.559022+00:00", 
    "description": "If instance is resizing and user tries to delete the instance, in that\ncase instance gets deleted successfully. After instance deletion, greenthread which was resizing the instance raises InstanceNotFound error, which caught in errors_out_migration and raises \"KeyError: 'migration' \".\n\nNow if user tries to restart the n-cpu service, it fails with InstanceNotFound error.\n\nSteps to reproduce:\n1. Create instance\n2. Resize instance\n3. Delete instance while resize is in progress (scp/rsync process is running)\n4. Instance is deleted successfully and instance files are cleaned from source compute node\n5. When scp/rsync process completes it throws error \"InstanceNotFound\" and later the migration status remains in 'migrating' status. After catching InstanceNotFound error in _errors_out_migration decorator, it throws \"KeyError: 'migration'\" from errors_out_migration decorator, where migration is expected to be a kwargs, but it is passed as args.\nIt throws below error:\n\n2015-04-14 23:29:12.466 ERROR nova.compute.manager [req-2b4e3718-a1fa-4603-bd9e-6c9481f75e16 demo demo] [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Setting instance vm_state to ERROR\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Traceback (most recent call last):\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/compute/manager.py\", line 6358, in _error_out_instance_on_exception\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     yield\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/compute/manager.py\", line 3984, in resize_instance\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     timeout, retry_interval)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6318, in migrate_disk_and_power_off\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     shared_storage)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     six.reraise(self.type_, self.value, self.tb)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6313, in migrate_disk_and_power_off\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     libvirt_utils.copy_image(from_path, img_path, host=dest)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/virt/libvirt/utils.py\", line 327, in copy_image\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     execute('scp', src, dest)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/virt/libvirt/utils.py\", line 55, in execute\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     return utils.execute(*args, **kwargs)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/utils.py\", line 206, in execute\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     return processutils.execute(*cmd, **kwargs)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/usr/local/lib/python2.7/dist-packages/oslo_concurrency/processutils.py\", line 238, in execute\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     cmd=sanitized_cmd)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] ProcessExecutionError: Unexpected error while running command.\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Command: scp /opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09_resize/disk.config 10.69.4.172:/opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09/disk.config\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Exit code: 1\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Stdout: u''\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Stderr: u'/opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09_resize/disk.config: No such file or directory\\n'\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]\n2015-04-14 23:29:12.632 DEBUG nova.compute.manager [req-2b4e3718-a1fa-4603-b\nd9e-6c9481f75e16 demo demo] [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Instance has been destroyed from under us while trying to set it to ERROR from (pid=28734) _set_instance_error_state /opt/stack/nova/nova/compute/manager.py:741\n2015-04-14 23:29:12.684 ERROR root [req-2b4e3718-a1fa-4603-bd9e-6c9481f75e16 demo demo] Original exception being dropped: ['Traceback (most recent call last):\\n', '  File \"/opt/stack/nova/nova/compute/manager.py\", line 269, in decorated_function\\n    return function(self, context, *args, **kwargs)\\n', '  File \"/opt/stack/nova/nova/compute/manager.py\", line 352, in decorated_function\\n    kwargs[\\'instance\\'], e, sys.exc_info())\\n', '  File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\\n    six.reraise(self.type_, self.value, self.tb)\\n', '  File \"/opt/stack/nova/nova/compute/manager.py\", line 340, in decorated_function\\n    return function(self, context, *args, **kwargs)\\n', '  File \"/opt/stack/nova/nova/compute/manager.py\", line 3984, in resize_instance\\n    timeout, retry_interval)\\n', '  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6318, in migrate_disk_and_power_off\\n    shared_storage)\\n', '  File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\\n    six.reraise(self.type_, self.value, self.tb)\\n', '  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6313, in migrate_disk_and_power_off\\n    libvirt_utils.copy_image(from_path, img_path, host=dest)\\n', '  File \"/opt/stack/nova/nova/virt/libvirt/utils.py\", line 327, in copy_image\\n    execute(\\'scp\\', src, dest)\\n', '  File \"/opt/stack/nova/nova/virt/libvirt/utils.py\", line 55, in execute\\n    return utils.execute(*args, **kwargs)\\n', '  File \"/opt/stack/nova/nova/utils.py\", line 206, in execute\\n    return processutils.execute(*cmd, **kwargs)\\n', '  File \"/usr/local/lib/python2.7/dist-packages/oslo_concurrency/processutils.py\", line 238, in execute\\n    cmd=sanitized_cmd)\\n', \"ProcessExecutionError: Unexpected error while running command.\\nCommand: scp /opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09_resize/disk.config 10.69.4.172:/opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09/disk.config\\nExit code: 1\\nStdout: u''\\nStderr: u'/opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09_resize/disk.config: No such file or directory\\\\n'\\n\"]\n2015-04-14 23:29:12.772 ERROR oslo_messaging.rpc.dispatcher [req-2b4e3718-a1fa-4603-bd9e-6c9481f75e16 demo demo] Exception during message handling: 'migration'\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher Traceback (most recent call last):\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 142, in _dispatch_and_reply\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     executor_callback))\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 186, in _dispatch\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     executor_callback)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 130, in _do_dispatch\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     result = func(ctxt, **new_args)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 6732, in resize_instance\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     clean_shutdown=clean_shutdown)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/exception.py\", line 88, in wrapped\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     payload)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/exception.py\", line 71, in wrapped\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     return f(self, context, *args, **kw)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 324, in decorated_function\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     LOG.warning(msg, e, instance_uuid=instance_uuid)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 295, in decorated_function\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 374, in decorated_function\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 272, in decorated_function\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     migration = kwargs['migration']\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher KeyError: 'migration'\n\n6. Stop and start nova-compute service\n\nWhen you start nova-compute service, it fails to start with below error.\n\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup Traceback (most recent call last):\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/threadgroup.py\", line 145, in wait\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     x.wait()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/threadgroup.py\", line 47, in wait\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return self.thread.wait()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 175, in wait\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return self._exit_event.wait()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 121, in wait\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return hubs.get_hub().switch()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 294, in switch\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return self.greenlet.switch()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 214, in main\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     result = function(*args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/service.py\", line 497, in run_service\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     service.start()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/service.py\", line 183, in start\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     self.manager.pre_start_hook()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/manager.py\", line 1287, in pre_start_hook\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     self.update_available_resource(nova.context.get_admin_context())\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/manager.py\", line 6236, in update_available_resource\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     rt.update_available_resource(context)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 402, in update_available_resource\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     self._update_available_resource(context, resources)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py\", line 445, in inner\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return f(*args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 445, in _update_available_resource\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     self._update_usage_from_migrations(context, resources, migrations)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 708, in _update_usage_from_migrations\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     instance = migration.instance\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/objects/migration.py\", line 80, in instance\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return objects.Instance.get_by_uuid(self._context, self.instance_uuid)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/objects/base.py\", line 161, in wrapper\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     args, kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/conductor/rpcapi.py\", line 325, in object_class_action\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     objver=objver, args=args, kwargs=kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 156, in call\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     retry=self.retry)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 90, in _send\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     timeout=timeout, retry=retry)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 350, in send\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     retry=retry)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 341, in _send\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     raise result\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup InstanceNotFound_Remote: Instance 1f24201e-4eac-4dc4-9532-8fb863949a09 could not be found.\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup Traceback (most recent call last):\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/conductor/manager.py\", line 423, in _object_dispatch\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return getattr(target, method)(*args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/objects/base.py\", line 163, in wrapper\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     result = fn(cls, context, *args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/objects/instance.py\", line 564, in get_by_uuid\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     use_slave=use_slave)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/db/api.py\", line 651, in instance_get_by_uuid\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     columns_to_join, use_slave=use_slave)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/db/sqlalchemy/api.py\", line 233, in wrapper\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return f(*args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/db/sqlalchemy/api.py\", line 1744, in instance_get_by_uuid\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     columns_to_join=columns_to_join, use_slave=use_slave)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/db/sqlalchemy/api.py\", line 1756, in _instance_get_by_uuid\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     raise exception.InstanceNotFound(instance_id=uuid)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup InstanceNotFound: Instance 1f24201e-4eac-4dc4-9532-8fb863949a09 could not be found.\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup", 
    "tags": [], 
    "importance": "High", 
    "heat": 14, 
    "link": "https://bugs.launchpad.net/nova/+bug/1444300", 
    "owner": "https://api.launchpad.net/1.0/~rajesh-tailor", 
    "id": 1444300, 
    "index": 1725, 
    "created": "2015-04-15 07:07:31.226899+00:00", 
    "title": "nova-compute service doesn't restart if resize operation fails", 
    "comments": [
        {
            "content": "If instance is resizing and user tries to delete the instance, in that\ncase instance gets deleted successfully. After instance deletion, greenthread which \nwas resizing the instance raises InstanceNotFound error, which caught in \nerrors_out_migration and raises \"KeyError: 'migration' \".\n\nNow if user tries to restart the n-cpu service, it fails with InstanceNotFound error.\n\nSteps to reproduce:\n1. Create instance\n2. Resize instance\n3. Delete instance while resize is in progress (scp/rsync process is running)\n4. Instance is deleted successfully and instance files are cleaned from source compute node\n5. When scp/rsync process completes it throws error \"InstanceNotFound\" and later the migration status remains in 'migrating' status. After catching InstanceNotFound error in _errors_out_migration decorator, it throws \"KeyError: 'migration'\" from errors_out_migration decorator, where migration is expected to be a kwargs, but it is passed as args.\nIt throws below error:\n\n2015-04-14 23:29:12.466 ERROR nova.compute.manager [req-2b4e3718-a1fa-4603-bd9e-6c9481f75e16 demo demo] [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Setting instance vm_state to ERROR\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Traceback (most recent call last):\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/compute/manager.py\", line 6358, in _error_out_instance_on_exception\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     yield\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/compute/manager.py\", line 3984, in resize_instance\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     timeout, retry_interval)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6318, in migrate_disk_and_power_off\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     shared_storage)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     six.reraise(self.type_, self.value, self.tb)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6313, in migrate_disk_and_power_off\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     libvirt_utils.copy_image(from_path, img_path, host=dest)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/virt/libvirt/utils.py\", line 327, in copy_image\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     execute('scp', src, dest)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/virt/libvirt/utils.py\", line 55, in execute\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     return utils.execute(*args, **kwargs)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/opt/stack/nova/nova/utils.py\", line 206, in execute\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     return processutils.execute(*cmd, **kwargs)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]   File \"/usr/local/lib/python2.7/dist-packages/oslo_concurrency/processutils.py\", line 238, in execute\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]     cmd=sanitized_cmd)\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] ProcessExecutionError: Unexpected error while running command.\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Command: scp /opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09_resize/disk.config 10.69.4.172:/opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09/disk.config\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Exit code: 1\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Stdout: u''\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Stderr: u'/opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09_resize/disk.config: No such file or directory\\n'\n2015-04-14 23:29:12.466 TRACE nova.compute.manager [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09]\n2015-04-14 23:29:12.632 DEBUG nova.compute.manager [req-2b4e3718-a1fa-4603-b\nd9e-6c9481f75e16 demo demo] [instance: 1f24201e-4eac-4dc4-9532-8fb863949a09] Instance has been destroyed from under us while trying to set it to ERROR from (pid=28734) _set_instance_error_state /opt/stack/nova/nova/compute/manager.py:741\n2015-04-14 23:29:12.684 ERROR root [req-2b4e3718-a1fa-4603-bd9e-6c9481f75e16 demo demo] Original exception being dropped: ['Traceback (most recent call last):\\n', '  File \"/opt/stack/nova/nova/compute/manager.py\", line 269, in decorated_function\\n    return function(self, context, *args, **kwargs)\\n', '  File \"/opt/stack/nova/nova/compute/manager.py\", line 352, in decorated_function\\n    kwargs[\\'instance\\'], e, sys.exc_info())\\n', '  File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\\n    six.reraise(self.type_, self.value, self.tb)\\n', '  File \"/opt/stack/nova/nova/compute/manager.py\", line 340, in decorated_function\\n    return function(self, context, *args, **kwargs)\\n', '  File \"/opt/stack/nova/nova/compute/manager.py\", line 3984, in resize_instance\\n    timeout, retry_interval)\\n', '  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6318, in migrate_disk_and_power_off\\n    shared_storage)\\n', '  File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\\n    six.reraise(self.type_, self.value, self.tb)\\n', '  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6313, in migrate_disk_and_power_off\\n    libvirt_utils.copy_image(from_path, img_path, host=dest)\\n', '  File \"/opt/stack/nova/nova/virt/libvirt/utils.py\", line 327, in copy_image\\n    execute(\\'scp\\', src, dest)\\n', '  File \"/opt/stack/nova/nova/virt/libvirt/utils.py\", line 55, in execute\\n    return utils.execute(*args, **kwargs)\\n', '  File \"/opt/stack/nova/nova/utils.py\", line 206, in execute\\n    return processutils.execute(*cmd, **kwargs)\\n', '  File \"/usr/local/lib/python2.7/dist-packages/oslo_concurrency/processutils.py\", line 238, in execute\\n    cmd=sanitized_cmd)\\n', \"ProcessExecutionError: Unexpected error while running command.\\nCommand: scp /opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09_resize/disk.config 10.69.4.172:/opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09/disk.config\\nExit code: 1\\nStdout: u''\\nStderr: u'/opt/stack/data/nova/instances/1f24201e-4eac-4dc4-9532-8fb863949a09_resize/disk.config: No such file or directory\\\\n'\\n\"]\n2015-04-14 23:29:12.772 ERROR oslo_messaging.rpc.dispatcher [req-2b4e3718-a1fa-4603-bd9e-6c9481f75e16 demo demo] Exception during message handling: 'migration'\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher Traceback (most recent call last):\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 142, in _dispatch_and_reply\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     executor_callback))\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 186, in _dispatch\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     executor_callback)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 130, in _do_dispatch\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     result = func(ctxt, **new_args)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 6732, in resize_instance\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     clean_shutdown=clean_shutdown)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/exception.py\", line 88, in wrapped\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     payload)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/exception.py\", line 71, in wrapped\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     return f(self, context, *args, **kw)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 324, in decorated_function\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     LOG.warning(msg, e, instance_uuid=instance_uuid)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 85, in __exit__\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 295, in decorated_function\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 374, in decorated_function\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher   File \"/opt/stack/nova/nova/compute/manager.py\", line 272, in decorated_function\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher     migration = kwargs['migration']\n2015-04-14 23:29:12.772 TRACE oslo_messaging.rpc.dispatcher KeyError: 'migration'\n\n6. Stop and start nova-compute service\n\nWhen you start nova-compute service, it fails to start with below error.\n\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup Traceback (most recent call last):\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/threadgroup.py\", line 145, in wait\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     x.wait()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/threadgroup.py\", line 47, in wait\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return self.thread.wait()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 175, in wait\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return self._exit_event.wait()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 121, in wait\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return hubs.get_hub().switch()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 294, in switch\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return self.greenlet.switch()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 214, in main\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     result = function(*args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/service.py\", line 497, in run_service\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     service.start()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/service.py\", line 183, in start\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     self.manager.pre_start_hook()\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/manager.py\", line 1287, in pre_start_hook\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     self.update_available_resource(nova.context.get_admin_context())\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/manager.py\", line 6236, in update_available_resource\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     rt.update_available_resource(context)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 402, in update_available_resource\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     self._update_available_resource(context, resources)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py\", line 445, in inner\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return f(*args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 445, in _update_available_resource\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     self._update_usage_from_migrations(context, resources, migrations)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 708, in _update_usage_from_migrations\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     instance = migration.instance\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/objects/migration.py\", line 80, in instance\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return objects.Instance.get_by_uuid(self._context, self.instance_uuid)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/objects/base.py\", line 161, in wrapper\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     args, kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/conductor/rpcapi.py\", line 325, in object_class_action\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     objver=objver, args=args, kwargs=kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 156, in call\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     retry=self.retry)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 90, in _send\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     timeout=timeout, retry=retry)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 350, in send\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     retry=retry)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 341, in _send\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     raise result\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup InstanceNotFound_Remote: Instance 1f24201e-4eac-4dc4-9532-8fb863949a09 could not be found.\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup Traceback (most recent call last):\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/conductor/manager.py\", line 423, in _object_dispatch\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return getattr(target, method)(*args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/objects/base.py\", line 163, in wrapper\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     result = fn(cls, context, *args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/objects/instance.py\", line 564, in get_by_uuid\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     use_slave=use_slave)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/db/api.py\", line 651, in instance_get_by_uuid\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     columns_to_join, use_slave=use_slave)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/db/sqlalchemy/api.py\", line 233, in wrapper\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     return f(*args, **kwargs)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/db/sqlalchemy/api.py\", line 1744, in instance_get_by_uuid\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     columns_to_join=columns_to_join, use_slave=use_slave)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/db/sqlalchemy/api.py\", line 1756, in _instance_get_by_uuid\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup     raise exception.InstanceNotFound(instance_id=uuid)\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup InstanceNotFound: Instance 1f24201e-4eac-4dc4-9532-8fb863949a09 could not be found.\n2015-04-14 23:31:31.256 TRACE nova.openstack.common.threadgroup", 
            "date_created": "2015-04-15 07:07:31.226899+00:00", 
            "author": "https://api.launchpad.net/1.0/~rajesh-tailor"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/173897", 
            "date_created": "2015-04-15 14:12:43.395903+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "I think part of the code was addressed at https://bugs.launchpad.net/nova/+bug/1444439\n\n", 
            "date_created": "2015-04-15 14:51:38.770462+00:00", 
            "author": "https://api.launchpad.net/1.0/~jichenjc"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/174288", 
            "date_created": "2015-04-16 10:25:50.809605+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Davanum Srinivas (dims) (<email address hidden>) on branch: master\nReview: https://review.openstack.org/173897\nReason: Abandoning in favor of Rajesh's review.", 
            "date_created": "2015-04-16 10:35:57.869359+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/174288\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=3add7923fc16c050d4cfaef98a87886c6b6a589c\nSubmitter: Jenkins\nBranch:    master\n\ncommit 3add7923fc16c050d4cfaef98a87886c6b6a589c\nAuthor: Rajesh Tailor <email address hidden>\nDate:   Wed Apr 15 06:59:04 2015 -0700\n\n    Fix kwargs['migration'] KeyError in @errors_out_migration decorator\n    \n    @errors_out_migration decorator is used in the compute manager on\n    resize_instance and finish_resize methods of ComputeManager class.\n    It is decorated via @utils.expects_func_args('migration') to check\n    'migration' is a parameter to the decorator method, however, that\n    only ensures there is a migration argument, not that it's in args or\n    kwargs (either is fine for what expects_func_args checks).\n    The errors_out_migration decorator can get a KeyError when checking\n    kwargs['migration'] and fails to set the migration status to 'error'.\n    \n    This fixes the KeyError in the decorator by normalizing the args/kwargs\n    list into a single dict that we can pull the migration from.\n    \n    Change-Id: I774ac9b749b21085f4fbcafa4965a78d68eec9c7\n    Closes-Bug: 1444300\n", 
            "date_created": "2015-04-20 16:30:59.038047+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/kilo\nReview: https://review.openstack.org/175570", 
            "date_created": "2015-04-20 20:53:00.538173+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/175570\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=a4e9a146c3993f5775501716a21632f34a63a3ad\nSubmitter: Jenkins\nBranch:    stable/kilo\n\ncommit a4e9a146c3993f5775501716a21632f34a63a3ad\nAuthor: Rajesh Tailor <email address hidden>\nDate:   Wed Apr 15 06:59:04 2015 -0700\n\n    Fix kwargs['migration'] KeyError in @errors_out_migration decorator\n    \n    @errors_out_migration decorator is used in the compute manager on\n    resize_instance and finish_resize methods of ComputeManager class.\n    It is decorated via @utils.expects_func_args('migration') to check\n    'migration' is a parameter to the decorator method, however, that\n    only ensures there is a migration argument, not that it's in args or\n    kwargs (either is fine for what expects_func_args checks).\n    The errors_out_migration decorator can get a KeyError when checking\n    kwargs['migration'] and fails to set the migration status to 'error'.\n    \n    This fixes the KeyError in the decorator by normalizing the args/kwargs\n    list into a single dict that we can pull the migration from.\n    \n    Change-Id: I774ac9b749b21085f4fbcafa4965a78d68eec9c7\n    Closes-Bug: 1444300\n    (cherry picked from commit 3add7923fc16c050d4cfaef98a87886c6b6a589c)\n", 
            "date_created": "2015-04-22 17:49:58.322146+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/179284", 
            "date_created": "2015-04-30 23:18:50.722563+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/179284\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=5228d4e418734164ffa5ccd91d2865d9cc659c00\nSubmitter: Jenkins\nBranch:    master\n\ncommit 906ab9d6522b3559b4ad36d40dec3af20397f223\nAuthor: He Jie Xu <email address hidden>\nDate:   Thu Apr 16 07:09:34 2015 +0800\n\n    Update rpc version aliases for kilo\n    \n    Update all of the rpc client API classes to include a version alias\n    for the latest version implemented in Kilo.  This alias is needed when\n    doing rolling upgrades from Kilo to Liberty.  With this in place, you can\n    ensure all services only send messages that both Kilo and Liberty will\n    understand.\n    \n    Closes-Bug: #1444745\n    \n    Conflicts:\n    \tnova/conductor/rpcapi.py\n    \n    NOTE(alex_xu): The conflict is due to there are some logs already added\n    into the master.\n    \n    Change-Id: I2952aec9aae747639aa519af55fb5fa25b8f3ab4\n    (cherry picked from commit 78a8b5802ca148dcf37c5651f75f2126d261266e)\n\ncommit f191a2147a21c7e50926b288768a96900cf4c629\nAuthor: Hans Lindgren <email address hidden>\nDate:   Fri Apr 24 13:10:39 2015 +0200\n\n    Add security group calls missing from latest compute rpc api version bump\n    \n    The recent compute rpc api version bump missed out on the security group\n    related calls that are part of the api.\n    \n    One possible reason is that both compute and security group client side\n    rpc api:s share a single target, which is of little value and only cause\n    mistakes like this.\n    \n    This change eliminates future problems like this by combining them into\n    one to get a 1:1 relationship between client and server api:s.\n    \n    Change-Id: I9207592a87fab862c04d210450cbac47af6a3fd7\n    Closes-Bug: #1448075\n    (cherry picked from commit bebd00b117c68097203adc2e56e972d74254fc59)\n\ncommit a2872a9262985bd0ee2c6df4f7593947e0516406\nAuthor: Dan Smith <email address hidden>\nDate:   Wed Apr 22 09:02:03 2015 -0700\n\n    Fix migrate_flavor_data() to catch instances with no instance_extra rows\n    \n    The way the query was being performed previously, we would not see any\n    instances that didn't have a row in instance_extra. This could happen if\n    an instance hasn't been touched for several releases, or if the data\n    set is old.\n    \n    The fix is a simple change to use outerjoin instead of join. This patch\n    includes a test that ensures that instances with no instance_extra rows\n    are included in the migration. If we query an instance without such a\n    row, we create it before doing a save on the instance.\n    \n    Closes-Bug: #1447132\n    Change-Id: I2620a8a4338f5c493350f26cdba3e41f3cb28de7\n    (cherry picked from commit 92714accc49e85579f406de10ef8b3b510277037)\n\ncommit e3a7b83834d1ae2064094e9613df75e3b07d77cd\nAuthor: OpenStack Proposal Bot <email address hidden>\nDate:   Thu Apr 23 02:18:41 2015 +0000\n\n    Updated from global requirements\n    \n    Change-Id: I5d4acd36329fe2dccb5772fed3ec55b442597150\n\ncommit 8c9b5e620eef3233677b64cd234ed2551e6aa182\nAuthor: Divya <email address hidden>\nDate:   Tue Apr 21 08:26:29 2015 +0200\n\n    Control create/delete flavor api permissions using policy.json\n    \n    The permissions of create/delete flavor api is currently broken\n    and expects the user to be always an admin, instead of controlling\n    the permissions by the rules defined in the nova policy.json.\n    \n    Change-Id: Ide3c9ec2fa674b4fe3ea9d935cd4f7848914b82e\n    Closes-Bug: 1445335\n    (cherry picked from commit ced60b1d1b1608dc8229741b207a95498bc0b212)\n\ncommit bf79742d26ae66886bcdc55eeaf27e1d7ce24be5\nAuthor: Przemyslaw Czesnowicz <email address hidden>\nDate:   Tue Apr 14 16:28:57 2015 +0100\n\n    Fix handling of pci_requests in consume_from_instance.\n    \n    Properly retrieve requests from pci_requests in consume_from_instance.\n    Without this the call to numa_fit_instance_to_host will fail because\n    it expects the request list.\n    And change the order in which apply_requests and numa_fit_instance_to_host\n    are called. Calling apply_requests first will remove devices from pools\n    and  may make numa_fit_instance_to_host fail.\n    \n    Change-Id: I41cf4e8e5c1dea5f91e5261a8f5e88f46c7994ef\n    Closes-bug: #1444021\n    (cherry picked from commit 0913e799e9ce3138235f5ea6f80159f468ad2aaa)\n\ncommit c2d7060b480608d9773340f51d6496fadf97b667\nAuthor: Przemyslaw Czesnowicz <email address hidden>\nDate:   Thu Apr 16 17:10:06 2015 +0100\n\n    Use list of requests in InstancePCIRequests.obj_from_db.\n    \n    InstancePCIRequests.obj_from_db assumes it's called with with a dict\n    of values from instances_extra table, but in some cases it's called\n    with just the value of pci_requests column.\n    This changes obj_from_db to be used with just the value of pci_requests column.\n    \n    Change-Id: I7bed733c845c365081719a70b8a2f0cc9a58370c\n    Closes-bug: #1445040\n    (cherry picked from commit a074d7b4465b45730a5171e024c5c39a66a9c927)\n\ncommit 7a609f153808f7cee1edbbb36accc292fa8df0d0\nAuthor: Przemyslaw Czesnowicz <email address hidden>\nDate:   Tue Apr 7 16:31:05 2015 +0100\n\n    Add numa_node field to PciDevicePool\n    \n    Without this field, PciDevicePool.from_dict will treat numa_node key in\n    the dict as a tag, which in turn means that the scheduler client will\n    drop it when converting stats to objects before reporting.\n    \n    Converting it back to dicts on the scheduler side thus will not have\n    access to the numa_node information which would cause any requests that\n    will look for the exact match between the device and instance NUMA nodes\n    in the NUMATopologyFilter to fail.\n    \n    Closes-Bug: #1441169\n    (cherry picked from commit 7db1ebc66c59205f78829d1e9cd10dcc1201d798)\n    \n    Conflicts:\n    \tnova/tests/unit/objects/test_objects.py\n    \n    Change-Id: I7381f909620e8e787178c0be9a362f8d3eb9ff7d\n\ncommit 880a356e40d327c0af4ce94b5a08fe0cd6fcab5d\nAuthor: Nikola Dipanov <email address hidden>\nDate:   Tue Apr 7 20:53:32 2015 +0100\n\n    scheduler: re-calculate NUMA on consume_from_instance\n    \n    This patch narrows down the race window between the filter running and\n    the consumption of resources from the instance after the host has been\n    chosen.\n    \n    It does so by re-calculating the fitted NUMA topology just before consuming it\n    from the chosen host. Thus we avoid any locking, but also make sure that\n    the host_state is kept as up to date as possible for concurrent\n    requests, as there is no opportunity for switching threads inside a\n    consume_from_instance.\n    \n    Several things worth noting:\n      * Scheduler being lock free (and thus racy) does not really affect\n      resources other than PCI and NUMA topology this badly - this is due\n      to complexity of said resources. In order for scheduler decesions to not\n      be based on basically guessing, in case of those two we will likely need\n      to introduce either locking or special heuristics.\n    \n      * There is a lot of repeated code between the 'consume_from_instance'\n      method and the actual filters. This situation should really be fixed but\n      is out of scope for this bug fix (which is about preventing valid\n      requests failing because of races in the scheduler).\n    \n    Change-Id: If0c7ad20506c9dddf4dec1eb64c9d6dd4fb75633\n    Closes-bug: #1438238\n    (cherry picked from commit d6b3156a6c89ddff9b149452df34c4b32c50b6c3)\n\ncommit a4e9a146c3993f5775501716a21632f34a63a3ad\nAuthor: Rajesh Tailor <email address hidden>\nDate:   Wed Apr 15 06:59:04 2015 -0700\n\n    Fix kwargs['migration'] KeyError in @errors_out_migration decorator\n    \n    @errors_out_migration decorator is used in the compute manager on\n    resize_instance and finish_resize methods of ComputeManager class.\n    It is decorated via @utils.expects_func_args('migration') to check\n    'migration' is a parameter to the decorator method, however, that\n    only ensures there is a migration argument, not that it's in args or\n    kwargs (either is fine for what expects_func_args checks).\n    The errors_out_migration decorator can get a KeyError when checking\n    kwargs['migration'] and fails to set the migration status to 'error'.\n    \n    This fixes the KeyError in the decorator by normalizing the args/kwargs\n    list into a single dict that we can pull the migration from.\n    \n    Change-Id: I774ac9b749b21085f4fbcafa4965a78d68eec9c7\n    Closes-Bug: 1444300\n    (cherry picked from commit 3add7923fc16c050d4cfaef98a87886c6b6a589c)\n\ncommit 389368bcfe498323b369f68682babb92a5b0ca54\nAuthor: Gary Kotton <email address hidden>\nDate:   Wed Apr 15 05:14:42 2015 -0700\n\n    Resource tracker: unable to restart nova compute\n    \n    The resource tracker calculates its used resources. In certain cases\n    of failed migrations and an instance being deleted the resource tracker\n    causes an exception in nova compute. If this situation arises then nova\n    compute may not even be able to restart.\n    \n    Change-Id: I4a154e0cae3b8e22bd59ed05ba708e07eed8dea7\n    Closes-bug: #1444439\n    (cherry picked from commit ee7a7446cc6947a6bacacb6cb514934cc22e5782)\n\ncommit bd6a40fecde943a3ded0124481a12c27dbb167de\nAuthor: Andreas Jaeger <email address hidden>\nDate:   Mon Apr 20 11:01:22 2015 +0200\n\n    Release Import of Translations from Transifex\n    \n    Manual import of Translations from Transifex. This change also removes\n    all po files that are less than 66 per cent translated since such\n    partially translated files will not help users.\n    \n    This updates also recreates all pot (translation source files) to\n    reflect the state of the repository.\n    \n    This change needs to be done manually since the automatic import does\n    not handle the proposed branches and we need to sync with latest\n    translations.\n    \n    Change-Id: I0e9ef00182a2229602d23b8a67a02f0be62ee239\n\ncommit 8ebd515aa94ed399074a3b55bd36fd8cd579a499\nAuthor: Matt Riedemann <email address hidden>\nDate:   Thu Apr 16 11:08:50 2015 -0700\n\n    Use kwargs from compute v4 proxy change_instance_metadata\n    \n    The args were passed to the compute manager method in the wrong order.\n    We noticed this in the gate with KeyError: 'uuid' in the logs because of\n    the LOG.debug statement in change_instance_metadata. Just use kwargs\n    like rpcapi would normally.\n    \n    There isn't a unit test for this since the v4 proxy code goes away in\n    liberty, this is for getting it into stable/kilo.\n    \n    Closes-Bug: #1444728\n    \n    Change-Id: Ic988f48d99e626ee5773c97904e09dbf00c5414a\n    (cherry picked from commit e55f746ea8590cce7c2b07a023197f369251a7ef)\n\ncommit b19764d2c6a8160102a806c1d6811c4182a8bac8\nAuthor: Matt Riedemann <email address hidden>\nDate:   Wed Apr 15 11:51:26 2015 -0700\n\n    compute: stop handling virt lifecycle events in cleanup_host()\n    \n    When rebooting a compute host, guest VMs can be getting shutdown\n    automatically by the hypervisor and the virt driver is sending events to\n    the compute manager to handle them. If the compute service is still up\n    while this happens it will try to call the stop API to power off the\n    instance and update the database to show the instance as stopped.\n    \n    When the compute service comes back up and events come in from the virt\n    driver that the guest VMs are running, nova will see that the vm_state\n    on the instance in the nova database is STOPPED and shut down the\n    instance by calling the stop API (basically ignoring what the virt\n    driver / hypervisor tells nova is the state of the guest VM).\n    \n    Alternatively, if the compute service shuts down after changing the\n    intance task_state to 'powering-off' but before the stop API cast is\n    complete, the instance can be in a strange vm_state/task_state\n    combination that requires the admin to manually reset the task_state to\n    recover the instance.\n    \n    Let's just try to avoid some of this mess by disconnecting the event\n    handling when the compute service is shutting down like we do for\n    neutron VIF plugging events. There could still be races here if the\n    compute service is shutting down after the hypervisor (e.g. libvirtd),\n    but this is at least a best attempt to do the mitigate the potential\n    damage.\n    \n    Closes-Bug: #1444630\n    Related-Bug: #1293480\n    Related-Bug: #1408176\n    \n    Change-Id: I1a321371dff7933cdd11d31d9f9c2a2f850fd8d9\n    (cherry picked from commit d1fb8d0fbdd6cb95c43b02f754409f1c728e8cd0)\n\ncommit 75e9de5d572578520c217b540aa2a40726f137f0\nAuthor: Roman Podoliaka <email address hidden>\nDate:   Wed Mar 4 17:27:06 2015 +0200\n\n    Forbid booting of QCOW2 images with virtual_size > root_gb\n    \n    Currently, it's possible to boot an instance from a QCOW2 image,\n    which has virtual_size bigger than one allowed by the given flavor\n    (root_gb).\n    \n    The issue is caused by two different problems in the code:\n    \n    1) typo in get_disk_size() has made it always return None and\n       effectively disabled verify_base_size() checks\n    \n    2) Rbd image backend skips the verify_base_size() step for\n       'cached' images (the one with base files), so it is possible to\n       boot an instance using a larger flavor once and then use smaller\n       flavors to boot the same image, even if allowed root_gb size is\n       smaller than the image virtual size\n    \n    Closes-Bug: #1429093\n    \n    Change-Id: I383130e5f8cc288f4b428ed43fe4d3aba7169473\n    (cherry picked from commit c1f9ed27af64e6893d9d0153a964df5aba99b8f0)\n\ncommit 33ba90240a2ad3165274d9e54ceb156273404c9a\nAuthor: Matt Riedemann <email address hidden>\nDate:   Mon Apr 13 14:47:20 2015 -0700\n\n    Pass migrate_data to pre_live_migration\n    \n    Commit ebfa09fa197a1d88d1b3ab1f308232c3df7dc009 added an RPC proxy but\n    as part of that was passing migrate_data=None for pre_live_migration\n    which breaks live block migration when not using shared storage.\n    \n    Closes-Bug: #984996\n    \n    Change-Id: I2a83f1fb0e4468f9a6c67a188af725c3406139d1\n    (cherry picked from commit 4e515ec2269a1c3187ee9ffad3a6be059ec74b0b)\n\ncommit dea6116723f22632c2e478e00bb0aafcd2febdc9\nAuthor: Timofey Durakov <email address hidden>\nDate:   Fri Apr 10 19:38:33 2015 +0300\n\n    Fixed order of arguments during execution live_migrate()\n    \n    order of arguments that passed to\n    ComputeManager.live_,migration() differs in ComputeManager and\n    _ComputeV4Proxy classes\n    \n    Change-Id: I23c25d219e9cdd0673ae6a12250219680fb7bda9\n    Closes-Bug:#1442656\n    (cherry picked from commit ba521fa53711774e0718808fe333aca676de57ae)\n\ncommit 22d7547c6b62fb9dabd861e4941edd34eedabfc6\nAuthor: Doug Hellmann <email address hidden>\nDate:   Wed Apr 15 19:58:17 2015 +0000\n\n    update .gitreview for stable/kilo\n    \n    Change-Id: I6356513ac42b79402dbde8ee5e75cbbd1aee7eef\n\ncommit 68d6f924037f3b931add2ce5d0d433913e720ca6\nAuthor: Ken'ichi Ohmichi <email address hidden>\nDate:   Wed Apr 15 03:13:43 2015 +0000\n\n    Add min/max of API microversions to version API\n    \n    As nova-spec api-microversions, versions API needs to expose minimum\n    and maximum microversions to version API, because clients need to\n    know available microversions through the API. That is very important\n    for the interoperability.\n    This patch adds these versions as the nova-spec mentioned.\n    \n    Note:\n      As v2(not v2.1) API change manner, we have added new extensions if\n      changing API. However, this patch doesn't add a new extension even\n      if adding new parameters \"version\" and \"min_version\" because version\n      API is independent from both v2 and v2.1 APIs.\n    \n    Change-Id: Id464a07d624d0e228fe0aa66a04c8e51f292ba0c\n    Closes-Bug: #1443375\n    (cherry picked from commit 1830870718fe7472b47037f3331cfe59b5bdda07)\n    (cherry picked from commit 853671e912c6ad9a4605acad2575417911875cdd)\n\ncommit d82d492c67db546d01addc5fead9708760fb6abd\nAuthor: Sabari Kumar Murugesan <email address hidden>\nDate:   Mon Apr 6 20:36:48 2015 -0700\n\n    VMware: Fix attribute error in resize\n    \n    The class DatastorePath was recently removed from ds_util as it's\n    available in oslo.vmware. One of the reference was missed during\n    the refactor.\n    \n    Change-Id: Idc5825c304a99e83cbf36e93751148d6f995131a\n    Closes-Bug: #1440968\n    (cherry picked from commit ab4a5a5300179a79f7a67688f0e9f3fc280c0efa)\n\ncommit 3cff2c673c6cdf487c2a1eb2a5c6c89c6de80d11\nAuthor: jichenjc <email address hidden>\nDate:   Fri Mar 20 08:36:37 2015 +0800\n\n    Release bdm constraint source and dest type\n    \n    https://bugs.launchpad.net/nova/+bug/1377958 fixed a problem\n    that source_type: image, destination_type: local is not\n    supported for boot instance, exception should be raised to\n    reject the param otherwise it will lead to instance become\n    ERROR state.\n    \n    However the fix introduced a problem on nova client\n    https://bugs.launchpad.net/python-novaclient/+bug/1418484\n    The fix of the bug leads to following command become invalid\n    \n    nova boot test-vm --flavor m1.medium --image centos-vm-32\n    --nic net-id=c3f40e33-d535-4217-916b-1450b8cd3987 --block-device\n    id=26b7b917-2794-452a-95e5-2efb2ca6e32d,bus=sata,source=volume,bootindex=1\n    \n    So we need to release the original constraint to allow\n    the above special case pass the validation check then\n    we can revert the nova client exception\n    (https://review.openstack.org/#/c/165932/)\n    \n    This patch checks the boot_index and whether image param is\n    given after we found the bdm has source_type: image,\n    destination_type: local, if this is the special case, then\n    no exception will be raised.\n    \n    Closes-Bug: #1433609\n    \n    Change-Id: If43faae95169bc3864449a8364975f5c887aac14\n    (cherry picked from commit cadbcc440a2fcfb8532f38111999a06557fbafc2)\n\ncommit 97145ba175291d6522afa079860c72220e43024a\nAuthor: Dan Smith <email address hidden>\nDate:   Fri Apr 10 07:10:52 2015 -0700\n\n    Fix check_can_live_migrate_destination() in ComputeV4Proxy\n    \n    There was a mismatch in the V4 proxy in the call signatures of this\n    function. This was missed because the \"destination\" parameter is passed\n    in the rpcapi as the host to contact, which is consumed by the rpc\n    layer and not passed. Since it was not called one of the standard\n    names (either host if to be not passed, or host_param if to be passed),\n    this was missed.\n    \n    Change-Id: Idf2160934dade650ed02b672f3b64cb26247f8e6\n    Closes-Bug: #1442602\n    (cherry picked from commit 0c08f7f2ef070f7c6172d7742f9789e0a8bda91a)\n", 
            "date_created": "2015-05-06 13:44:52.745635+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}