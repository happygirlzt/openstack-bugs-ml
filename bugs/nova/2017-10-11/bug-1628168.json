{
    "status": "Confirmed", 
    "last_updated": "2017-06-27 15:54:20.832905+00:00", 
    "description": "I have an OS Mitaka deployment that was done by Fuel (9.0).\n\nI have a system with 8GPUs in a single box. We are trying to allow VMs to request access to GPU resources via this box.\n\nI know that with PCI Passthrough you can only have a device assigned to a single VM (e.g. 1 device <-> 1 VM). However, this box has 8 GPUs (8 separate devices). So I want support (1GPU -> 1VM) * 8, or (2GPU -> 1VM) * 4, (4GPU -> 1VM) * 2, or (8GPU -> 1VM) * 1.\n\nI have successfully been able to get the system to have 1 GPU <-> 1 VM, however when I go to create another VM with a GPU I get \"not enough hosts found\".\n\nThis is what I have done so far.\n\n/etc/nova/nova.conf\n\nAdd:\n Pic_passthrough_whitelist = [{\"vendor_id\": \"10de\", \"product_id\": \"17c2\"}]\n\nsudo gedit /etc/modules and add:\n pci_stub\n vfio\n vfio_iommu_type1\n vfio_pci\n kvm\n kvm_intel\n\nSudo vi /etc/default/grub\n GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash intel_iommu=on vfio_iommu_type1.allow_unsafe_interrupts=1\"\n\n//BLACKLIST\n\nsudo gedit /etc/initramfs-tools/modules\n pci_stub ids=10de:17c2\n sudo update-initramfs -u\n\nOn Controller Node:\n\nEdit nova.conf\n\nAdd specifically for GPU you want to use!\n\npci_alias={\"vendor_id\":\"10de\", \"product_id\":\"17c2\", \"name\":\"titanx\"}\n Add\n\nscheduler_driver=nova.scheduler.filter_scheduler.FilterScheduler\n scheduler_available_filters=nova.scheduler.filters.all_filters\n scheduler_available_filters=nova.scheduler.filters.pci_passthrough_filter.PciPassthroughFilter\n scheduler_default_filters=RamFilter,ComputeFilter,AvailabilityZoneFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,PciPassthroughFilter\n\n#: source openrc\n Nova flavor-key g1.xlarge set \"pci_passthrough:alias\"=\"titanx:1\"\n\nActual Results: \nWhen I go to create my second VM with the same flavor it errors out with this message. (If I create 1 VM it works and a GPU is assigned to that machine).\n\nMessage: No valid host was found. There are not enough hosts available.\n Code: 500\n File \"/usr/lib/python2.7/dist-packages/nova/conductor/manager.py\", line 392, in build_instances context, request_spec, filter_properties) File \"/usr/lib/python2.7/dist-packages/nova/conductor/manager.py\", line 436, in _schedule_instances hosts = self.scheduler_client.select_destinations(context, spec_obj) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/utils.py\", line 372, in wrapped return func(*args, **kwargs) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/client/__init__.py\", line 51, in select_destinations return self.queryclient.select_destinations(context, spec_obj) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/client/__init__.py\", line 37, in __run_method return getattr(self.instance, __name)(*args, **kwargs) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/client/query.py\", line 32, in select_destinations return self.scheduler_rpcapi.select_destinations(context, spec_obj) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/rpcapi.py\", line 121, in select_destinations return cctxt.call(ctxt, 'select_destinations', **msg_args) File \"/usr/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 158, in call retry=self.retry) File \"/usr/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 91, in _send timeout=timeout, retry=retry) File \"/usr/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 512, in send retry=retry) File \"/usr/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 503, in _send raise result\n\nRunning SELECT * FROM pci_devices; on the nova database I get the following\n\nhttp://imgur.com/a/voGki\n\nAs you can see it shows 7 are available.\n\nExpected Results:\n\nAnother VM created with 1 more GPU used from the system.", 
    "tags": [
        "libvirt", 
        "openstack-version.mitaka", 
        "pci"
    ], 
    "importance": "Low", 
    "heat": 8, 
    "link": "https://bugs.launchpad.net/nova/+bug/1628168", 
    "owner": "None", 
    "id": 1628168, 
    "index": 821, 
    "created": "2016-09-27 15:35:23.274932+00:00", 
    "title": "Can't assign system with multiple GPUs to different VMs", 
    "comments": [
        {
            "content": "I have an OS Mitaka deployment that was done by Fuel (9.0).\n\nI have a system with 8GPUs in a single box. We are trying to allow VMs to request access to GPU resources via this box.\n\nI know that with PCI Passthrough you can only have a device assigned to a single VM (e.g. 1 device <-> 1 VM). However, this box has 8 GPUs (8 separate devices). So I want support (1GPU -> 1VM) * 8, or (2GPU -> 1VM) * 4, (4GPU -> 1VM) * 2, or (8GPU -> 1VM) * 1.\n\nI have successfully been able to get the system to have 1 GPU <-> 1 VM, however when I go to create another VM with a GPU I get \"not enough hosts found\".\n\nThis is what I have done so far.\n\n/etc/nova/nova.conf\n\nAdd:\n Pic_passthrough_whitelist = [{\"vendor_id\": \"10de\", \"product_id\": \"17c2\"}]\n\nsudo gedit /etc/modules and add:\n pci_stub\n vfio\n vfio_iommu_type1\n vfio_pci\n kvm\n kvm_intel\n\nSudo vi /etc/default/grub\n GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash intel_iommu=on vfio_iommu_type1.allow_unsafe_interrupts=1\"\n\n//BLACKLIST\n\nsudo gedit /etc/initramfs-tools/modules\n pci_stub ids=10de:17c2\n sudo update-initramfs -u\n\nOn Controller Node:\n\nEdit nova.conf\n\nAdd specifically for GPU you want to use!\n\npci_alias={\"vendor_id\":\"10de\", \"product_id\":\"17c2\", \"name\":\"titanx\"}\n Add\n\nscheduler_driver=nova.scheduler.filter_scheduler.FilterScheduler\n scheduler_available_filters=nova.scheduler.filters.all_filters\n scheduler_available_filters=nova.scheduler.filters.pci_passthrough_filter.PciPassthroughFilter\n scheduler_default_filters=RamFilter,ComputeFilter,AvailabilityZoneFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,PciPassthroughFilter\n\n#: source openrc\n Nova flavor-key g1.xlarge set \"pci_passthrough:alias\"=\"titanx:1\"\n\nActual Results: \nWhen I go to create my second VM with the same flavor it errors out with this message. (If I create 1 VM it works and a GPU is assigned to that machine).\n\nMessage: No valid host was found. There are not enough hosts available.\n Code: 500\n File \"/usr/lib/python2.7/dist-packages/nova/conductor/manager.py\", line 392, in build_instances context, request_spec, filter_properties) File \"/usr/lib/python2.7/dist-packages/nova/conductor/manager.py\", line 436, in _schedule_instances hosts = self.scheduler_client.select_destinations(context, spec_obj) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/utils.py\", line 372, in wrapped return func(*args, **kwargs) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/client/__init__.py\", line 51, in select_destinations return self.queryclient.select_destinations(context, spec_obj) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/client/__init__.py\", line 37, in __run_method return getattr(self.instance, __name)(*args, **kwargs) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/client/query.py\", line 32, in select_destinations return self.scheduler_rpcapi.select_destinations(context, spec_obj) File \"/usr/lib/python2.7/dist-packages/nova/scheduler/rpcapi.py\", line 121, in select_destinations return cctxt.call(ctxt, 'select_destinations', **msg_args) File \"/usr/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 158, in call retry=self.retry) File \"/usr/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 91, in _send timeout=timeout, retry=retry) File \"/usr/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 512, in send retry=retry) File \"/usr/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 503, in _send raise result\n\nRunning SELECT * FROM pci_devices; on the nova database I get the following\n\nhttp://imgur.com/a/voGki\n\nAs you can see it shows 7 are available.\n\nExpected Results:\n\nAnother VM created with 1 more GPU used from the system.", 
            "date_created": "2016-09-27 15:35:23.274932+00:00", 
            "author": "https://api.launchpad.net/1.0/~kvasko"
        }, 
        {
            "content": "Was doing some more investigating and found this in the nova-all.log. This looks to like an issue like the device (0f:00.0) is busy, however it shouldn't be as the only one in use *should* be 10:00.0. \n\nAll devices seem to be claimed by pci-stub which from my understanding indicates that they can't be claimed by the current running OS.\n\n<179>Sep 27 18:53:48 node-13 nova-conductor: 2016-09-27 18:53:48.631 24595 ERROR nova.scheduler.utils [req-dfd5dfe7-ea36-4ce0-8fe7-2412df59db20 11a8bdff50d34c64b2a9fc2b477af74b 81d1532551c2436793417cd7ef0abf35 - - -] [instance: e5fadc3b-6fab-4524-9a35-c8ac954014bd] Error from last host: cirrascale1 (node cirrascale1): [u'Traceback (most recent call last):\\n', u'  File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 1926, in _do_build_and_run_instance\\n    filter_properties)\\n', u'  File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 2116, in _build_and_run_instance\\n    instance_uuid=instance.uuid, reason=six.text_type(e))\\n', u\"RescheduledException: Build of instance e5fadc3b-6fab-4524-9a35-c8ac954014bd was re-scheduled: internal error: process exited while connecting to monitor: 2016-09-27T18:53:46.506916Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: vfio: Error: Failed to setup INTx fd: Device or resource busy\\n2016-09-27T18:53:46.507929Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: Device initialization failed\\n2016-09-27T18:53:46.507952Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: Device 'vfio-pci' could not be initialized\\n\\n\"]", 
            "date_created": "2016-09-27 19:29:16.800711+00:00", 
            "author": "https://api.launchpad.net/1.0/~kvasko"
        }, 
        {
            "content": "So a little more information. I was able to get more than 1 VM to start with a GPU attached (e.g. I had 2 VMs, each had 1 GPU attached). I restarted the host VM with the GPUs. \n\n\nIt appears that some of the GPUs are getting into an \"in-use\" state and won't return. \n\nOn the host system that has the GPUs when I reboot the machine and use the command lspci -vnnn | grep VGA, all 8 GPUs show up as the following:\n\n04:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev a1) (prog-if 00 [VGA controller])\n\n05:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev a1) (prog-if 00 [VGA controller])\n06:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev a1) (prog-if 00 [VGA controller])\n07:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev a1) (prog-if 00 [VGA controller])\n0d:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev a1) (prog-if 00 [VGA controller])\n0e:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev a1) (prog-if 00 [VGA controller])\n0f:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev a1) (prog-if 00 [VGA controller])\n10:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev a1) (prog-if 00 [VGA controller])\n\nThis is with 0 VM instances running that have a GPU associated with them.\n\nAt this point after a fresh reboot I started and stopped multiple VMs (started 3x VMs each with 1 GPU attached). Stopped them, and started them back up. No issues. I did that a few more times and then randomly I saw this appear when running lspci -vnnn | grep VGA on one of the cards.\n\n 0d:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev ff) (prog-if ff)\n\nI've got 2 machines running with a GPU attached, now at this point any time I try to start another VM with a GPU I get the no hosts found error. So what I *think* is happening is.\n\nAfter rebooting the host machine none of the GPUS are in that weird (prog-if ff) state. At that point the VMs start up fine with a GPU, until one of the GPUs go into that \"(rev ff) (prog-if ff) state. At that point any time OS tries to schedule a new VM to be created it is trying to use the GPU that is \"(rev ff) (prog-if)\", since it is marked as available in the MySQL database. At that point no other VMs can be created with a VM.\n\nWhatever is causing the GPUs to go into the (rev ff) (prog-if ff) state I'm not sure. All I am doing is creating the VM, seeing if it launches successfully, logging into it, making sure the VM has a GPU associated with the VM and then deleting it from OS.\n\nI'm using the CentOS7 image to test with from here. http://docs.openstack.org/image-guide/obtain-images.html\n\nI'm going to try to debug this issue some more to see if I can narrow down the cause of the cards going into that odd state.", 
            "date_created": "2016-09-27 21:19:23.820223+00:00", 
            "author": "https://api.launchpad.net/1.0/~kvasko"
        }, 
        {
            "content": "So I seem to be able to reproduce this more frequently with the Ubuntu image on the page I linked above. \n\nLooking at dmesg I see.\n\n[    0.638033] pci 0000:00:05.0: unknown header type 7f, ignoring device\n\nIf I go run lspci -vnnn | grep VGA on the host GPU system I see \n\n0d:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev ff) (prog-if ff)\n\nAt this point it won't launch another GPU based machine.\n\nI'm currently trying to change the libvirt version to see if that resolves the issue based off this information http://www.spinics.net/lists/kvm/msg51006.html", 
            "date_created": "2016-09-28 16:07:04.200806+00:00", 
            "author": "https://api.launchpad.net/1.0/~kvasko"
        }, 
        {
            "content": "I'm confused, you are saying that \"All devices seem to be claimed by pci-stub\", but looking at the qemu command line, it is using vfio-pci driver (pci-stub is legacy).  So make sure your device is using the right driver when it is passthrough to the guest (for e.g. /sys/bus/pci/devices/0000\\:89\\:00.0/driver should point to vfio-pci).  Based on qemu command line, looks like your fine, but just need to validate ...\n\nWhen you delete the guest, libvirt should reset the driver back.  So in my case (I'm using Intel NICs), the driver gets back to ixgbe (I'm using an Intel NIC ).  That might validate if the issue is with libvirt (like you are mentionning above).\n\nAlso, look at the libvirt (/var/log/libvirt/libvirtd.log) and qemu logs (under /var/log/libvirt/qemu/), there might be something of interest there.", 
            "date_created": "2016-09-29 21:23:57.657893+00:00", 
            "author": "https://api.launchpad.net/1.0/~ludovic-beliveau"
        }, 
        {
            "content": "I followed the instructions from this guide to mark the devices as blacklisted by pci-stub.\n\nhttps://www.pugetsystems.com/labs/articles/Multiheaded-NVIDIA-Gaming-using-Ubuntu-14-04-KVM-585/\n\nI'm using Ubuntu 14.04 which has Kernel 3.x, this (http://vfio.blogspot.com/2015/05/vfio-gpu-how-to-series-part-3-host.html) said vfio-pci only worked with version 4.x+.\n\nI ended up resetting the host and putting it back into OS hoping I messed something up in the process and redoing the process would resolve it. However it seems I took a sidestep where the CentOS7 image won't even work. I see no errors that would indicate why the PCIDevice won't show up in the CentOS7 VM on the first start the VM.\n\nI added all configuration settings to nova.conf and blacklisted the GPUs they show up in the nova database properly.\n\nI started up a CentOS7 machine (see the attached dmesg log).\n\nI checked the libvirtd.log and saw this.\n\n2016-09-30 16:43:41.162+0000: 9360: warning : qemuDomainObjTaint:1900 : Domain id=6 name='instance-0000012e' uuid=4f12ae0c-0d50-4d83-9f8b-3061273b64da is tainted: high-privileges\n\nthe ./qemu/instance-0000012e.log looks like this.\n\n2016-09-30 16:43:41.162+0000: starting up\nLC_ALL=C PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin QEMU_AUDIO_DRV=none /usr/bin/kvm -name instance-0000012e -S -machine pc-i440fx-vivid,accel=kvm,usb=off -cpu Haswell-noTSX,+abm,+pdpe1gb,+rdrand,+f16c,+osxsave,+dca,+pdcm,+xtpr,+tm2,+est,+smx,+vmx,+ds_cpl,+monitor,+dtes64,+pbe,+tm,+ht,+ss,+acpi,+ds,+vme -m 16384 -realtime mlock=off -smp 6,sockets=6,cores=1,threads=1 -uuid 4f12ae0c-0d50-4d83-9f8b-3061273b64da -smbios type=1,manufacturer=OpenStack Foundation,product=OpenStack Nova,version=13.0.0,serial=8e34e073-7b4c-4e69-84fa-2d044032ad30,uuid=4f12ae0c-0d50-4d83-9f8b-3061273b64da,family=Virtual Machine -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/instance-0000012e.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc,driftfix=slew -global kvm-pit.lost_tick_policy=discard -no-hpet -no-shutdown -boot strict=on -device piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2 -drive file=/var/lib/nova/instances/4f12ae0c-0d50-4d83-9f8b-3061273b64da/disk,if=none,id=drive-virtio-disk0,format=qcow2,cache=writethrough -device virtio-blk-pci,scsi=off,bus=pci.0,addr=0x4,drive=drive-virtio-disk0,id=virtio-disk0,bootindex=1 -netdev tap,fd=26,id=hostnet0,vhost=on,vhostfd=27 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=fa:16:3e:0c:a0:ea,bus=pci.0,addr=0x3 -chardev file,id=charserial0,path=/var/lib/nova/instances/4f12ae0c-0d50-4d83-9f8b-3061273b64da/console.log -device isa-serial,chardev=charserial0,id=serial0 -chardev pty,id=charserial1 -device isa-serial,chardev=charserial1,id=serial1 -device usb-tablet,id=input0 -vnc 0.0.0.0:0 -k en-us -device cirrus-vga,id=video0,bus=pci.0,addr=0x2 -device vfio-pci,host=10:00.0,id=hostdev0,bus=pci.0,addr=0x5 -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x6 -msg timestamp=on\nDomain id=6 is tainted: high-privileges\nchar device redirected to /dev/pts/2 (label charserial1)\n\nvfio-pci,host=10:00.0 is the GPU on the host so not sure why it won't show up (dmesg of the vm instance is attached)\n\nAt this point the GPU was set into this state (sometimes it does, some times it doesn't, im not sure what it means)\n\n10:00.0 VGA compatible controller [0300]: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:17c2] (rev ff) (prog-if ff)\n\nI then tried to startup another instance \n\nin libvirtd.log I see this.\n\n2016-09-30 16:47:47.786+0000: 9357: warning : qemuDomainObjTaint:1900 : Domain id=7 name='instance-0000012f' uuid=dc37c94f-d6d2-42ac-8fff-1c3a6604f317 is tainted: high-privileges\n2016-09-30 16:47:52.308+0000: 9355: error : qemuMonitorIORead:554 : Unable to read from monitor: Connection reset by peer\n2016-09-30 16:47:52.308+0000: 9355: error : qemuMonitorIO:697 : internal error: early end of file from monitor: possible problem:\n2016-09-30T16:47:51.356627Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: vfio: Error: Failed to setup INTx fd: Device or resource busy\n2016-09-30T16:47:51.358248Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: Device initialization failed\n2016-09-30T16:47:51.358300Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: Device 'vfio-pci' could not be initialized\n\n2016-09-30 16:47:52.308+0000: 9357: error : qemuProcessWaitForMonitor:2052 : internal error: process exited while connecting to monitor: 2016-09-30T16:47:51.356627Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: vfio: Error: Failed to setup INTx fd: Device or resource busy\n2016-09-30T16:47:51.358248Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: Device initialization failed\n2016-09-30T16:47:51.358300Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: Device 'vfio-pci' could not be initialized\n\n\nThe associated instance-0000012f.log\n\n2016-09-30 16:47:47.786+0000: starting up\nLC_ALL=C PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin QEMU_AUDIO_DRV=none /usr/bin/kvm -name instance-0000012f -S -machine pc-i440fx-vivid,accel=kvm,usb=off -cpu Haswell-noTSX,+abm,+pdpe1gb,+rdrand,+f16c,+osxsave,+dca,+pdcm,+xtpr,+tm2,+est,+smx,+vmx,+ds_cpl,+monitor,+dtes64,+pbe,+tm,+ht,+ss,+acpi,+ds,+vme -m 16384 -realtime mlock=off -smp 6,sockets=6,cores=1,threads=1 -uuid dc37c94f-d6d2-42ac-8fff-1c3a6604f317 -smbios type=1,manufacturer=OpenStack Foundation,product=OpenStack Nova,version=13.0.0,serial=8e34e073-7b4c-4e69-84fa-2d044032ad30,uuid=dc37c94f-d6d2-42ac-8fff-1c3a6604f317,family=Virtual Machine -no-user-config -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/instance-0000012f.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc,driftfix=slew -global kvm-pit.lost_tick_policy=discard -no-hpet -no-shutdown -boot strict=on -device piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2 -drive file=/var/lib/nova/instances/dc37c94f-d6d2-42ac-8fff-1c3a6604f317/disk,if=none,id=drive-virtio-disk0,format=qcow2,cache=writethrough -device virtio-blk-pci,scsi=off,bus=pci.0,addr=0x4,drive=drive-virtio-disk0,id=virtio-disk0,bootindex=1 -netdev tap,fd=26,id=hostnet0,vhost=on,vhostfd=28 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=fa:16:3e:cf:9c:1d,bus=pci.0,addr=0x3 -chardev file,id=charserial0,path=/var/lib/nova/instances/dc37c94f-d6d2-42ac-8fff-1c3a6604f317/console.log -device isa-serial,chardev=charserial0,id=serial0 -chardev pty,id=charserial1 -device isa-serial,chardev=charserial1,id=serial1 -device usb-tablet,id=input0 -vnc 0.0.0.0:1 -k en-us -device cirrus-vga,id=video0,bus=pci.0,addr=0x2 -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5 -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x6 -msg timestamp=on\nDomain id=7 is tainted: high-privileges\nchar device redirected to /dev/pts/4 (label charserial1)\n2016-09-30T16:47:51.356627Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: vfio: Error: Failed to setup INTx fd: Device or resource busy\n2016-09-30T16:47:51.358248Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: Device initialization failed\n2016-09-30T16:47:51.358300Z qemu-system-x86_64: -device vfio-pci,host=0f:00.0,id=hostdev0,bus=pci.0,addr=0x5: Device 'vfio-pci' could not be initialized\n2016-09-30 16:47:52.308+0000: shutting down\n\nSo at this point I can't add another VM with a GPU (even though 7 devices should be free).\n\nIf I delete all VMs with associated GPUs and then start another instance, it will let me start up a GPU instance but still can't see any GPUs attached to the VM (just like the first time). If I try to start a second VM, the same thing happens. \n", 
            "date_created": "2016-09-30 17:29:01.753968+00:00", 
            "author": "https://api.launchpad.net/1.0/~kvasko"
        }, 
        {
            "content": "Automatically discovered version mitaka in description. If this is incorrect, please update the description to include 'nova version: ...'", 
            "date_created": "2017-06-27 15:54:20.147106+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }
    ]
}