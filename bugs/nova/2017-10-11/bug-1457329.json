{
    "status": "Invalid", 
    "last_updated": "2015-09-18 21:50:53.120848+00:00", 
    "description": "devstack,version:\nubuntu@dev1:/opt/stack/nova$ git log -1\ncommit 2833f8c08fcfb7961b3c64b285ceff958bf5a05e\nAuthor: Zhengguang <email address hidden>\nDate:   Thu May 21 02:31:50 2015 +0000\n\n    remove _rescan_iscsi from disconnect_volume_multipath_iscsi\n    \n    terminating instance that attached more than one volume, disconnect\n    the first volume is ok, but the first volume is not removed, then\n    disconnect the second volume, disconnect_volume_multipath_iscsi\n    will call _rescan_iscsi so that rescan the first device, although\n    the instance is destroyed, the first device is residual, therefor\n    we don't need rescan when disconnect volume.\n    \n    Change-Id: I7f2c688aba9e69afaf370b2badc86a2bb3ee899d\n    Closes-Bug:#1402535\n\nsuspend instance, then got exception as follows\uff1a\n\nSetting instance vm_state to ERROR^[[00m^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager\nTraceback (most recent call last):\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   File \"/opt/stack/nova/nova/compute/manager.py\", line 6089, in _error_out_instance_on_exception^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager    yield\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   File \"/opt/stack/nova/nova/compute/manager.py\", line 4014, in suspend_instance^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager    self.driver.suspend(context, instance)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 2248, in suspend^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager dom.managedSave(0)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 183, in doit ^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   result = proxy_call(self._autowrap, f, *args, **kwargs)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager  File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 141, in proxy_call    rv = execute(f, *args, **kwargs)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager  File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 122, in execute six.reraise(c, e, tb)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager  File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 80, in tworker   rv = meth(*args, **kwargs)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager  File \"/usr/local/lib/python2.7/dist-packages/libvirt.py\", line 1167, in managedSave\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   if ret == -1: raise libvirtError ('virDomainManagedSave() failed', dom=self)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0libvirtError: operation failed: domain save job: unexpectedly failed\n\nubuntu@dev1:~$ nova list\n+--------------------------------------+-------+-----------+------------+-------------+------------------------------------------------------+\n| ID                                   | Name  | Status    | Task State | Power State | Networks                                             |\n+--------------------------------------+-------+-----------+------------+-------------+------------------------------------------------------+\n| 0096094f-b854-4a56-bb35-c112cdbe20fb | test5 | ERROR     | -          | Running     | private=10.0.0.5, fd3b:f9:a091:0:f816:3eff:fe8e:dc62 |\n+--------------------------------------+-------+-----------+------------+-------------+------------------------------------------------------+\n\n\"virsh list\" can see the instance is running\nubuntu@dev1:~$ virsh list --all\n\u00a0Id    Name                           State\n----------------------------------------------------\n\u00a02     instance-00000003              running\n\nExpected result:\nEven though occurs excption, the status of instance still should be \"ACTIVE\".", 
    "tags": [
        "compute", 
        "libvirt"
    ], 
    "importance": "Undecided", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1457329", 
    "owner": "https://api.launchpad.net/1.0/~shuquan", 
    "id": 1457329, 
    "index": 5549, 
    "created": "2015-05-21 06:20:11.003282+00:00", 
    "title": "Error status of instance after suspend exception", 
    "comments": [
        {
            "content": "devstack , the newest code, suspend instance, then got exception as follows\uff1a\n\nSetting instance vm_state to ERROR^[[00m^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager \nTraceback (most recent call last):\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   File \"/opt/stack/nova/nova/compute/manager.py\", line 6089, in _error_out_instance_on_exception^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager    yield\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   File \"/opt/stack/nova/nova/compute/manager.py\", line 4014, in suspend_instance^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager    self.driver.suspend(context, instance)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 2248, in suspend^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager dom.managedSave(0)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 183, in doit ^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   result = proxy_call(self._autowrap, f, *args, **kwargs)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager  File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 141, in proxy_call    rv = execute(f, *args, **kwargs)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager  File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 122, in execute six.reraise(c, e, tb)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager  File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 80, in tworker   rv = meth(*args, **kwargs)\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager  File \"/usr/local/lib/python2.7/dist-packages/libvirt.py\", line 1167, in managedSave\n^[[01;31m2015-05-21 04:48:29.179 TRACE nova.compute.manager   if ret == -1: raise libvirtError ('virDomainManagedSave() failed', dom=self)\n                libvirtError: operation failed: domain save job: unexpectedly failed\n\nubuntu@dev1:~$ nova list\n+--------------------------------------+-------+-----------+------------+-------------+------------------------------------------------------+\n| ID                                   | Name  | Status    | Task State | Power State | Networks                                             |\n+--------------------------------------+-------+-----------+------------+-------------+------------------------------------------------------+\n| 0096094f-b854-4a56-bb35-c112cdbe20fb | test5 | ERROR     | -          | Running     | private=10.0.0.5, fd3b:f9:a091:0:f816:3eff:fe8e:dc62 |\n+--------------------------------------+-------+-----------+------------+-------------+------------------------------------------------------+\n\n\"virsh list\" can see the instance is running\nubuntu@dev1:~$ virsh list --all\n Id    Name                           State\n----------------------------------------------------\n 2     instance-00000003              running\n\nExpected result:\nEven though occurs excption, the status of instance still should be \"ACTIVE\".", 
            "date_created": "2015-05-21 06:20:11.003282+00:00", 
            "author": "https://api.launchpad.net/1.0/~271025598-9"
        }, 
        {
            "content": "My opinion is we need to leave this as Error,\nthe reason is libvirt will not guarantee after that exception raised, the vm can be used without\nany issue even the power state is 'running'.\n\nif an user/admin can verify that 'Error'  status vm still can be used, they can run nova reset-state", 
            "date_created": "2015-09-02 03:35:37.206063+00:00", 
            "author": "https://api.launchpad.net/1.0/~taget-9"
        }, 
        {
            "content": "Why is this tagged with 'volumes'?  Was this a volume backed instance or have a volume attached?", 
            "date_created": "2015-09-18 21:46:56.916021+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I agree with Eli that if libvirt fails we shouldn't assume the instance is running and should be reset to ACTIVE status.\n\nThe suspend method in the compute manager will revert the task state to None because it's using the @reverts_task_state decorator, so at least you can delete the instance after it's gone into ERROR status:\n\nhttps://github.com/openstack/nova/blob/master/nova/compute/manager.py#L4018\n\nI guess from the virsh output above the instance is still running in the hypervisor, so maybe there could be a case made that if the call to libvirt fails with a certain type of error we could handle it and check if the guest is still running, but we'd still need to report an instance fault since the operation failed.\n\nAnyway, I agree the reset-state API is what should be used here.", 
            "date_created": "2015-09-18 21:50:07.209401+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }
    ]
}