{
    "status": "Invalid", 
    "last_updated": "2014-02-05 22:37:15.198419+00:00", 
    "description": "Version : Havana\n\nI have two controllers in my environment, and deploy glance-api on each controller.\nIn nova.conf :\nglance_api_servers=controller2:9292,controller2:9292\nglance_num_retries = 2\n\nWhen I kill the glance on controller2, then run \"nova image-list\", I will get error sometimes:\n# nova image-list\n+--------------------------------------+--------+--------+--------+\n| ID                                   | Name   | Status | Server |\n+--------------------------------------+--------+--------+--------+\n| 668a4e66-97d9-40d7-888e-dd9db53438c4 | centos | ACTIVE |        |\n| 7e7917a6-96c5-4000-b167-efc13be4124c | cirros | ACTIVE |        |\n+--------------------------------------+--------+--------+--------+\n# nova image-list\nERROR: The server has either erred or is incapable of performing the requested operation. (HTTP 500) (Request-ID: req-09d764df-4e8b-4330-b39e-14e4736c2e68)\n\nThe error in /var/log/nova/api.log is:\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack Traceback (most recent call last):\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/__init__.py\", line 119, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return req.get_response(self.application)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/request.py\", line 1296, in send\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     application, catch_exc_info=False)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/request.py\", line 1260, in call_application\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     app_iter = application(self.environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 144, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return resp(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/keystoneclient/middleware/auth_token.py\", line 574, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return self.app(env, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 144, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return resp(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 144, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return resp(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/Routes-1.12.3-py2.6.egg/routes/middleware.py\", line 131, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     response = self.app(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 144, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return resp(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 130, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     resp = self.call_func(req, *args, **self.kwargs)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 195, in call_func\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return self.func(req, *args, **kwargs)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/wsgi.py\", line 917, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     content_type, body, accept)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/wsgi.py\", line 976, in _process_stack\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     action_result = self.dispatch(meth, request, action_args)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/wsgi.py\", line 1057, in dispatch\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return method(req=request, **action_args)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/compute/images.py\", line 203, in detail\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     **page_params)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/image/glance.py\", line 264, in detail\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     for image in images:\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/glanceclient/v1/images.py\", line 174, in paginate\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     images = self._list(url, \"images\")\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/glanceclient/common/base.py\", line 53, in _list\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     resp, body = self.api.json_request('GET', url)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/glanceclient/common/http.py\", line 266, in json_request\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     resp, body_iter = self._http_request(url, method, **kwargs)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/glanceclient/common/http.py\", line 235, in _http_request\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     raise exc.CommunicationError(message=message)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack CommunicationError: Error communicating with http://10.224.159.75:9292 [Errno 111] ECONNREFUSED\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack\n2014-01-22 05:33:08.572 8866 INFO nova.api.openstack [req-5d5b5dd1-36a5-48d9-8d6e-21be5551b135 feea78294ac84fb29583327109e899d6 3a5541d10e6b4a0fbcd45213e0e17ada] http://10.224.159.111/v2/3a5541d10e6b4a0fbcd45213e0e17ada/images/detail returned with HTTP 500\n\n\n\n\"10.224.159.75:9292\" is my controller2 IP.", 
    "tags": [], 
    "importance": "Undecided", 
    "heat": 8, 
    "link": "https://bugs.launchpad.net/nova/+bug/1271417", 
    "owner": "None", 
    "id": 1271417, 
    "index": 4495, 
    "created": "2014-01-22 05:36:41.376325+00:00", 
    "title": "glance_num_retries can't work", 
    "comments": [
        {
            "content": "Version : Havana\n\nI have two controllers in my environment, and deploy glance-api on each controller.\nIn nova.conf :\nglance_api_servers=controller2:9292,controller2:9292\nglance_num_retries = 2\n\nWhen I kill the glance on controller2, then run \"nova image-list\", I will get error sometimes:\n# nova image-list\n+--------------------------------------+--------+--------+--------+\n| ID                                   | Name   | Status | Server |\n+--------------------------------------+--------+--------+--------+\n| 668a4e66-97d9-40d7-888e-dd9db53438c4 | centos | ACTIVE |        |\n| 7e7917a6-96c5-4000-b167-efc13be4124c | cirros | ACTIVE |        |\n+--------------------------------------+--------+--------+--------+\n# nova image-list\nERROR: The server has either erred or is incapable of performing the requested operation. (HTTP 500) (Request-ID: req-09d764df-4e8b-4330-b39e-14e4736c2e68)\n\nThe error in /var/log/nova/api.log is:\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack Traceback (most recent call last):\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/__init__.py\", line 119, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return req.get_response(self.application)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/request.py\", line 1296, in send\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     application, catch_exc_info=False)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/request.py\", line 1260, in call_application\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     app_iter = application(self.environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 144, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return resp(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/keystoneclient/middleware/auth_token.py\", line 574, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return self.app(env, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 144, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return resp(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 144, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return resp(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/Routes-1.12.3-py2.6.egg/routes/middleware.py\", line 131, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     response = self.app(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 144, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return resp(environ, start_response)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 130, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     resp = self.call_func(req, *args, **self.kwargs)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/webob/dec.py\", line 195, in call_func\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return self.func(req, *args, **kwargs)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/wsgi.py\", line 917, in __call__\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     content_type, body, accept)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/wsgi.py\", line 976, in _process_stack\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     action_result = self.dispatch(meth, request, action_args)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/wsgi.py\", line 1057, in dispatch\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     return method(req=request, **action_args)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/api/openstack/compute/images.py\", line 203, in detail\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     **page_params)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/nova/image/glance.py\", line 264, in detail\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     for image in images:\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/glanceclient/v1/images.py\", line 174, in paginate\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     images = self._list(url, \"images\")\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/glanceclient/common/base.py\", line 53, in _list\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     resp, body = self.api.json_request('GET', url)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/glanceclient/common/http.py\", line 266, in json_request\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     resp, body_iter = self._http_request(url, method, **kwargs)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/glanceclient/common/http.py\", line 235, in _http_request\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack     raise exc.CommunicationError(message=message)\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack CommunicationError: Error communicating with http://10.224.159.75:9292 [Errno 111] ECONNREFUSED\n2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack\n2014-01-22 05:33:08.572 8866 INFO nova.api.openstack [req-5d5b5dd1-36a5-48d9-8d6e-21be5551b135 feea78294ac84fb29583327109e899d6 3a5541d10e6b4a0fbcd45213e0e17ada] http://10.224.159.111/v2/3a5541d10e6b4a0fbcd45213e0e17ada/images/detail returned with HTTP 500\n\n\n\n\"10.224.159.75:9292\" is my controller2 IP.", 
            "date_created": "2014-01-22 05:36:41.376325+00:00", 
            "author": "https://api.launchpad.net/1.0/~limao"
        }, 
        {
            "content": "2014-01-22 05:33:08.568 8866 TRACE nova.api.openstack CommunicationError: Error communicating with http://10.224.159.75:9292 [Errno 111] ECONNREFUSED\n\nI think you might be having network issues in your setup. I will try to reproduce. I will try to reproduce it.", 
            "date_created": "2014-01-22 09:11:28.699097+00:00", 
            "author": "https://api.launchpad.net/1.0/~maithem"
        }, 
        {
            "content": "indeed, you look to have a problem with your network setup.\nJust for information, you can reset the state of your instance by the command \"nova reset-state\"", 
            "date_created": "2014-01-26 16:18:03.004403+00:00", 
            "author": "https://api.launchpad.net/1.0/~sahid-ferdjaoui"
        }, 
        {
            "content": "Actually not sure the problem comes from the network setup. \n\nhow did you disable the glance service?  there is a command to manage services \"nova service-enable/disable\"\nif you kill the process, i'm not sure about the behavior.\n\nJust for information, you can reset the state of your instance by the command \"nova reset-state\"", 
            "date_created": "2014-01-26 16:23:08.734820+00:00", 
            "author": "https://api.launchpad.net/1.0/~sahid-ferdjaoui"
        }, 
        {
            "content": "I have two controller node, which has nova-api and glance-api on each compute node.\nand in nova.conf I have:\nglance_api_servers=controller2:9292,controller2:9292\nglance_num_retries = 2\n\nSo I think here just like \"LoadBalance\" in nova-api to call glance-api. This means even one of the glance-api is down, nova-api can work well too.\n\nBut when I test, I find that if the glance-api on controller1 and controller2 are all up, nova-api can work well. But if one of the glance-api is down, \"nova image-list\" will can't work sometimes. \nFor example, if the glance-api on controller2 is down and  the glance-api on controller1 is up. If I run \"nova image-list\", I will get the result as below:\n[root@ci91szcmp001 ~]# nova image-list\nERROR: The server has either erred or is incapable of performing the requested operation. (HTTP 500) (Request-ID: req-1dfcbeef-b84a-4550-9ee3-424e47fdc0dd)\n[root@ci91szcmp001 ~]# nova image-list\n+--------------------------------------+------------------------+--------+--------+\n| ID                                   | Name                   | Status | Server |\n+--------------------------------------+------------------------+--------+--------+\n| ea93090c-f447-4de2-8034-028ece93787d | CentOS6.3_64bit_harden | ACTIVE |        |\n| 696cb379-57bc-4a84-98cc-cc29e957f7f2 | cirros1                | ACTIVE |        |\n| 98f581e6-718e-4adc-bf78-4085339f6860 | cirros2                | ACTIVE |        |\n+--------------------------------------+------------------------+--------+--------+\n\nIn /var/log/nova/api.log, I have:\n2014-01-27 01:14:00.032 3936 TRACE nova.api.openstack     resp, body_iter = self._http_request(url, method, **kwargs)\n2014-01-27 01:14:00.032 3936 TRACE nova.api.openstack   File \"/usr/lib/python2.6/site-packages/glanceclient/common/http.py\", line 235, in _http_request\n2014-01-27 01:14:00.032 3936 TRACE nova.api.openstack     raise exc.CommunicationError(message=message)\n2014-01-27 01:14:00.032 3936 TRACE nova.api.openstack CommunicationError: Error communicating with http://10.224.159.75:9292 [Errno 111] ECONNREFUSED\n2014-01-27 01:14:00.032 3936 TRACE nova.api.openstack\n\nhttp://10.224.159.75:9292 is the glance-api on controller2, I shutdown glance-api on controller. But I think we have \"glance_num_retries=2\" in nova.conf, the glance-api on controller1 is up, we should not get error here. So I think this a bug.", 
            "date_created": "2014-01-27 01:23:55.841125+00:00", 
            "author": "https://api.launchpad.net/1.0/~limao"
        }, 
        {
            "content": "If you want to do load balancing you should do it by putting both glance servers behind the same IP somehow.\n\nThe current glance logic randomly picks one of the glance_api_servers, and has no concept of knowing which glance_api_server is down.\n\nWe are trying to move away from using the glance_api_servers config option and use the keystone registry as well.", 
            "date_created": "2014-02-05 22:37:06.838555+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }
    ]
}