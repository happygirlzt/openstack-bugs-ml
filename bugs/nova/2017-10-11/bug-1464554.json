{
    "status": "Invalid", 
    "last_updated": "2015-06-23 23:46:36.137126+00:00", 
    "description": "I'm trying to launch an instance with external network but result in failed status. But instances with internal network are fine.\n\n\u00a0F ollowing is the nova-compute.log from compute node\n\n2015-06-12 15:22:50.899 3121 INFO nova.compute.manager [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Starting instance...\n2015-06-12 15:22:50.997 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Attempting claim: memory 2048 MB, disk 50 GB\n2015-06-12 15:22:50.997 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Total memory: 515884 MB, used: 2560.00 MB\n2015-06-12 15:22:50.998 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] memory limit: 773826.00 MB, free: 771266.00 MB\n2015-06-12 15:22:50.998 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Total disk: 1144 GB, used: 50.00 GB\n2015-06-12 15:22:50.998 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] disk limit not specified, defaulting to unlimited\n2015-06-12 15:22:51.023 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Claim successful\n2015-06-12 15:22:51.134 3121 INFO nova.scheduler.client.report [-] Compute_service record updated for ('openstack-kvm1', 'openstack-kvm1')\n2015-06-12 15:22:51.270 3121 INFO nova.scheduler.client.report [-] Compute_service record updated for ('openstack-kvm1', 'openstack-kvm1')\n2015-06-12 15:22:51.470 3121 INFO nova.virt.libvirt.driver [req-02283432-2fd3-4835-a548-8c5bd74f4340 - - - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Creating image\n2015-06-12 15:22:51.760 3121 INFO nova.scheduler.client.report [-] Compute_service record updated for ('openstack-kvm1', 'openstack-kvm1')\n2015-06-12 15:22:51.993 3121 ERROR nova.compute.manager [req-02283432-2fd3-4835-a548-8c5bd74f4340 - - - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Instance failed to spawn\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Traceback (most recent call last):\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 2442, in _build_resources\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     yield resources\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 2314, in _build_and_run_instance\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     block_device_info=block_device_info)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 2351, in spawn\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     write_to_disk=True)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4172, in _get_guest_xml\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     context)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4043, in _get_guest_config\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     flavor, virt_type)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/vif.py\", line 374, in get_config\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     _(\"Unexpected vif_type=%s\") % vif_type)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] NovaException: Unexpected vif_type=binding_failed\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]\n2015-06-12 15:22:51.995 3121 INFO nova.compute.manager [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Terminating instance\n2015-06-12 15:22:52.002 3121 INFO nova.virt.libvirt.driver [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] During wait destroy, instance disappeared.\n2015-06-12 15:22:52.015 3121 INFO nova.virt.libvirt.driver [req-02283432-2fd3-4835-a548-8c5bd74f4340 - - - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Deleting instance files /var/lib/nova/instances/8da458b4-c064-47c8-a1bb-aad4e4400772_del\n2015-06-12 15:22:52.017 3121 INFO nova.virt.libvirt.driver [req-02283432-2fd3-4835-a548-8c5bd74f4340 - - - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Deletion of /var/lib/nova/instances/8da458b4-c064-47c8-a1bb-aad4e4400772_del complete\n\nneuton-server.log from neutron-server node\n\n2015-06-12 15:22:51.437 6583 INFO neutron.wsgi [req-bd04266c-e4a1-4c5b-be8d-52a30e32b46a ] 11.11.176.41 - - [12/Jun/2015 15:22:51] \"GET /v2.0/security-groups.json?tenant_id=700e680640e0415faf591e950cdb42d0 HTTP/1.1\" 200 1765 0.017019\n2015-06-12 15:22:51.440 6583 INFO neutron.wsgi [req-835c2aab-e3f5-44bb-8586-8c37b6e6b228 ] 11.11.176.35 - - [12/Jun/2015 15:22:51] \"GET /v2.0/extensions.json HTTP/1.1\" 200 4806 0.002097\n2015-06-12 15:22:51.518 6583 INFO neutron.callbacks.manager [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] Notify callbacks for port, after_create\n2015-06-12 15:22:51.518 6583 INFO neutron.callbacks.manager [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] Calling callback neutron.db.l3_dvrscheduler_db._notify_l3_agent_new_port\n2015-06-12 15:22:51.528 6583 ERROR neutron.plugins.ml2.managers [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] Failed to bind port 68a23b41-a9dd-4d4b-88b0-359834b75f97 on host openstack-kvm1\n2015-06-12 15:22:51.529 6583 ERROR neutron.plugins.ml2.managers [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] Failed to bind port 68a23b41-a9dd-4d4b-88b0-359834b75f97 on host openstack-kvm1\n2015-06-12 15:22:51.571 6583 INFO neutron.wsgi [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] 11.11.176.41 - - [12/Jun/2015 15:22:51] \"POST /v2.0/ports.json HTTP/1.1\" 201 928 0.130556\n2015-06-12 15:22:51.594 6583 INFO neutron.wsgi [req-c88f52ef-e3fc-4245-9225-980ad67c8718 ] 11.11.176.41 - - [12/Jun/2015 15:22:51] \"GET /v2.0/ports.json?tenant_id=700e680640e0415faf591e950cdb42d0&device_id=8da458b4-c064-47c8-a1bb-aad4e4400772 HTTP/1.1\" 200 926 0.019260\n\nnova-scheduler.log  from nova-controller node\n\n2015-06-12 15:22:52.271 2673 INFO nova.filters [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] Filter RetryFilter returned 0 hosts\n\nnova-conductor.log from nova-controller node\n\n2015-06-12 15:22:52.252 1191 ERROR nova.scheduler.utils [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Error from last host: openstack-kvm1 (node openstack-kvm1): [u'Traceback (most recent call last):\\n', u'  File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 2219, in _do_build_and_run_instance\\n    filter_properties)\\n', u'  File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 2362, in _build_and_run_instance\\n    instance_uuid=instance.uuid, reason=six.text_type(e))\\n', u'RescheduledException: Build of instance 8da458b4-c064-47c8-a1bb-aad4e4400772 was re-scheduled: Unexpected vif_type=binding_failed\\n']\n2015-06-12 15:22:52.275 1191 WARNING nova.scheduler.utils [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] Failed to compute_task_build_instances: No valid host was found. There are not enough hosts available.\nTraceback (most recent call last):\n\n\u00a0\u00a0File \"/usr/lib/python2.7/dist-packages/oslo_messaging/rpc/server.py\", line 142, in inner\n\u00a0\u00a0\u00a0\u00a0return func(*args, **kwargs)\n\n\u00a0\u00a0File \"/usr/lib/python2.7/dist-packages/nova/scheduler/manager.py\", line 86, in select_destinations\n\u00a0\u00a0\u00a0\u00a0filter_properties)\n\n\u00a0\u00a0File \"/usr/lib/python2.7/dist-packages/nova/scheduler/filter_scheduler.py\", line 80, in select_destinations\n\u00a0\u00a0\u00a0\u00a0raise exception.NoValidHost(reason=reason)\n\nNoValidHost: No valid host was found. There are not enough hosts available.\n\n2015-06-12 15:22:52.276 1191 WARNING nova.scheduler.utils [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Setting instance to ERROR state.\n\n\n\nThe setup of this case is like below:\n\nnova-control   neutron   neutron-node  are installed on a vmware virtual machine, nova-control and neutron have their eth0 with a static ip for management, the neutron-node has eth0 for management, eth1 for tunnel and eth2 for external network, all the network devices are using dvswitch of vmware esxi and in the same vlan dvPortgroup.\n\nThe openstack-kvm is a physical host with eth0 for management and eth1 for tunnel, eth0 is in a different vlan from the virtual ones and eth1 set to be in the same vlan as neutron/nova/neutron-node with a static Ip but the physical switch has been set to trunk mode. All the machines mentioned above are able to ping allocated static IPs of each other.", 
    "tags": [
        "network"
    ], 
    "importance": "Undecided", 
    "heat": 20, 
    "link": "https://bugs.launchpad.net/nova/+bug/1464554", 
    "owner": "None", 
    "id": 1464554, 
    "index": 5602, 
    "created": "2015-06-12 07:45:24.795490+00:00", 
    "title": "instance failed to spawn with external network", 
    "comments": [
        {
            "content": "I'm trying to launch an instance with external network but result in failed status. But instances with internal network are fine.\n\n\n F ollowing is the nova-compute.log from compute node\n\n2015-06-12 15:22:50.899 3121 INFO nova.compute.manager [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Starting instance...\n2015-06-12 15:22:50.997 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Attempting claim: memory 2048 MB, disk 50 GB\n2015-06-12 15:22:50.997 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Total memory: 515884 MB, used: 2560.00 MB\n2015-06-12 15:22:50.998 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] memory limit: 773826.00 MB, free: 771266.00 MB\n2015-06-12 15:22:50.998 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Total disk: 1144 GB, used: 50.00 GB\n2015-06-12 15:22:50.998 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] disk limit not specified, defaulting to unlimited\n2015-06-12 15:22:51.023 3121 INFO nova.compute.claims [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Claim successful\n2015-06-12 15:22:51.134 3121 INFO nova.scheduler.client.report [-] Compute_service record updated for ('openstack-kvm1', 'openstack-kvm1')\n2015-06-12 15:22:51.270 3121 INFO nova.scheduler.client.report [-] Compute_service record updated for ('openstack-kvm1', 'openstack-kvm1')\n2015-06-12 15:22:51.470 3121 INFO nova.virt.libvirt.driver [req-02283432-2fd3-4835-a548-8c5bd74f4340 - - - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Creating image\n2015-06-12 15:22:51.760 3121 INFO nova.scheduler.client.report [-] Compute_service record updated for ('openstack-kvm1', 'openstack-kvm1')\n2015-06-12 15:22:51.993 3121 ERROR nova.compute.manager [req-02283432-2fd3-4835-a548-8c5bd74f4340 - - - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Instance failed to spawn\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Traceback (most recent call last):\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 2442, in _build_resources\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     yield resources\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 2314, in _build_and_run_instance\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     block_device_info=block_device_info)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 2351, in spawn\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     write_to_disk=True)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4172, in _get_guest_xml\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     context)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4043, in _get_guest_config\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     flavor, virt_type)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/vif.py\", line 374, in get_config\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772]     _(\"Unexpected vif_type=%s\") % vif_type)\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] NovaException: Unexpected vif_type=binding_failed\n2015-06-12 15:22:51.993 3121 TRACE nova.compute.manager [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] \n2015-06-12 15:22:51.995 3121 INFO nova.compute.manager [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Terminating instance\n2015-06-12 15:22:52.002 3121 INFO nova.virt.libvirt.driver [-] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] During wait destroy, instance disappeared.\n2015-06-12 15:22:52.015 3121 INFO nova.virt.libvirt.driver [req-02283432-2fd3-4835-a548-8c5bd74f4340 - - - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Deleting instance files /var/lib/nova/instances/8da458b4-c064-47c8-a1bb-aad4e4400772_del\n2015-06-12 15:22:52.017 3121 INFO nova.virt.libvirt.driver [req-02283432-2fd3-4835-a548-8c5bd74f4340 - - - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Deletion of /var/lib/nova/instances/8da458b4-c064-47c8-a1bb-aad4e4400772_del complete\n\n\nneuton-server.log from neutron-server node\n\n2015-06-12 15:22:51.437 6583 INFO neutron.wsgi [req-bd04266c-e4a1-4c5b-be8d-52a30e32b46a ] 11.11.176.41 - - [12/Jun/2015 15:22:51] \"GET /v2.0/security-groups.json?tenant_id=700e680640e0415faf591e950cdb42d0 HTTP/1.1\" 200 1765 0.017019\n2015-06-12 15:22:51.440 6583 INFO neutron.wsgi [req-835c2aab-e3f5-44bb-8586-8c37b6e6b228 ] 11.11.176.35 - - [12/Jun/2015 15:22:51] \"GET /v2.0/extensions.json HTTP/1.1\" 200 4806 0.002097\n2015-06-12 15:22:51.518 6583 INFO neutron.callbacks.manager [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] Notify callbacks for port, after_create\n2015-06-12 15:22:51.518 6583 INFO neutron.callbacks.manager [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] Calling callback neutron.db.l3_dvrscheduler_db._notify_l3_agent_new_port\n2015-06-12 15:22:51.528 6583 ERROR neutron.plugins.ml2.managers [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] Failed to bind port 68a23b41-a9dd-4d4b-88b0-359834b75f97 on host openstack-kvm1\n2015-06-12 15:22:51.529 6583 ERROR neutron.plugins.ml2.managers [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] Failed to bind port 68a23b41-a9dd-4d4b-88b0-359834b75f97 on host openstack-kvm1\n2015-06-12 15:22:51.571 6583 INFO neutron.wsgi [req-523b2d9c-8026-4c9c-9ba0-cfd30833e3b8 ] 11.11.176.41 - - [12/Jun/2015 15:22:51] \"POST /v2.0/ports.json HTTP/1.1\" 201 928 0.130556\n2015-06-12 15:22:51.594 6583 INFO neutron.wsgi [req-c88f52ef-e3fc-4245-9225-980ad67c8718 ] 11.11.176.41 - - [12/Jun/2015 15:22:51] \"GET /v2.0/ports.json?tenant_id=700e680640e0415faf591e950cdb42d0&device_id=8da458b4-c064-47c8-a1bb-aad4e4400772 HTTP/1.1\" 200 926 0.019260\n\nnova-scheduler.log  from nova-controller node\n\n2015-06-12 15:22:52.271 2673 INFO nova.filters [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] Filter RetryFilter returned 0 hosts\n\n\nnova-conductor.log from nova-controller node\n\n2015-06-12 15:22:52.252 1191 ERROR nova.scheduler.utils [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Error from last host: openstack-kvm1 (node openstack-kvm1): [u'Traceback (most recent call last):\\n', u'  File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 2219, in _do_build_and_run_instance\\n    filter_properties)\\n', u'  File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 2362, in _build_and_run_instance\\n    instance_uuid=instance.uuid, reason=six.text_type(e))\\n', u'RescheduledException: Build of instance 8da458b4-c064-47c8-a1bb-aad4e4400772 was re-scheduled: Unexpected vif_type=binding_failed\\n']\n2015-06-12 15:22:52.275 1191 WARNING nova.scheduler.utils [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] Failed to compute_task_build_instances: No valid host was found. There are not enough hosts available.\nTraceback (most recent call last):\n\n  File \"/usr/lib/python2.7/dist-packages/oslo_messaging/rpc/server.py\", line 142, in inner\n    return func(*args, **kwargs)\n\n  File \"/usr/lib/python2.7/dist-packages/nova/scheduler/manager.py\", line 86, in select_destinations\n    filter_properties)\n\n  File \"/usr/lib/python2.7/dist-packages/nova/scheduler/filter_scheduler.py\", line 80, in select_destinations\n    raise exception.NoValidHost(reason=reason)\n\nNoValidHost: No valid host was found. There are not enough hosts available.\n\n2015-06-12 15:22:52.276 1191 WARNING nova.scheduler.utils [req-6b9424ce-2eda-469e-9cba-63807a8643c9 28740e72adf04dde88a2b2a1aa701e66 700e680640e0415faf591e950cdb42d0 - - -] [instance: 8da458b4-c064-47c8-a1bb-aad4e4400772] Setting instance to ERROR state.", 
            "date_created": "2015-06-12 07:45:24.795490+00:00", 
            "author": "https://api.launchpad.net/1.0/~yao.long"
        }, 
        {
            "content": "Same issue here. Juno deployment, vxlan. In my case the install is done with Red Hat Foreman and the rhelosp installer.", 
            "date_created": "2015-06-15 04:32:00.688486+00:00", 
            "author": "https://api.launchpad.net/1.0/~augustsimonelli"
        }, 
        {
            "content": "An external network is typically only used for Neutron routers; non-admin users cannot attach instances to external networks. Chances are the plugin configuration file (ie. ml2_conf.ini) on the compute node has not been configured to support the external bridge. There could be errors in the agent log file on the compute node to support this. If the agent is unable to complete the work of setting up the bridge/port connection, it can result in the 'binding_failed' error seen in the logs above. \n\nYou might want to consider attaching neutron routers to the internal network with your instances, and also to the external network to provide inbound/outbound connectivity to/from those instances.", 
            "date_created": "2015-06-23 02:52:26.288875+00:00", 
            "author": "https://api.launchpad.net/1.0/~james-denton"
        }, 
        {
            "content": "Here is the ml2_conf.ini from my compute node. All the settings in this file are from the openstack installation manual kilo draft.\n\n\n--------------------------------------------------------------------------------------------------------------------------\n[ml2]\n# (ListOpt) List of network type driver entrypoints to be loaded from\n# the neutron.ml2.type_drivers namespace.\n#\ntype_drivers = local,flat,vlan,gre,vxlan\n# Example: type_drivers = flat,vlan,gre,vxlan\n\n# (ListOpt) Ordered list of network_types to allocate as tenant\n# networks. The default value 'local' is useful for single-box testing\n# but provides no connectivity between hosts.\n#\ntenant_network_types = gre\n# Example: tenant_network_types = vlan,gre,vxlan\n\n# (ListOpt) Ordered list of networking mechanism driver entrypoints\n# to be loaded from the neutron.ml2.mechanism_drivers namespace.\nmechanism_drivers = openvswitch\n# Example: mechanism_drivers = openvswitch,mlnx\n# Example: mechanism_drivers = arista\n# Example: mechanism_drivers = cisco,logger\n# Example: mechanism_drivers = openvswitch,brocade\n# Example: mechanism_drivers = linuxbridge,brocade\n\n# (ListOpt) Ordered list of extension driver entrypoints\n# to be loaded from the neutron.ml2.extension_drivers namespace.\n# extension_drivers =\n# Example: extension_drivers = anewextensiondriver\n\n# =========== items for MTU selection and advertisement =============\n# (IntOpt) Path MTU.  The maximum permissible size of an unfragmented\n# packet travelling from and to addresses where encapsulated Neutron\n# traffic is sent.  Drivers calculate maximum viable MTU for\n# validating tenant requests based on this value (typically,\n# path_mtu - max encap header size).  If <=0, the path MTU is\n# indeterminate and no calculation takes place.\n# path_mtu = 0\n\n# (IntOpt) Segment MTU.  The maximum permissible size of an\n# unfragmented packet travelling a L2 network segment.  If <=0,\n# the segment MTU is indeterminate and no calculation takes place.\n# segment_mtu = 0\n\n# (ListOpt) Physical network MTUs.  List of mappings of physical\n# network to MTU value.  The format of the mapping is\n# <physnet>:<mtu val>.  This mapping allows specifying a\n# physical network MTU value that differs from the default\n# segment_mtu value.\n# physical_network_mtus =\n# Example: physical_network_mtus = physnet1:1550, physnet2:1500\n# ======== end of items for MTU selection and advertisement =========\n\n[ml2_type_flat]\n# (ListOpt) List of physical_network names with which flat networks\n# can be created. Use * to allow flat networks with arbitrary\n# physical_network names.\n#\n# flat_networks =\n# Example:flat_networks = physnet1,physnet2\n# Example:flat_networks = *\n\n[ml2_type_vlan]\n# (ListOpt) List of <physical_network>[:<vlan_min>:<vlan_max>] tuples\n# specifying physical_network names usable for VLAN provider and\n# tenant networks, as well as ranges of VLAN tags on each\n# physical_network available for allocation as tenant networks.\n#\n# network_vlan_ranges =\n# Example: network_vlan_ranges = physnet1:1000:2999,physnet2\n\n[ml2_type_gre]\n# (ListOpt) Comma-separated list of <tun_min>:<tun_max> tuples enumerating ranges of GRE tunnel IDs that are available for tenant network allocation\ntunnel_id_ranges = 1:1000\n\n[ml2_type_vxlan]\n# (ListOpt) Comma-separated list of <vni_min>:<vni_max> tuples enumerating\n# ranges of VXLAN VNI IDs that are available for tenant network allocation.\n#\n# vni_ranges =\n\n# (StrOpt) Multicast group for the VXLAN interface. When configured, will\n# enable sending all broadcast traffic to this multicast group. When left\n# unconfigured, will disable multicast VXLAN mode.\n#\n# vxlan_group =\n# Example: vxlan_group = 239.1.1.1\n\n[securitygroup]\n# Controls if neutron security group is enabled or not.\n# It should be false when you use nova security group.\nenable_security_group = True\n\n# Use ipset to speed-up the iptables security groups. Enabling ipset support\n# requires that ipset is installed on L2 agent node.\nenable_ipset = True\n\nfirewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver\n\n\n[ovs]\nlocal_ip = 11.11.176.41\n\n[agent]\ntunnel_types = gre\n-------------------------------------------------------------------------------------------------------------------------------\n\n\nAnd I got an instance connecting to the neutron router connected with both internal and external networks. I believe I have the right security group settings but unable to ping the instance with an assigned floating IP from the external network.", 
            "date_created": "2015-06-23 09:22:42.000778+00:00", 
            "author": "https://api.launchpad.net/1.0/~yao.long"
        }, 
        {
            "content": "You may want to verify that you can ping the instance from within the router namespace. If that doesn't work, you'll want to verify ARP resolution is working (you don't have l2population enabled), the sec group is properly applied to the instance's port, and maybe run some packet captures on the tap interface of the instance to see if its making it. This assumes that GRE tunneling is working. Did the instance get it's IP via DHCP properly?\n\nIf the ping is successful from the router namespace, try running packet captures within the router namespace while pinging the floating IP from an external host and verify the address translation is happening properly.", 
            "date_created": "2015-06-23 13:18:12.022294+00:00", 
            "author": "https://api.launchpad.net/1.0/~james-denton"
        }, 
        {
            "content": "Hi James. The instance got its fixed IP properly and is capable of communicating with other instances sharing the same subnet and router. I check the external interface on the neutron-node and it seems that it just wont get its assigned ip for routing.", 
            "date_created": "2015-06-23 14:13:17.356358+00:00", 
            "author": "https://api.launchpad.net/1.0/~yao.long"
        }, 
        {
            "content": "Neither the external bridge or interface (ie. eth2) would get an IP assigned to it by Neutron; the expectation is that there is a gateway device in the external VLAN that would handle the routing. When the external subnet was configured in Neutron, I imagine a gateway IP was assigned. That IP would need to be configured on the external gateway device, as that's the default gateway for the Neutron router.", 
            "date_created": "2015-06-23 14:40:02.745377+00:00", 
            "author": "https://api.launchpad.net/1.0/~james-denton"
        }, 
        {
            "content": "The only way to get external connectivity via tenant network is to setup so-called provider network.\nIt would be a tenant network going through specifically configured bridges and having fixed cidr which is a part of global ipv4 pool.\n\nOther than that VMs can't be plugged into an external network.", 
            "date_created": "2015-06-23 23:45:27.310111+00:00", 
            "author": "https://api.launchpad.net/1.0/~enikanorov"
        }, 
        {
            "content": "I think it's invalid for nova as well since it doesn't really care a type of network provided on VM boot", 
            "date_created": "2015-06-23 23:46:34.627931+00:00", 
            "author": "https://api.launchpad.net/1.0/~enikanorov"
        }
    ]
}