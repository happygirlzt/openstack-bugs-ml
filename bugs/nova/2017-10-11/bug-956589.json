{
    "status": "Expired", 
    "last_updated": "2016-07-05 09:41:09.753030+00:00", 
    "description": "Sometimes, I have this error when I'm shutting down an instance:\n\n\n2012-03-15 19:49:33 ERROR nova.virt.disk.api [-] Failed to remove container: Unexpected error while running command.\nCommand: sudo nova-rootwrap kpartx -d /dev/nbd9\nExit code: 1\nStdout: ''\nStderr: 'device-mapper: remove ioctl failed: Device or resource busy\\n'\n(nova.virt.disk.api): TRACE: Traceback (most recent call last):\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/disk/api.py\", line 288, in destroy_container\n(nova.virt.disk.api): TRACE:     img.umount()\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/disk/api.py\", line 216, in umount\n(nova.virt.disk.api): TRACE:     self._mounter.do_umount()\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/disk/mount.py\", line 125, in do_umount\n(nova.virt.disk.api): TRACE:     self.unmap_dev()\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/disk/mount.py\", line 92, in unmap_dev\n(nova.virt.disk.api): TRACE:     utils.execute('kpartx', '-d', self.device, run_as_root=True)\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/utils.py\", line 240, in execute\n(nova.virt.disk.api): TRACE:     cmd=' '.join(cmd))\n(nova.virt.disk.api): TRACE: ProcessExecutionError: Unexpected error while running command.\n(nova.virt.disk.api): TRACE: Command: sudo nova-rootwrap kpartx -d /dev/nbd9\n(nova.virt.disk.api): TRACE: Exit code: 1\n(nova.virt.disk.api): TRACE: Stdout: ''\n(nova.virt.disk.api): TRACE: Stderr: 'device-mapper: remove ioctl failed: Device or resource busy\\n'\n(nova.virt.disk.api): TRACE:\n\nIt happens when I have a daemon running inside the lxc instance.\nI'm using the current trunk and this is my nova.conf file:\n\n\n--auth_strategy=keystone\n--sql_connection=postgresql://nova:password@localhost:5432/nova\n--allow_admin_api\n--allow_ec2_admin_api\n--img_handlers=nbd\n\n--dhcpbridge_flagfile=/etc/nova/nova.conf\n--dhcpbridge=/usr/bin/nova-dhcpbridge\n--logdir=/var/log/nova\n--state_path=/var/lib/nova\n--lock_path=/var/lock/nova\n--force_dhcp_release\n--iscsi_helper=tgtadm\n--libvirt_use_virtio_for_bridges\n--connection_type=libvirt\n--root_helper=sudo nova-rootwrap\n--verbose", 
    "tags": [
        "lxc"
    ], 
    "importance": "Undecided", 
    "heat": 16, 
    "link": "https://bugs.launchpad.net/nova/+bug/956589", 
    "owner": "None", 
    "id": 956589, 
    "index": 2700, 
    "created": "2012-03-16 00:10:38.085049+00:00", 
    "title": "Device is  busy error on lxc instance shutdown", 
    "comments": [
        {
            "content": "Sometimes, I have this error when I'm shutting down an instance:\n\n\n2012-03-15 19:49:33 ERROR nova.virt.disk.api [-] Failed to remove container: Unexpected error while running command.\nCommand: sudo nova-rootwrap kpartx -d /dev/nbd9\nExit code: 1\nStdout: ''\nStderr: 'device-mapper: remove ioctl failed: Device or resource busy\\n'\n(nova.virt.disk.api): TRACE: Traceback (most recent call last):\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/disk/api.py\", line 288, in destroy_container\n(nova.virt.disk.api): TRACE:     img.umount()\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/disk/api.py\", line 216, in umount\n(nova.virt.disk.api): TRACE:     self._mounter.do_umount()\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/disk/mount.py\", line 125, in do_umount\n(nova.virt.disk.api): TRACE:     self.unmap_dev()\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/disk/mount.py\", line 92, in unmap_dev\n(nova.virt.disk.api): TRACE:     utils.execute('kpartx', '-d', self.device, run_as_root=True)\n(nova.virt.disk.api): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/utils.py\", line 240, in execute\n(nova.virt.disk.api): TRACE:     cmd=' '.join(cmd))\n(nova.virt.disk.api): TRACE: ProcessExecutionError: Unexpected error while running command.\n(nova.virt.disk.api): TRACE: Command: sudo nova-rootwrap kpartx -d /dev/nbd9\n(nova.virt.disk.api): TRACE: Exit code: 1\n(nova.virt.disk.api): TRACE: Stdout: ''\n(nova.virt.disk.api): TRACE: Stderr: 'device-mapper: remove ioctl failed: Device or resource busy\\n'\n(nova.virt.disk.api): TRACE:\n\nIt happens when I have a daemon running inside the lxc instance.\nI'm using the current trunk and this is my nova.conf file:\n\n\n--auth_strategy=keystone\n--sql_connection=postgresql://nova:password@localhost:5432/nova\n--allow_admin_api\n--allow_ec2_admin_api\n--img_handlers=nbd\n\n--dhcpbridge_flagfile=/etc/nova/nova.conf\n--dhcpbridge=/usr/bin/nova-dhcpbridge\n--logdir=/var/log/nova\n--state_path=/var/lib/nova\n--lock_path=/var/lock/nova\n--force_dhcp_release\n--iscsi_helper=tgtadm\n--libvirt_use_virtio_for_bridges\n--connection_type=libvirt\n--root_helper=sudo nova-rootwrap\n--verbose", 
            "date_created": "2012-03-16 00:10:38.085049+00:00", 
            "author": "https://api.launchpad.net/1.0/~patrick-hetu"
        }, 
        {
            "content": "Are you still having this problem?\r\n\r\nRegards\r\nchuck", 
            "date_created": "2012-07-12 13:24:13.674358+00:00", 
            "author": "https://api.launchpad.net/1.0/~zulcss"
        }, 
        {
            "content": "We cannot solve the issue you reported without more information. Could you please provide the requested information ?", 
            "date_created": "2012-09-10 13:07:15.608376+00:00", 
            "author": "https://api.launchpad.net/1.0/~ttx"
        }, 
        {
            "content": "I didn't have this problem since I upgrade to Folom. I think this issue is solved.", 
            "date_created": "2012-09-10 17:07:35.969776+00:00", 
            "author": "https://api.launchpad.net/1.0/~patrick-hetu"
        }, 
        {
            "content": "Closing then.", 
            "date_created": "2012-09-16 02:28:49.190076+00:00", 
            "author": "https://api.launchpad.net/1.0/~zulcss"
        }, 
        {
            "content": "I got the same error with havana-stable nova while I booting a kvm instance with libvirt driver,\n2014-05-20 14:44:13.179 24237 DEBUG nova.virt.disk.mount.api [req-63dccfa5-ed06-4daa-8759-ee22c1259edf 830d8718e9e4454a886dee12ce3e8b8e dfbb396e096e4f2f95f2d7b6a6713e8c] Umount /dev/mapper/nbd9p1 unmnt_dev /usr/lib/python2.7/dist-packages/nova/virt/disk/mount/api.py:208\n2014-05-20 14:44:13.180 24237 DEBUG nova.openstack.common.processutils [req-63dccfa5-ed06-4daa-8759-ee22c1259edf 830d8718e9e4454a886dee12ce3e8b8e dfbb396e096e4f2f95f2d7b6a6713e8c] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf umount /dev/mapper/nbd9p1 execute /usr/lib/python2.7/dist-packages/nova/openstack/common/processutils.py:147\n2014-05-20 14:44:13.249 24237 DEBUG nova.virt.disk.mount.api [req-63dccfa5-ed06-4daa-8759-ee22c1259edf 830d8718e9e4454a886dee12ce3e8b8e dfbb396e096e4f2f95f2d7b6a6713e8c] Unmap dev /dev/nbd9 unmap_dev /usr/lib/python2.7/dist-packages/nova/virt/disk/mount/api.py:184\n2014-05-20 14:44:13.250 24237 DEBUG nova.openstack.common.processutils [req-63dccfa5-ed06-4daa-8759-ee22c1259edf 830d8718e9e4454a886dee12ce3e8b8e dfbb396e096e4f2f95f2d7b6a6713e8c] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf kpartx -d /dev/nbd9 execute /usr/lib/python2.7/dist-packages/nova/openstack/common/processutils.py:147\n2014-05-20 14:44:13.324 24237 DEBUG nova.openstack.common.processutils [req-63dccfa5-ed06-4daa-8759-ee22c1259edf 830d8718e9e4454a886dee12ce3e8b8e dfbb396e096e4f2f95f2d7b6a6713e8c] Result was 1 execute /usr/lib/python2.7/dist-packages/nova/openstack/common/processutils.py:172\n2014-05-20 14:44:13.325 24237 DEBUG nova.virt.disk.vfs.localfs [req-63dccfa5-ed06-4daa-8759-ee22c1259edf 830d8718e9e4454a886dee12ce3e8b8e dfbb396e096e4f2f95f2d7b6a6713e8c] Failed to unmount /tmp/openstack-vfs-localfsUz8SQH: Unexpected error while running command.\n2014-05-20 14:44:13.326 24237 DEBUG nova.virt.disk.vfs.localfs [req-63dccfa5-ed06-4daa-8759-ee22c1259edf 830d8718e9e4454a886dee12ce3e8b8e dfbb396e096e4f2f95f2d7b6a6713e8c] Failed to remove /tmp/openstack-vfs-localfsUz8SQH: [Errno 16] Device or resource busy: '/tmp/openstack-vfs-localfsUz8SQH' teardown /usr/lib/python2.7/dist-packages/nova/virt/disk/vfs/localfs.py:98\n\nand I did the file injection processes manually as below:\n1) qemu-nbd -c /dev/nbd16 $INSTNCE_PATH/$UUID/disk\n2) kpartx -a /dev/nbd16\n3) mount /dev/mapper/nbd16p1 /tmp/openstack-localfsxxxxx\nand then try to release the resources above(with no file operation in the /tmp/openstack-localfsxxxxx):\n1) umount /dev/mapper/nbd16p1 (this operation return with no error/warnning output, I also can't see any files under /tmp/openstack/localfsxxxxx, I think it runs successfully)\n2) kpartx -d /dev/nbd16 (this operation failed with output 'device-mapper: remove ioctl on nbd16p1 failed: Device or resource busy')\n3) then I try this operation several times, after a few minutes(1~3 in my mind), it runs successfully.\nI think this is the really issue we should fix here, we should add a 'attempts' parameter to run the 'kpartx -d' operation, \ndo the same change as unget_dev in loop.py:\ndef unget_dev(self):\n        if not self.linked:\n            return\n\n        # NOTE(mikal): On some kernels, losetup -d will intermittently fail,\n        # thus leaking a loop device unless the losetup --detach is retried:\n        # https://lkml.org/lkml/2012/9/28/62\n        LOG.debug(_(\"Release loop device %s\"), self.device)\n        utils.execute('losetup', '--detach', self.device, run_as_root=True,\n                      attempts=3)\n        self.linked = False\n        self.device = None\n", 
            "date_created": "2014-05-21 02:53:07.910819+00:00", 
            "author": "https://api.launchpad.net/1.0/~hzwangpan"
        }, 
        {
            "content": "I got this issue with a lot of netns mounted on this host, I think this may be the reason why we should wait for a few minutes to run kpartx -d after the nbd16p1 is unmounted.\n\nhzwangpan@10-120-120-32:/data/log/nova$ mount\nsysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)\nproc on /proc type proc (rw,nosuid,nodev,noexec,relatime)\nudev on /dev type devtmpfs (rw,relatime,size=10240k,nr_inodes=6176362,mode=755)\ndevpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000)\ntmpfs on /run type tmpfs (rw,nosuid,noexec,relatime,size=4942480k,mode=755)\n/dev/disk/by-uuid/44c6be13-2bc9-45bd-bd06-5befb9611dbd on / type ext4 (rw,relatime,errors=remount-ro,data=ordered)\ntmpfs on /run/lock type tmpfs (rw,nosuid,nodev,noexec,relatime,size=5120k)\ntmpfs on /run/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=10723820k)\n/dev/sda8 on /home type ext4 (rw,relatime,data=ordered)\n/dev/sda7 on /tmp type ext4 (rw,relatime,data=ordered)\n/dev/sda6 on /var type ext4 (rw,relatime,data=ordered)\nrpc_pipefs on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw,relatime)\ncgroup on /sys/fs/cgroup type tmpfs (rw,relatime,mode=755)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)\ncgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)\ncgroup on /sys/fs/cgroup/cpuacct type cgroup (rw,relatime,cpuacct)\ncgroup on /sys/fs/cgroup/memory type cgroup (rw,relatime,memory)\ncgroup on /sys/fs/cgroup/devices type cgroup (rw,relatime,devices)\ncgroup on /sys/fs/cgroup/freezer type cgroup (rw,relatime,freezer)\ncgroup on /sys/fs/cgroup/net_cls type cgroup (rw,relatime,net_cls)\ncgroup on /sys/fs/cgroup/blkio type cgroup (rw,relatime,blkio)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (rw,relatime,perf_event)\ncgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,relatime,hugetlb)\ntmpfs on /run/netns type tmpfs (rw,nosuid,noexec,relatime,size=4942480k,mode=755)\nproc on /run/netns/qdhcp-725627d3-0104-444f-a5dc-1b2abd6beefe type proc (rw,nosuid,nodev,noexec,relatime)\nproc on /run/netns/qdhcp-24bc3aca-55a9-4e79-9eb7-84ab43f9c329 type proc (rw,nosuid,nodev,noexec,relatime)\nproc on /run/netns/qdhcp-9f725213-952d-482b-91c1-dfdbf6a8bb12 type proc (rw,nosuid,nodev,noexec,relatime)\nproc on /run/netns/qdhcp-6c31f880-5599-4a14-b9ed-f9b859fc4968 type proc (rw,nosuid,nodev,noexec,relatime)\nproc on /run/netns/qdhcp-24ced4a6-de3c-41b4-9308-1201f6eddd7f type proc (rw,nosuid,nodev,noexec,relatime)\n....\n\nhzwangpan@10-120-120-32:/data/log/nova$ mount | grep -c netns\n864", 
            "date_created": "2014-05-21 03:04:47.257180+00:00", 
            "author": "https://api.launchpad.net/1.0/~hzwangpan"
        }, 
        {
            "content": "\nThis is an automated cleanup. This bug report has been closed because it\nis older than 18 months and there is no open code change to fix this.\nAfter this time it is unlikely that the circumstances which lead to\nthe observed issue can be reproduced.\n\nIf you can reproduce the bug, please:\n* reopen the bug report (set to status \"New\")\n* AND add the detailed steps to reproduce the issue (if applicable)\n* AND leave a comment \"CONFIRMED FOR: <RELEASE_NAME>\"\n  Only still supported release names are valid (LIBERTY, MITAKA, OCATA, NEWTON).\n  Valid example: CONFIRMED FOR: LIBERTY\n", 
            "date_created": "2016-07-05 09:41:08.143381+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }
    ]
}