{
    "status": "Invalid", 
    "last_updated": "2015-01-15 19:38:18.388632+00:00", 
    "description": "logstash query:   message:\"cgroup\\: No space left on device\" AND filename:logs*screen-n-cpu.txt\n\nhttp://logs.openstack.org/12/80412/8/check/check-tempest-dsvm-postgres-full/f9f6158/logs/screen-n-cpu.txt.gz?level=TRACE#_2014-03-21_17_45_12_490\n\n\nERROR nova.compute.manager [req-630b71d6-0fbe-4e9e-99fe-019da7d29a3a FixedIPsNegativeTestJson-475659359 FixedIPsNegativeTestJson-265680949] [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] Error: internal error unable to add domain instance-00000002 task 3057 to cgroup: No space left on device\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] Traceback (most recent call last):\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1304, in _build_instance\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     set_access_ip=set_access_ip)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 394, in decorated_function\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     return function(self, context, *args, **kwargs)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1716, in _spawn\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     LOG.exception(_('Instance failed to spawn'), instance=instance)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     six.reraise(self.type_, self.value, self.tb)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1713, in _spawn\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     block_device_info)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 2241, in spawn\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     block_device_info)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3621, in _create_domain_and_network\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     power_on=power_on)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3531, in _create_domain\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     domain.XMLDesc(0))\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     six.reraise(self.type_, self.value, self.tb)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3526, in _create_domain\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     domain.createWithFlags(launch_flags)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 179, in doit\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 139, in proxy_call\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     rv = execute(f,*args,**kwargs)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 77, in tworker\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     rv = meth(*args,**kwargs)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 581, in createWithFlags\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] libvirtError: internal error unable to add domain instance-00000002 task 3057 to cgroup: No space left on device\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] \n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] Traceback (most recent call last):\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1184, in _run_instance\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     instance, image_meta, legacy_bdm_in_spec)\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1354, in _build_instance\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     reason=unicode(exc_info[1]))\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] RescheduledException: Build of instance 3f281136-ed69-4bfb-bf36-a7d4aa1c0640 was re-scheduled: internal error unable to add domain instance-00000002 task 3057 to cgroup: No space left on device\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] \n\n\nThis started right around the time we started using: https://review.openstack.org/#/c/79816/ (serge's libvirt fix for https://bugs.launchpad.net/nova/+bug/1254872)", 
    "tags": [
        "libvirt", 
        "testing"
    ], 
    "importance": "Medium", 
    "heat": 14, 
    "link": "https://bugs.launchpad.net/nova/+bug/1295876", 
    "owner": "None", 
    "id": 1295876, 
    "index": 3843, 
    "created": "2014-03-21 22:41:51.568861+00:00", 
    "title": " libvirtError: internal error unable to add domain xxx to cgroup: No space left on device", 
    "comments": [
        {
            "content": "logstash query:   message:\"cgroup\\: No space left on device\" AND filename:logs*screen-n-cpu.txt\n\nhttp://logs.openstack.org/12/80412/8/check/check-tempest-dsvm-postgres-full/f9f6158/logs/screen-n-cpu.txt.gz?level=TRACE#_2014-03-21_17_45_12_490\n\n\nERROR nova.compute.manager [req-630b71d6-0fbe-4e9e-99fe-019da7d29a3a FixedIPsNegativeTestJson-475659359 FixedIPsNegativeTestJson-265680949] [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] Error: internal error unable to add domain instance-00000002 task 3057 to cgroup: No space left on device\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] Traceback (most recent call last):\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1304, in _build_instance\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     set_access_ip=set_access_ip)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 394, in decorated_function\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     return function(self, context, *args, **kwargs)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1716, in _spawn\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     LOG.exception(_('Instance failed to spawn'), instance=instance)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     six.reraise(self.type_, self.value, self.tb)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1713, in _spawn\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     block_device_info)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 2241, in spawn\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     block_device_info)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3621, in _create_domain_and_network\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     power_on=power_on)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3531, in _create_domain\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     domain.XMLDesc(0))\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     six.reraise(self.type_, self.value, self.tb)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3526, in _create_domain\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     domain.createWithFlags(launch_flags)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 179, in doit\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 139, in proxy_call\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     rv = execute(f,*args,**kwargs)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 77, in tworker\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     rv = meth(*args,**kwargs)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 581, in createWithFlags\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] libvirtError: internal error unable to add domain instance-00000002 task 3057 to cgroup: No space left on device\n26028 TRACE nova.compute.manager [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] \n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] Traceback (most recent call last):\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1184, in _run_instance\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     instance, image_meta, legacy_bdm_in_spec)\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 1354, in _build_instance\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640]     reason=unicode(exc_info[1]))\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] RescheduledException: Build of instance 3f281136-ed69-4bfb-bf36-a7d4aa1c0640 was re-scheduled: internal error unable to add domain instance-00000002 task 3057 to cgroup: No space left on device\n26028 TRACE nova.compute.utils [instance: 3f281136-ed69-4bfb-bf36-a7d4aa1c0640] \n\n\nThis started right around the time we started using: https://review.openstack.org/#/c/79816/ (serge's libvirt fix for https://bugs.launchpad.net/nova/+bug/1254872)", 
            "date_created": "2014-03-21 22:41:51.568861+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "We have seen 10 hits in last 12 hours  across all jobs, so this bug appears to be less frequent then  https://bugs.launchpad.net/nova/+bug/1254872 was", 
            "date_created": "2014-03-21 22:50:36.565707+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "ENOSPC is what you get when you try to move a task into a cpuset which has an uninitialized cpuset.cpus or cpuset.mems.  This will happen if cgroup.clone_children is unset and libvirt does not set those values itself.\n\nPlease try ensuring that something does echo 1 > /sys/fs/cgroup/cpuset/cgroup.clone_children at boot and see if that helps.", 
            "date_created": "2014-03-21 23:53:31.016654+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Hm, looking at the code in libvirt which sets up the inheritence of those values, there seems to be no way there could be a race.\n\nIs there any way to get log output with log_level=1 in /etc/libvirt/libvirtd.conf?  (I realize that's probably not convenient, and it also may end up masking whatever is going on)\n", 
            "date_created": "2014-03-22 00:34:04.207053+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "This makes me nervous, this merged on 3/20 and logstash shows that's when this started failing:\n\nhttps://review.openstack.org/77593", 
            "date_created": "2014-03-22 03:39:29.332759+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "This also merged on 3/20 and deals with vcpus, which looks bad given what Serge said, but the change looks pretty tame:\n\nhttps://review.openstack.org/#/c/73548/\n\nThe logic seems OK to me.", 
            "date_created": "2014-03-22 03:42:42.290442+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Serge, you mentioned we should set the cgroups at boot, so does that mean this won't work: https://review.openstack.org/#/c/82630/", 
            "date_created": "2014-03-24 23:19:18.073698+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Quoting Joe Gordon (<email address hidden>):\n> Serge, you mentioned we should set the cgroups at boot, so does that\n> mean this won't work: https://review.openstack.org/#/c/82630/\n\nHi Joe - yes, this *definately* should work.  However it's a workaround\nand *should* not be needed, and given the mysterious nature of the\ncurrent failure, it's quite possible that the root cause will go on to\ncause another symptom.\n", 
            "date_created": "2014-03-25 03:02:57+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "@Matt,\n\nyeah, regarding https://review.openstack.org/#/c/73548/14/nova/virt/libvirt/driver.py,unified - cursory glance suggests that get_vcpu_used() is just for reporting on vms, so shouldn't have anything to do with this bug. ", 
            "date_created": "2014-03-25 03:54:26.583892+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Status changed to 'Confirmed' because the bug affects multiple users.", 
            "date_created": "2014-03-26 19:36:53.320441+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }, 
        {
            "content": "It looks like this bug has returned in Gate yesterday April 22nd. http://status.openstack.org/elastic-recheck/", 
            "date_created": "2014-04-23 22:15:11.741307+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "@serge unfortunately we can't really set libvirt to that log level for a race bug, as that generations > 100MB of log per libvirt run. If there is a more targeted log filter we can look at it. ", 
            "date_created": "2014-04-23 22:48:11.643848+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "@sean: For cgroups, below are the specific filter variables to log debug level messages:\n\n    LIBVIRT_LOG_FILTERS=\"1:cgroup\"\n    LIBVIRT_LOG_OUTPUTS=1:file:/var//tmp/libvirt.log", 
            "date_created": "2014-05-29 09:36:10.754473+00:00", 
            "author": "https://api.launchpad.net/1.0/~kashyapc"
        }, 
        {
            "content": "no hits in a while looks like changing the version of libvirt fixed this", 
            "date_created": "2014-08-29 23:15:47.943019+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }
    ]
}