{
    "status": "Expired", 
    "last_updated": "2017-03-14 04:17:53.146559+00:00", 
    "description": "For every detached volume the nova-compute instance deletes all multipath devices from the host while detaching. This is working fine if the volumes are detached each by each, but not for multiple detachment.\nNova-compute always rescans the iscsi devices before it detaches them. The rescan reconnects all missing devices if the Volume is still available on the VNX. In the time between the iscsi devices are deleted and cinder-volume is actually detaching the volume on the vnx site, the iscsi connections will be always reconnected by any rescan. All detachments run into one thread on the host, so the detachment is done one by one. However the detachment on the cinder-volume site is done through multithreading and the nova-compute is not waiting between the detachments for cinder-volume to detach. So it can happen that the device is deleted and the next detachment of the next volume brings back the devices.\nThe next time a volume is attached to this VM on this host an error will occur. Or if this is working the the volume will stay in use until the VM is terminated. It is not possible to detach the volume again.\nAlso the information of the volume is not updated for the second detachment. The size stays the same also the new attachment is totally different.\n\n\n3600601604781340063b2b4293601e411 dm-2 DGC     ,VRAID\nsize=4.0G features='0' hwhandler='0' wp=rw\n|-+- policy='round-robin 0' prio=2 status=enabled\n| |- 7:0:0:3 sdr  65:16  failed ready  running\n| `- 6:0:0:3 sdq  65:0   failed ready  running\n`-+- policy='round-robin 0' prio=1 status=enabled\n  `- 9:0:0:3 sds  65:32  failed ready  running", 
    "tags": [
        "multipath", 
        "volumes"
    ], 
    "importance": "Undecided", 
    "heat": 48, 
    "link": "https://bugs.launchpad.net/nova/+bug/1336683", 
    "owner": "None", 
    "id": 1336683, 
    "index": 4964, 
    "created": "2014-07-02 08:41:19.131858+00:00", 
    "title": "Multipath device descriptor and iscsi device not deleted when detaching multiple volumes at the same time at the same host", 
    "comments": [
        {
            "content": "For every detached volume the nova-compute instance deletes all multipath devices from the host while detaching. This is working fine if the volumes are detached each by each, but not for multiple detachment.\nNova-compute always rescans the iscsi devices before it detaches them. The rescan reconnects all missing devices if the Volume is still available on the VNX. In the time between the iscsi devices are deleted and cinder-volume is actually detaching the volume on the vnx site, the iscsi connections will be always reconnected by any rescan. All detachments run into one thread on the host, so the detachment is done one by one. However the detachment on the cinder-volume site is done through multithreading and the nova-compute is not waiting between the detachments for cinder-volume to detach. So it can happen that the device is deleted and the next detachment of the next volume brings back the devices.\nThe next time a volume is attached to this VM on this host an error will occur. Or if this is working the the volume will stay in use until the VM is terminated. It is not possible to detach the volume again.\nAlso the information of the volume is not updated for the second detachment. The size stays the same also the new attachment is totally different.\n\n\n3600601604781340063b2b4293601e411 dm-2 DGC     ,VRAID\nsize=4.0G features='0' hwhandler='0' wp=rw\n|-+- policy='round-robin 0' prio=2 status=enabled\n| |- 7:0:0:3 sdr  65:16  failed ready  running\n| `- 6:0:0:3 sdq  65:0   failed ready  running\n`-+- policy='round-robin 0' prio=1 status=enabled\n  `- 9:0:0:3 sds  65:32  failed ready  running", 
            "date_created": "2014-07-02 08:41:19.131858+00:00", 
            "author": "https://api.launchpad.net/1.0/~nikolas-hermanns"
        }, 
        {
            "content": "Influenced functions:\ndef _detach_volume(self, context, instance, bdm): in nova/compute/manager.py\ndef _delete_mpath(self, iscsi_properties, multipath_device, ips_iqns): in nova/virtlibvirt/volume.py\nUsed backend: EMC VNX 5400\nOS: Windriver/Ubuntu\n", 
            "date_created": "2014-07-02 08:44:47.126817+00:00", 
            "author": "https://api.launchpad.net/1.0/~nikolas-hermanns"
        }, 
        {
            "content": "I've just run into this on Ubuntu 14.04 + Icehouse 2nd point release with the Storwize backend for cinder.", 
            "date_created": "2014-09-10 11:26:09.750707+00:00", 
            "author": "https://api.launchpad.net/1.0/~zoltan"
        }, 
        {
            "content": "It's even worse in some case, as I have the iSCSI mapped block devices lingering around even tho they don't exist anymore on the store thus anything touching them will hang.", 
            "date_created": "2014-09-10 12:04:27.736163+00:00", 
            "author": "https://api.launchpad.net/1.0/~zoltan"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/172341", 
            "date_created": "2015-04-10 08:47:54.101586+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Michael Still (<email address hidden>) on branch: master\nReview: https://review.openstack.org/172341\nReason: This patch is very old and appears to not be active any more. I am therefore abandoning it to keep the nova review queue sane. Feel free to restore the change when you're actively working on it again.", 
            "date_created": "2016-01-20 18:36:25.670343+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "\nThis is an automated cleanup. This bug report has been closed because it\nis older than 18 months and there is no open code change to fix this.\nAfter this time it is unlikely that the circumstances which lead to\nthe observed issue can be reproduced.\n\nIf you can reproduce the bug, please:\n* reopen the bug report (set to status \"New\")\n* AND add the detailed steps to reproduce the issue (if applicable)\n* AND leave a comment \"CONFIRMED FOR: <RELEASE_NAME>\"\n  Only still supported release names are valid (LIBERTY, MITAKA, OCATA, NEWTON).\n  Valid example: CONFIRMED FOR: LIBERTY\n", 
            "date_created": "2016-07-05 09:50:06.803332+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "Reopening after seeing this downstream against Kilo / OSP 7. This still looks possible in master so I'll reproduce early next week using the LVM/iSCSI volume backend with a sleep in terminate_connection to fake a slow volume backend such as the VNX.", 
            "date_created": "2016-07-23 10:36:43.227719+00:00", 
            "author": "https://api.launchpad.net/1.0/~lyarwood"
        }, 
        {
            "content": "Lee Yarwood, were you able to reproduce it?", 
            "date_created": "2016-08-16 04:29:18.565256+00:00", 
            "author": "https://api.launchpad.net/1.0/~mszankin"
        }, 
        {
            "content": "I've been unable to reproduce with or without the artificial slow down of the terminate_connection calls. That said we continue to see this against a customers VNX backend, using dm-multipath and queue_if_no_path enabled. I'll continue trying to reproduce so please leave this as `In Progress` for now.", 
            "date_created": "2016-08-17 09:02:19.892815+00:00", 
            "author": "https://api.launchpad.net/1.0/~lyarwood"
        }, 
        {
            "content": "[Expired for OpenStack Compute (nova) because there has been no activity for 60 days.]", 
            "date_created": "2017-03-14 04:17:49.514160+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ]
}