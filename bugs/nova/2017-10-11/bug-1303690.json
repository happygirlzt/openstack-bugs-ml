{
    "status": "Invalid", 
    "last_updated": "2015-04-23 15:13:32.218545+00:00", 
    "description": "I have block live migration configured in my environment (no shared storage) and it is very fast for instances which don't use volumes. An instance with 2.5G disk image takes ~40 seconds to migrate to different host.\nWhen I migrate instances which do use ceph backed volumes they take much longer and it depends on the volume size. For example migration of an instance with 1G volume takes around 1 minute, 10G ~8 minutes and with 50G I had to wait nearly 50 minutes for the process to complete. It completes without errors every time, it is just very slow.\n\nI was looking at the network traffic during migration and it looks a bit strange. Lets say I am migrating an instance with 50B volume from compute node A to compute node B and ceph is running on hosts X,Y and Z.\n\nI initiate live migration and as expected there is lots of traffic going from host A to B, this lasts less than 1 minute (disk image transfer). Then traffic from A to B goes down to ~200Mbit/s and stays at this level until migration is completed.\nAfter initial traffic burst between host A and B host B starts sending data to the ceph nodes X,Y and Z. I can see between 40 to 80Mbit/s of going from host B to each of the ceph nodes. This continues for ~50 minutes, then migration completes and networks traffic idles.\n\nEvery time I tried migration eventually completed fine but for instances with lets say 200G volume it could take nearly 4 hours to complete.\n\nI am using havana on precise.\n\nCompute nodes:\nii  nova-common                      1:2013.2.2-0ubuntu1~cloud0\nii  nova-compute                     1:2013.2.2-0ubuntu1~cloud0\nii  nova-compute-kvm                 1:2013.2.2-0ubuntu1~cloud0\n\nCeph:\nii  ceph                             0.67.4-0ubuntu2.2~cloud0\nii  ceph-common                      0.67.4-0ubuntu2.2~cloud0\nii  libcephfs1                       0.67.4-0ubuntu2.2~cloud0", 
    "tags": [
        "canonical-bootstack", 
        "canonical-is", 
        "ops"
    ], 
    "importance": "Medium", 
    "heat": 62, 
    "link": "https://bugs.launchpad.net/nova/+bug/1303690", 
    "owner": "https://api.launchpad.net/1.0/~tdurakov", 
    "id": 1303690, 
    "index": 3869, 
    "created": "2014-04-07 09:48:37.955875+00:00", 
    "title": "nova live-migration slow when using volumes", 
    "comments": [
        {
            "content": "I have block live migration configured in my environment (no shared storage) and it is very fast for instances which don't use volumes. An instance with 2.5G disk image takes ~40 seconds to migrate to different host.\nWhen I migrate instances which do use ceph backed volumes they take much longer and it depends on the volume size. For example migration of an instance with 1G volume takes around 1 minute, 10G ~8 minutes and with 50G I had to wait nearly 50 minutes for the process to complete. It completes without errors every time, it is just very slow.\n\nI was looking at the network traffic during migration and it looks a bit strange. Lets say I am migrating an instance with 50B volume from compute node A to compute node B and ceph is running on hosts X,Y and Z.\n\nI initiate live migration and as expected there is lots of traffic going from host A to B, this lasts less than 1 minute (disk image transfer). Then traffic from A to B goes down to ~200Mbit/s and stays at this level until migration is completed.\nAfter initial traffic burst between host A and B host B starts sending data to the ceph nodes X,Y and Z. I can see between 40 to 80Mbit/s of going from host B to each of the ceph nodes. This continues for ~50 minutes, then migration completes and networks traffic idles.\n\nEvery time I tried migration eventually completed fine but for instances with lets say 200G volume it could take nearly 4 hours to complete.\n\nI am using havana on precise.\n\nCompute nodes:\nii  nova-common                      1:2013.2.2-0ubuntu1~cloud0\nii  nova-compute                     1:2013.2.2-0ubuntu1~cloud0\nii  nova-compute-kvm                 1:2013.2.2-0ubuntu1~cloud0\n\nCeph:\nii  ceph                             0.67.4-0ubuntu2.2~cloud0\nii  ceph-common                      0.67.4-0ubuntu2.2~cloud0\nii  libcephfs1                       0.67.4-0ubuntu2.2~cloud0", 
            "date_created": "2014-04-07 09:48:37.955875+00:00", 
            "author": "https://api.launchpad.net/1.0/~jacekn"
        }, 
        {
            "content": "I can confirm similar behavior in slightly different scenario (regular iscsi cinder volumes instead of ceph backed ones).\nData from attached volume is being block-migrated just like qcow file between source and destination host. And because this is a iscsi volume from another server the data flow is:\ncinder-volume-host -> compute-node-source -> compute-node-dest -> cinder-volume-host\ntoday I tried with version 2013.2.3 - still the same.\nI'm also running havana on precise.", 
            "date_created": "2014-05-22 20:50:50.602067+00:00", 
            "author": "https://api.launchpad.net/1.0/~kswia"
        }, 
        {
            "content": "I can confirm this scenario creates insane amount of traffic between \n- source host (on which VM resides)\n- destination host\n- host from migrated VM has volume attached\n\nThe same setup: havana with precise", 
            "date_created": "2014-05-23 00:01:59.833483+00:00", 
            "author": "https://api.launchpad.net/1.0/~tzn"
        }, 
        {
            "content": "Also seen in icehouse on trusty, with ceph volumes.  After 24+ hours with a 900G volume instance is still migrating.", 
            "date_created": "2015-01-23 22:56:41.869061+00:00", 
            "author": "https://api.launchpad.net/1.0/~jillrouleau"
        }, 
        {
            "content": "moved bug to 'Invalid' state. \nHere is bug https://bugs.launchpad.net/nova/+bug/1398999 the closes this functionality in nova.\nPatch from it proposed to stable/juno", 
            "date_created": "2015-04-23 15:13:22.445597+00:00", 
            "author": "https://api.launchpad.net/1.0/~tdurakov"
        }
    ]
}