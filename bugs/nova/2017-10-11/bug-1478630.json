{
    "status": "Invalid", 
    "last_updated": "2015-09-23 14:10:52.184213+00:00", 
    "description": "vi /var/log/nova-all.log\n<180>Jul 27 10:15:33 node-1 nova-compute Auditing locally available compute resources\n<179>Jul 27 10:15:33 node-1 nova-compute Error during ComputeManager.update_available_resource: [Errno 24] Too many open files\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task Traceback (most recent call last):\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/periodic_task.py\", line 198, in run_periodic_tasks\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     task(self, context)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 5963, in update_available_resource\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     rt.update_available_resource(context)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/compute/resource_tracker.py\", line 313, in update_available_resource\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     resources = self.driver.get_available_resource(self.nodename)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4939, in get_available_resource\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     stats = self.get_host_stats(refresh=True)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5809, in get_host_stats\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     return self.host_state.get_host_stats(refresh=refresh)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6383, in get_host_stats\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     self.update_status()\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6406, in update_status\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     disk_info_dict = self.driver._get_local_gb_info()\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4552, in _get_local_gb_info\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     info = LibvirtDriver._get_rbd_driver().get_pool_info()\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/rbd_utils.py\", line 273, in get_pool_info\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     with RADOSClient(self) as client:\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/rbd_utils.py\", line 86, in __init__\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     self.cluster, self.ioctx = driver._connect_to_rados(pool)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/rbd_utils.py\", line 108, in _connect_to_rados\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     conffile=self.ceph_conf)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/rados.py\", line 198, in __init__\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     librados_path = find_library('rados')\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/ctypes/util.py\", line 224, in find_library\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     return _findSoname_ldconfig(name) or _get_soname(_findLib_gcc(name))\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/ctypes/util.py\", line 213, in _findSoname_ldconfig\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     f = os.popen('/sbin/ldconfig -p 2>/dev/null')\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task OSError: [Errno 24] Too many open files\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task\n\n\nCurrent limit setting:\nroot@node-1:/tmp# ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 386140\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 1024\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 386140\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\nroot@node-1:/tmp# ulimit -n\n1024", 
    "tags": [], 
    "importance": "Undecided", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1478630", 
    "owner": "None", 
    "id": 1478630, 
    "index": 5667, 
    "created": "2015-07-27 16:21:01.674314+00:00", 
    "title": "nova-compute was forced down due to '[Errno 24] too many open files'", 
    "comments": [
        {
            "content": "vi /var/log/nova-all.log\n<180>Jul 27 10:15:33 node-1 nova-compute Auditing locally available compute resources\n<179>Jul 27 10:15:33 node-1 nova-compute Error during ComputeManager.update_available_resource: [Errno 24] Too many open files\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task Traceback (most recent call last):\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/periodic_task.py\", line 198, in run_periodic_tasks\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     task(self, context)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 5963, in update_available_resource\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     rt.update_available_resource(context)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/compute/resource_tracker.py\", line 313, in update_available_resource\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     resources = self.driver.get_available_resource(self.nodename)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4939, in get_available_resource\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     stats = self.get_host_stats(refresh=True)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5809, in get_host_stats\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     return self.host_state.get_host_stats(refresh=refresh)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6383, in get_host_stats\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     self.update_status()\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6406, in update_status\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     disk_info_dict = self.driver._get_local_gb_info()\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4552, in _get_local_gb_info\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     info = LibvirtDriver._get_rbd_driver().get_pool_info()\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/rbd_utils.py\", line 273, in get_pool_info\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     with RADOSClient(self) as client:\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/rbd_utils.py\", line 86, in __init__\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     self.cluster, self.ioctx = driver._connect_to_rados(pool)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/rbd_utils.py\", line 108, in _connect_to_rados\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     conffile=self.ceph_conf)\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/dist-packages/rados.py\", line 198, in __init__\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     librados_path = find_library('rados')\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/ctypes/util.py\", line 224, in find_library\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     return _findSoname_ldconfig(name) or _get_soname(_findLib_gcc(name))\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task   File \"/usr/lib/python2.7/ctypes/util.py\", line 213, in _findSoname_ldconfig\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task     f = os.popen('/sbin/ldconfig -p 2>/dev/null')\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task OSError: [Errno 24] Too many open files\n2015-07-27 10:15:33.401 12422 TRACE nova.openstack.common.periodic_task\n\n\nCurrent limit setting:\nroot@node-1:/tmp# ulimit -a\ncore file size          (blocks, -c) 0\ndata seg size           (kbytes, -d) unlimited\nscheduling priority             (-e) 0\nfile size               (blocks, -f) unlimited\npending signals                 (-i) 386140\nmax locked memory       (kbytes, -l) 64\nmax memory size         (kbytes, -m) unlimited\nopen files                      (-n) 1024\npipe size            (512 bytes, -p) 8\nPOSIX message queues     (bytes, -q) 819200\nreal-time priority              (-r) 0\nstack size              (kbytes, -s) 8192\ncpu time               (seconds, -t) unlimited\nmax user processes              (-u) 386140\nvirtual memory          (kbytes, -v) unlimited\nfile locks                      (-x) unlimited\nroot@node-1:/tmp# ulimit -n\n1024", 
            "date_created": "2015-07-27 16:21:01.674314+00:00", 
            "author": "https://api.launchpad.net/1.0/~yichengli"
        }, 
        {
            "content": "root@node-1:/tmp# ps aux | grep nova-compute\nroot      6077  0.0  0.0   6508   624 pts/1    R+   16:23   0:00 grep --color=auto nova-compute\nnova      8119  2.6  0.2 2181460 104976 ?      Ssl  10:29   9:28 /usr/bin/python /usr/bin/nova-compute --config-file=/etc/nova/nova.conf --config-file=/etc/nova/nova-compute.conf\nroot@node-1:/tmp# cat /proc/8119/limits\nLimit                     Soft Limit           Hard Limit           Units     \nMax cpu time              unlimited            unlimited            seconds   \nMax file size             unlimited            unlimited            bytes     \nMax data size             unlimited            unlimited            bytes     \nMax stack size            8388608              unlimited            bytes     \nMax core file size        0                    unlimited            bytes     \nMax resident set          unlimited            unlimited            bytes     \nMax processes             386140               386140               processes \nMax open files            1024                 4096                 files     \nMax locked memory         65536                65536                bytes     \nMax address space         unlimited            unlimited            bytes     \nMax file locks            unlimited            unlimited            locks     \nMax pending signals       386140               386140               signals   \nMax msgqueue size         819200               819200               bytes     \nMax nice priority         0                    0                    \nMax realtime priority     0                    0                    \nMax realtime timeout      unlimited            unlimited            us ", 
            "date_created": "2015-07-27 16:24:44.054311+00:00", 
            "author": "https://api.launchpad.net/1.0/~yichengli"
        }, 
        {
            "content": "@JohnsonYi:\n\nCould you describe more in detail which steps you've executed before this issue happened? Can this be reproduced?", 
            "date_created": "2015-07-28 14:31:09.866482+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "@Markus:\n\nYep, it happened about 2 times/day Please check the details below,\n\nEnv:\nMOS 6.0(Openstack juno 2014.2)\n3 controller, 2 compute, 3 ceph\n(oslo.messaging was updated from MOS6.1 oslo.messaging 1.4.1)\n\nBut I found that the ceph.conf for one controller node has configuration mistake (with incorrect mgmt&storage ip/copied from another node), after revise the ceph.config, I didn't find any errors like \"[Errno 24] Too many open files\" so far.\n\nIt's not a real bug maybe.\n\n", 
            "date_created": "2015-07-30 01:43:46.068214+00:00", 
            "author": "https://api.launchpad.net/1.0/~yichengli"
        }, 
        {
            "content": "Assuming you haven't seen any more of these since changing your ceph config, lets close this one as invalid. ", 
            "date_created": "2015-09-23 14:10:51.740910+00:00", 
            "author": "https://api.launchpad.net/1.0/~mjdoffma"
        }
    ]
}