{
    "status": "In Progress", 
    "last_updated": "2017-09-28 17:40:52.860397+00:00", 
    "description": "Seeing this in Tempest runs on master (pike):\n\nhttp://logs.openstack.org/24/471024/2/check/gate-tempest-dsvm-neutron-linuxbridge-ubuntu-xenial/6b98d38/logs/screen-n-cpu.txt.gz?level=TRACE#_Jun_06_02_16_02_855503\n\nJun 06 02:16:02.855503 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: WARNING nova.compute.manager [None req-b4a50024-a2fd-4279-b284-340d2074f1c1 tempest-TestNetworkBasicOps-1479445685 tempest-TestNetworkBasicOps-1479445685] [instance: 2668bcb9-b13d-4b5b-8ee5-edbdee3b15a8] Detach interface failed, port_id=3843caa3-ab04-45f1-94d8-f330390e40fe, reason: Device detach failed for fa:16:3e:ab:e3:3f: Unable to detach from guest transient domain.: DeviceDetachFailed: Device detach failed for fa:16:3e:ab:e3:3f: Unable to detach from guest transient domain.\nJun 06 02:16:02.884007 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server [None req-b4a50024-a2fd-4279-b284-340d2074f1c1 tempest-TestNetworkBasicOps-1479445685 tempest-TestNetworkBasicOps-1479445685] Exception during message handling: InterfaceDetachFailed: Failed to detach network adapter device from 2668bcb9-b13d-4b5b-8ee5-edbdee3b15a8\nJun 06 02:16:02.884180 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server Traceback (most recent call last):\nJun 06 02:16:02.884286 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/server.py\", line 157, in _process_incoming\nJun 06 02:16:02.884395 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)\nJun 06 02:16:02.884538 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 213, in dispatch\nJun 06 02:16:02.884669 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)\nJun 06 02:16:02.884777 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 183, in _do_dispatch\nJun 06 02:16:02.884869 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)\nJun 06 02:16:02.884968 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/exception_wrapper.py\", line 77, in wrapped\nJun 06 02:16:02.885069 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     function_name, call_dict, binary)\nJun 06 02:16:02.885171 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\nJun 06 02:16:02.885272 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     self.force_reraise()\nJun 06 02:16:02.885367 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\nJun 06 02:16:02.885461 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\nJun 06 02:16:02.885554 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/exception_wrapper.py\", line 68, in wrapped\nJun 06 02:16:02.885649 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)\nJun 06 02:16:02.885755 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 214, in decorated_function\nJun 06 02:16:02.885856 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     kwargs['instance'], e, sys.exc_info())\nJun 06 02:16:02.885950 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\nJun 06 02:16:02.886053 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     self.force_reraise()\nJun 06 02:16:02.886143 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\nJun 06 02:16:02.886232 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\nJun 06 02:16:02.886322 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 202, in decorated_function\nJun 06 02:16:02.886415 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)\nJun 06 02:16:02.886505 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 5224, in detach_interface\nJun 06 02:16:02.886601 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)\nJun 06 02:16:02.886695 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server InterfaceDetachFailed: Failed to detach network adapter device from 2668bcb9-b13d-4b5b-8ee5-edbdee3b15a8\nJun 06 02:16:02.886794 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server \n\nThis probably started with: https://review.openstack.org/#/c/349014/ (merged 5/31)\n\nhttp://logstash.openstack.org/#/dashboard/file/logstash.json?query=message:%5C%22Detach%20interface%20failed%5C%22%20AND%20message:%5C%22reason:%20Device%20detach%20failed%20for%5C%22%20AND%20message:%5C%22Unable%20to%20detach%20from%20guest%20transient%20domain%5C%22%20AND%20tags:%5C%22screen-n-cpu.txt%5C%22&from=10d\n\nMight need something like this: https://review.openstack.org/#/c/441204/", 
    "tags": [
        "in-stable-newton", 
        "in-stable-ocata", 
        "libvirt", 
        "openstack-version.pike"
    ], 
    "importance": "High", 
    "heat": 28, 
    "link": "https://bugs.launchpad.net/nova/+bug/1696125", 
    "owner": "https://api.launchpad.net/1.0/~mriedem", 
    "id": 1696125, 
    "index": 2087, 
    "created": "2017-06-06 13:31:42.265516+00:00", 
    "title": "Detach interface failed - timeout waiting to detach tap device in linuxbridge job (pike)", 
    "comments": [
        {
            "content": "Seeing this in Tempest runs on master (pike):\n\nhttp://logs.openstack.org/24/471024/2/check/gate-tempest-dsvm-neutron-linuxbridge-ubuntu-xenial/6b98d38/logs/screen-n-cpu.txt.gz?level=TRACE#_Jun_06_02_16_02_855503\n\nJun 06 02:16:02.855503 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: WARNING nova.compute.manager [None req-b4a50024-a2fd-4279-b284-340d2074f1c1 tempest-TestNetworkBasicOps-1479445685 tempest-TestNetworkBasicOps-1479445685] [instance: 2668bcb9-b13d-4b5b-8ee5-edbdee3b15a8] Detach interface failed, port_id=3843caa3-ab04-45f1-94d8-f330390e40fe, reason: Device detach failed for fa:16:3e:ab:e3:3f: Unable to detach from guest transient domain.: DeviceDetachFailed: Device detach failed for fa:16:3e:ab:e3:3f: Unable to detach from guest transient domain.\nJun 06 02:16:02.884007 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server [None req-b4a50024-a2fd-4279-b284-340d2074f1c1 tempest-TestNetworkBasicOps-1479445685 tempest-TestNetworkBasicOps-1479445685] Exception during message handling: InterfaceDetachFailed: Failed to detach network adapter device from 2668bcb9-b13d-4b5b-8ee5-edbdee3b15a8\nJun 06 02:16:02.884180 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server Traceback (most recent call last):\nJun 06 02:16:02.884286 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/server.py\", line 157, in _process_incoming\nJun 06 02:16:02.884395 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)\nJun 06 02:16:02.884538 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 213, in dispatch\nJun 06 02:16:02.884669 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)\nJun 06 02:16:02.884777 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 183, in _do_dispatch\nJun 06 02:16:02.884869 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)\nJun 06 02:16:02.884968 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/exception_wrapper.py\", line 77, in wrapped\nJun 06 02:16:02.885069 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     function_name, call_dict, binary)\nJun 06 02:16:02.885171 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\nJun 06 02:16:02.885272 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     self.force_reraise()\nJun 06 02:16:02.885367 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\nJun 06 02:16:02.885461 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\nJun 06 02:16:02.885554 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/exception_wrapper.py\", line 68, in wrapped\nJun 06 02:16:02.885649 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)\nJun 06 02:16:02.885755 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 214, in decorated_function\nJun 06 02:16:02.885856 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     kwargs['instance'], e, sys.exc_info())\nJun 06 02:16:02.885950 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\nJun 06 02:16:02.886053 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     self.force_reraise()\nJun 06 02:16:02.886143 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\nJun 06 02:16:02.886232 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\nJun 06 02:16:02.886322 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 202, in decorated_function\nJun 06 02:16:02.886415 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)\nJun 06 02:16:02.886505 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 5224, in detach_interface\nJun 06 02:16:02.886601 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server     raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid)\nJun 06 02:16:02.886695 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server InterfaceDetachFailed: Failed to detach network adapter device from 2668bcb9-b13d-4b5b-8ee5-edbdee3b15a8\nJun 06 02:16:02.886794 ubuntu-xenial-ovh-bhs1-9149075 nova-compute[24118]: ERROR oslo_messaging.rpc.server \n\nThis probably started with: https://review.openstack.org/#/c/349014/ (merged 5/31)\n\nhttp://logstash.openstack.org/#/dashboard/file/logstash.json?query=message:%5C%22Detach%20interface%20failed%5C%22%20AND%20message:%5C%22reason:%20Device%20detach%20failed%20for%5C%22%20AND%20message:%5C%22Unable%20to%20detach%20from%20guest%20transient%20domain%5C%22%20AND%20tags:%5C%22screen-n-cpu.txt%5C%22&from=10d\n\nMight need something like this: https://review.openstack.org/#/c/441204/", 
            "date_created": "2017-06-06 13:31:42.265516+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Impacting CI runs so bumping to High severity.", 
            "date_created": "2017-06-06 16:59:17.652092+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "https://review.openstack.org/#/c/441204/ should address this.", 
            "date_created": "2017-06-06 18:34:33.557001+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/441204\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=563c0927d14d052e3f1fad80df95fe4a7c48d38b\nSubmitter: Jenkins\nBranch:    master\n\ncommit 563c0927d14d052e3f1fad80df95fe4a7c48d38b\nAuthor: Matt Riedemann <email address hidden>\nDate:   Tue Jun 6 14:08:37 2017 -0400\n\n    libvirt: Check if domain is persistent before detaching devices\n    \n    Previously the libvirt driver would always assume that it was only\n    detaching devices (volumes or virtual interfaces) from a persistent\n    domain however that is not always the case.\n    \n    For example when rolling back from a live migration an attempt is made\n    to detach volumes from the transient destination domain that is being\n    cleaned up. This attempt would fail with the previous assumption of the\n    domain being persistent in place.\n    \n    This change introduces a simple call to has_persistent_configuration\n    within detach_device_with_retry to confirm the state of the domain\n    before attempting to detach.\n    \n    Closes-Bug: #1669857\n    Closes-Bug: #1696125\n    Change-Id: I95948721a0119f5f54dbe50d4455fd47d422164b\n", 
            "date_created": "2017-06-07 21:44:23.824545+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/ocata\nReview: https://review.openstack.org/472309", 
            "date_created": "2017-06-08 16:08:20.483819+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/newton\nReview: https://review.openstack.org/472345", 
            "date_created": "2017-06-08 17:01:08.417126+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Apparently this is still failing on master even though the fix was merged:\n\nhttp://status.openstack.org/elastic-recheck/#1696125\n\nIt's pretty much all in the gate-tempest-dsvm-neutron-linuxbridge-ubuntu-xenial job and this test:\n\ntempest.scenario.test_network_basic_ops.TestNetworkBasicOps.test_hotplug_nic[compute,id-c5adff73-e961-41f1-b4a9-343614f18cfa,network]\n\nIhar pointed out this Neutron change for how linux bridge vifs are plugged:\n\nhttps://review.openstack.org/#/c/447150/\n\nMaybe there is something there with how nova thinks things are going to be down when unplugging the vif that is the wrong assumption? I'm not sure why libvirt is considering it a transient domain though.", 
            "date_created": "2017-06-08 17:43:16.226652+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "https://wiki.libvirt.org/page/VM_lifecycle#Transient_guest_domains_vs_Persistent_guest_domains", 
            "date_created": "2017-06-08 17:43:48.744762+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/472371", 
            "date_created": "2017-06-08 18:31:00.400344+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Neutron revert of the LB tap type change:\n\nhttps://review.openstack.org/#/c/472365/\n\nJust to see if that is part of the issue.", 
            "date_created": "2017-06-08 18:49:20.040540+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/472377", 
            "date_created": "2017-06-08 18:54:30.707953+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Running debug on the nova side using:\n\nhttps://review.openstack.org/#/c/471494/", 
            "date_created": "2017-06-08 18:56:49.254857+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 16.0.0.0b2 development milestone.", 
            "date_created": "2017-06-08 21:51:13.128688+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/472371\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=fabfb347f51afbe9064a6d0061404316786140cb\nSubmitter: Jenkins\nBranch:    master\n\ncommit fabfb347f51afbe9064a6d0061404316786140cb\nAuthor: Matt Riedemann <email address hidden>\nDate:   Thu Jun 8 14:28:50 2017 -0400\n\n    libvirt: fix alternative_device_name for detaching interfaces\n    \n    There are two changes here:\n    \n    1. Get the actual vif device name for logging, e.g. tap3e81295f-c1\n    2. Log that in detach_device_with_retry so we're not logging an\n       LibvirtConfigGuestInterface object.\n    \n    Change-Id: I7588c17a9936eb765269c662cad4cbedc5f58fbf\n    Related-Bug: #1696125\n", 
            "date_created": "2017-06-12 07:46:42.258066+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Got a hit in the neutron debug patch:\n\nhttp://logs.openstack.org/94/471494/2/check/gate-tempest-dsvm-neutron-linuxbridge-ubuntu-xenial/e0332b9/logs/screen-n-cpu.txt.gz#_Jun_12_22_21_12_373317\n\nhttp://paste.openstack.org/show/612460/\n\nSo when this fails, we're looking for this:\n\n<interface type=\"ethernet\">\n  <mac address=\"fa:16:3e:3b:f6:dc\"/>\n  <model type=\"virtio\"/>\n  <driver name=\"qemu\"/>\n  <target dev=\"tapb2bdb0c0-62\"/>\n</interface>\n\nAnd within the guest I see:\n\n<interface type='ethernet'>\n  <mac address='fa:16:3e:3b:f6:dc'/>\n  <target dev='tapb2bdb0c0-62'/>\n  <model type='virtio'/>\n  <driver name='qemu'/>\n  <alias name='net1'/>\n  <address type='pci' domain='0x0000' bus='0x00' slot='0x06' function='0x0'/>\n</interface>\n\nThis is what it's comparing against:\n\nhttps://github.com/openstack/nova/blob/a2dd78580ec5bcc7a73924cde46a53afe2c09348/nova/virt/libvirt/guest.py#L251-L255\n\nif (interface.mac_addr == cfg.mac_addr and\n       interface.net_type == cfg.net_type and\n       interface.source_dev == cfg.source_dev and\n       interface.target_dev == cfg.target_dev and\n       interface.vhostuser_path == cfg.vhostuser_path):\nreturn interface\n\nWhich is going to match on net_type, mac_addr and target_dev since source_dev and vhostuser_path are both None.", 
            "date_created": "2017-06-13 19:30:26.342129+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "This is the qemu guest log but there isn't much there:\n\nhttp://logs.openstack.org/94/471494/2/check/gate-tempest-dsvm-neutron-linuxbridge-ubuntu-xenial/e0332b9/logs/libvirt/qemu/instance-00000077.txt.gz", 
            "date_created": "2017-06-13 19:36:24.491019+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Looking at the libvirtd logs, I see the net1 device being added shortly before the detach:\n\n2017-06-12 22:19:28.525+0000: 30400: debug : virThreadJobSet:96 : Thread 30400 (virNetServerHandleJob) is now running job remoteDispatchDomainAttachDeviceFlags\n...\n2017-06-12 22:19:28.623+0000: 30400: debug : virDomainPCIAddressGetNextSlot:761 : PCI slot 0000:00:01 already in use\n2017-06-12 22:19:28.623+0000: 30400: debug : virDomainPCIAddressGetNextSlot:761 : PCI slot 0000:00:02 already in use\n2017-06-12 22:19:28.623+0000: 30400: debug : virDomainPCIAddressGetNextSlot:761 : PCI slot 0000:00:03 already in use\n2017-06-12 22:19:28.623+0000: 30400: debug : virDomainPCIAddressGetNextSlot:761 : PCI slot 0000:00:04 already in use\n2017-06-12 22:19:28.623+0000: 30400: debug : virDomainPCIAddressGetNextSlot:761 : PCI slot 0000:00:05 already in use\n2017-06-12 22:19:28.623+0000: 30400: debug : virDomainPCIAddressGetNextSlot:810 : Found free PCI slot 0000:00:06\n2017-06-12 22:19:28.623+0000: 30400: debug : virDomainPCIAddressReserveAddr:574 : Reserving PCI slot 0000:00:06.0 (multifunction='off')\n...\n2017-06-12 22:19:28.625+0000: 30400: debug : qemuMonitorAddDeviceWithFd:3063 : device=virtio-net-pci,netdev=hostnet1,id=net1,mac=fa:16:3e:3b:f6:dc,bus=pci.0,addr=0x6 fd=-1 fdname=<null>\n...\n2017-06-12 22:19:28.625+0000: 30400: debug : qemuMonitorJSONCommandWithFd:296 : Send command '{\"execute\":\"device_add\",\"arguments\":{\"driver\":\"virtio-net-pci\",\"netdev\":\"hostnet1\",\"id\":\"net1\",\"mac\":\"fa:16:3e:3b:f6:dc\",\"bus\":\"pci.0\",\"addr\":\"0x6\"},\"id\":\"libvirt-19\"}' for write with FD -1\n\n--\n\nThen we start detaching here:\n\n2017-06-12 22:19:31.201+0000: 30402: debug : virThreadJobSet:96 : Thread 30402 (virNetServerHandleJob) is now running job remoteDispatchDomainDetachDeviceFlags\n2017-06-12 22:19:31.201+0000: 30402: debug : qemuDomainObjBeginJobInternal:3268 : Starting job: modify (vm=0x7fa8cc003350 name=instance-00000077, current job=none async=none)\n...\n2017-06-12 22:19:31.246+0000: 30402: debug : qemuMonitorJSONCommandWithFd:296 : Send command '{\"execute\":\"device_del\",\"arguments\":{\"id\":\"net1\"},\"id\":\"libvirt-21\"}' for write with FD -1\n...\n2017-06-12 22:19:36.250+0000: 30402: debug : virThreadJobClear:121 : Thread 30402 (virNetServerHandleJob) finished job remoteDispatchDomainDetachDeviceFlags with ret=0\n\nAnd then right after that there is a another detach job it looks like:\n\n2017-06-12 22:19:36.255+0000: 30401: debug : virThreadJobSet:96 : Thread 30401 (virNetServerHandleJob) is now running job remoteDispatchDomainDetachDeviceFlags\n2017-06-12 22:19:36.255+0000: 30401: debug : qemuDomainObjBeginJobInternal:3268 : Starting job: modify (vm=0x7fa8cc003350 name=instance-00000077, current job=none async=none)\n2017-06-12 22:19:36.255+0000: 30401: debug : qemuDomainObjBeginJobInternal:3309 : Started job: modify (async=none vm=0x7fa8cc003350 name=instance-00000077)\n...\n2017-06-12 22:19:36.257+0000: 30401: debug : qemuMonitorJSONCommandWithFd:296 : Send command '{\"execute\":\"device_del\",\"arguments\":{\"id\":\"net1\"},\"id\":\"libvirt-23\"}' for write with FD -1\n\nThat could be from when we start the retry loop doing detaches on what we think is the transient domain.\n\nEventually I finally see this:\n\n2017-06-12 22:24:17.842+0000: 30399: debug : qemuProcessHandleDeviceDeleted:1351 : Device net1 removed from domain 0x7fa8cc003350 instance-00000077\n...\n2017-06-12 22:24:17.842+0000: 1366: debug : processDeviceDeletedEvent:4074 : Removing device net1 from domain 0x7fa8cc003350 instance-00000077\n...\n2017-06-12 22:24:17.842+0000: 1366: debug : qemuDomainRemoveNetDevice:3844 : Removing network interface net1 from domain 0x7fa8cc003350 instance-00000077\n\nShortly after that, the destroy command comes in to shutdown and destroy the guest:\n\n2017-06-12 22:24:33.335+0000: 30402: debug : qemuDomainObjBeginJobInternal:3268 : Starting job: destroy (vm=0x7fa8cc003350 name=instance-00000077, current job=none async=none)\n\nSo before that, it looks like it took ~5 seconds for the net1 device to be removed. And we timed out our retry loop at 22:21:12.373317.\n\nOur initial detach from nova was at:\n\nJun 12 22:19:31.200463 ubuntu-xenial-internap-mtl01-9270284 nova-compute[23597]: DEBUG nova.virt.libvirt.guest [None req-fd8ab969-7349-4740-89de-dd5621ee2154 tempest-TestNetworkBasicOps-1239760647 tempest-TestNetworkBasicOps-1239760647] Attempting initial detach for device tapb2bdb0c0-62 {{(pid=23597) detach_device_with_retry /opt/stack/new/nova/nova/virt/libvirt/guest.py:433}}\n\nWhich aligns with the libvirtd log:\n\n2017-06-12 22:19:31.201+0000: 30402: debug : virThreadJobSet:96 : Thread 30402 (virNetServerHandleJob) is now running job remoteDispatchDomainDetachDeviceFlags\n\nAnd net1 isn't removed until 2017-06-12 22:24:17.842+0000, but we timed out at:\n\nJun 12 22:21:12.373317 ubuntu-xenial-internap-mtl01-9270284 nova-compute[23597]: WARNING nova.virt.libvirt.driver [None req-fd8ab969-7349-4740-89de-dd5621ee2154 tempest-TestNetworkBasicOps-1239760647 tempest-TestNetworkBasicOps-1239760647] [instance: fb351e95-745f-4c40-bb58-d122353e35f4] Failed to detach interface tapb2bdb0c0-62 after repeated attempts. Final interface xml:\n\nSo nova retried and waited for ~2 minutes, but it took ~5 minutes for the device to be gone.\n\nThis is the code nova is using:\n\nhttps://github.com/openstack/nova/blob/a2dd78580ec5bcc7a73924cde46a53afe2c09348/nova/virt/libvirt/guest.py#L374\n\nCalling the RetryDecorator:\n\nhttp://git.openstack.org/cgit/openstack/oslo.service/tree/oslo_service/loopingcall.py#n345\n\nLooking at that, it should retry 7 times with an incremental sleep starting at 2, so 2 + 4 + 6 + 8 + 10 + 12 + 14 = ~58 seconds total sleep time.\n\nSo it really looks to be a problem with the underlying type of device and/or something with libvirt/qemu that it takes so long for the device to actually be removed from the guest.", 
            "date_created": "2017-06-13 20:16:57.012558+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Looking in the neutron L2 agent logs, I see the tap device is attached/added here:\n\nhttp://logs.openstack.org/94/471494/2/check/gate-tempest-dsvm-neutron-linuxbridge-ubuntu-xenial/e0332b9/logs/screen-q-agt.txt.gz#_Jun_12_22_19_30_156456\n\nJun 12 22:19:30.156456 ubuntu-xenial-internap-mtl01-9270284 neutron-linuxbridge-agent[18735]: DEBUG neutron.plugins.ml2.drivers.agent._common_agent [None req-2b21118e-0da6-4c4a-a9d5-5d0e2cf4ccf8 None None] Port tapb2bdb0c0-62 added {{(pid=18735) _process_device_if_exists /opt/stack/new/neutron/neutron/plugins/ml2/drivers/agent/_common_agent.py:236}}\n...\nJun 12 22:19:30.240016 ubuntu-xenial-internap-mtl01-9270284 neutron-linuxbridge-agent[18735]: DEBUG neutron.plugins.ml2.drivers.linuxbridge.agent.linuxbridge_neutron_agent [None req-2b21118e-0da6-4c4a-a9d5-5d0e2cf4ccf8 None None] Adding device tapb2bdb0c0-62 to bridge brq8bb2148d-ee {{(pid=18735) _add_tap_interface /opt/stack/new/neutron/neutron/plugins/ml2/drivers/linuxbridge/agent/linuxbridge_neutron_agent.py:532}}\n\nThen it's removed here:\n\nJun 12 22:19:31.745781 ubuntu-xenial-internap-mtl01-9270284 neutron-linuxbridge-agent[18735]: DEBUG neutron.plugins.ml2.drivers.agent._common_agent [None req-2b21118e-0da6-4c4a-a9d5-5d0e2cf4ccf8 None None] Agent loop found changes! {'current': set(['tap3578cb80-7a', 'tape6c02d6c-e4', 'tap8b6dc92f-75', 'tapb7c1b8db-1e', 'tap999bcb19-81', 'tap839063fe-6d', 'tap3a6b0b5c-cb', 'tap14bcf3bb-af', 'tap0f5cf6b7-63']), 'timestamps': {'tap3578cb80-7a': 9, 'tape6c02d6c-e4': 483, 'tap8b6dc92f-75': 6, 'tapb7c1b8db-1e': 10, 'tap999bcb19-81': 478, 'tap839063fe-6d': 484, 'tap3a6b0b5c-cb': 480, 'tap14bcf3bb-af': 479, 'tap0f5cf6b7-63': 11}, 'removed': set(['tapb2bdb0c0-62']), 'added': set([]), 'updated': set([])} {{(pid=18735) daemon_loop /opt/stack/new/neutron/neutron/plugins/ml2/drivers/agent/_common_agent.py:452}}\n...\nJun 12 22:19:31.840782 ubuntu-xenial-internap-mtl01-9270284 neutron-linuxbridge-agent[18735]: INFO neutron.agent.securitygroups_rpc [None req-2b21118e-0da6-4c4a-a9d5-5d0e2cf4ccf8 None None] Remove device filter for set(['tapb2bdb0c0-62'])\n...\nJun 12 22:19:31.901327 ubuntu-xenial-internap-mtl01-9270284 neutron-linuxbridge-agent[18735]: INFO neutron.plugins.ml2.drivers.agent._common_agent [None req-2b21118e-0da6-4c4a-a9d5-5d0e2cf4ccf8 None None] Attachment tapb2bdb0c0-62 removed", 
            "date_created": "2017-06-13 20:34:38.289854+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "There is a weird 5 minute gap in the neutron L2 agent logs here:\n\nhttp://logs.openstack.org/94/471494/2/check/gate-tempest-dsvm-neutron-linuxbridge-ubuntu-xenial/e0332b9/logs/screen-q-agt.txt.gz#_Jun_12_22_24_33_893133\n\nJun 12 22:19:32.086692 ubuntu-xenial-internap-mtl01-9270284 neutron-linuxbridge-agent[18735]: DEBUG oslo_concurrency.lockutils [None req-2b21118e-0da6-4c4a-a9d5-5d0e2cf4ccf8 None None] Lock \"ebtables\" released by \"neutron.plugins.ml2.drivers.linuxbridge.agent.arp_protect.delete_arp_spoofing_protection\" :: held 0.033s {{(pid=18735) inner /usr/local/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py:282}}\nJun 12 22:24:33.893133 ubuntu-xenial-internap-mtl01-9270284 neutron-linuxbridge-agent[18735]: DEBUG neutron.plugins.ml2.drivers.agent._common_agent [None req-2b21118e-0da6-4c4a-a9d5-5d0e2cf4ccf8 None None] Agent loop found changes! {'current': set(['tap3578cb80-7a', 'tap8b6dc92f-75', 'tapb7c1b8db-1e', 'tap999bcb19-81', 'tap839063fe-6d', 'tap3a6b0b5c-cb', 'tap14bcf3bb-af', 'tap0f5cf6b7-63']), 'timestamps': {'tap3578cb80-7a': 9, 'tap8b6dc92f-75': 6, 'tapb7c1b8db-1e': 10, 'tap999bcb19-81': 478, 'tap839063fe-6d': 484, 'tap3a6b0b5c-cb': 480, 'tap14bcf3bb-af': 479, 'tap0f5cf6b7-63': 11}, 'removed': set(['tape6c02d6c-e4']), 'added': set([]), 'updated': set([])} {{(pid=18735) daemon_loop /opt/stack/new/neutron/neutron/plugins/ml2/drivers/agent/_common_agent.py:452}}", 
            "date_created": "2017-06-13 20:37:13.194575+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I also wonder if we could be hitting some weird apparmor issues or something, see:\n\nhttps://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1665698\n\nAnd https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1620407.", 
            "date_created": "2017-06-13 22:18:45.686037+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/472377\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=a4e51d5c69b9dced99db0b0d78ef8b784cb50960\nSubmitter: Jenkins\nBranch:    master\n\ncommit a4e51d5c69b9dced99db0b0d78ef8b784cb50960\nAuthor: Matt Riedemann <email address hidden>\nDate:   Thu Jun 8 14:52:08 2017 -0400\n\n    libvirt: dump debug info when interface detach times out\n    \n    The retry loop for detaching an interface is comparing the\n    list of LibvirtConfigGuestInterfaces in the guest to the\n    one we're trying to detach, so if we timeout waiting for\n    the device to be gone from the guest it would be helpful\n    to dump what is currently in the guest xml and the interface\n    device we're looking for to compare.\n    \n    Change-Id: Id20a53812dbb1f888d8debc964418e79dd3e0a30\n    Related-Bug: #1696125\n", 
            "date_created": "2017-06-13 23:06:45.966088+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "It seems vif_type='tap' is just broken with libvirt so it's not safe to use. There isn't anything we can do on the Neutron side to fix this other than suggest plugins not use that vif_type until a fix is found in libvirt.", 
            "date_created": "2017-06-19 10:47:40.984344+00:00", 
            "author": "https://api.launchpad.net/1.0/~kevinbenton"
        }, 
        {
            "content": "Automatically discovered version pike in description. If this is incorrect, please update the description to include 'nova version: ...'", 
            "date_created": "2017-06-27 16:04:15.185563+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "Related fix proposed to branch: stable/ocata\nReview: https://review.openstack.org/491843", 
            "date_created": "2017-08-08 16:04:58.693170+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: stable/newton\nReview: https://review.openstack.org/491844", 
            "date_created": "2017-08-08 16:09:51.313914+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/472309\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=55e2c851f15d68e7891f867cc5f32eece9a95034\nSubmitter: Jenkins\nBranch:    stable/ocata\n\ncommit 55e2c851f15d68e7891f867cc5f32eece9a95034\nAuthor: Lee Yarwood <email address hidden>\nDate:   Tue Jun 6 14:08:37 2017 -0400\n\n    libvirt: Check if domain is persistent before detaching devices\n    \n    Previously the libvirt driver would always assume that it was only\n    detaching devices (volumes or virtual interfaces) from a persistent\n    domain however that is not always the case.\n    \n    For example when rolling back from a live migration an attempt is made\n    to detach volumes from the transient destination domain that is being\n    cleaned up. This attempt would fail with the previous assumption of the\n    domain being persistent in place.\n    \n    This change introduces a simple call to has_persistent_configuration\n    within detach_device_with_retry to confirm the state of the domain\n    before attempting to detach.\n    \n    Closes-Bug: #1669857\n    Closes-Bug: #1696125\n    Change-Id: I95948721a0119f5f54dbe50d4455fd47d422164b\n    (cherry picked from commit 563c0927d14d052e3f1fad80df95fe4a7c48d38b)\n", 
            "date_created": "2017-08-13 01:42:35.932259+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/491843\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=c04c5d57cc41deacec53e18abe3ba93a1d5b5ccf\nSubmitter: Jenkins\nBranch:    stable/ocata\n\ncommit c04c5d57cc41deacec53e18abe3ba93a1d5b5ccf\nAuthor: Matt Riedemann <email address hidden>\nDate:   Thu Jun 8 14:28:50 2017 -0400\n\n    libvirt: fix alternative_device_name for detaching interfaces\n    \n    There are two changes here:\n    \n    1. Get the actual vif device name for logging, e.g. tap3e81295f-c1\n    2. Log that in detach_device_with_retry so we're not logging an\n       LibvirtConfigGuestInterface object.\n    \n    Change-Id: I7588c17a9936eb765269c662cad4cbedc5f58fbf\n    Related-Bug: #1696125\n    (cherry picked from commit fabfb347f51afbe9064a6d0061404316786140cb)\n", 
            "date_created": "2017-08-16 02:30:34.267122+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/472345\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=b2bafd09c3cde8cfd782a69aa8aa5dd53809d5bc\nSubmitter: Jenkins\nBranch:    stable/newton\n\ncommit b2bafd09c3cde8cfd782a69aa8aa5dd53809d5bc\nAuthor: Lee Yarwood <email address hidden>\nDate:   Tue Jun 6 14:08:37 2017 -0400\n\n    libvirt: Check if domain is persistent before detaching devices\n    \n    Previously the libvirt driver would always assume that it was only\n    detaching devices (volumes or virtual interfaces) from a persistent\n    domain however that is not always the case.\n    \n    For example when rolling back from a live migration an attempt is made\n    to detach volumes from the transient destination domain that is being\n    cleaned up. This attempt would fail with the previous assumption of the\n    domain being persistent in place.\n    \n    This change introduces a simple call to has_persistent_configuration\n    within detach_device_with_retry to confirm the state of the domain\n    before attempting to detach.\n    \n    Closes-Bug: #1669857\n    Closes-Bug: #1696125\n    Change-Id: I95948721a0119f5f54dbe50d4455fd47d422164b\n    (cherry picked from commit 563c0927d14d052e3f1fad80df95fe4a7c48d38b)\n    (cherry picked from commit 00b7b714b37dbbaac8a3570541ecc6b75ce3a77f)\n", 
            "date_created": "2017-08-16 08:48:48.746864+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/491844\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=2cf2b7ea6441c2eb73574a6e35ef10ae07550c6b\nSubmitter: Jenkins\nBranch:    stable/newton\n\ncommit 2cf2b7ea6441c2eb73574a6e35ef10ae07550c6b\nAuthor: Matt Riedemann <email address hidden>\nDate:   Thu Jun 8 14:28:50 2017 -0400\n\n    libvirt: fix alternative_device_name for detaching interfaces\n    \n    There are two changes here:\n    \n    1. Get the actual vif device name for logging, e.g. tap3e81295f-c1\n    2. Log that in detach_device_with_retry so we're not logging an\n       LibvirtConfigGuestInterface object.\n    \n    Change-Id: I7588c17a9936eb765269c662cad4cbedc5f58fbf\n    Related-Bug: #1696125\n    (cherry picked from commit fabfb347f51afbe9064a6d0061404316786140cb)\n    (cherry picked from commit c04c5d57cc41deacec53e18abe3ba93a1d5b5ccf)\n", 
            "date_created": "2017-08-16 19:53:24.592315+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 15.0.7 release.", 
            "date_created": "2017-08-22 11:39:06.297926+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 14.0.8 release.", 
            "date_created": "2017-08-28 09:55:00.119291+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "While debugging the LiveMigrationTest.test_iscsi_volume tempest test, I am seeing this in my local env as one of the causes of intermittent failures with this test. I can get this to fail maybe 2-3x a day. This is what I run to provoke it:\n\n$ tempest run --regex test_live_migration --concurrency=4\n\nI haven't seen it fail on a single threaded test, but it's hard to say since it fails so infrequently.\n\nThe failure in n-cpu.log is:\n\n2017-09-20 14:01:50.192 ^[[01;31mERROR oslo_messaging.rpc.server [^[[01;36mreq-6db9664a-4c6e-4d47-bffc-224b45b34eb0 ^[[00;36mtempest-LiveMigrationTest-1489892041 tempest-LiveMigrationTest-1489892041^[[01;31m] ^[[01;35m^[[01;31mException during message handling^[[00m: DeviceDetachFailed: Device detach failed for vdb: Unable to detach from guest transient domain.\n\nThe tempest error is:\n\n    tempest.lib.exceptions.TimeoutException: Request timed out\n    Details: volume 3194b6d9-cb70-4e67-8c28-ebf9ea094297 failed to reach ['available'] status (current in-use) within the required time (196 s).\n\nI am adding more debug code to help debug this.", 
            "date_created": "2017-09-21 12:45:32.320586+00:00", 
            "author": "https://api.launchpad.net/1.0/~steve-noyes"
        }, 
        {
            "content": "Version of nova:\n\n$ git show\ncommit e9daa28bae07fff7e617f03ef6b4956148db17f2\nMerge: c1de4c7 10f8a9a\nAuthor: Jenkins <email address hidden>\nDate:   Thu Aug 31 07:00:41 2017 +0000\n\n    Merge \"[placement] Require at least one resource class in allocation\"\n", 
            "date_created": "2017-09-21 12:46:07.462251+00:00", 
            "author": "https://api.launchpad.net/1.0/~steve-noyes"
        }, 
        {
            "content": "It doesn't look like a timeout issue. When the test is going to fail, you see these messages in the logs:\n\n2017-09-19 14:13:01.172 DEBUG oslo.service.loopingcall [-] Invoking nova.virt.libvirt.guest._do_wait_and_retry_detach; retry count is 6. from (pid=611) _func /usr/local/lib/python2.7/dist-packages/oslo_service/loopingcall.py:393\n...\n2017-09-19 14:13:23.765 DEBUG oslo.service.loopingcall [-] Invoking nova.virt.libvirt.guest._do_wait_and_retry_detach; retry count is 7. from (pid=611) _func /usr/local/lib/python2.7/dist-packages/oslo_service/loopingcall.py:393\n\nWhen the test passes, you don't see these messages, so if retries start happening, the detach will eventually fail.", 
            "date_created": "2017-09-21 15:10:10.005247+00:00", 
            "author": "https://api.launchpad.net/1.0/~steve-noyes"
        }, 
        {
            "content": "Something to know about detaching from a guest transient domain is that it's an asynchronous request to the guest OS [1], which the guest OS can choose to ignore (e.g. if it has a file open or is otherwise busy).\n\n\"Beware that depending on the hypervisor and device type, detaching a device from a running domain may be asynchronous. That is, calling virDomainDetachDeviceFlags may just request device removal while the device is actually removed later (in cooperation with a guest OS).\"\n\nSo it seems like what you're seeing is the guest OS ignoring the request to detach for some reason and Nova keeps retrying and eventually gives up. The retry simply requests the detach again and then checks for existence of the device. If the device remains, it tries again, until the max retry count is reached.\n\n[1] https://libvirt.org/html/libvirt-libvirt-domain.html#virDomainDetachDeviceFlags", 
            "date_created": "2017-09-21 19:46:54.149578+00:00", 
            "author": "https://api.launchpad.net/1.0/~melwitt"
        }, 
        {
            "content": "Thanks for the comment. In this case, that shouldn't be the case as I don't think the volume was ever mounted by the instance's OS. From what I've seen cirros doesn't automount volumes that get attached. And if it's not mounted, I can't think of anything that the OS would do to prevent it from be detached. But I certainly could be missing something...", 
            "date_created": "2017-09-28 17:40:49.815601+00:00", 
            "author": "https://api.launchpad.net/1.0/~steve-noyes"
        }
    ]
}