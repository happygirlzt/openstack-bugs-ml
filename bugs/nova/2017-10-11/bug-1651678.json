{
    "status": "Fix Released", 
    "last_updated": "2017-03-22 10:13:27.417114+00:00", 
    "description": "Ironic gate jobs are randomly timing out during last few weeks:\n\n\nAn example is: http://logs.openstack.org/46/327046/36/check/gate-tempest-dsvm-ironic-ipa-partition-pxe_ipmitool-tinyipa-ubuntu-xenial/48db3ea/console.html\n\n2016-12-20 23:30:24.418214 |     Traceback (most recent call last):\n2016-12-20 23:30:24.418231 |       File \"tempest/test.py\", line 99, in wrapper\n2016-12-20 23:30:24.418248 |         return f(self, *func_args, **func_kwargs)\n2016-12-20 23:30:24.418296 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/ironic_tempest_plugin/tests/scenario/test_baremetal_basic_ops.py\", line 111, in test_baremetal_server_ops\n2016-12-20 23:30:24.418316 |         self.instance, self.node = self.boot_instance()\n2016-12-20 23:30:24.418361 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/ironic_tempest_plugin/tests/scenario/baremetal_manager.py\", line 173, in boot_instance\n2016-12-20 23:30:24.418375 |         self.wait_node(instance['id'])\n2016-12-20 23:30:24.418417 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/ironic_tempest_plugin/tests/scenario/baremetal_manager.py\", line 117, in wait_node\n2016-12-20 23:30:24.418441 |         raise lib_exc.TimeoutException(msg)\n2016-12-20 23:30:24.418464 |     tempest.lib.exceptions.TimeoutException: Request timed out\n2016-12-20 23:30:24.418494 |     Details: Timed out waiting to get Ironic node by instance id 50e23a00-5b92-49b7-8dd0-5b8715ba7e26\n\nNova compute seems stuck at \"_do_build_and_run_instance /opt/stack/new/nova/nova/compute/manager.py:1754\"\n\n2016-12-21 13:24:24.307 21735 DEBUG oslo_messaging._drivers.amqpdriver [-] received message with unique_id: 3b9dab54da604a8cadc6c854588a1a5d __call__ /usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py:196\n2016-12-21 13:24:24.312 21735 DEBUG oslo_concurrency.lockutils [req-7b291e0c-c5b3-4a8a-b4db-e7cef3150b03 tempest-BaremetalBasicOps-1775111554 tempest-BaremetalBasicOps-1775111554] Lock \"6376a75b-2970-42f5-9f1b-b34db22a23e4\" acquired by \"nova.compute.manager._locked_do_build_and_run_instance\" :: waited 0.000s inner /usr/local/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py:270\n2016-12-21 13:24:24.313 21735 DEBUG oslo_messaging._drivers.amqpdriver [req-7b291e0c-c5b3-4a8a-b4db-e7cef3150b03 tempest-BaremetalBasicOps-1775111554 tempest-BaremetalBasicOps-1775111554] CALL msg_id: 92cc73436d164feab727c5b7c81ec179 exchange 'nova' topic 'conductor' _send /usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py:442\n2016-12-21 13:24:24.326 21735 DEBUG oslo_messaging._drivers.amqpdriver [-] received reply msg_id: 92cc73436d164feab727c5b7c81ec179 __call__ /usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py:299\n2016-12-21 13:24:24.327 21735 DEBUG nova.compute.manager [req-7b291e0c-c5b3-4a8a-b4db-e7cef3150b03 tempest-BaremetalBasicOps-1775111554 tempest-BaremetalBasicOps-1775111554] [instance: 6376a75b-2970-42f5-9f1b-b34db22a23e4] Starting instance... _do_build_and_run_instance /opt/stack/new/nova/nova/compute/manager.py:1754\n2016-12-21 13:24:24.330 21735 DEBUG oslo_messaging._drivers.amqpdriver [req-7b291e0c-c5b3-4a8a-b4db-e7cef3150b03 tempest-BaremetalBasicOps-1775111554 tempest-BaremetalBasicOps-1775111554] CALL msg_id: 15898ce761a143c690ea51c6af5d4f23 exchange 'nova' topic 'conductor' _send /usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py:442\n2016-12-21 13:24:24.367 21735 DEBUG nova.compute.resource_tracker [req-f3cfc8fa-df45-4da4-adf2-83688458fa16 - -] Compute_service record updated for ubuntu-xenial-osic-cloud1-s3500-6327285:039bbc98-5123-470c-8e09-74e8f35a1391 _update_available_resource /opt/stack/new/nova/nova/compute/resource_tracker.py:601\n2016-12-21 13:24:24.367 21735 DEBUG oslo_concurrency.lockutils [req-f3cfc8fa-df45-4da4-adf2-83688458fa16 - -] Lock \"compute_resources\" released by \"nova.compute.resource_tracker._update_available_resource\" :: held 6.935s inner /usr/local/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py:282\n\nfull log available: http://logs.openstack.org/39/404239/14/check/gate-tempest-dsvm-ironic-ipa-wholedisk-pxe_snmp-tinyipa-ubuntu-xenial-nv/8f98498/logs/screen-n-cpu.txt.gz#_2016-12-21_13_24_24_307", 
    "tags": [
        "compute", 
        "ironic"
    ], 
    "importance": "High", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1651678", 
    "owner": "https://api.launchpad.net/1.0/~jaypipes", 
    "id": 1651678, 
    "index": 2014, 
    "created": "2016-12-21 08:33:59.710324+00:00", 
    "title": "boot server request randomly hanging at n-cpu side, and didn't get to Ironic", 
    "comments": [
        {
            "content": "Ironic gate jobs are randomly timing out during last few weeks. Nothing strange in the logs, just receives slow VMs:\n\n\nAn example is: http://logs.openstack.org/46/327046/36/check/gate-tempest-dsvm-ironic-ipa-partition-pxe_ipmitool-tinyipa-ubuntu-xenial/48db3ea/console.html\n\n2016-12-20 23:30:24.418214 |     Traceback (most recent call last):\n2016-12-20 23:30:24.418231 |       File \"tempest/test.py\", line 99, in wrapper\n2016-12-20 23:30:24.418248 |         return f(self, *func_args, **func_kwargs)\n2016-12-20 23:30:24.418296 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/ironic_tempest_plugin/tests/scenario/test_baremetal_basic_ops.py\", line 111, in test_baremetal_server_ops\n2016-12-20 23:30:24.418316 |         self.instance, self.node = self.boot_instance()\n2016-12-20 23:30:24.418361 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/ironic_tempest_plugin/tests/scenario/baremetal_manager.py\", line 173, in boot_instance\n2016-12-20 23:30:24.418375 |         self.wait_node(instance['id'])\n2016-12-20 23:30:24.418417 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/ironic_tempest_plugin/tests/scenario/baremetal_manager.py\", line 117, in wait_node\n2016-12-20 23:30:24.418441 |         raise lib_exc.TimeoutException(msg)\n2016-12-20 23:30:24.418464 |     tempest.lib.exceptions.TimeoutException: Request timed out\n2016-12-20 23:30:24.418494 |     Details: Timed out waiting to get Ironic node by instance id 50e23a00-5b92-49b7-8dd0-5b8715ba7e26", 
            "date_created": "2016-12-21 08:33:59.710324+00:00", 
            "author": "https://api.launchpad.net/1.0/~vsaienko"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/413499", 
            "date_created": "2016-12-21 08:36:14.140958+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "@Nova team: please have look at the issue, request stuck at nova compute and didn't get to ironic.", 
            "date_created": "2016-12-22 14:57:38.428797+00:00", 
            "author": "https://api.launchpad.net/1.0/~vsaienko"
        }, 
        {
            "content": "@vasienko: Is there a particular time period that this started happening?", 
            "date_created": "2016-12-22 15:22:45.268303+00:00", 
            "author": "https://api.launchpad.net/1.0/~jaypipes"
        }, 
        {
            "content": "Looks like inventory records are trying to be written for VCPU resource class with a total of 0. This should never happen, so I'll throw some verbose logging into a local Nova and see what's up...", 
            "date_created": "2016-12-22 15:46:47.139216+00:00", 
            "author": "https://api.launchpad.net/1.0/~jaypipes"
        }, 
        {
            "content": "Jay's logging patch: https://review.openstack.org/#/c/414214/\n\nThis also might help: https://review.openstack.org/#/c/414230/", 
            "date_created": "2016-12-22 17:05:20.724081+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "@Jay. From http://ci-watch.tintri.com/project?project=ironic&time=7+days, it looks like it started happening Dec 19, eg with this patch https://review.openstack.org/#/c/250478/25.", 
            "date_created": "2016-12-22 21:48:10.583089+00:00", 
            "author": "https://api.launchpad.net/1.0/~rloo"
        }, 
        {
            "content": "I noticed with Jay's logging patch see this:\nhttp://logs.openstack.org/26/414426/1/check/gate-tempest-dsvm-ironic-ipa-wholedisk-agent_ipmitool-tinyipa-multinode-ubuntu-xenial-nv/af7b923/logs/screen-n-cpu.txt.gz?level=WARNING#_2016-12-23_06_21_16_401\n\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager [req-485b5c7b-3eb4-4e36-8fb0-3234acb45957 - -] Error updating resources for node 4e8e9ae3-f417-49c4-a0ab-4d1300e4ef0e.\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager Traceback (most recent call last):\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 6536, in update_available_resource_for_node\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager     rt.update_available_resource(context)\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager   File \"/opt/stack/new/nova/nova/compute/resource_tracker.py\", line 526, in update_available_resource\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager     self._verify_resources(resources)\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager   File \"/opt/stack/new/nova/nova/compute/resource_tracker.py\", line 962, in _verify_resources\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager     uuid = self.compute_node.uuid\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager AttributeError: 'NoneType' object has no attribute 'uuid'\n2016-12-23 06:21:16.401 29357 ERROR nova.compute.manager \n\nI wonder if that is an issue that self.compute_node is None.", 
            "date_created": "2016-12-23 06:48:33.649868+00:00", 
            "author": "https://api.launchpad.net/1.0/~happycamp"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/414579", 
            "date_created": "2016-12-23 13:18:57.666092+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Here is a bit of code from our driver:\n\nhttps://github.com/openstack/nova/blob/1506c36b4446f6ba1487a2d68e4b23cb3fca44cb/nova/virt/ironic/driver.py#L318-L326", 
            "date_created": "2016-12-23 13:21:18.073308+00:00", 
            "author": "https://api.launchpad.net/1.0/~vdrok"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/414603", 
            "date_created": "2016-12-23 14:35:43.581994+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Vladyslav Drok (<email address hidden>) on branch: master\nReview: https://review.openstack.org/414603", 
            "date_created": "2016-12-23 18:46:11.588710+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Vladyslav Drok (<email address hidden>) on branch: master\nReview: https://review.openstack.org/414579", 
            "date_created": "2016-12-23 18:46:29.842553+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Looks like the instance booting block on acquire lock on COMPUTE_RESOURCE_SEMAPHORE?\n\nThe instance stop after:\n\nhttp://logs.openstack.org/39/404239/14/check/gate-tempest-dsvm-ironic-ipa-wholedisk-pxe_snmp-tinyipa-ubuntu-xenial-nv/8f98498/logs/screen-n-cpu.txt.gz#_2016-12-21_13_24_24_327\n\nThen periodic task update_available_resource always get the lock:\n\nrelease the lock http://logs.openstack.org/39/404239/14/check/gate-tempest-dsvm-ironic-ipa-wholedisk-pxe_snmp-tinyipa-ubuntu-xenial-nv/8f98498/logs/screen-n-cpu.txt.gz#_2016-12-21_13_24_24_367\n\nThen acquire lock soon http://logs.openstack.org/39/404239/14/check/gate-tempest-dsvm-ironic-ipa-wholedisk-pxe_snmp-tinyipa-ubuntu-xenial-nv/8f98498/logs/screen-n-cpu.txt.gz#_2016-12-21_13_24_24_370\n\n\nI don't know why update_available_resource always run, there should be 60 seconds interval?", 
            "date_created": "2016-12-27 03:28:18.667070+00:00", 
            "author": "https://api.launchpad.net/1.0/~xuhj"
        }, 
        {
            "content": "@Alex: each Ironic node appear in nova like hypervisor, nova lock whole compute when update resources for hypervisor. In the log [0] you can see that resources are updated for different ironic nodes (nova hypervisors). Short report from the log [2]. When we send 0 values to placement API, it returns 400 error, and it takes near 6 seconds to complete this operation. In [2] I've copied update resources for single node (acquired lock at: 13:24:44.599 released lock at: 13:24:51.281, held 6.681s). So indeed it looks like lock starvation which is caused by trying to send 0 values to placement API, which anyways not valid value and request is discarded on API anyway (we got 400). The fix proposed [3] avoids sending 0 values, as they will never be accepted by API.\n\n[0] http://logs.openstack.org/39/404239/14/check/gate-tempest-dsvm-ironic-ipa-wholedisk-pxe_snmp-tinyipa-ubuntu-xenial-nv/8f98498/logs/screen-n-cpu.txt.gz#_2016-12-21_13_24_24_327\n[1] http://paste.openstack.org/show/593421/\n[2] http://paste.openstack.org/show/593422/\n[3] https://review.openstack.org/#/c/414214/\n", 
            "date_created": "2016-12-27 09:02:29.288121+00:00", 
            "author": "https://api.launchpad.net/1.0/~vsaienko"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/415403", 
            "date_created": "2016-12-28 08:41:56.012905+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/415403\nCommitted: https://git.openstack.org/cgit/openstack/ironic/commit/?id=be6f34c3388365f93c84671f07af7a1cffb6efd8\nSubmitter: Jenkins\nBranch:    master\n\ncommit be6f34c3388365f93c84671f07af7a1cffb6efd8\nAuthor: Vasyl Saienko <email address hidden>\nDate:   Wed Dec 28 10:39:44 2016 +0200\n\n    Disable placement-api by default\n    \n    With placement-api enablement Ironic jobs got into regression due to\n    [0]. The fix in Nova stuck at the decision phase [1]. Until Nova fix\n    issue permanently disable it in ironic to unblock CI.\n    \n    [0] https://bugs.launchpad.net/ironic/+bug/1651678\n    [1] https://review.openstack.org/#/c/414214/\n    \n    Change-Id: I658ec963761dd4c5111a98e77298a8974553e857\n    Related-Bug: #1651678\n", 
            "date_created": "2016-12-28 14:20:32.287743+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/415523", 
            "date_created": "2016-12-28 18:44:16.163301+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/414214\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=3c217acb9c55d647ca362320d697e80d7cfa5ceb\nSubmitter: Jenkins\nBranch:    master\n\ncommit 3c217acb9c55d647ca362320d697e80d7cfa5ceb\nAuthor: Jay Pipes <email address hidden>\nDate:   Thu Dec 22 11:09:15 2016 -0500\n\n    placement: Do not save 0-valued inventory\n    \n    Ironic nodes that are not available or operable have 0 values for vcpus,\n    memory_mb, and local_gb in the returned dict from the Ironic virt driver's\n    get_available_resource() call. Don't try to save these 0 values in the\n    placement API inventory records, since the placement REST API will return an\n    error. Instead, attempt to delete any inventory records for that Ironic node\n    resource provider by PUT'ing an empty set of inventory records to the placement\n    API.\n    \n    Closes-bug: #1651678\n    \n    Change-Id: I10b22606f704abcb970939fb2cd77f026d4d6322\n", 
            "date_created": "2017-01-04 16:24:44.784690+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/newton\nReview: https://review.openstack.org/416762", 
            "date_created": "2017-01-04 22:45:38.497518+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/415523\nCommitted: https://git.openstack.org/cgit/openstack/ironic/commit/?id=dc673e34b4243ed704e3a4562c5ca73d6b4f4ccd\nSubmitter: Jenkins\nBranch:    master\n\ncommit dc673e34b4243ed704e3a4562c5ca73d6b4f4ccd\nAuthor: Matt Riedemann <email address hidden>\nDate:   Wed Dec 28 18:44:09 2016 +0000\n\n    Revert \"Disable placement-api by default\"\n    \n    This reverts commit be6f34c3388365f93c84671f07af7a1cffb6efd8\n    \n    Now that the openstack/nova commit\n    3c217acb9c55d647ca362320d697e80d7cfa5ceb has landed. The issue is now\n    fixed and we can revert this change.\n    \n    Change-Id: I6729706b13d49a277a2f037ea7ef00211d4a4ca9\n    Related-Bug: #1651678\n", 
            "date_created": "2017-01-10 10:49:28.089626+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 15.0.0.0b3 development milestone.", 
            "date_created": "2017-01-27 00:51:59.958271+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/416762\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=d9b74f230c9c5233f9ccea74a61b051d618061a3\nSubmitter: Jenkins\nBranch:    stable/newton\n\ncommit d9b74f230c9c5233f9ccea74a61b051d618061a3\nAuthor: Jay Pipes <email address hidden>\nDate:   Thu Dec 22 11:09:15 2016 -0500\n\n    placement: Do not save 0-valued inventory\n    \n    Ironic nodes that are not available or operable have 0 values for vcpus,\n    memory_mb, and local_gb in the returned dict from the Ironic virt driver's\n    get_available_resource() call. Don't try to save these 0 values in the\n    placement API inventory records, since the placement REST API will return an\n    error. Instead, attempt to delete any inventory records for that Ironic node\n    resource provider by PUT'ing an empty set of inventory records to the placement\n    API.\n    \n    Closes-bug: #1651678\n    \n    Conflicts:\n            nova/scheduler/client/report.py\n            nova/tests/unit/scheduler/client/test_report.py\n    \n    NOTE(mriedem): The test conflict is due to refacoring change\n    1870c75c45a99f879ac7dc0ab5e5b30ad82880cb not being in\n    stable/newton. The report.py conflict is due to change\n    13ba33a57488f5e553dcca7162cc35b58ff0e7f8 coming before this.\n    \n    Change-Id: I10b22606f704abcb970939fb2cd77f026d4d6322\n    (cherry picked from commit 3c217acb9c55d647ca362320d697e80d7cfa5ceb)\n", 
            "date_created": "2017-03-06 12:18:33.844762+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 14.0.5 release.", 
            "date_created": "2017-03-22 10:13:26.708967+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}