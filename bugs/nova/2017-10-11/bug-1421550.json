{
    "status": "Fix Released", 
    "last_updated": "2017-06-08 21:52:31.550016+00:00", 
    "description": "Environment:\nnova 2014.2.1\ncinder 2014.2.1\nUbuntu 14.04 LTS\nCinder volumes whose backend is NFS are used.\n\nThere are two 'ACTIVE' VM instances on the same compute node.\nCreating VM image(VM snapshot) fails under the race condition with detaching volume for the other VM instance.\nIn creating VM image, starting VM instance fails(remains 'SHUTOFF' state) and the VM image is deleted.\n\nnova-compute's log is as follows:\n---------------------------------------------------------------------------------------------------------------\n2015-01-26 10:28:47,000.744 11535 ERROR nova.virt.libvirt.driver [req-7ee6f579-63f5-4822-a2b3-10e53bb1dce0 None] Error launching a defined domain with XML: <domain type='kvm'>\n(snipped...)\n2015-01-26 10:28:47,000.767 11535 DEBUG nova.compute.manager [req-7ee6f579-63f5-4822-a2b3-10e53bb1dce0 None] [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0] Cleaning up image e8c3255c-b4e8-4324-addb-365c5d7b1868 decorated_function /usr/lib/python2.7/dist-packages/nova/compute/manager.py:373\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0] Traceback (most recent call last):\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 369, in decorated_function\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     *args, **kwargs)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 3027, in snapshot_instance\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     task_states.IMAGE_SNAPSHOT)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 3058, in _snapshot_instance\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     update_task_state)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 1733, in snapshot\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     new_dom = self._create_domain(domain=virt_dom)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4338, in _create_domain\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     LOG.error(err)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/excutils.py\", line 82, in __exit__\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     six.reraise(self.type_, self.value, self.tb)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4329, in _create_domain\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     domain.createWithFlags(launch_flags)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 183, in doit\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 141, in proxy_call\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     rv = execute(f, *args, **kwargs)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 122, in execute\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     six.reraise(c, e, tb)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 80, in tworker\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     rv = meth(*args, **kwargs)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 896, in createWithFlags\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0] libvirtError: Failed to open file '/var/lib/nova/mnt/339b9d35866664794a8155657a049127/volume-27f59813-76f0-4b56-ba42-75922537c36c': No such file or directory\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0] \n---------------------------------------------------------------------------------------------------------------\n\nIn detaching volume, umounting NFS is performed without checking whether the other VM instance is being attached volumes or not.\nSo if the other VM is stopped, umounting NFS succeeds.\n\nIf there are no processes using the NFS directory, the NFS directory is umounted.\nnova/virt/libvirt/volumes.py(2014.2.1):\n---------------------------------------------------------------------------------------------------------------\nclass LibvirtNFSVolumeDriver(LibvirtBaseVolumeDriver):\n(snipped...)\n    def disconnect_volume(self, connection_info, disk_dev):\n        \"\"\"Disconnect the volume.\"\"\"\n\n        export = connection_info['data']['export']\n        mount_path = os.path.join(CONF.libvirt.nfs_mount_point_base,\n                                  utils.get_hash_str(export))\n\n        try:\n            utils.execute('umount', mount_path, run_as_root=True)\n        except processutils.ProcessExecutionError as exc:\n            if ('device is busy' in exc.message or\n                'target is busy' in exc.message):\n                LOG.debug(\"The NFS share %s is still in use.\", export)\n            else:\n                LOG.exception(_LE(\"Couldn't unmount the NFS share %s\"), export)\n---------------------------------------------------------------------------------------------------------------\n* This code has been added in https://review.openstack.org/#/c/76558/.\n\nA VM instance is stopped once by creating VM image.\nAnd then detaching volume for the other VM instance on the same compute node is executed.\nIf there are no VMs connecting cinder volumes, umounting NFS directory succeeds.\nAfter VM snapshot is completed, the VM instance is restarted.\nBut the VM instance cannot access volumes because NFS directory has been umounted.\nSo the error occurs and the VM instance cannot be restarted.\n\nAnd this issue also occurs under the race condition with starting a VM instance\nand detaching volumes for another VM instance('ACTIVE') on the same compute node.\n\n1. _connect_volume in starting a VM instance(mount NFS directory if not mounted.)\n2. _disconnect_volume in detaching volume(umount NFS directory if no processes use it.)\n3. The libvirt domain starts in starting a VM instance", 
    "tags": [
        "nfs", 
        "volumes"
    ], 
    "importance": "Medium", 
    "heat": 22, 
    "link": "https://bugs.launchpad.net/nova/+bug/1421550", 
    "owner": "https://api.launchpad.net/1.0/~mbooth-9", 
    "id": 1421550, 
    "index": 4150, 
    "created": "2015-02-13 07:54:32.141255+00:00", 
    "title": "Creating VM image fails under the race condition with detaching volume", 
    "comments": [
        {
            "content": "Environment:\nnova 2014.2.1\ncinder 2014.2.1\nUbuntu 14.04 LTS\nCinder volumes whose backend is NFS are used.\n\nThere are two 'ACTIVE' VM instances on the same compute node.\nCreating VM image(VM snapshot) fails under the race condition with detaching volume for the other VM instance.\nIn creating VM image, starting VM instance fails(remains 'SHUTOFF' state) and the VM image is deleted.\n\nnova-compute's log is as follows:\n---------------------------------------------------------------------------------------------------------------\n2015-01-26 10:28:47,000.744 11535 ERROR nova.virt.libvirt.driver [req-7ee6f579-63f5-4822-a2b3-10e53bb1dce0 None] Error launching a defined domain with XML: <domain type='kvm'>\n(snipped...)\n2015-01-26 10:28:47,000.767 11535 DEBUG nova.compute.manager [req-7ee6f579-63f5-4822-a2b3-10e53bb1dce0 None] [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0] Cleaning up image e8c3255c-b4e8-4324-addb-365c5d7b1868 decorated_function /usr/lib/python2.7/dist-packages/nova/compute/manager.py:373\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0] Traceback (most recent call last):\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 369, in decorated_function\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     *args, **kwargs)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 3027, in snapshot_instance\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     task_states.IMAGE_SNAPSHOT)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 3058, in _snapshot_instance\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     update_task_state)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 1733, in snapshot\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     new_dom = self._create_domain(domain=virt_dom)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4338, in _create_domain\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     LOG.error(err)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/openstack/common/excutils.py\", line 82, in __exit__\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     six.reraise(self.type_, self.value, self.tb)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4329, in _create_domain\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     domain.createWithFlags(launch_flags)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 183, in doit\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 141, in proxy_call\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     rv = execute(f, *args, **kwargs)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 122, in execute\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     six.reraise(c, e, tb)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 80, in tworker\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     rv = meth(*args, **kwargs)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 896, in createWithFlags\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0] libvirtError: Failed to open file '/var/lib/nova/mnt/339b9d35866664794a8155657a049127/volume-27f59813-76f0-4b56-ba42-75922537c36c': No such file or directory\n2015-01-26 10:28:47,000.767 11535 TRACE nova.compute.manager [instance: d613cfc9-109a-4920-bbc1-41ce4146ace0] \n---------------------------------------------------------------------------------------------------------------\n\nIn detaching volume, umounting NFS is performed without checking whether the other VM instance is being attached volumes or not.\nSo if the other VM is stopped, umounting NFS succeeds.\n\nIf there are no processes using the NFS directory, the NFS directory is umounted.\nnova/virt/libvirt/volumes.py(2014.2.1):\n---------------------------------------------------------------------------------------------------------------\nclass LibvirtNFSVolumeDriver(LibvirtBaseVolumeDriver):\n(snipped...)\n    def disconnect_volume(self, connection_info, disk_dev):\n        \"\"\"Disconnect the volume.\"\"\"\n\n        export = connection_info['data']['export']\n        mount_path = os.path.join(CONF.libvirt.nfs_mount_point_base,\n                                  utils.get_hash_str(export))\n\n        try:\n            utils.execute('umount', mount_path, run_as_root=True)\n        except processutils.ProcessExecutionError as exc:\n            if ('device is busy' in exc.message or\n                'target is busy' in exc.message):\n                LOG.debug(\"The NFS share %s is still in use.\", export)\n            else:\n                LOG.exception(_LE(\"Couldn't unmount the NFS share %s\"), export)\n---------------------------------------------------------------------------------------------------------------\n* This code has been added in https://review.openstack.org/#/c/76558/.\n\nA VM instance is stopped once by creating VM image.\nAnd then detaching volume for the other VM instance on the same compute node is executed.\nIf there are no VMs connecting cinder volumes, umounting NFS directory succeeds.\nAfter VM snapshot is completed, the VM instance is restarted.\nBut the VM instance cannot access volumes because NFS directory has been umounted.\nSo the error occurs and the VM instance cannot be restarted.\n\nAnd this issue also occurs under the race condition with starting a VM instance\nand detaching volumes for another VM instance('ACTIVE') on the same compute node.\n\n1. _connect_volume in starting a VM instance(mount NFS directory if not mounted.)\n2. _disconnect_volume in detaching volume(umount NFS directory if no processes use it.)\n3. The libvirt domain starts in starting a VM instance", 
            "date_created": "2015-02-13 07:54:32.141255+00:00", 
            "author": "https://api.launchpad.net/1.0/~natsume-takashi"
        }, 
        {
            "content": "Hi Joe\n\nI have submitted a patch for this issue, please review it:\nhttps://review.openstack.org/#/c/166152/\n\nthanks", 
            "date_created": "2015-05-11 02:58:59.365314+00:00", 
            "author": "https://api.launchpad.net/1.0/~271025598-9"
        }, 
        {
            "content": "Change abandoned by Matt Riedemann (<email address hidden>) on branch: master\nReview: https://review.openstack.org/166152\nReason: This looks abandoned, please restore and update to address review comments if you want to continue working on this.", 
            "date_created": "2016-02-17 16:52:09.014331+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/290510", 
            "date_created": "2016-03-09 13:56:50.413675+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Zhengguang Ou (<email address hidden>) on branch: master\nReview: https://review.openstack.org/166152", 
            "date_created": "2016-03-09 13:59:03.462551+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "A newer patch from Zhengguang Ou is up for review here:\n\nhttps://review.openstack.org/#/c/290510/", 
            "date_created": "2016-05-05 20:22:31.335392+00:00", 
            "author": "https://api.launchpad.net/1.0/~diana-clarke"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/383859", 
            "date_created": "2016-10-07 18:38:48.139573+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Check it: https://bugs.launchpad.net/nova/+bug/1396965", 
            "date_created": "2016-10-13 19:50:18.959049+00:00", 
            "author": "https://api.launchpad.net/1.0/~tcanascimento"
        }, 
        {
            "content": "Change abandoned by Sean Dague (<email address hidden>) on branch: master\nReview: https://review.openstack.org/290510\nReason: This review is > 6 weeks without comment, and failed Jenkins the last time it was checked. We are abandoning this for now. Feel free to reactivate the review by pressing the restore button and leaving a 'recheck' comment to get fresh test results.", 
            "date_created": "2016-12-09 21:03:51.003028+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/383859\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=4aa39c44a4b08ee4e05548d5c258e795089b2bdd\nSubmitter: Jenkins\nBranch:    master\n\ncommit 4aa39c44a4b08ee4e05548d5c258e795089b2bdd\nAuthor: Matthew Booth <email address hidden>\nDate:   Fri Oct 7 19:14:38 2016 +0100\n\n    libvirt: Fix races with nfs volume mount/umount\n    \n    A single nfs export typically contains multiple volumes. We were\n    handling this in the libvirt driver by:\n    \n    1. On mount, we 'ensure' the mount is available, so we don't fail if\n       another instance already has it mounted.\n    \n    2. On umount, we trap and ignore 'device is busy' so we don't fail if\n       another instance is already using it.\n    \n    Unfortunately, while this works for serial mounts and unmounts, there\n    are multiple failure cases when volumes from the same export are\n    mounted and unmounted simultaneously. It causes an error if an\n    instance is stopped: as the qemu process is not actively using the\n    mountpoint it will not prevent an unmount for another volume on the\n    same mountpoint from succeeding. It will not be possible to restart\n    the instance, because its mountpoint will not be mounted.\n    \n    To fix this, we create a singleton manager object, which tracks mounts\n    and umount requests per export, and calls the real mount/umount only\n    when required. It uses per-export locks to allow concurrency while\n    avoiding races. Because we now expect to know the state of the host at\n    all times, we no longer need to execute speculative mount/umount\n    commands.\n    \n    As we track attachments (a mapping from volume to instance) rather\n    than volumes, we also gracefully support multi-attach.\n    \n    This change implements this for nfs, but the solution is intended to\n    be extended to all LibvirtBaseFileSystemVolumeDrivers.\n    \n    Closes-Bug: #1421550\n    Change-Id: I3155984d76df06371a6c45f633aa448168a96d64\n", 
            "date_created": "2017-05-11 16:17:29.825381+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 16.0.0.0b2 development milestone.", 
            "date_created": "2017-06-08 21:52:31.074510+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}