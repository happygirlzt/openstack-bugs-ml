{
    "status": "Fix Released", 
    "last_updated": "2014-10-16 08:58:22.465630+00:00", 
    "description": "This is showing up all over the n-cpu logs on teardown of tempest tests:\n\nUnexpectedTaskStateError: Unexpected task state: expecting (u'powering-off',) but the actual state is None\n\nFor example:\n\nhttp://logs.openstack.org/06/103206/4/check/check-tempest-dsvm-postgres-full/b5e8f3c/logs/screen-n-cpu.txt.gz?level=TRACE\n\nWe have nearly 40K hits on this in logstash in 7 days:\n\nmessage:\"UnexpectedTaskStateError: Unexpected task state: expecting (u'powering-off',) but the actual state is None\" AND tags:\"screen-n-cpu.txt\"\n\nhttp://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwiVW5leHBlY3RlZFRhc2tTdGF0ZUVycm9yOiBVbmV4cGVjdGVkIHRhc2sgc3RhdGU6IGV4cGVjdGluZyAodSdwb3dlcmluZy1vZmYnLCkgYnV0IHRoZSBhY3R1YWwgc3RhdGUgaXMgTm9uZVwiIEFORCB0YWdzOlwic2NyZWVuLW4tY3B1LnR4dFwiIiwiZmllbGRzIjpbXSwib2Zmc2V0IjowLCJ0aW1lZnJhbWUiOiI2MDQ4MDAiLCJncmFwaG1vZGUiOiJjb3VudCIsInRpbWUiOnsidXNlcl9pbnRlcnZhbCI6MH0sInN0YW1wIjoxNDA0ODQxMjQ3MDk4fQ==\n\nThis is the interesting traceback from the compute manager:\n\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher Traceback (most recent call last):\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 134, in _dispatch_and_reply\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     incoming.message))\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 177, in _dispatch\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return self._do_dispatch(endpoint, method, ctxt, args)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 123, in _do_dispatch\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     result = getattr(endpoint, method)(ctxt, **new_args)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/exception.py\", line 88, in wrapped\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     payload)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 82, in __exit__\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/exception.py\", line 71, in wrapped\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return f(self, context, *args, **kw)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 272, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     LOG.info(_(\"Task possibly preempted: %s\") % e.format_message())\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 82, in __exit__\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 266, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 330, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 308, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     kwargs['instance'], e, sys.exc_info())\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 82, in __exit__\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 296, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2356, in stop_instance\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     instance.save(expected_task_state=task_states.POWERING_OFF)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/objects/base.py\", line 187, in wrapper\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     ctxt, self, fn.__name__, args, kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/conductor/rpcapi.py\", line 349, in object_action\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     objmethod=objmethod, args=args, kwargs=kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/rpc/client.py\", line 152, in call\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     retry=self.retry)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/transport.py\", line 90, in _send\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     timeout=timeout, retry=retry)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/_drivers/amqpdriver.py\", line 404, in send\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     retry=retry)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/_drivers/amqpdriver.py\", line 395, in _send\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     raise result\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher UnexpectedTaskStateError_Remote: Unexpected task state: expecting (u'powering-off',) but the actual state is None", 
    "tags": [
        "compute"
    ], 
    "importance": "Medium", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1339235", 
    "owner": "https://api.launchpad.net/1.0/~mriedem", 
    "id": 1339235, 
    "index": 3946, 
    "created": "2014-07-08 17:44:37.068707+00:00", 
    "title": "UnexpectedTaskStateError: Unexpected task state: expecting (u'powering-off',) but the actual state is None", 
    "comments": [
        {
            "content": "This is showing up all over the n-cpu logs on teardown of tempest tests:\n\nUnexpectedTaskStateError: Unexpected task state: expecting (u'powering-off',) but the actual state is None\n\nFor example:\n\nhttp://logs.openstack.org/06/103206/4/check/check-tempest-dsvm-postgres-full/b5e8f3c/logs/screen-n-cpu.txt.gz?level=TRACE\n\nWe have nearly 40K hits on this in logstash in 7 days:\n\nmessage:\"UnexpectedTaskStateError: Unexpected task state: expecting (u'powering-off',) but the actual state is None\" AND tags:\"screen-n-cpu.txt\"\n\nhttp://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwiVW5leHBlY3RlZFRhc2tTdGF0ZUVycm9yOiBVbmV4cGVjdGVkIHRhc2sgc3RhdGU6IGV4cGVjdGluZyAodSdwb3dlcmluZy1vZmYnLCkgYnV0IHRoZSBhY3R1YWwgc3RhdGUgaXMgTm9uZVwiIEFORCB0YWdzOlwic2NyZWVuLW4tY3B1LnR4dFwiIiwiZmllbGRzIjpbXSwib2Zmc2V0IjowLCJ0aW1lZnJhbWUiOiI2MDQ4MDAiLCJncmFwaG1vZGUiOiJjb3VudCIsInRpbWUiOnsidXNlcl9pbnRlcnZhbCI6MH0sInN0YW1wIjoxNDA0ODQxMjQ3MDk4fQ==\n\nThis is the interesting traceback from the compute manager:\n\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher Traceback (most recent call last):\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 134, in _dispatch_and_reply\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     incoming.message))\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 177, in _dispatch\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return self._do_dispatch(endpoint, method, ctxt, args)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/rpc/dispatcher.py\", line 123, in _do_dispatch\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     result = getattr(endpoint, method)(ctxt, **new_args)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/exception.py\", line 88, in wrapped\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     payload)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 82, in __exit__\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/exception.py\", line 71, in wrapped\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return f(self, context, *args, **kw)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 272, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     LOG.info(_(\"Task possibly preempted: %s\") % e.format_message())\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 82, in __exit__\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 266, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 330, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 308, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     kwargs['instance'], e, sys.exc_info())\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 82, in __exit__\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     six.reraise(self.type_, self.value, self.tb)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 296, in decorated_function\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     return function(self, context, *args, **kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 2356, in stop_instance\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     instance.save(expected_task_state=task_states.POWERING_OFF)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/objects/base.py\", line 187, in wrapper\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     ctxt, self, fn.__name__, args, kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/opt/stack/new/nova/nova/conductor/rpcapi.py\", line 349, in object_action\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     objmethod=objmethod, args=args, kwargs=kwargs)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/rpc/client.py\", line 152, in call\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     retry=self.retry)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/transport.py\", line 90, in _send\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     timeout=timeout, retry=retry)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/_drivers/amqpdriver.py\", line 404, in send\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     retry=retry)\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/_drivers/amqpdriver.py\", line 395, in _send\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher     raise result\n2014-07-08 00:46:47.922 18853 TRACE oslo.messaging.rpc.dispatcher UnexpectedTaskStateError_Remote: Unexpected task state: expecting (u'powering-off',) but the actual state is None", 
            "date_created": "2014-07-08 17:44:37.068707+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I see this right before the error:\n\n2014-07-08 00:46:47.916 INFO nova.compute.manager [req-f1763a6c-d8b1-4a7f-af14-cc5df9807611 None None] Task possibly preempted: Unexpected task state: expecting (u'powering-off',) but the actual state is None\n\nSo that leads me to believe the periodic task that syncs power states with the virt driver and hypervisor is updating the database and causing the race.\n\nSo this might be a duplicate of bug 1320628.", 
            "date_created": "2014-07-08 17:48:29.496454+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "This is actually worse after 7/14 when the fix for bug 1320628 was merged:\n\nhttp://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwiVW5leHBlY3RlZFRhc2tTdGF0ZUVycm9yOiBVbmV4cGVjdGVkIHRhc2sgc3RhdGU6IGV4cGVjdGluZyAodSdwb3dlcmluZy1vZmYnLCkgYnV0IHRoZSBhY3R1YWwgc3RhdGUgaXMgTm9uZVwiIEFORCB0YWdzOlwic2NyZWVuLW4tY3B1LnR4dFwiIiwiZmllbGRzIjpbXSwib2Zmc2V0IjowLCJ0aW1lZnJhbWUiOiJjdXN0b20iLCJncmFwaG1vZGUiOiJjb3VudCIsInRpbWUiOnsiZnJvbSI6IjIwMTQtMDctMDRUMTM6MDY6MzcrMDA6MDAiLCJ0byI6IjIwMTQtMDctMThUMTM6MDY6MzcrMDA6MDAiLCJ1c2VyX2ludGVydmFsIjoiMCJ9LCJzdGFtcCI6MTQwNTY4ODg4MTUwMn0=", 
            "date_created": "2014-07-18 13:12:32.106182+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Looks like this is contributing to bug 1266611 also.", 
            "date_created": "2014-07-18 13:42:42.824053+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/108014", 
            "date_created": "2014-07-18 13:59:02.038173+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/108014\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=aa1792eb4c1d10e9a192142ce7e20d37871d916a\nSubmitter: Jenkins\nBranch:    master\n\ncommit aa1792eb4c1d10e9a192142ce7e20d37871d916a\nAuthor: Matt Riedemann <email address hidden>\nDate:   Tue Sep 2 12:11:55 2014 -0700\n\n    Stop stack tracing when trying to auto-stop a stopped instance\n    \n    Commit cc5388bbe81aba635fb757e202d860aeed98f3e8 added locks to\n    stop_instance and the _sync_power_states periodic task to try and fix a\n    race between stopping the instance via the API where the task_state is\n    set to powering-off, and the periodic task seeing the instance\n    power_state as shutdown in _sync_instance_power_state and calling the\n    stop API again, at which point the task_state is already None from the\n    first stop API call and we get an UnexpectedTaskStateError.\n    \n    The handle_lifecycle_event method is getting callbacks from the libvirt\n    driver on state changes on the VM and calling the\n    _sync_instance_power_state method which may try to stop the instance\n    asynchronously, and lead to UnexpectedTaskStateError if the instance is\n    already stopped by the time it gets the lock and the task_state has\n    changed.\n    \n    Attempting to lock in handle_lifecycle_event just moves the race around\n    so this change adds logic to stop_instance such that if the instance\n    says it's active but the virt driver says it's not running, then we add\n    None to the expected_task_state so we don't stacktrace on\n    instance.save().\n    \n    An alternative and/or additional change to this would be doing a call\n    rather than a cast when _sync_instance_power_state calls the stop API\n    but in some previous testing it doesn't appear to make a significant\n    difference in the race found when we hit the stop_instance method.\n    \n    Adds a bunch of debug logging since this code is inherently racey and\n    is needed when looking at failures around these operations.\n    \n    Closes-Bug: #1339235\n    Closes-Bug: #1266611\n    Related-Bug: #1320628\n    \n    Change-Id: Ib495a5ab15de88051c5fa7abfb58a5445691dcad\n", 
            "date_created": "2014-09-12 20:14:20.035811+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ]
}