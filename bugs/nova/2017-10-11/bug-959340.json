{
    "status": "Invalid", 
    "last_updated": "2012-09-10 13:11:58.011391+00:00", 
    "description": "Found in nova-compute:\n\n2012-03-19 10:29:19 DEBUG nova.utils [-] Running cmd (subprocess): cp /opt/stack/nova/instances/_base/6b4b8998-743d-42c7-a635-05524b9e1240 /opt/stack/nova/instances/instance-0000001f/ramdisk from (pid=2161) execute /opt/stack/nova/nova/utils.py:217\n2012-03-19 10:29:19 DEBUG nova.virt.libvirt.connection [-] block_device_list [] from (pid=2161) _volume_in_mapping /opt/stack/nova/nova/virt/libvirt/connection.py:1300\n2012-03-19 10:29:19 DEBUG nova.utils [-] Attempting to grab semaphore \"092d586b5c34c0ad418d42872f22aa7cb60ef614\" for method \"call_if_not_exists\"... from (pid=2161) inner /opt/stack/nova/nova/utils.py:885\n2012-03-19 10:29:19 DEBUG nova.utils [-] Got semaphore \"092d586b5c34c0ad418d42872f22aa7cb60ef614\" for method \"call_if_not_exists\"... from (pid=2161) inner /opt/stack/nova/nova/utils.py:889\n2012-03-19 10:29:19 DEBUG nova.utils [-] Attempting to grab semaphore \"/opt/stack/nova/instances/_base/092d586b5c34c0ad418d42872f22aa7cb60ef614\" for method \"copy_and_extend\"... from (pid=2161) inner /opt/stack/nova/nova/utils.py:885\n2012-03-19 10:29:19 DEBUG nova.utils [-] Got semaphore \"/opt/stack/nova/instances/_base/092d586b5c34c0ad418d42872f22aa7cb60ef614\" for method \"copy_and_extend\"... from (pid=2161) inner /opt/stack/nova/nova/utils.py:889\n2012-03-19 10:29:19 DEBUG nova.utils [-] Running cmd (subprocess): qemu-img create -f qcow2 -o cluster_size=2M,backing_file=/opt/stack/nova/instances/_base/092d586b5c34c0ad418d42872f22aa7cb60ef614 /opt/stack/nova/instances/instance-0000001f/disk from (pid=2161) execute /opt/stack/nova/nova/utils.py:217\nlibvir: QEMU error : operation failed: cannot restore domain 'instance-0000001f' uuid 2453b24b-87e1-4f85-9c25-ce3706a8c1d1 from a file which belongs to domain 'instance-0000001f' uuid deb8e941-4693-4768-90cc-03ad98444c85\n2012-03-19 10:29:20 ERROR nova.compute.manager [-] [instance: 2453b24b-87e1-4f85-9c25-ce3706a8c1d1] Instance failed to spawn\n(nova.compute.manager): TRACE: Traceback (most recent call last):\n(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 592, in _spawn\n(nova.compute.manager): TRACE:     self._legacy_nw_info(network_info), block_device_info)\n(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/exception.py\", line 114, in wrapped\n(nova.compute.manager): TRACE:     return f(*args, **kw)\n(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 864, in spawn\n(nova.compute.manager): TRACE:     self._create_new_domain(xml)\n(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 1476, in _create_new_domain\n(nova.compute.manager): TRACE:     domain.createWithFlags(launch_flags)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 372, in createWithFlags\n(nova.compute.manager): TRACE:     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n(nova.compute.manager): TRACE: libvirtError: operation failed: cannot restore domain 'instance-0000001f' uuid 2453b24b-87e1-4f85-9c25-ce3706a8c1d1 from a file which belongs to domain 'instance-0000001f' uuid deb8e941-4693-4768-90cc-03ad98444c85\n(nova.compute.manager): TRACE: \n2012-03-19 10:29:20 DEBUG nova.compute.manager [-] [instance: 2453b24b-87e1-4f85-9c25-ce3706a8c1d1] Deallocating network for instance from (pid=2161) _deallocate_network /opt/stack/nova/nova/compute/manager.py:616\n2012-03-19 10:29:20 DEBUG nova.rpc.amqp [-] Making asynchronous cast on network... from (pid=2161) cast /opt/stack/nova/nova/rpc/amqp.py:346\n2012-03-19 10:29:20 ERROR nova.rpc.amqp [-] Exception during message handling\n(nova.rpc.amqp): TRACE: Traceback (most recent call last):\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/rpc/amqp.py\", line 252, in _process_data\n(nova.rpc.amqp): TRACE:     rval = node_func(context=ctxt, **node_args)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/exception.py\", line 114, in wrapped\n(nova.rpc.amqp): TRACE:     return f(*args, **kw)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 177, in decorated_function\n(nova.rpc.amqp): TRACE:     sys.exc_info())\n(nova.rpc.amqp): TRACE:   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n(nova.rpc.amqp): TRACE:     self.gen.next()\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 171, in decorated_function\n(nova.rpc.amqp): TRACE:     return function(self, context, instance_uuid, *args, **kwargs)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 648, in run_instance\n(nova.rpc.amqp): TRACE:     self._run_instance(context, instance_uuid, **kwargs)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 451, in _run_instance\n(nova.rpc.amqp): TRACE:     self._set_instance_error_state(context, instance_uuid)\n(nova.rpc.amqp): TRACE:   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n(nova.rpc.amqp): TRACE:     self.gen.next()\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 432, in _run_instance\n(nova.rpc.amqp): TRACE:     self._deallocate_network(context, instance)\n(nova.rpc.amqp): TRACE:   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n(nova.rpc.amqp): TRACE:     self.gen.next()\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 429, in _run_instance\n(nova.rpc.amqp): TRACE:     injected_files, admin_password)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 592, in _spawn\n(nova.rpc.amqp): TRACE:     self._legacy_nw_info(network_info), block_device_info)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/exception.py\", line 114, in wrapped\n(nova.rpc.amqp): TRACE:     return f(*args, **kw)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 864, in spawn\n(nova.rpc.amqp): TRACE:     self._create_new_domain(xml)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 1476, in _create_new_domain\n(nova.rpc.amqp): TRACE:     domain.createWithFlags(launch_flags)\n(nova.rpc.amqp): TRACE:   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 372, in createWithFlags\n(nova.rpc.amqp): TRACE:     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n(nova.rpc.amqp): TRACE: libvirtError: operation failed: cannot restore domain 'instance-0000001f' uuid 2453b24b-87e1-4f85-9c25-ce3706a8c1d1 from a file which belongs to domain 'instance-0000001f' uuid deb8e941-4693-4768-90cc-03ad98444c85\n\nA number of different tests in Tempest can trigger this issue. It does not happen every time a particular test is run, only about half the time, and seems to be a timing issue.\n\nThe code in the tests in question follow this pattern:\n\n1) Create a server via the Compute API, supplying an AMI image ID and a tiny flavor code\n2) Wait for the server to go into ACTIVE status\n\nThe code eventually hits a timeout, as the server goes into ERROR status after hitting the traceback shown above.", 
    "tags": [], 
    "importance": "Undecided", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/959340", 
    "owner": "None", 
    "id": 959340, 
    "index": 2706, 
    "created": "2012-03-19 14:36:56.881120+00:00", 
    "title": "Error restoring server -- race condition where old instance disk ID used in restore", 
    "comments": [
        {
            "content": "Found in nova-compute:\n\n2012-03-19 10:29:19 DEBUG nova.utils [-] Running cmd (subprocess): cp /opt/stack/nova/instances/_base/6b4b8998-743d-42c7-a635-05524b9e1240 /opt/stack/nova/instances/instance-0000001f/ramdisk from (pid=2161) execute /opt/stack/nova/nova/utils.py:217\n2012-03-19 10:29:19 DEBUG nova.virt.libvirt.connection [-] block_device_list [] from (pid=2161) _volume_in_mapping /opt/stack/nova/nova/virt/libvirt/connection.py:1300\n2012-03-19 10:29:19 DEBUG nova.utils [-] Attempting to grab semaphore \"092d586b5c34c0ad418d42872f22aa7cb60ef614\" for method \"call_if_not_exists\"... from (pid=2161) inner /opt/stack/nova/nova/utils.py:885\n2012-03-19 10:29:19 DEBUG nova.utils [-] Got semaphore \"092d586b5c34c0ad418d42872f22aa7cb60ef614\" for method \"call_if_not_exists\"... from (pid=2161) inner /opt/stack/nova/nova/utils.py:889\n2012-03-19 10:29:19 DEBUG nova.utils [-] Attempting to grab semaphore \"/opt/stack/nova/instances/_base/092d586b5c34c0ad418d42872f22aa7cb60ef614\" for method \"copy_and_extend\"... from (pid=2161) inner /opt/stack/nova/nova/utils.py:885\n2012-03-19 10:29:19 DEBUG nova.utils [-] Got semaphore \"/opt/stack/nova/instances/_base/092d586b5c34c0ad418d42872f22aa7cb60ef614\" for method \"copy_and_extend\"... from (pid=2161) inner /opt/stack/nova/nova/utils.py:889\n2012-03-19 10:29:19 DEBUG nova.utils [-] Running cmd (subprocess): qemu-img create -f qcow2 -o cluster_size=2M,backing_file=/opt/stack/nova/instances/_base/092d586b5c34c0ad418d42872f22aa7cb60ef614 /opt/stack/nova/instances/instance-0000001f/disk from (pid=2161) execute /opt/stack/nova/nova/utils.py:217\nlibvir: QEMU error : operation failed: cannot restore domain 'instance-0000001f' uuid 2453b24b-87e1-4f85-9c25-ce3706a8c1d1 from a file which belongs to domain 'instance-0000001f' uuid deb8e941-4693-4768-90cc-03ad98444c85\n2012-03-19 10:29:20 ERROR nova.compute.manager [-] [instance: 2453b24b-87e1-4f85-9c25-ce3706a8c1d1] Instance failed to spawn\n(nova.compute.manager): TRACE: Traceback (most recent call last):\n(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 592, in _spawn\n(nova.compute.manager): TRACE:     self._legacy_nw_info(network_info), block_device_info)\n(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/exception.py\", line 114, in wrapped\n(nova.compute.manager): TRACE:     return f(*args, **kw)\n(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 864, in spawn\n(nova.compute.manager): TRACE:     self._create_new_domain(xml)\n(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 1476, in _create_new_domain\n(nova.compute.manager): TRACE:     domain.createWithFlags(launch_flags)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 372, in createWithFlags\n(nova.compute.manager): TRACE:     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n(nova.compute.manager): TRACE: libvirtError: operation failed: cannot restore domain 'instance-0000001f' uuid 2453b24b-87e1-4f85-9c25-ce3706a8c1d1 from a file which belongs to domain 'instance-0000001f' uuid deb8e941-4693-4768-90cc-03ad98444c85\n(nova.compute.manager): TRACE: \n2012-03-19 10:29:20 DEBUG nova.compute.manager [-] [instance: 2453b24b-87e1-4f85-9c25-ce3706a8c1d1] Deallocating network for instance from (pid=2161) _deallocate_network /opt/stack/nova/nova/compute/manager.py:616\n2012-03-19 10:29:20 DEBUG nova.rpc.amqp [-] Making asynchronous cast on network... from (pid=2161) cast /opt/stack/nova/nova/rpc/amqp.py:346\n2012-03-19 10:29:20 ERROR nova.rpc.amqp [-] Exception during message handling\n(nova.rpc.amqp): TRACE: Traceback (most recent call last):\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/rpc/amqp.py\", line 252, in _process_data\n(nova.rpc.amqp): TRACE:     rval = node_func(context=ctxt, **node_args)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/exception.py\", line 114, in wrapped\n(nova.rpc.amqp): TRACE:     return f(*args, **kw)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 177, in decorated_function\n(nova.rpc.amqp): TRACE:     sys.exc_info())\n(nova.rpc.amqp): TRACE:   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n(nova.rpc.amqp): TRACE:     self.gen.next()\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 171, in decorated_function\n(nova.rpc.amqp): TRACE:     return function(self, context, instance_uuid, *args, **kwargs)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 648, in run_instance\n(nova.rpc.amqp): TRACE:     self._run_instance(context, instance_uuid, **kwargs)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 451, in _run_instance\n(nova.rpc.amqp): TRACE:     self._set_instance_error_state(context, instance_uuid)\n(nova.rpc.amqp): TRACE:   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n(nova.rpc.amqp): TRACE:     self.gen.next()\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 432, in _run_instance\n(nova.rpc.amqp): TRACE:     self._deallocate_network(context, instance)\n(nova.rpc.amqp): TRACE:   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n(nova.rpc.amqp): TRACE:     self.gen.next()\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 429, in _run_instance\n(nova.rpc.amqp): TRACE:     injected_files, admin_password)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 592, in _spawn\n(nova.rpc.amqp): TRACE:     self._legacy_nw_info(network_info), block_device_info)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/exception.py\", line 114, in wrapped\n(nova.rpc.amqp): TRACE:     return f(*args, **kw)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 864, in spawn\n(nova.rpc.amqp): TRACE:     self._create_new_domain(xml)\n(nova.rpc.amqp): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 1476, in _create_new_domain\n(nova.rpc.amqp): TRACE:     domain.createWithFlags(launch_flags)\n(nova.rpc.amqp): TRACE:   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 372, in createWithFlags\n(nova.rpc.amqp): TRACE:     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n(nova.rpc.amqp): TRACE: libvirtError: operation failed: cannot restore domain 'instance-0000001f' uuid 2453b24b-87e1-4f85-9c25-ce3706a8c1d1 from a file which belongs to domain 'instance-0000001f' uuid deb8e941-4693-4768-90cc-03ad98444c85\n\nA number of different tests in Tempest can trigger this issue. It does not happen every time a particular test is run, only about half the time, and seems to be a timing issue.\n\nThe code in the tests in question follow this pattern:\n\n1) Create a server via the Compute API, supplying an AMI image ID and a tiny flavor code\n2) Wait for the server to go into ACTIVE status\n\nThe code eventually hits a timeout, as the server goes into ERROR status after hitting the traceback shown above.", 
            "date_created": "2012-03-19 14:36:56.881120+00:00", 
            "author": "https://api.launchpad.net/1.0/~jaypipes"
        }, 
        {
            "content": "I refactored this code recently:\n\nhttps://review.openstack.org/#/c/8020/\n\n and I think it may have eliminated this race condition.  Can you verify that it still occurs with trunk? It is odd that the same instance number is getting two different uuids, so if it is still ocurring, we will have to track down how that is happening.", 
            "date_created": "2012-06-07 18:05:51.856090+00:00", 
            "author": "https://api.launchpad.net/1.0/~vishvananda"
        }, 
        {
            "content": "We cannot solve the issue you reported without more information. Could you please provide the requested information ?", 
            "date_created": "2012-07-12 14:09:55.384406+00:00", 
            "author": "https://api.launchpad.net/1.0/~ttx"
        }, 
        {
            "content": "This bug lacks the necessary information to effectively reproduce and fix it, therefore it has been closed. Feel free to reopen the bug by providing the requested information and set the bug status back to ''New''.", 
            "date_created": "2012-09-10 13:11:55.880174+00:00", 
            "author": "https://api.launchpad.net/1.0/~ttx"
        }
    ]
}