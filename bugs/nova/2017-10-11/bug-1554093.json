{
    "status": "Confirmed", 
    "last_updated": "2016-04-13 06:56:49.665862+00:00", 
    "description": "After a prolonged outage of >= 24 hours any cached images stored on shared instance storage are prone to removal as compute nodes race to complete a pass of the cache manager once the storage returns. \n\nThis pass of the cache manager first registers the current node as an active user of the instance store before compiling a list of instances on hosts registered to the instance store. This list then being used to determine which of the cached images can be safely removed.\n\nAfter a prolonged outage of >= 24 hours the first compute node to run a cache manager pass will only find itself listed as an active user of the instance store. Thus it can and likely will remove cached images for instances hosted on other compute nodes.\n\nIMHO additional care should be taken before calling for the removal of cached images for instances on registered but seemingly inactive compute nodes.", 
    "tags": [
        "compute", 
        "image-cache"
    ], 
    "importance": "Low", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1554093", 
    "owner": "None", 
    "id": 1554093, 
    "index": 700, 
    "created": "2016-03-07 15:24:51.239850+00:00", 
    "title": "Cached images incorrectly removed after instance storage comes back online after a prolonged >= 24 hour outage", 
    "comments": [
        {
            "content": "After a prolonged outage of >= 24 hours any cached images stored on shared instance storage are prone to removal as compute nodes race to complete a pass of the cache manager once the storage returns. \n\nThis pass of the cache manager first registers the current node as an active user of the instance store before compiling a list of instances on hosts registered to the instance store. This list then being used to determine which of the cached images can be safely removed.\n\nAfter a prolonged outage of >= 24 hours the first compute node to run a cache manager pass will only find itself listed as an active user of the instance store. Thus it can and likely will remove cached images for instances hosted on other compute nodes.\n\nIMHO additional care should be taken before calling for the removal of cached images for instances on registered but seemingly inactive compute nodes.", 
            "date_created": "2016-03-07 15:24:51.239850+00:00", 
            "author": "https://api.launchpad.net/1.0/~lyarwood"
        }, 
        {
            "content": "* Adding tag \"compute\" as it affects the compute manager at [1].\n\n> After a prolonged outage of >= 24 hours [...]\n\nThis is due to the config option:\n    DEFAULT.remove_unused_original_minimum_age_seconds = 86400\n\nReferences:\n[1] https://git.openstack.org/cgit/openstack/nova/tree/nova/compute/manager.py?id=56a8fe0cc7339ea08e3044406d67341a616eb843#n6683\n[2] http://docs.openstack.org/developer/nova/sample_config.html", 
            "date_created": "2016-03-10 10:33:44.176234+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "@Lee Yarwood:\nWe have different virt drivers which handle the cleanup differently.\nWhich driver (libvirt, vmware, ...) did you use? Please set the status\nback to \"new\" when you provide this information.", 
            "date_created": "2016-03-10 10:33:56.365489+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "Apologies for not highlighting this originally but I've yet to reproduce this against master, this report is currently based on a reported issue downstream (RHBZ#1310143).\n\n> We have different virt drivers which handle the cleanup differently.\n> Which driver (libvirt, vmware, ...) did you use? Please set the status\n> back to \"new\" when you provide this information.\n\nI'm using the libvirt driver but IMHO this race starts within the compute manager.\n\nWhen building the list of filtered_instances we first fetch a list of active hosts. At present this uses a hard coded value of 24 hours  [1] to determine if a registered node, that had previously written to the compute_nodes file is still active.\n\nThis becomes a problem after a prolonged outage as the first host to run a cache pass will potentially find that it is the only active host using the instance store. Thus all instances on the remaining hosts are deemed to be inactive, allowing the removal of any associated cached images, swap files etc.\n\n>> This is due to the config option:\n>>    DEFAULT.remove_unused_original_minimum_age_seconds = 86400\n\nThis configurable ultimately allows for these `unused` images to be removed but IMHO the actual issue is still between the compute manager and storage_users.\n\n[1] https://git.openstack.org/cgit/openstack/nova/tree/nova/virt/storage_users.py?id=f4dd117a81c68d9fb600dff456e1171841758b43#n76\n\n\n", 
            "date_created": "2016-03-10 13:42:49.202938+00:00", 
            "author": "https://api.launchpad.net/1.0/~lyarwood"
        }, 
        {
            "content": "The mentioned downstream bug report is documented at [1]. This report\nalso describes that the issue occurs when:\n* The original image was deleted in glance\n* The cached image in the shared storage got deleted\n* The instance gets rebooted\nCommit [2] introduced the logic due to bug 1078594 [3] in the \"Grizzly\"\nrelease. I haven't reproduced it but this report here sounds valid\nbut with an very low chance of happening.\n\nReferences:\n[1] https://bugzilla.redhat.com/show_bug.cgi?id=1310143\n[2] https://github.com/openstack/nova/commit/c2de33a0a2132774dc295861cef138ec24bb0cf9\n[3] https://bugs.launchpad.net/nova/+bug/1078594", 
            "date_created": "2016-03-11 08:59:11.533164+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "Can you please mention the version which  you found this error?", 
            "date_created": "2016-03-18 05:55:52.473708+00:00", 
            "author": "https://api.launchpad.net/1.0/~anseela-m00"
        }, 
        {
            "content": "The downstream issue was reported against Kilo however Newton still appears susceptible to this.", 
            "date_created": "2016-03-29 09:44:50.556441+00:00", 
            "author": "https://api.launchpad.net/1.0/~lyarwood"
        }
    ]
}