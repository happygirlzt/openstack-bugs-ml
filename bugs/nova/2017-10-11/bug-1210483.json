{
    "status": "Invalid", 
    "last_updated": "2015-01-20 08:36:44.768668+00:00", 
    "description": "2013-08-09 09:05:28.205 | ======================================================================\n2013-08-09 09:05:28.220 | FAIL: tempest.api.compute.servers.test_server_addresses.ServerAddressesTestXML.test_list_server_addresses[gate,smoke]\n2013-08-09 09:05:28.231 | ----------------------------------------------------------------------\n2013-08-09 09:05:28.232 | _StringException: Traceback (most recent call last):\n2013-08-09 09:05:28.232 |   File \"/opt/stack/new/tempest/tempest/api/compute/servers/test_server_addresses.py\", line 56, in test_list_server_addresses\n2013-08-09 09:05:28.232 |     self.assertTrue(len(addresses) >= 1)\n2013-08-09 09:05:28.233 |   File \"/usr/lib/python2.7/unittest/case.py\", line 420, in assertTrue\n2013-08-09 09:05:28.233 |     raise self.failureException(msg)\n2013-08-09 09:05:28.233 | AssertionError: False is not true\n\nhttp://logs.openstack.org/80/38980/2/check/gate-tempest-devstack-vm-neutron/1e116fa/", 
    "tags": [
        "gate-failure", 
        "havana-backport-potential", 
        "icehouse-backport-potential", 
        "l3-ipam-dhcp"
    ], 
    "importance": "Undecided", 
    "heat": 52, 
    "link": "https://bugs.launchpad.net/nova/+bug/1210483", 
    "owner": "None", 
    "id": 1210483, 
    "index": 3939, 
    "created": "2013-08-09 11:18:02.166613+00:00", 
    "title": "ServerAddressesTestXML.test_list_server_addresses FAIL", 
    "comments": [
        {
            "content": "2013-08-09 09:05:28.205 | ======================================================================\n2013-08-09 09:05:28.220 | FAIL: tempest.api.compute.servers.test_server_addresses.ServerAddressesTestXML.test_list_server_addresses[gate,smoke]\n2013-08-09 09:05:28.231 | ----------------------------------------------------------------------\n2013-08-09 09:05:28.232 | _StringException: Traceback (most recent call last):\n2013-08-09 09:05:28.232 |   File \"/opt/stack/new/tempest/tempest/api/compute/servers/test_server_addresses.py\", line 56, in test_list_server_addresses\n2013-08-09 09:05:28.232 |     self.assertTrue(len(addresses) >= 1)\n2013-08-09 09:05:28.233 |   File \"/usr/lib/python2.7/unittest/case.py\", line 420, in assertTrue\n2013-08-09 09:05:28.233 |     raise self.failureException(msg)\n2013-08-09 09:05:28.233 | AssertionError: False is not true\n\nhttp://logs.openstack.org/80/38980/2/check/gate-tempest-devstack-vm-neutron/1e116fa/", 
            "date_created": "2013-08-09 11:18:02.166613+00:00", 
            "author": "https://api.launchpad.net/1.0/~afazekas"
        }, 
        {
            "content": "This is another instance of neutron racing on allocating IP addresses, and our tests failing because the server is active before it has a valid IP. There may be other related bugs to this.", 
            "date_created": "2013-08-09 14:20:58.985156+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "IMHO:\n\nThere are two threads trying to update instance info_cache:\n1.periodic task:\n2013-08-09 09:01:43.965 30251 DEBUG nova.compute.manager [-] [instance: 2b92028f-fee4-43d3-b55a-80ced1dc3ff1] Updated the info_cache for instance _heal_instance_info_cache /opt/stack/new/nova/nova/compute/manager.py:4109\n\n\n2. instance creation process:\n    @refresh_cache\n    def allocate_for_instance(self, context, instance, **kwargs):\n\n2013-08-09 09:01:43.124 30251 DEBUG nova.network.neutronv2.api [-] allocate_for_instance() for ServerAddressesTestXML-instance1227692404 allocate_for_instance /opt/stack/new/nova/nova/network/neutronv2/api.py:169\n2013-08-09 09:01:43.708 30251 DEBUG neutronclient.client [-] RESP:{'date': 'Fri, 09 Aug 2013 09:01:43 GMT', 'status': '200', 'content-length': '611', 'content-type': 'application/json; charset=UTF-8', 'content-location': 'http://127.0.0.1:9696/v2.0/ports.json?tenant_id=b4c67f546ea94bba8427b1157a2b1f42&device_id=2b92028f-fee4-43d3-b55a-80ced1dc3ff1'} {\"ports\": [{\"status\": \"DOWN\", \"binding:host_id\": \"devstack-1376034070\", \"name\": \"\", \"admin_state_up\": true, \"network_id\": \"23071a9a-1432-4d75-805d-4fbbf4b2b967\", \"tenant_id\": \"b4c67f546ea94bba8427b1157a2b1f42\", \"binding:vif_type\": \"ovs\", \"device_owner\": \"compute:None\", \"binding:capabilities\": {\"port_filter\": true}, \"mac_address\": \"fa:16:3e:0b:57:ad\", \"fixed_ips\": [{\"subnet_id\": \"53159554-9944-4983-9f3d-ed17e53e3ca5\", \"ip_address\": \"10.1.0.13\"}], \"id\": \"368091ff-b7d7-4485-859b-1b4bb211778a\", \"security_groups\": [\"e959cf62-9a51-4645-b98b-ea2523627123\"], \"device_id\": \"2b92028f-fee4-43d3-b55a-80ced1dc3ff1\"}]}\n\nthe API used by this tempest test relies on info_cache updated by these two threads. The result is not deterministic, but in the end the info_cache will be consistent.\n\nso to write this smoke test, I suggest,  we wait for two cycles of CONF.heal_instance_info_cache_interval.\n", 
            "date_created": "2013-08-14 10:15:52.333021+00:00", 
            "author": "https://api.launchpad.net/1.0/~gongysh"
        }, 
        {
            "content": "review link: https://review.openstack.org/#/c/42472/", 
            "date_created": "2013-08-17 14:50:21.033460+00:00", 
            "author": "https://api.launchpad.net/1.0/~zhhuabj"
        }, 
        {
            "content": "It does not sounds good.\n\nLooks like the nova when using neutron provides invalid information to the end users without any clue the info is not fresh.\nI wonder is this information refreshed before a floating-ip-assocition request sent to the neutron ? \n\nVM can exists without a known address, how can I distinguish that situation, from a just waiting for some internal process or I do not have an address?\n\nIMHO the address should be updated before the VM reaches the ACTIVE status or at the first address query after it is ACTIVE.\n", 
            "date_created": "2013-08-21 07:01:03.659205+00:00", 
            "author": "https://api.launchpad.net/1.0/~afazekas"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/43279", 
            "date_created": "2013-08-22 12:12:49.996389+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/43279\nCommitted: http://github.com/openstack/nova/commit/c51f23834db599558098e38a7b4ccd7ef1c49a95\nSubmitter: Jenkins\nBranch:    master\n\ncommit c51f23834db599558098e38a7b4ccd7ef1c49a95\nAuthor: zhhuabj <email address hidden>\nDate:   Thu Aug 22 20:11:08 2013 +0800\n\n    Should finish allocating network before VM reaches ACTIVE\n    \n    This patch can fix issues like tempest caused by async\n    network allocation. Nova uses NetworkInfoAsyncWrapper\n    to allocate network in an async manner, and this allows\n    one to start querying for network info before you know\n    you will need it. Nova will invoke refresh_cache method\n    to update instance_cache_info after excuting the\n    allocate_for_instance method as well.\n    \n    However, nova rest api will query instance_cache_info\n    directly, thus maybe get the empty network info before\n    instance_cache_info table has been updated asynchronously.\n    Thus will cause VM can exist without a known address\n    accidentally, the caller is difficult to distinguish\n    this situation, unless waiting for some internal process\n    or it will not have an address. So should finish\n    allocating network before the VM reaches ACTIVE status.\n    For more detail can refer the bug description.\n    \n    BTW, almost all create server related unit tests have\n    coverred this case.\n    \n    Closes-Bug: #1210483\n    Change-Id: Iab542df1be7d5c9661d717ec596d2a37b975169a\n", 
            "date_created": "2013-09-18 22:03:21.718579+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "\n\nI am out of the office until 10/07/2013.\n\nI will take vacation from 28th Sep to 7th Oct . If have any urgent, please\ncall 13910806810\n\n\nNote: This is an automated response to your message  \"[Bug 1210483] Re:\nServerAddressesTestXML.test_list_server_addresses\tFAIL\" sent on\n10/03/2013 16:00:02.\n\nThis is the only notification you will receive while this person is away.", 
            "date_created": "2013-10-03 14:19:40+00:00", 
            "author": "https://api.launchpad.net/1.0/~zhikunliu"
        }, 
        {
            "content": "This is marked as Fix Released but seems to have happened recently here https://review.openstack.org/#/c/50052/", 
            "date_created": "2013-10-22 19:36:37.152845+00:00", 
            "author": "https://api.launchpad.net/1.0/~david-kranz"
        }, 
        {
            "content": "This is not a tempest bug.\n\nThe network info should be available when it is queried.\n Now the nova should fill the nw_info before reporting an ACTIVE state. Tempest only quires the address of an ACTIVE instance.", 
            "date_created": "2013-11-12 12:50:44.262753+00:00", 
            "author": "https://api.launchpad.net/1.0/~afazekas"
        }, 
        {
            "content": "I just hit this here so it's obviously not fixed:\n\nhttp://logs.openstack.org/42/56642/2/gate/gate-tempest-devstack-vm-neutron/a712b82/", 
            "date_created": "2013-11-22 00:02:38.110689+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Looks like it starts showing up again on 11/9, unless my query is not restrictive enough:\n\nhttp://bit.ly/19MyhEq", 
            "date_created": "2013-11-22 02:32:46.654982+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "So the original 'fix' for this bug was merged on 9/18, David Kranz reported seeing it again on 10/22, and this was merged on 10/14 which was related to the network info cache code (which has other bugs breaking the check/gate queues this week), so maybe a culprit?\n\nhttps://review.openstack.org/51401", 
            "date_created": "2013-11-22 02:39:36.398452+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "This is really not a tempest issue, it's a neutron race from what I can figure out (possibly a nova interaction as well).", 
            "date_created": "2013-11-25 16:36:20.533064+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "I believe the patch https://review.openstack.org/#/c/43279/ can fix async network allocation problem well on nova side, \nif the issue still exist, may be because neutron can't provide network service in that time, so not sure if this patch (https://review.openstack.org/#/c/57509) can fix this issue.", 
            "date_created": "2013-11-26 08:28:15.135849+00:00", 
            "author": "https://api.launchpad.net/1.0/~zhhuabj"
        }, 
        {
            "content": "The patch https://review.openstack.org/#/c/57509 was merged on Nov 21, 2013, I think we can observe if has the same report since that day.", 
            "date_created": "2013-11-27 00:05:18.993006+00:00", 
            "author": "https://api.launchpad.net/1.0/~zhhuabj"
        }, 
        {
            "content": "Is there anything in the nova or neutron logs that we can use as a fingerprint for this bug? If so we can add it to elastic-recheck", 
            "date_created": "2013-12-06 14:03:50.512261+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Joe, looks like it's already showing up:\n\nhttp://status.openstack.org/elastic-recheck/\n\nhttps://review.openstack.org/gitweb?p=openstack-infra/elastic-recheck.git;a=blob;f=queries/1210483.yaml;h=a937ae7e8a4830edbfc6e957c264952514fdb65c;hb=refs/heads/master", 
            "date_created": "2013-12-06 14:28:00.238211+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Looking at the log file that Matt R referenced above, I did some digging around and there's a traceback in there around not being able to set the network info cache:\n\n2013-11-21 23:15:52.403 ERROR nova.network.api [req-b2745c05-f148-4a09-aa34-ffa8d7d9d1cd demo demo] [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95] Failed storing info cache\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95] Traceback (most recent call last):\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/network/api.py\", line 74, in update_instance_cache_with_nw_info\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     nw_info = api._get_instance_nw_info(context, instance)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/network/api.py\", line 49, in wrapper\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     res = f(self, context, *args, **kwargs)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/network/neutronv2/api.py\", line 456, in _get_instance_nw_info\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     nw_info = self._build_network_info_model(context, instance, networks)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/network/neutronv2/api.py\", line 984, in _build_network_info_model\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     context, instance['uuid'])['info_cache']['network_info']\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/conductor/api.py\", line 74, in instance_get_by_uuid\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     columns_to_join)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/conductor/rpcapi.py\", line 165, in instance_get_by_uuid\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     return cctxt.call(context, 'instance_get_by_uuid', **kwargs)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/rpcclient.py\", line 85, in call\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     return self._invoke(self.proxy.call, ctxt, method, **kwargs)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/rpcclient.py\", line 63, in _invoke\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     return cast_or_call(ctxt, msg, **self.kwargs)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/proxy.py\", line 126, in call\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     result = rpc.call(context, real_topic, msg, timeout)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/__init__.py\", line 139, in call\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     return _get_impl().call(CONF, context, topic, msg, timeout)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/impl_kombu.py\", line 816, in call\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     rpc_amqp.get_connection_pool(conf, Connection))\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/amqp.py\", line 572, in call\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     rv = multicall(conf, context, topic, msg, timeout, connection_pool)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/amqp.py\", line 566, in multicall\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     conn.topic_send(topic, rpc_common.serialize_msg(msg), timeout)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/impl_kombu.py\", line 720, in topic_send\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     self.publisher_send(TopicPublisher, topic, msg, timeout)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/impl_kombu.py\", line 691, in publisher_send\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     self.ensure(_error_callback, _publish)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/impl_kombu.py\", line 577, in ensure\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     return method(*args, **kwargs)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/impl_kombu.py\", line 688, in _publish\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     publisher = cls(self.conf, self.channel, topic, **kwargs)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/impl_kombu.py\", line 369, in __init__\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     **options)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/impl_kombu.py\", line 316, in __init__\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     self.reconnect(channel)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/opt/stack/new/nova/nova/openstack/common/rpc/impl_kombu.py\", line 324, in reconnect\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     routing_key=self.routing_key)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/usr/local/lib/python2.7/dist-packages/kombu/messaging.py\", line 82, in __init__\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     self.revive(self._channel)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/usr/local/lib/python2.7/dist-packages/kombu/messaging.py\", line 216, in revive\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     self.declare()\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/usr/local/lib/python2.7/dist-packages/kombu/messaging.py\", line 102, in declare\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     self.exchange.declare()\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/usr/local/lib/python2.7/dist-packages/kombu/entity.py\", line 166, in declare\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     nowait=nowait, passive=passive,\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/usr/local/lib/python2.7/dist-packages/amqp/channel.py\", line 612, in exchange_declare\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     (40, 11),  # Channel.exchange_declare_ok\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/usr/local/lib/python2.7/dist-packages/amqp/abstract_channel.py\", line 73, in wait\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     self.channel_id, allowed_methods)\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/usr/local/lib/python2.7/dist-packages/amqp/connection.py\", line 220, in _wait_method\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     self.method_reader.read_method()\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]   File \"/usr/local/lib/python2.7/dist-packages/amqp/method_framing.py\", line 195, in read_method\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95]     raise m\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95] RuntimeError: maximum recursion depth exceeded while calling a Python object\n2013-11-21 23:15:52.403 4036 TRACE nova.network.api [instance: d3bd703c-a3f4-4e83-8ab0-a2f3e603ec95] \n\nThe traceback indicates that perhaps there is a recursion limit in the amqp method_framing.read_method function?\n", 
            "date_created": "2013-12-27 03:13:20.301689+00:00", 
            "author": "https://api.launchpad.net/1.0/~jaypipes"
        }, 
        {
            "content": "No occurrences for the last 3 weeks. Lowering to 'Medium'", 
            "date_created": "2014-01-27 21:20:56.243905+00:00", 
            "author": "https://api.launchpad.net/1.0/~enikanorov"
        }, 
        {
            "content": "> No occurrences for the last 3 weeks. Lowering to 'Medium'\n\nWas there a fix on master, if so please backport, it was seen in stable/havana http://logs.openstack.org/14/67214/3/check/check-tempest-dsvm-neutron-pg-isolated/9287c4d/logs/testr_results.html.gz", 
            "date_created": "2014-02-01 23:14:10.268702+00:00", 
            "author": "https://api.launchpad.net/1.0/~apevec"
        }, 
        {
            "content": "\n\nI am out of the office until 02/14/2014.\n\nZhangHua will leave for Spring Festival from Jan 29 to Feb 14, any argent\ncan reach me via 158-110-220-56, Hope everyone a happy holiday.\n\n\nNote: This is an automated response to your message  \"[Bug 1210483] Re:\nServerAddressesTestXML.test_list_server_addresses FAIL\" sent on 02/02/2014\n7:01:15.\n\nThis is the only notification you will receive while this person is away.", 
            "date_created": "2014-02-02 02:00:29+00:00", 
            "author": "https://api.launchpad.net/1.0/~zhhuabj"
        }, 
        {
            "content": "Just hit this again:\n\nhttp://logs.openstack.org/84/71184/3/check/check-tempest-dsvm-neutron/46c7a06/console.html", 
            "date_created": "2014-02-15 19:37:50.839952+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Thanks Matt,\nI investigated the log you pointed.\n\nThe summary:\nProblem server_id: 78fe9cfd-1f0b-4d0a-8164-4b752e759246\n2014-02-15 16:52:03.587: (tempest.log): received a response of \"create server\" API\n2014-02-15 16:52:03.743: (n-api.log): from Neutron: {\"ports\": []}\n2014-02-15 16:52:04.878: (n-api.log): from Neutron: {\"ports\": [{\"status\": \"DOWN\", \"name\": \"\", \"allowed_address_pairs\": [] ..\n2014-02-15 16:52:06.088: (n-api.log): from Neutron: {\"ports\": [{\"status\": \"DOWN\", \"name\": \"\", \"allowed_address_pairs\": [] ..\n2014-02-15 16:52:07.232: (n-api.log): from Neutron: {\"ports\": [{\"status\": \"DOWN\", \"name\": \"\", \"allowed_address_pairs\": [] ..\n2014-02-15 16:52:08.348: (n-api.log): from Neutron: {\"ports\": [{\"status\": \"DOWN\", \"name\": \"\", \"allowed_address_pairs\": [] ..\n2014-02-15 16:52:08.371: (tempest.log): received a response of server status \"ACTIVE\"\n2014-02-15 16:52:08,502: (testr.log): The test failed because the response of \"get ips\" did not contain addresses info.\n\nAccording to Russell's Nova meetup summary[1], there is asynchronous between Nova and Neutron during server creation.\nThis problem seems due to that.\n\n[1]: http://lists.openstack.org/pipermail/openstack-dev/2014-February/027370.html", 
            "date_created": "2014-02-18 00:18:54.458468+00:00", 
            "author": "https://api.launchpad.net/1.0/~oomichi"
        }, 
        {
            "content": "Ken'ichi, so should we skip the test if configured with neutron?  There are 44 hits on this failure in the last 7 days:\n\nhttp://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwic2VsZi5hc3NlcnRUcnVlKGxlbihhZGRyZXNzZXMpID49IDEpXCIgQU5EIGZpbGVuYW1lOlwiY29uc29sZS5odG1sXCIiLCJmaWVsZHMiOltdLCJvZmZzZXQiOjAsInRpbWVmcmFtZSI6IjYwNDgwMCIsImdyYXBobW9kZSI6ImNvdW50IiwidGltZSI6eyJ1c2VyX2ludGVydmFsIjowfSwic3RhbXAiOjEzOTI3NDQ2NTE0NjB9\n\nLooking at the build_name it's definitely a neutron problem.  If we're looking to fix the info cache races and vif ready state in Icehouse, then we should be able to remove the skip on the test if it's fixed before the end of the release.", 
            "date_created": "2014-02-18 17:33:14.751134+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "This is the blueprint I was thinking of:\n\nhttps://blueprints.launchpad.net/nova/+spec/check-neutron-port-status", 
            "date_created": "2014-02-18 20:38:45.799589+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Confirming that tempest v2 and v3 versions of this test both fail:\n\nhttp://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwiRkFJTFxcOiB0ZW1wZXN0LmFwaS5jb21wdXRlLnYzLnNlcnZlcnMudGVzdF9zZXJ2ZXJfYWRkcmVzc2VzLlNlcnZlckFkZHJlc3Nlc1YzVGVzdC50ZXN0X2xpc3Rfc2VydmVyX2FkZHJlc3Nlc1wiIEFORCBmaWxlbmFtZTpcImNvbnNvbGUuaHRtbFwiIiwiZmllbGRzIjpbXSwib2Zmc2V0IjowLCJ0aW1lZnJhbWUiOiI2MDQ4MDAiLCJncmFwaG1vZGUiOiJjb3VudCIsInRpbWUiOnsidXNlcl9pbnRlcnZhbCI6MH0sInN0YW1wIjoxMzkyNzU3NjEyNjM1fQ==", 
            "date_created": "2014-02-18 21:08:09.064363+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I have a patch up in tempest to skip the tests for now if using neutron: https://review.openstack.org/#/c/74504/", 
            "date_created": "2014-02-18 21:55:42.533825+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Matt,\n\nI agree with you.\nThe skipped tests of your patch are only 2 tests in neutron gate.\nThat is reasonable for me.", 
            "date_created": "2014-02-18 23:48:15.004504+00:00", 
            "author": "https://api.launchpad.net/1.0/~oomichi"
        }, 
        {
            "content": "Was this addressed by the admin event extension?", 
            "date_created": "2014-09-18 23:51:40.685084+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "Probably, let's re-enable the test now.", 
            "date_created": "2014-10-15 21:31:21.758751+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Tempest change to enable the tests again: https://review.openstack.org/#/c/128772/", 
            "date_created": "2014-10-15 21:40:36.928252+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Apparently this bug is not valid for neutron anymore. The test has been enabled, no failures encountered with it.", 
            "date_created": "2014-11-21 12:01:40.521147+00:00", 
            "author": "https://api.launchpad.net/1.0/~enikanorov"
        }, 
        {
            "content": "XML API tests are removed already, so this bug doesn't happen now.", 
            "date_created": "2015-01-20 08:35:38.687464+00:00", 
            "author": "https://api.launchpad.net/1.0/~oomichi"
        }
    ]
}