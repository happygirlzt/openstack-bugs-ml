{
    "status": "Won't Fix", 
    "last_updated": "2016-02-18 00:30:12.880622+00:00", 
    "description": "I just booted 46 nodes at once from a single Ironic conductor/Nova/keystone etc all in one cloud.\n\nAfter this, according to Ironic:\n\n - 1 node was in maintenance mode (see bug 1326279) 5 have instance_uuid None and the rest are active.\n\nBut according to Nova:\n\n - 8 are in ERROR spawning:\n(in nova) | eb0e1255-4da5-46cb-b8e4-d3e1059e1087 | hw-test-eb0e1255-4da5-46cb-b8e4-d3e1059e1087 | ERROR  | spawning   | NOSTATE     |                       |\n(in ironic) | ebd0e2c1-7630-4067-94c1-81771c1680b6 | eb0e1255-4da5-46cb-b8e4-d3e1059e1087 | power on    | active             | False       |\n(see bug 1341346)\n\n - 5 are in ERROR NOSTATE:\n(nova)| c389bb7b-1760-4e69-a4ea-0aea07ccd4d8 | hw-test-c389bb7b-1760-4e69-a4ea-0aea07ccd4d8 | ERROR  | -          | NOSTATE     | ctlplane=10.10.16.146 |\nnova show shows us that it has a hypervisor \n| OS-EXT-SRV-ATTR:hypervisor_hostname  | 8bc4357a-6b32-47de-b3ee-cec5b41e72d2       \nbut in ironic there is no instance uuid (nor a deployment dict..):\n| 8bc4357a-6b32-47de-b3ee-cec5b41e72d2 | None                                 | power off   | None               | False       |\n\nThis bug is about the Nova instance having a hypervisor attribute that is wrong :) \n\nI have logs for this copied inside the DC, but a) its a production environment, so only tripleo-cd-admins can look (due to me being concened about passwords being in the logs) and b) they are 2.6GB in size, so its not all that feasible to attach them to the bug anyhow :).", 
    "tags": [
        "ironic", 
        "nova-driver"
    ], 
    "importance": "Low", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1341347", 
    "owner": "None", 
    "id": 1341347, 
    "index": 39, 
    "created": "2014-07-13 20:09:29.538947+00:00", 
    "title": "failed Ironic deploys can have incorrect hypervisor attribute in Nova", 
    "comments": [
        {
            "content": "I just booted 46 nodes at once from a single Ironic conductor/Nova/keystone etc all in one cloud.\n\nAfter this, according to Ironic:\n\n - 1 node was in maintenance mode (see bug 1326279) 5 have instance_uuid None and the rest are active.\n\nBut according to Nova:\n\n - 8 are in ERROR spawning:\n(in nova) | eb0e1255-4da5-46cb-b8e4-d3e1059e1087 | hw-test-eb0e1255-4da5-46cb-b8e4-d3e1059e1087 | ERROR  | spawning   | NOSTATE     |                       |\n(in ironic) | ebd0e2c1-7630-4067-94c1-81771c1680b6 | eb0e1255-4da5-46cb-b8e4-d3e1059e1087 | power on    | active             | False       |\n(see bug 1341346)\n\n - 5 are in ERROR NOSTATE:\n(nova)| c389bb7b-1760-4e69-a4ea-0aea07ccd4d8 | hw-test-c389bb7b-1760-4e69-a4ea-0aea07ccd4d8 | ERROR  | -          | NOSTATE     | ctlplane=10.10.16.146 |\nnova show shows us that it has a hypervisor \n| OS-EXT-SRV-ATTR:hypervisor_hostname  | 8bc4357a-6b32-47de-b3ee-cec5b41e72d2       \nbut in ironic there is no instance uuid (nor a deployment dict..):\n| 8bc4357a-6b32-47de-b3ee-cec5b41e72d2 | None                                 | power off   | None               | False       |\n\nThis bug is about the Nova instance having a hypervisor attribute that is wrong :) \n\nI have logs for this copied inside the DC, but a) its a production environment, so only tripleo-cd-admins can look (due to me being concened about passwords being in the logs) and b) they are 2.6GB in size, so its not all that feasible to attach them to the bug anyhow :).", 
            "date_created": "2014-07-13 20:09:29.538947+00:00", 
            "author": "https://api.launchpad.net/1.0/~lifeless"
        }, 
        {
            "content": "for tripleo-cd-admins, logs are in the hp1 region undercloud in /var/log/bug-1341346-and-1341347/", 
            "date_created": "2014-07-13 20:12:59.152968+00:00", 
            "author": "https://api.launchpad.net/1.0/~lifeless"
        }, 
        {
            "content": "I tend to think the instance should always be tagged with a \"hypervisor\" for a record of where it was built. In the past this could cause problems with the resource tracker, but those are long solved.\n\nThere's also the part of this where the logs are likely gone by now, tripleo has changed its architecture up, etc. This is likely to be hard to reproduce, even if we think it is a bug.\n\nGoing to close this as WONTFIX, feel free to reopen if you think I'm a terrible person :)", 
            "date_created": "2016-02-18 00:29:52.453655+00:00", 
            "author": "https://api.launchpad.net/1.0/~jim-rollenhagen"
        }
    ]
}