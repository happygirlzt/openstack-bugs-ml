{
    "status": "Fix Released", 
    "last_updated": "2013-11-05 07:04:08.976867+00:00", 
    "description": "Sometimes on Instance deletion the following error is logged:\n\n2012-08-22 11:16:10 AUDIT nova.compute.manager [req-ba764e1d-36e0-4479-988e-7dc15fe47c29 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] [\ninstance: 9ea4c222-e36d-468a-85b3-4aafd24eff9a] Terminating instance\n2012-08-22 11:16:14 WARNING nova.virt.libvirt.connection [req-ba764e1d-36e0-4479-988e-7dc15fe47c29 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca490\n0211856] [instance: 9ea4c222-e36d-468a-85b3-4aafd24eff9a] Error from libvirt during saved instance removal. Code=3 Error=this function is not supported by th\ne connection driver: virDomainHasManagedSaveImage\n2012-08-22 11:16:14 INFO nova.virt.libvirt.connection [req-ba764e1d-36e0-4479-988e-7dc15fe47c29 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca490021\n1856] [instance: 9ea4c222-e36d-468a-85b3-4aafd24eff9a] Deleting instance files /var/lib/nova/instances/f9226d17-1bfe-4819-b440-939e7635ed50/instance-0000000c\n2012-08-22 11:16:14 ERROR nova.rpc.amqp [req-ba764e1d-36e0-4479-988e-7dc15fe47c29 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Exceptio\nn during message handling\n2012-08-22 11:16:14 TRACE nova.rpc.amqp Traceback (most recent call last):\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/rpc/amqp.py\", line 253, in _process_data\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     rval = node_func(context=ctxt, **node_args)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/exception.py\", line 114, in wrapped\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     return f(*args, **kw)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 162, in decorated_function\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     function(self, context, instance_uuid, *args, **kwargs)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 186, in decorated_function\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     sys.exc_info())\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/contextlib.py\", line 23, in __exit__\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     self.gen.next()\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 180, in decorated_function\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     return function(self, context, instance_uuid, *args, **kwargs)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 769, in terminate_instance\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     do_terminate_instance()\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/utils.py\", line 945, in inner\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     retval = f(*args, **kwargs)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 762, in do_terminate_instance\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     self._delete_instance(context, instance)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 740, in _delete_instance\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     self._shutdown_instance(context, instance, 'Terminating')\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 709, in _shutdown_instance\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     block_device_info)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py\", line 515, in destroy\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     cleanup=True)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py\", line 509, in _destroy\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     self._cleanup(instance)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py\", line 524, in _cleanup\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     shutil.rmtree(target)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/shutil.py\", line 221, in rmtree\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     onerror(os.rmdir, path, sys.exc_info())\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/shutil.py\", line 219, in rmtree\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     os.rmdir(path)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp OSError: [Errno 39] Directory not empty: '/var/lib/nova/instances/f9226d17-1bfe-4819-b440-939e7635ed50/instance-00000\n00c'\n2012-08-22 11:16:14 TRACE nova.rpc.amqp\n2012-08-22 11:16:15 INFO nova.virt.libvirt.connection [-] [instance: 9ea4c222-e36d-468a-85b3-4aafd24eff9a] Instance destroyed successfully.\n\nThe instance stays in the \"deleting\" task_state and another api call then deletes it successfully. We store instance files on a NFS mount, and shutil.rmtree has a known (as in: google is full of it) problem on NFS when the files that are to be deleted are still opened by someone. The nfs-client renames the open file to .nfs0000... and will automatically delete it once it is no longer open. Since there are indeed .nfs000... files in the directory rmdir fails.\n\nThe following is shortened output of a repeating directory listing, where you can see how the image files are first renamed and then disappear.\n\ndrwxr-xr-x   2 root root        4096 Aug 21 10:44 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-rw----   1 root root           0 Aug 21 10:43 console.log\n-rw-r--r--   1 root root 23622320128 Aug 22 11:16 disk\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 disk.swap\n-rw-r--r--   1 root root        1689 Aug 21 10:43 libvirt.xml\ntotal 6074632\ndrwxr-xr-x   2 root root        4096 Aug 21 10:44 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-rw----   1 root root           0 Aug 21 10:43 console.log\n-rw-r--r--   1 root root 23622320128 Aug 22 11:16 disk\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 disk.swap\n-rw-r--r--   1 root root        1689 Aug 21 10:43 libvirt.xml\ntotal 6074628\ndrwxr-xr-x   2 root root        4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-r--r--   1 root root 23622320128 Aug 22 11:16 .nfs0000000000004f8400000001\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 .nfs0000000000004f8600000002\ntotal 6074628\ndrwxr-xr-x   2 root root        4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-r--r--   1 root root 23622320128 Aug 22 11:16 .nfs0000000000004f8400000001\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 .nfs0000000000004f8600000002\ntotal 6074628\ndrwxr-xr-x   2 root root        4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 .nfs0000000000004f8600000002\ntotal 52\ndrwxr-xr-x   2 root root        4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 .nfs0000000000004f8600000002\ntotal 52\ndrwxr-xr-x   2 root root  4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root 28672 Aug 22 10:35 ..\ntotal 36\ndrwxr-xr-x   2 root root  4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root 28672 Aug 22 10:35 ..\ntotal 36", 
    "tags": [
        "ops"
    ], 
    "importance": "Medium", 
    "heat": 20, 
    "link": "https://bugs.launchpad.net/nova/+bug/1040110", 
    "owner": "https://api.launchpad.net/1.0/~mikal", 
    "id": 1040110, 
    "index": 3020, 
    "created": "2012-08-22 14:55:24.994050+00:00", 
    "title": "Deleting instance files sometimes fails on NFS", 
    "comments": [
        {
            "content": "Sometimes on Instance deletion the following error is logged:\n\n2012-08-22 11:16:10 AUDIT nova.compute.manager [req-ba764e1d-36e0-4479-988e-7dc15fe47c29 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] [\ninstance: 9ea4c222-e36d-468a-85b3-4aafd24eff9a] Terminating instance\n2012-08-22 11:16:14 WARNING nova.virt.libvirt.connection [req-ba764e1d-36e0-4479-988e-7dc15fe47c29 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca490\n0211856] [instance: 9ea4c222-e36d-468a-85b3-4aafd24eff9a] Error from libvirt during saved instance removal. Code=3 Error=this function is not supported by th\ne connection driver: virDomainHasManagedSaveImage\n2012-08-22 11:16:14 INFO nova.virt.libvirt.connection [req-ba764e1d-36e0-4479-988e-7dc15fe47c29 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca490021\n1856] [instance: 9ea4c222-e36d-468a-85b3-4aafd24eff9a] Deleting instance files /var/lib/nova/instances/f9226d17-1bfe-4819-b440-939e7635ed50/instance-0000000c\n2012-08-22 11:16:14 ERROR nova.rpc.amqp [req-ba764e1d-36e0-4479-988e-7dc15fe47c29 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Exceptio\nn during message handling\n2012-08-22 11:16:14 TRACE nova.rpc.amqp Traceback (most recent call last):\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/rpc/amqp.py\", line 253, in _process_data\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     rval = node_func(context=ctxt, **node_args)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/exception.py\", line 114, in wrapped\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     return f(*args, **kw)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 162, in decorated_function\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     function(self, context, instance_uuid, *args, **kwargs)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 186, in decorated_function\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     sys.exc_info())\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/contextlib.py\", line 23, in __exit__\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     self.gen.next()\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 180, in decorated_function\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     return function(self, context, instance_uuid, *args, **kwargs)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 769, in terminate_instance\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     do_terminate_instance()\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/utils.py\", line 945, in inner\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     retval = f(*args, **kwargs)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 762, in do_terminate_instance\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     self._delete_instance(context, instance)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 740, in _delete_instance\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     self._shutdown_instance(context, instance, 'Terminating')\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 709, in _shutdown_instance\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     block_device_info)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py\", line 515, in destroy\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     cleanup=True)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py\", line 509, in _destroy\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     self._cleanup(instance)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py\", line 524, in _cleanup\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     shutil.rmtree(target)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/shutil.py\", line 221, in rmtree\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     onerror(os.rmdir, path, sys.exc_info())\n2012-08-22 11:16:14 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/shutil.py\", line 219, in rmtree\n2012-08-22 11:16:14 TRACE nova.rpc.amqp     os.rmdir(path)\n2012-08-22 11:16:14 TRACE nova.rpc.amqp OSError: [Errno 39] Directory not empty: '/var/lib/nova/instances/f9226d17-1bfe-4819-b440-939e7635ed50/instance-00000\n00c'\n2012-08-22 11:16:14 TRACE nova.rpc.amqp\n2012-08-22 11:16:15 INFO nova.virt.libvirt.connection [-] [instance: 9ea4c222-e36d-468a-85b3-4aafd24eff9a] Instance destroyed successfully.\n\nThe instance stays in the \"deleting\" task_state and another api call then deletes it successfully. We store instance files on a NFS mount, and shutil.rmtree has a known (as in: google is full of it) problem on NFS when the files that are to be deleted are still opened by someone. The nfs-client renames the open file to .nfs0000... and will automatically delete it once it is no longer open. Since there are indeed .nfs000... files in the directory rmdir fails.\n\nThe following is shortened output of a repeating directory listing, where you can see how the image files are first renamed and then disappear.\n\ndrwxr-xr-x   2 root root        4096 Aug 21 10:44 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-rw----   1 root root           0 Aug 21 10:43 console.log\n-rw-r--r--   1 root root 23622320128 Aug 22 11:16 disk\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 disk.swap\n-rw-r--r--   1 root root        1689 Aug 21 10:43 libvirt.xml\ntotal 6074632\ndrwxr-xr-x   2 root root        4096 Aug 21 10:44 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-rw----   1 root root           0 Aug 21 10:43 console.log\n-rw-r--r--   1 root root 23622320128 Aug 22 11:16 disk\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 disk.swap\n-rw-r--r--   1 root root        1689 Aug 21 10:43 libvirt.xml\ntotal 6074628\ndrwxr-xr-x   2 root root        4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-r--r--   1 root root 23622320128 Aug 22 11:16 .nfs0000000000004f8400000001\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 .nfs0000000000004f8600000002\ntotal 6074628\ndrwxr-xr-x   2 root root        4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-r--r--   1 root root 23622320128 Aug 22 11:16 .nfs0000000000004f8400000001\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 .nfs0000000000004f8600000002\ntotal 6074628\ndrwxr-xr-x   2 root root        4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 .nfs0000000000004f8600000002\ntotal 52\ndrwxr-xr-x   2 root root        4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root       28672 Aug 22 10:35 ..\n-rw-r--r--   1 root root 34359738368 Aug 21 10:44 .nfs0000000000004f8600000002\ntotal 52\ndrwxr-xr-x   2 root root  4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root 28672 Aug 22 10:35 ..\ntotal 36\ndrwxr-xr-x   2 root root  4096 Aug 22 11:16 .\ndrwxr-xr-x 167 root root 28672 Aug 22 10:35 ..\ntotal 36", 
            "date_created": "2012-08-22 14:55:24.994050+00:00", 
            "author": "https://api.launchpad.net/1.0/~lgesslein"
        }, 
        {
            "content": "These .nfs files are apparently created when you delete a file on NFS that is still held open by a process:\n\nhttp://librelist.com/browser//libgit2/2012/4/3/file-locking-in-libgit2/#7a19b8c37c5235ddfd60ff8a137c94ef\n\nSo, we need to figure out why the file is still open.\n\nThis is interesting:\n\n  Error from libvirt during saved instance removal. Code=3 Error=this function is not supported by the connection driver: virDomainHasManagedSaveImage\n\nand could indicate another problem\n\nWhat exact versions of OpenStack components are you using? What version of libvirt and what distro?\n\nCould you enable debugging (debug=true in nova.conf) and attach the full compute log?", 
            "date_created": "2012-08-22 16:29:28.139597+00:00", 
            "author": "https://api.launchpad.net/1.0/~markmc"
        }, 
        {
            "content": "We are running nova 2012.1.2, libvirt 0.9.6, hypervisor is XEN (which i think is the only cause for the function not supported thing), and all this is happening on SLES 11 SP2.  lsof +D does not list open files on the instance storage path while the VM is running, I was not yet quick enough to capture which process has open file handles while terminating. Here is the full debug log:\r\n\r\n\r\n2012-08-27 10:14:07 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 4783ef04-e521-451b-9ace-743c5ecc326c] Checking state from (pid=21989) _get_power_state /usr/lib64/python2.6/site-packages/nova/compute/manager.py:282\r\n2012-08-27 10:14:07 DEBUG nova.virt.libvirt.connection [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] Connecting to libvirt: xen:/// from (pid=21989) _get_connection /usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py:296\r\n2012-08-27 10:14:13 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 4783ef04-e521-451b-9ace-743c5ecc326c] Current state is 2, state in DB is 2. from (pid=21989) init_host /usr/lib64/python2.6/site-packages/nova/compute/manager.py:250\r\n2012-08-27 10:14:13 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 6fdb2052-0c07-4371-a5e9-900ea9c783dc] Checking state from (pid=21989) _get_power_state /usr/lib64/python2.6/site-packages/nova/compute/manager.py:282\r\n2012-08-27 10:14:13 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 6fdb2052-0c07-4371-a5e9-900ea9c783dc] Current state is 2, state in DB is 1. from (pid=21989) init_host /usr/lib64/python2.6/site-packages/nova/compute/manager.py:250\r\n2012-08-27 10:14:13 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: bf1fa3e8-cc82-444e-9205-7e65834aa540] Checking state from (pid=21989) _get_power_state /usr/lib64/python2.6/site-packages/nova/compute/manager.py:282\r\n2012-08-27 10:14:13 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: bf1fa3e8-cc82-444e-9205-7e65834aa540] Current state is 2, state in DB is 1. from (pid=21989) init_host /usr/lib64/python2.6/site-packages/nova/compute/manager.py:250\r\n2012-08-27 10:14:13 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: f98f88ad-6f7a-4109-adb8-c5376f6d639d] Checking state from (pid=21989) _get_power_state /usr/lib64/python2.6/site-packages/nova/compute/manager.py:282\r\n2012-08-27 10:14:13 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: f98f88ad-6f7a-4109-adb8-c5376f6d639d] Current state is 2, state in DB is 1. from (pid=21989) init_host /usr/lib64/python2.6/site-packages/nova/compute/manager.py:250\r\n2012-08-27 10:14:13 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 2d814f2b-5739-408b-b85d-1366853700a6] Checking state from (pid=21989) _get_power_state /usr/lib64/python2.6/site-packages/nova/compute/manager.py:282\r\n2012-08-27 10:14:14 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 2d814f2b-5739-408b-b85d-1366853700a6] Current state is 2, state in DB is 1. from (pid=21989) init_host /usr/lib64/python2.6/site-packages/nova/compute/manager.py:250\r\n2012-08-27 10:14:14 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: db125c15-67e7-41f6-87cc-353323aeb16e] Checking state from (pid=21989) _get_power_state /usr/lib64/python2.6/site-packages/nova/compute/manager.py:282\r\n2012-08-27 10:14:14 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: db125c15-67e7-41f6-87cc-353323aeb16e] Current state is 2, state in DB is 1. from (pid=21989) init_host /usr/lib64/python2.6/site-packages/nova/compute/manager.py:250\r\n2012-08-27 10:14:14 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 407bbc4c-d3f4-4310-8bbe-a5240d042bb0] Checking state from (pid=21989) _get_power_state /usr/lib64/python2.6/site-packages/nova/compute/manager.py:282\r\n2012-08-27 10:14:14 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 407bbc4c-d3f4-4310-8bbe-a5240d042bb0] Current state is 2, state in DB is 2. from (pid=21989) init_host /usr/lib64/python2.6/site-packages/nova/compute/manager.py:250\r\n2012-08-27 10:14:14 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 63a89eca-8905-4017-8cfa-6aec3da9e5eb] Checking state from (pid=21989) _get_power_state /usr/lib64/python2.6/site-packages/nova/compute/manager.py:282\r\n2012-08-27 10:14:14 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 63a89eca-8905-4017-8cfa-6aec3da9e5eb] Current state is 2, state in DB is 2. from (pid=21989) init_host /usr/lib64/python2.6/site-packages/nova/compute/manager.py:250\r\n2012-08-27 10:14:14 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 1a5a1b3b-676e-4bcf-b8a2-ec83ce76c098] Checking state from (pid=21989) _get_power_state /usr/lib64/python2.6/site-packages/nova/compute/manager.py:282\r\n2012-08-27 10:14:15 DEBUG nova.compute.manager [req-572dadf2-15be-45f4-87db-2c3c20f4f36f None None] [instance: 1a5a1b3b-676e-4bcf-b8a2-ec83ce76c098] Current state is 2, state in DB is 1. from (pid=21989) init_host /usr/lib64/python2.6/site-packages/nova/compute/manager.py:250\r\n2012-08-27 10:14:22 INFO nova.virt.libvirt.connection [-] Compute_service record updated for dewdfxen0048.wdf.sap.corp \r\n2012-08-27 10:14:22 INFO nova.rpc.common [-] Connected to AMQP server on spwdfvml605.wdf.sap.corp:5672\r\n2012-08-27 10:14:22 DEBUG nova.service [-] Creating Consumer connection for Service compute from (pid=21989) start /usr/lib64/python2.6/site-packages/nova/service.py:178\r\n2012-08-27 10:14:22 DEBUG nova.rpc.amqp [-] received {u'_context_roles': [u'admin'], u'_context_request_id': u'req-d65269d6-6ad6-420a-bb46-e697b95360a6', u'_context_read_deleted': u'no', u'args': {u'instance_uuid': u'4783ef04-e521-451b-9ace-743c5ecc326c'}, u'_context_auth_token': '<SANITIZED>', u'_context_is_admin': True, u'_context_project_id': u'd4bf9021295a4573aa10ca4900211856', u'_context_timestamp': u'2012-08-27T08:14:19.600594', u'_context_user_id': u'bdb0bf5eb88b47f7a8fa8de5123e48ee', u'method': u'terminate_instance', u'_context_remote_address': u'10.68.71.89'} from (pid=21989) _safe_log /usr/lib64/python2.6/site-packages/nova/rpc/common.py:160\r\n2012-08-27 10:14:22 DEBUG nova.rpc.amqp [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] unpacked context: {'user_id': u'bdb0bf5eb88b47f7a8fa8de5123e48ee', 'roles': [u'admin'], 'timestamp': '2012-08-27T08:14:19.600594', 'auth_token': '<SANITIZED>', 'remote_address': u'10.68.71.89', 'is_admin': True, 'request_id': u'req-d65269d6-6ad6-420a-bb46-e697b95360a6', 'project_id': u'd4bf9021295a4573aa10ca4900211856', 'read_deleted': u'no'} from (pid=21989) _safe_log /usr/lib64/python2.6/site-packages/nova/rpc/common.py:160\r\n2012-08-27 10:14:22 INFO nova.compute.manager [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] check_instance_lock: decorating: |<function terminate_instance at 0x1136758>|\r\n2012-08-27 10:14:22 INFO nova.compute.manager [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] check_instance_lock: arguments: |<nova.compute.manager.ComputeManager object at 0xf86890>| |<nova.rpc.amqp.RpcContext object at 0x2ae4ad0>| |4783ef04-e521-451b-9ace-743c5ecc326c|\r\n2012-08-27 10:14:22 DEBUG nova.compute.manager [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] instance 4783ef04-e521-451b-9ace-743c5ecc326c: getting locked state from (pid=21989) get_lock /usr/lib64/python2.6/site-packages/nova/compute/manager.py:1619\r\n2012-08-27 10:14:23 INFO nova.compute.manager [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] check_instance_lock: locked: |False|\r\n2012-08-27 10:14:23 INFO nova.compute.manager [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] check_instance_lock: admin: |True|\r\n2012-08-27 10:14:23 INFO nova.compute.manager [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] check_instance_lock: executing: |<function terminate_instance at 0x1136758>|\r\n2012-08-27 10:14:23 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Attempting to grab semaphore \"4783ef04-e521-451b-9ace-743c5ecc326c\" for method \"do_terminate_instance\"... from (pid=21989) inner /usr/lib64/python2.6/site-packages/nova/utils.py:927\r\n2012-08-27 10:14:23 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Got semaphore \"4783ef04-e521-451b-9ace-743c5ecc326c\" for method \"do_terminate_instance\"... from (pid=21989) inner /usr/lib64/python2.6/site-packages/nova/utils.py:931\r\n2012-08-27 10:14:23 AUDIT nova.compute.manager [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] [instance: 4783ef04-e521-451b-9ace-743c5ecc326c] Terminating instance\r\n2012-08-27 10:14:23 DEBUG nova.rpc.amqp [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Making asynchronous call on network ... from (pid=21989) multicall /usr/lib64/python2.6/site-packages/nova/rpc/amqp.py:326\r\n2012-08-27 10:14:23 DEBUG nova.rpc.amqp [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] MSG_ID is 897b9bda7a3441c4a0502e44f60f5b93 from (pid=21989) multicall /usr/lib64/python2.6/site-packages/nova/rpc/amqp.py:329\r\n2012-08-27 10:14:23 DEBUG nova.rpc.amqp [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Pool creating new connection from (pid=21989) create /usr/lib64/python2.6/site-packages/nova/rpc/amqp.py:60\r\n2012-08-27 10:14:23 INFO nova.rpc.common [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Connected to AMQP server on spwdfvml605.wdf.sap.corp:5672\r\n2012-08-27 10:14:23 DEBUG nova.compute.manager [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] [instance: 4783ef04-e521-451b-9ace-743c5ecc326c] Deallocating network for instance from (pid=21989) _deallocate_network /usr/lib64/python2.6/site-packages/nova/compute/manager.py:638\r\n2012-08-27 10:14:23 DEBUG nova.rpc.amqp [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Making asynchronous call on network ... from (pid=21989) multicall /usr/lib64/python2.6/site-packages/nova/rpc/amqp.py:326\r\n2012-08-27 10:14:23 DEBUG nova.rpc.amqp [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] MSG_ID is db370db03a0c4456a13023b009f21d27 from (pid=21989) multicall /usr/lib64/python2.6/site-packages/nova/rpc/amqp.py:329\r\n2012-08-27 10:15:22 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Running periodic task ComputeManager._publish_service_capabilities from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:152\r\n2012-08-27 10:15:22 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Running periodic task ComputeManager._poll_rescued_instances from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:152\r\n2012-08-27 10:15:22 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Skipping ComputeManager._sync_power_states, 10 ticks left until next run from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:147\r\n2012-08-27 10:15:22 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Running periodic task ComputeManager._poll_bandwidth_usage from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:152\r\n2012-08-27 10:15:22 INFO nova.compute.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Updating bandwidth usage cache\r\n2012-08-27 10:15:22 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Running periodic task ComputeManager.update_available_resource from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:152\r\n2012-08-27 10:15:25 WARNING nova.virt.libvirt.connection [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] [instance: 4783ef04-e521-451b-9ace-743c5ecc326c] Error from libvirt during saved instance removal. Code=3 Error=this function is not supported by the connection driver: virDomainHasManagedSaveImage\r\n2012-08-27 10:15:26 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Running cmd (subprocess): sudo ip link delete tap07d6bfeb-a3 from (pid=21989) execute /usr/lib64/python2.6/site-packages/nova/utils.py:219\r\n2012-08-27 10:15:26 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Result was 255 from (pid=21989) execute /usr/lib64/python2.6/site-packages/nova/utils.py:235\r\n2012-08-27 10:15:26 WARNING nova.virt.libvirt.vif [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Failed while unplugging vif of instance 'instance-00000011'\r\n2012-08-27 10:15:26 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Running cmd (subprocess): sudo ip link delete tapc5cc2c9f-47 from (pid=21989) execute /usr/lib64/python2.6/site-packages/nova/utils.py:219\r\n2012-08-27 10:15:26 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Result was 255 from (pid=21989) execute /usr/lib64/python2.6/site-packages/nova/utils.py:235\r\n2012-08-27 10:15:26 WARNING nova.virt.libvirt.vif [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Failed while unplugging vif of instance 'instance-00000011'\r\n2012-08-27 10:15:26 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Running cmd (subprocess): sudo ip link delete tap68ac2210-0f from (pid=21989) execute /usr/lib64/python2.6/site-packages/nova/utils.py:219\r\n2012-08-27 10:15:26 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Result was 255 from (pid=21989) execute /usr/lib64/python2.6/site-packages/nova/utils.py:235\r\n2012-08-27 10:15:26 WARNING nova.virt.libvirt.vif [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Failed while unplugging vif of instance 'instance-00000011'\r\n2012-08-27 10:15:26 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Running cmd (subprocess): sudo ip link delete tap61eaa2e3-1a from (pid=21989) execute /usr/lib64/python2.6/site-packages/nova/utils.py:219\r\n2012-08-27 10:15:27 DEBUG nova.utils [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Result was 255 from (pid=21989) execute /usr/lib64/python2.6/site-packages/nova/utils.py:235\r\n2012-08-27 10:15:27 WARNING nova.virt.libvirt.vif [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Failed while unplugging vif of instance 'instance-00000011'\r\n2012-08-27 10:15:27 INFO nova.virt.libvirt.connection [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] [instance: 4783ef04-e521-451b-9ace-743c5ecc326c] Deleting instance files /var/lib/nova/instances/f9226d17-1bfe-4819-b440-939e7635ed50/instance-00000011\r\n2012-08-27 10:15:27 ERROR nova.rpc.amqp [req-d65269d6-6ad6-420a-bb46-e697b95360a6 bdb0bf5eb88b47f7a8fa8de5123e48ee d4bf9021295a4573aa10ca4900211856] Exception during message handling\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp Traceback (most recent call last):\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/rpc/amqp.py\", line 253, in _process_data\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     rval = node_func(context=ctxt, **node_args)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/exception.py\", line 114, in wrapped\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     return f(*args, **kw)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 162, in decorated_function\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     function(self, context, instance_uuid, *args, **kwargs)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 186, in decorated_function\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     sys.exc_info())\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/contextlib.py\", line 23, in __exit__\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     self.gen.next()\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 180, in decorated_function\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     return function(self, context, instance_uuid, *args, **kwargs)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 769, in terminate_instance\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     do_terminate_instance()\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/utils.py\", line 945, in inner\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     retval = f(*args, **kwargs)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 762, in do_terminate_instance\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     self._delete_instance(context, instance)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 740, in _delete_instance\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     self._shutdown_instance(context, instance, 'Terminating')\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/compute/manager.py\", line 709, in _shutdown_instance\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     block_device_info)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py\", line 515, in destroy\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     cleanup=True)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py\", line 509, in _destroy\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     self._cleanup(instance)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py\", line 524, in _cleanup\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     shutil.rmtree(target)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/shutil.py\", line 221, in rmtree\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     onerror(os.rmdir, path, sys.exc_info())\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp   File \"/usr/lib64/python2.6/shutil.py\", line 219, in rmtree\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp     os.rmdir(path)\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp OSError: [Errno 39] Directory not empty: '/var/lib/nova/instances/f9226d17-1bfe-4819-b440-939e7635ed50/instance-00000011'\r\n2012-08-27 10:15:27 TRACE nova.rpc.amqp \r\n2012-08-27 10:15:27 INFO nova.virt.libvirt.connection [-] [instance: 4783ef04-e521-451b-9ace-743c5ecc326c] Instance destroyed successfully.\r\n2012-08-27 10:15:33 INFO nova.virt.libvirt.connection [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Compute_service record updated for dewdfxen0048.wdf.sap.corp \r\n2012-08-27 10:15:33 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Running periodic task ComputeManager._poll_rebooting_instances from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:152\r\n2012-08-27 10:15:33 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Skipping ComputeManager._cleanup_running_deleted_instances, 30 ticks left until next run from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:147\r\n2012-08-27 10:15:33 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Running periodic task ComputeManager._heal_instance_info_cache from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:152\r\n2012-08-27 10:15:34 DEBUG nova.rpc.amqp [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Making asynchronous call on network ... from (pid=21989) multicall /usr/lib64/python2.6/site-packages/nova/rpc/amqp.py:326\r\n2012-08-27 10:15:34 DEBUG nova.rpc.amqp [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] MSG_ID is 3bd9f71a342e425ea8f5accd0eb7e484 from (pid=21989) multicall /usr/lib64/python2.6/site-packages/nova/rpc/amqp.py:329\r\n2012-08-27 10:15:34 DEBUG nova.compute.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Updated the info_cache for instance 4783ef04-e521-451b-9ace-743c5ecc326c from (pid=21989) _heal_instance_info_cache /usr/lib64/python2.6/site-packages/nova/compute/manager.py:2249\r\n2012-08-27 10:15:34 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Skipping ComputeManager._run_image_cache_manager_pass, 40 ticks left until next run from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:147\r\n2012-08-27 10:15:34 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Running periodic task ComputeManager._reclaim_queued_deletes from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:152\r\n2012-08-27 10:15:34 DEBUG nova.compute.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] FLAGS.reclaim_instance_interval <= 0, skipping... from (pid=21989) _reclaim_queued_deletes /usr/lib64/python2.6/site-packages/nova/compute/manager.py:2402\r\n2012-08-27 10:15:34 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Running periodic task ComputeManager._report_driver_status from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:152\r\n2012-08-27 10:15:34 INFO nova.compute.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Updating host status\r\n2012-08-27 10:15:34 DEBUG nova.virt.libvirt.connection [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Updating host stats from (pid=21989) update_status /usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py:2552\r\n2012-08-27 10:15:34 DEBUG nova.virt.libvirt.connection [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Connecting to libvirt: xen:/// from (pid=21989) _get_connection /usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py:296\r\n2012-08-27 10:15:40 DEBUG nova.virt.libvirt.connection [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Updating host stats from (pid=21989) update_status /usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py:2552\r\n2012-08-27 10:15:40 DEBUG nova.manager [req-8ebf4a94-9e83-4df4-8832-698194ac031f None None] Running periodic task ComputeManager._poll_unconfirmed_resizes from (pid=21989) periodic_tasks /usr/lib64/python2.6/site-packages/nova/manager.py:152", 
            "date_created": "2012-08-27 08:44:21.355146+00:00", 
            "author": "https://api.launchpad.net/1.0/~lgesslein"
        }, 
        {
            "content": "From reading the kernel nfs-client code i get that nfs does not only rename open files to .nfs000.. but every file it is about to unlink. Files that are not held open just then disappear so fast that it normally does not matter and you do not see the renamed file. I'm guessing in our case the files are not actually open, but the nfs just takes a while to send back an ack for the rpc call.", 
            "date_created": "2012-08-27 09:10:28.039122+00:00", 
            "author": "https://api.launchpad.net/1.0/~lgesslein"
        }, 
        {
            "content": "This is what change i have tested now, seems to be working around the issue reliably so far:\r\n\r\n--- connection.py.orig  2012-08-27 12:10:47.000000000 +0200\r\n+++ /usr/lib64/python2.6/site-packages/nova/virt/libvirt/connection.py  2012-08-27 13:02:31.000000000 +0200\r\n@@ -215,6 +215,13 @@\r\n def _get_eph_disk(ephemeral):\r\n     return 'disk.eph' + str(ephemeral['num'])\r\n\r\n+def _rmtree_wait_nfs(function, path, excinfo):\r\n+    LOG.warning(_(\"Cloud not delete %s, exception: %s\\n\"), path, excinfo)\r\n+    while any(\".nfs\" in element for element in os.listdir(path) ):\r\n+        LOG.warning(_(\".nfs files found, waiting 2 seconds\"))\r\n+        time.sleep(2)\r\n+    shutil.rmtree(path)\r\n+\r\n\r\n class LibvirtConnection(driver.ComputeDriver):\r\n\r\n@@ -521,7 +528,7 @@\r\n         if FLAGS.libvirt_type == 'lxc':\r\n             disk.destroy_container(self.container)\r\n         if os.path.exists(target):\r\n-            shutil.rmtree(target)\r\n+            shutil.rmtree(target,onerror=_rmtree_wait_nfs)\r\n\r\n     def get_volume_connector(self, instance):\r\n         if not self._initiator:\r\n@@ -538,7 +545,7 @@\r\n         target = os.path.join(self.get_instances_path(instance),\r\n                               instance['name'] + \"_resize\")\r\n         if os.path.exists(target):\r\n-            shutil.rmtree(target)\r\n+            shutil.rmtree(target,onerror=_rmtree_wait_nfs)\r\n\r\n     def volume_driver_method(self, method_name, connection_info,\r\n                              *args, **kwargs):", 
            "date_created": "2012-08-27 11:23:06.597015+00:00", 
            "author": "https://api.launchpad.net/1.0/~lgesslein"
        }, 
        {
            "content": "Ok, thanks for all the info. Hopefully we can figure out something better than the workaround you're using.", 
            "date_created": "2012-08-27 12:07:21.884270+00:00", 
            "author": "https://api.launchpad.net/1.0/~markmc"
        }, 
        {
            "content": "I think we could resolve this by adding a periodic task which did retries of deletes, and then each file which isn't deleted gets added to the queue for that periodic task to process. However, its way too late in grizzly to implement something like that, so I'm going to assign this bug to myself to I remember to revisit this in Havana.", 
            "date_created": "2013-03-12 15:40:25.494185+00:00", 
            "author": "https://api.launchpad.net/1.0/~mikal"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/26315", 
            "date_created": "2013-04-07 07:47:37.698752+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Sorry, this bug was fixed by I895869e18f92ed57bd2f8c1683cf9a398d88b680, but that wasn't linked properly to this bug.", 
            "date_created": "2013-09-01 10:10:01.683484+00:00", 
            "author": "https://api.launchpad.net/1.0/~mikal"
        }, 
        {
            "content": "It looks like this bug is not fixed by the change I895869e18f92ed57bd2f8c1683cf9a398d88b680. There is still exception thrown using NFS backend. And there is also a bug reported by other stacker. https://bugs.launchpad.net/nova/+bug/1248019", 
            "date_created": "2013-11-05 07:04:08.243909+00:00", 
            "author": "https://api.launchpad.net/1.0/~yuyangbj"
        }
    ]
}