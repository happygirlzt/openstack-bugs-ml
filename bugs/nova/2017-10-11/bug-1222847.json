{
    "status": "Fix Released", 
    "last_updated": "2014-11-07 08:51:14.439737+00:00", 
    "description": "I installed a xenserver and on this server a PV guest. In this guest I deployed devstack. I'm using the following localrc:\n\nMYSQL_PASSWORD=password\nSERVICE_TOKEN=password\nADMIN_PASSWORD=password\nRABBIT_PASSWORD=password\nGUEST_PASSWORD=password\nSERVICE_PASSWORD=password\n\nHOST_IP=10.197.217.86\n\nFLOATING_RANGE=192.168.1.224/27\nFIXED_RANGE=10.11.12.0/24\nFIXED_NETWORK_SIZE=256\nFLAT_INTERFACE=eth1\nFLAT_NETWORK_BRIDGE=xapi1\n\nXENAPI_PASSWORD=toto\nXENAPI_CONNECTION_URL=\"http://10.197.217.85\"\n\nIMAGE_URLS=\"\\\nhttps://github.com/downloads/citrix-openstack/warehouse/cirros-0.3.0-x86_64-disk.vhd.tgz,\\\nhttp://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-uec.tar.gz\"\n\nVIRT_DRIVER=xenserver\n\nVNCSERVER_PROXYCLIENT_ADDRESS=10.197.217.85\n\nMULTI_HOST=1\nACTIVE_TIMEOUT=45\n\nWhen I try to boot a VM, I have an error:\n\n  Failure: ['UUID_INVALID', 'VDI', 'a9162793-5e64-41fb-a018-c281a694fcbf']\n\nComplete log is here: http://paste.openstack.org/show/46313/\n\nIt seems that the UUID used is not the good one because if I look the list of VDIs I see:\n\nuuid ( RO)                : 3aefa6cc-0d75-e356-f934-1c6fe8af1553\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0name-label ( RW): a9162793-5e64-41fb-a018-c281a694fcbf.vhd\n\u00a0\u00a0\u00a0\u00a0name-description ( RW):\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0sr-uuid ( RO): 4362c04b-e140-41f8-bcb5-36eed394576e\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0virtual-size ( RO): 42025472\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0sharable ( RO): false\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0read-only ( RO): false\n\nSo the UUID that is used is the name-label and not the real UUID.", 
    "tags": [
        "xenserver"
    ], 
    "importance": "Low", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1222847", 
    "owner": "None", 
    "id": 1222847, 
    "index": 5866, 
    "created": "2013-09-09 14:22:27.333686+00:00", 
    "title": "xenapi: openstack not working with xenserver core and vhd images", 
    "comments": [
        {
            "content": "I installed a xenserver and on this server a PV guest. In this guest I deployed devstack. I'm using the following localrc:\n\nMYSQL_PASSWORD=password\nSERVICE_TOKEN=password\nADMIN_PASSWORD=password\nRABBIT_PASSWORD=password\nGUEST_PASSWORD=password\nSERVICE_PASSWORD=password\n\nHOST_IP=10.197.217.86\n\nFLOATING_RANGE=192.168.1.224/27\nFIXED_RANGE=10.11.12.0/24\nFIXED_NETWORK_SIZE=256\nFLAT_INTERFACE=eth1\nFLAT_NETWORK_BRIDGE=xapi1\n\n\nXENAPI_PASSWORD=xlcloud\nXENAPI_CONNECTION_URL=\"http://10.197.217.85\"\n\nIMAGE_URLS=\"\\\nhttps://github.com/downloads/citrix-openstack/warehouse/cirros-0.3.0-x86_64-disk.vhd.tgz,\\\nhttp://download.cirros-cloud.net/0.3.1/cirros-0.3.1-x86_64-uec.tar.gz\"\n\nVIRT_DRIVER=xenserver\n\nVNCSERVER_PROXYCLIENT_ADDRESS=10.197.217.85\n\nMULTI_HOST=1\nACTIVE_TIMEOUT=45\n\n\nWhen I try to boot a VM, I have an error:\n\n2013-09-09 16:13:31.959 ERROR nova.utils [req-68e2a934-cda3-4543-8d8f-bd16de1f2b31 demo demo] [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f] Failed to spawn, rolling back\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f] Traceback (most recent call last):\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 500, in spawn\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     vdis = create_disks_step(undo_mgr, disk_image_type, image_meta)\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 153, in inner\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     rv = f(*args, **kwargs)\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 380, in create_disks_step\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     block_device_info=block_device_info)\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 351, in _create_disks\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     block_device_info=block_device_info)\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 532, in get_vdis_for_instance\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     context, session, instance, name_label, image, image_type)\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1111, in _create_image\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     image_id, image_type)\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1057, in _create_cached_image\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     'VDI.get_by_uuid', vdis['root']['uuid'])\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/opt/stack/nova/nova/virt/xenapi/driver.py\", line 732, in call_xenapi\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     return session.xenapi_request(method, args)\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/usr/lib/python2.7/dist-packages/XenAPI.py\", line 139, in xenapi_request\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     result = _parse_result(getattr(self, methodname)(*full_params))\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]   File \"/usr/lib/python2.7/dist-packages/XenAPI.py\", line 209, in _parse_result\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f]     raise Failure(result['ErrorDescription'])\n2013-09-09 16:13:31.959 TRACE nova.utils [instance: 41ebf2b4-9518-48eb-bc37-e57183d8b04f] Failure: ['UUID_INVALID', 'VDI', 'a9162793-5e64-41fb-a018-c281a694fcbf']\n\n\nIt seems that the UUID used is not the good one because if I look the list of VDIs I see:\n\nuuid ( RO)                : 3aefa6cc-0d75-e356-f934-1c6fe8af1553\n          name-label ( RW): a9162793-5e64-41fb-a018-c281a694fcbf.vhd\n    name-description ( RW): \n             sr-uuid ( RO): 4362c04b-e140-41f8-bcb5-36eed394576e\n        virtual-size ( RO): 42025472\n            sharable ( RO): false\n           read-only ( RO): false\n\nSo the UUID that is used is the name-label and not the real UUID.", 
            "date_created": "2013-09-09 14:22:27.333686+00:00", 
            "author": "https://api.launchpad.net/1.0/~guillaume-thouvenin"
        }, 
        {
            "content": "The image that I'm using has a VHD disk format and the container has the OVF type. I also tried with a bare container :\n\n$ glance image-list\n+--------------------------------------+---------------------------------+-------------+------------------+----------+--------+\n| ID                                   | Name                            | Disk Format | Container Format | Size     | Status |\n+--------------------------------------+---------------------------------+-------------+------------------+----------+--------+\n| b7b4761a-2b82-4b75-ba42-927da0898c3d | cirros-0.3.0-x86_64-disk        | vhd         | ovf              | 9220018  | active |\n| 4e3462a1-72a4-4bad-a57b-8241c997a3da | cirros-0.3.1-x86_64-uec         | ami         | ami              | 25165824 | active |\n| 44ff0a3d-1227-45a2-a53c-0239b0cb9274 | cirros-0.3.1-x86_64-uec-kernel  | aki         | aki              | 4955792  | active |\n| 2f4bbc75-db94-48f8-8feb-a62adfa58d07 | cirros-0.3.1-x86_64-uec-ramdisk | ari         | ari              | 3714968  | active |\n| 9b13b4a5-c203-4abf-83e0-3de0ee3926a7 | xenimage                        | vhd         | bare             | 42025472 | active |\n+--------------------------------------+---------------------------------+-------------+------------------+----------+--------+\n", 
            "date_created": "2013-09-09 14:25:58.826303+00:00", 
            "author": "https://api.launchpad.net/1.0/~guillaume-thouvenin"
        }, 
        {
            "content": "@guillaume could you please tell us what type of SR your are using EXT or LVM?", 
            "date_created": "2013-09-09 16:35:24.997183+00:00", 
            "author": "https://api.launchpad.net/1.0/~johngarbutt"
        }, 
        {
            "content": "I'm using EXT and the version of xenserver is the one installed with xenserver-tech-preview-release-0.3.0-0.x86_64 (Xen version 4.2.2-2021.el6 )\n\n\n# xe sr-list uuid=4362c04b-e140-41f8-bcb5-36eed394576e\nuuid ( RO)                : 4362c04b-e140-41f8-bcb5-36eed394576e\n          name-label ( RW): /var/run/sr-mount/4362c04b-e140-41f8-bcb5-36eed394576e\n    name-description ( RW): Files stored in /var/run/sr-mount/4362c04b-e140-41f8-bcb5-36eed394576e\n                host ( RO): r421-e2-5\n                type ( RO): ext\n        content-type ( RO): default\n\nand the filesystem is :\n\n# df -T\nFilesystem    Type   1K-blocks      Used Available Use% Mounted on\n/dev/sda3     ext4    51606140  25691052  23293648  53% /\ntmpfs        tmpfs      277404         4    277400   1% /dev/shm\n/dev/sda1     ext4     1032088    127320    852340  13% /boot\n/dev/sda4     ext4   907762552   2491248 859159560   1% /var/run/sr-mount/4362c04b-e140-41f8-bcb5-36eed394576e\nxenstore     tmpfs      277404        72    277332   1% /var/lib/xenstored\n\nIn /var/run/sr-mount/4362c04b-e140-41f8-bcb5-36eed394576 I can see the file created when I try to start the instance:\n\n# ll /var/run/sr-mount/4362c04b-e140-41f8-bcb5-36eed394576e/\n...\n-rw-r--r--. 1 1000 1000   42025472 Dec 10  2012 a9162793-5e64-41fb-a018-c281a694fcbf.vhd\n...\n\n", 
            "date_created": "2013-09-10 08:09:27.373434+00:00", 
            "author": "https://api.launchpad.net/1.0/~guillaume-thouvenin"
        }, 
        {
            "content": "Ah, interesting, so this is the xenserver tech-preview.\n\nThanks for the extra info.", 
            "date_created": "2013-09-10 10:23:19.712823+00:00", 
            "author": "https://api.launchpad.net/1.0/~johngarbutt"
        }, 
        {
            "content": "Yes it is the xenserver tech-preview and I have the same issue with xenserver-core (xenserver-core-0.9.0-9.x86_64)", 
            "date_created": "2013-09-10 11:54:30.958538+00:00", 
            "author": "https://api.launchpad.net/1.0/~guillaume-thouvenin"
        }, 
        {
            "content": "I dig a little and there is something that I don't understand.  The function _fetch_vhd_image() returns a list of dictionaries that describe VDIs. So for example if I have a disk like this one:\n\n# xe vdi-list\nuuid ( RO)                : 46addb2a-52a8-0010-4751-ad2e5538440e\n          name-label ( RW): 7e65ebc1-ac4a-4c35-b66d-73af3d5451c6.vhd\n    name-description ( RW):\n             sr-uuid ( RO): 1d0018c1-808b-4205-ba69-3ed1806d6839\n        virtual-size ( RO): 42025472\n            sharable ( RO): false\n           read-only ( RO): false\n\nIf the disk is the root of the VM, the corresponding VDIs should be something like vdis={'root': {'uuid': '46addb2a-52a8-0010-4751-ad2e5538440e'}}\n\nWhen I look the following piece of code in _fetch_vhd_image():\n\n1222\n1223         vdis = default_handler.download_image(\n1224                 context, session, instance, image_id)\n1225 \n1226     sr_ref = safe_find_sr(session)\n1227     _scan_sr(session, sr_ref)\n1228 \n\nAt 1225, for my case, the file 7e65ebc1-ac4a-4c35-b66d-73af3d5451c6.vhd has been copied in the SR and vdis = {'root': {'uuid': '7e65ebc1-ac4a-4c35-b66d-73af3d5451c6'}}.\n\nWhen the SR.scan is ran, it creates the vdi shows previously (with the uuid=46a...). So shouldn't we update the vdis after the scan of the SR? ", 
            "date_created": "2013-09-11 10:16:45.365524+00:00", 
            "author": "https://api.launchpad.net/1.0/~guillaume-thouvenin"
        }, 
        {
            "content": "I still have this error with devastack. This error only occurs when I'm using the VHD file and a HVM guest. I can start an PV guest with an image, a kernel and an ramdisk.", 
            "date_created": "2013-10-03 11:45:17.245104+00:00", 
            "author": "https://api.launchpad.net/1.0/~guillaume-thouvenin"
        }, 
        {
            "content": "In that version of xenserver-core the ext SR is actually an ffs (flat file system) SR which is an experimental SR type.  I guess that there is a strange interaction between what the dom0 plugins expect to be able to do and how the FFS SR is interpreting it.\n\nDelete that SR and create an FFS SR without telling it to pretend to be ext3.\n\nRecent changes accepted into OpenStack should mean this works much better than it did when we added the pretend-ext3 SR.", 
            "date_created": "2013-10-03 12:15:15.165832+00:00", 
            "author": "https://api.launchpad.net/1.0/~bob-ball"
        }, 
        {
            "content": "I modified the pool so the default SR is now the one with ffs-type:\n\nuuid ( RO)                : 106ab117-5431-0931-889b-6c534cd061c6\n          name-label ( RW): /usr/share/xapi/images\n    name-description ( RW): Files stored in /usr/share/xapi/images\n                host ( RO): r421-e3-2\n                type ( RO): ffs\n        content-type ( RO): default\n\n\nI tried to start an instance but unfortunatly I have the same issue with the uuid that is the name-label without the vhd extension:\n\nnova.compute.manager [...] Failure: ['UUID_INVALID', 'VDI', 'e6b6c517-ad7e-4e42-82c2-1f7e00858075']\n\nand\n\nxe vdi-list name-label=e6b6c517-ad7e-4e42-82c2-1f7e00858075.vhd \nuuid ( RO)                : 3d719010-a7a7-dea2-19f8-8441bae2a630\n          name-label ( RW): e6b6c517-ad7e-4e42-82c2-1f7e00858075.vhd\n    name-description ( RW): \n             sr-uuid ( RO): 106ab117-5431-0931-889b-6c534cd061c6\n        virtual-size ( RO): 2299062272\n            sharable ( RO): false\n           read-only ( RO): false\n", 
            "date_created": "2013-10-03 14:05:43.056236+00:00", 
            "author": "https://api.launchpad.net/1.0/~guillaume-thouvenin"
        }, 
        {
            "content": "Sorry to insist but I don't see how it can work. I probably miss something but in the function _fetch_vhd_image(), first we download the vhd image in the repository that corresponds to the SR. So after \n\n  vdis = handler.download_image(context, session, instance, image_id)\n\nvdis contains the name of the file. Not the UUID of the vdi that will be created when we will invoke the sr-scan. So at this point we send a request to glance to download the image and it is stored in the directory:\n\n# ls /usr/share/xapi/images\n951e5aa6-7ef6-43ad-8edd-79edb4ad428e.vhd\n\nthe value of vdis is: vdis = 'root': {'uuid': '951e5aa6-7ef...-79edb4ad428e'}}\n\nand the VHD is not seen yet by the SR in Xen.\n\n  The next step is to scan the SR so we will be able to see the VHD file. The result is that the UUID is attributed to the disk and we can see it now:\n\n# xe vdi-list \n uuid ( RO)                : acd06ed8-dacf-7b8d-4f95-c5d835691383\n          name-label ( RW): 951e5aa6-7ef6-43ad-8edd-79edb4ad428e.vhd\n    name-description ( RW): \n             sr-uuid ( RO): 106ab117-5431-0931-889b-6c534cd061c6\n        virtual-size ( RO): 2299062272\n            sharable ( RO): false\n           read-only ( RO): false\n\nbut the content of vdis is always the same. So I don't understand how we can retrieve information of a disk wih UUID=951e5aa6-7ef6-43ad-8edd-79edb4ad428e from Xen. The UUID seems invalid.\n\nI tried to go deeper but I'm lost when _call_glance_plugin() is called. Don't hesitate to ask for more information. I can get some trace from pdb or things like that.\n\n", 
            "date_created": "2013-10-04 13:00:36.931598+00:00", 
            "author": "https://api.launchpad.net/1.0/~guillaume-thouvenin"
        }, 
        {
            "content": "GlanceStore.download_image calls through to dom0 with the \"glance\" plugin, method \"download_vhd\".\n\nThis method will pull down the VHDs and rename them - which _SHOULD_ mean that the SR detects them with the correct UUID.\n\nIn this case, it does not, because there is a bug in the FFS SR which means that even when you have a correctly formatted UUID for the VHD name it will pick a new ID when introducing to XAPI.\n\nThe only way to do this with the current release is to use an EXT SR, so create a large file, loop-back mount it, and introduce it as an SR to XenServer - or if you have a spare block device, just use that / set up a new LV for it.  Some of the instructions you'd need are in http://support.citrix.com/article/ctx116324 - don't delete the original SR, just create a new one and set it to the pool default.\n\nI've also asked for this bug in FFS to be fixed - see https://github.com/xapi-project/xenserver-core/issues/243\n\nOpenStack can also be fixed, but this is a slightly bigger task - ", 
            "date_created": "2013-10-04 13:39:55.700273+00:00", 
            "author": "https://api.launchpad.net/1.0/~bob-ball"
        }, 
        {
            "content": "I tried this solution. I mounted an ext4 filesystem on /opt/main-sr:\n\nxe sr-create content-type=user type=ext device-config:path=/opt/main-sr name-label=\"Main storage\"\n\nwhere \n\n# df -hT\nFilesystem    Type    Size  Used Avail Use% Mounted on\n/dev/sdb2     ext4    628G  2,4G  594G   1% /opt/main-sr\n\nI also set this new SR as the default SR in the pool. Unfortunatly I still have the same error:\n\nFailure: ['UUID_INVALID', 'VDI', '0eda1484-beba-4425-b7d1-1c2b266d3a0b']\n\nand \n\n# ll /opt/main-sr/\ntotal 2245200\n-rw-------. 1 1000 users 2299062272  3 oct.  13:52 0eda1484-beba-4425-b7d1-1c2b266d3a0b.vhd\n\n# xe vdi-list name-label=0eda1484-beba-4425-b7d1-1c2b266d3a0b.vhd \nuuid ( RO)                : 2738a98c-e3fb-9b16-0a3e-3b7c9df4b69e\n          name-label ( RW): 0eda1484-beba-4425-b7d1-1c2b266d3a0b.vhd\n    name-description ( RW): \n             sr-uuid ( RO): 44bf67ce-7fbf-ed56-45e4-b9195c097b30\n        virtual-size ( RO): 2299062272\n            sharable ( RO): false\n           read-only ( RO): false\n", 
            "date_created": "2013-10-07 09:33:10.664036+00:00", 
            "author": "https://api.launchpad.net/1.0/~guillaume-thouvenin"
        }, 
        {
            "content": "FFS SRs are not going to be supported in OpenStack; EXT3 SRs are now supported in buildroot (formally known as xenserver-core).\n\nWe've confirmed that EXT3 SRs are indeed supported under buildroot at least from the Juno release of OpenStack.", 
            "date_created": "2014-11-07 08:50:39.248075+00:00", 
            "author": "https://api.launchpad.net/1.0/~bob-ball"
        }
    ]
}