{
    "status": "Expired", 
    "last_updated": "2016-01-27 13:40:26.428396+00:00", 
    "description": "During vm delete operation, vif unplug is invoked after delete is performed. Due to this problem, since vm is deleted, unplug reports an error.\nThis is related to liberty.\nReproduce steps : \n1. Deploy a VM\n2. Delete VM\nDoes not happen very often, but in continuous deploy/delete scenarios, this problem is reproduced.\n\nVM got deleted successfully, but vif unplug failed to locate vm to remove vlan associated with it.", 
    "tags": [], 
    "importance": "Undecided", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1514437", 
    "owner": "None", 
    "id": 1514437, 
    "index": 5833, 
    "created": "2015-11-09 14:06:07.372172+00:00", 
    "title": "vif unplug is invoked after vm delete", 
    "comments": [
        {
            "content": "During vm delete operation, vif unplug is invoked after delete is performed. Due to this problem, since vm is deleted, unplug reports an error.\nThis is related to liberty.\nReproduce steps : \n1. Deploy a VM\n2. Delete VM\nDoes not happen very often, but in continuous deploy/delete scenarios, this problem is reproduced.\n\nVM got deleted successfully, but vif unplug failed to locate vm to remove vlan associated with it.", 
            "date_created": "2015-11-09 14:06:07.372172+00:00", 
            "author": "https://api.launchpad.net/1.0/~svenkat"
        }, 
        {
            "content": "So, there does need to be a question why the manager allowed this.  Sridhar, I believe you have a stack trace though that shows that we are not raising a proper NovaException in this case?  Can you add that here?", 
            "date_created": "2015-11-09 14:22:11.854690+00:00", 
            "author": "https://api.launchpad.net/1.0/~thorst"
        }, 
        {
            "content": "Stack trace : \n\n2015-11-06 18:27:18.778 34392 INFO nova_powervm.virt.powervm.tasks.vm [req-3eaee1d9-a23b-4301-87bb-39099dec253b 0688b01e6439ca32d698d20789d52169126fb41fb1a4ddafcebb97d854e836c9 b7ed54d96abd4b14b0444827eebc3eb3 - - -] Deleting instance HAR_RHEL_7DT_-468bf5c8-000000cd from system.\n2015-11-06 18:27:18.779 34392 INFO nova_powervm.virt.powervm.vm [req-3eaee1d9-a23b-4301-87bb-39099dec253b 0688b01e6439ca32d698d20789d52169126fb41fb1a4ddafcebb97d854e836c9 b7ed54d96abd4b14b0444827eebc3eb3 - - -] Deleting virtual machine. LPARID: 468BF5C8-D533-484E-B35A-61313EA4E65B\n2015-11-06 18:27:19.190 34392 INFO nova_powervm.virt.powervm.vm [req-3eaee1d9-a23b-4301-87bb-39099dec253b 0688b01e6439ca32d698d20789d52169126fb41fb1a4ddafcebb97d854e836c9 b7ed54d96abd4b14b0444827eebc3eb3 - - -] Virtual machine delete status: 204\n\n...\n\n2015-11-06 18:27:22.601 34392 INFO nova_powervm.virt.powervm.driver [req-20cba4d3-8cd7-4c44-8215-3f80ee8866bc ccef2cf310f3c87a1f7694fd1efec05df65170786399ba92e1aa07fbe72f746f f86572c7774b4d30a3eea74ab72c5011 - - -] Operation: unplug_vifs. Virtual machine display name: HAR_RHEL_7DT_001_199, name: HAR_RHEL_7DT_-468bf5c8-000000cd, UUID: 468bf5c8-d533-484e-b35a-61313ea4e65b\n...\n\n2015-11-06 18:27:22.299 34392 INFO nova_powervm.virt.powervm.driver [req-3536e9f3-6fc6-4a28-ad19-c6895ec27d22 0688b01e6439ca32d698d20789d52169126fb41fb1a4ddafcebb97d854e836c9 b7ed54d96abd4b14b0444827eebc3eb3 - - -] Operation: destroy. Virtual machine display name: HAR_RHEL_7DT_002_009, name: HAR_RHEL_7DT_-9dfb56ab-000000d7, UUID: 9dfb56ab-0ed2-478d-9ed6-809f7eddcd1f\n2015-11-06 18:27:22.524 34392 INFO nova.compute.manager [req-20cba4d3-8cd7-4c44-8215-3f80ee8866bc ccef2cf310f3c87a1f7694fd1efec05df65170786399ba92e1aa07fbe72f746f f86572c7774b4d30a3eea74ab72c5011 - - -] [instance: 468bf5c8-d533-484e-b35a-61313ea4e65b] Neutron deleted interface 64c735a4-f18d-4e9b-9846-2abe834d8b0d; detaching it from the instance and deleting it from the info cache\n2015-11-06 18:27:22.601 34392 INFO nova_powervm.virt.powervm.driver [req-20cba4d3-8cd7-4c44-8215-3f80ee8866bc ccef2cf310f3c87a1f7694fd1efec05df65170786399ba92e1aa07fbe72f746f f86572c7774b4d30a3eea74ab72c5011 - - -] Operation: unplug_vifs. Virtual machine display name: HAR_RHEL_7DT_001_199, name: HAR_RHEL_7DT_-468bf5c8-000000cd, UUID: 468bf5c8-d533-484e-b35a-61313ea4e65b\n2015-11-06 18:27:23.561 34392 INFO pypowervm.helpers.log_helper [req-20cba4d3-8cd7-4c44-8215-3f80ee8866bc ccef2cf310f3c87a1f7694fd1efec05df65170786399ba92e1aa07fbe72f746f f86572c7774b4d30a3eea74ab72c5011 - - -] REQUEST: {'auditmemento': 'None', 'sensitive': 'False', 'headers': \"{'Accept': 'application/atom+xml', 'X-Audit-Memento': 'nova'}\", 'timeout': '-1', 'path': '/rest/api/uom/ManagedSystem/7bf5091c-0a4e-3c79-968c-22eb636be47d/LogicalPartition/468BF5C8-D533-484E-B35A-61313EA4E65B?group=None', 'method': 'GET'}\n2015-11-06 18:27:23.562 34392 INFO pypowervm.helpers.log_helper [req-20cba4d3-8cd7-4c44-8215-3f80ee8866bc ccef2cf310f3c87a1f7694fd1efec05df65170786399ba92e1aa07fbe72f746f f86572c7774b4d30a3eea74ab72c5011 - - -] RESPONSE: {'status': '404', 'adapter': 'None', 'reqbody': '', 'reqpath': '/rest/api/uom/ManagedSystem/7bf5091c-0a4e-3c79-968c-22eb636be47d/LogicalPartition/468BF5C8-D533-484E-B35A-61313EA4E65B?group=None', 'headers': '{\\'Content-Type\\': \\'application/atom+xml\\', \\'Content-Length\\': \\'1645\\', \\'X-Powered-By\\': \\'Servlet/3.1\\', \\'Set-Cookie\\': \\'JSESSIONID=0000fWTPKpc56_UICxveSLT7X5H:5206b9d9-ad42-47b6-81d2-0bface72b5a8; Path=/; Secure; HttpOnly\\', \\'Expires\\': \\'Thu, 01 Dec 1994 16:00:00 GMT\\', \\'Connection\\': \\'Close\\', \\'X-Transaction-ID\\': \\'XT10071506\\', \\'Cache-Control\\': \\'no-cache=\"set-cookie, set-cookie2\"\\', \\'Date\\': \\'Fri, 06 Nov 2015 23:27:23 GMT\\', \\'X-MC-Type\\': \\'PVM\\', \\'X-TransactionRecord-Uuid\\': \\'8bf39b15-e590-4532-8d96-39828641e100\\'}', 'reason': 'Not Found', 'reqheaders': \"{'Accept': 'application/atom+xml', 'X-Audit-Memento': 'nova'}\", 'orig_reqpath': '', 'reqmethod': 'GET'}\n2015-11-06 18:27:23.563 34392 INFO pypowervm.helpers.log_helper [req-20cba4d3-8cd7-4c44-8215-3f80ee8866bc ccef2cf310f3c87a1f7694fd1efec05df65170786399ba92e1aa07fbe72f746f f86572c7774b4d30a3eea74ab72c5011 - - -]", 
            "date_created": "2015-11-09 14:31:10.436110+00:00", 
            "author": "https://api.launchpad.net/1.0/~svenkat"
        }, 
        {
            "content": "That's an issue which happened with the out-of-tree PowerVM driver, right? IIRC PowerVM does *not* use the in-tree manager, which is responsible for the order of calls. Is that true? I'm asking because I'm unsure if such a bug report would fit here. Any thoughts?", 
            "date_created": "2015-11-23 15:30:33.253629+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "[Expired for OpenStack Compute (nova) because there has been no activity for 60 days.]", 
            "date_created": "2016-01-23 04:17:36.949459+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }, 
        {
            "content": "I got a hold of Sridhar on this.  The short answer is that I think this defect can be canceled.\n\nWhat happened:\n - User started the destroy operation for a VM.\n - User immediately kicked off a detach_interface operation while the destroy was still ongoing\n\nHad the destroy finished before the detach_interface was called, a 404 (instance not found) error would have been exposed.  However, the instance did still exist when the command came in.\n\nThat led to the issue.  I think that this is more a usability issue.  It is perfectly OK for the compute log to provide messaging around this.", 
            "date_created": "2016-01-27 13:40:25.994220+00:00", 
            "author": "https://api.launchpad.net/1.0/~thorst"
        }
    ]
}