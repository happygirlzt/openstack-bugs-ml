{
    "status": "Expired", 
    "last_updated": "2016-08-02 04:17:30.149340+00:00", 
    "description": "Consistently getting the below error from libvirt when I take a second snap of a network type disk ...\n\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18] Traceback (most recent call last):\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 1749, in _volume_snapshot_create\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     domain.snapshotCreateXML(snapshot_xml, snap_flags)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 183, in doit\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 141, in proxy_call\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     rv = execute(f, *args, **kwargs)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 122, in execute\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     six.reraise(c, e, tb)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 80, in tworker\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     rv = meth(*args, **kwargs)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 2472, in snapshotCreateXML\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     if ret is None:raise libvirtError('virDomainSnapshotCreateXML() failed', dom=self)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18] libvirtError: End of file while reading data: Input/output error\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18] \n\n\nMore details will follow in subsequent comments.", 
    "tags": [
        "cinder", 
        "glusterfs", 
        "libgfapi", 
        "libvirt", 
        "snapshot"
    ], 
    "importance": "Undecided", 
    "heat": 20, 
    "link": "https://bugs.launchpad.net/nova/+bug/1484081", 
    "owner": "None", 
    "id": 1484081, 
    "index": 5703, 
    "created": "2015-08-12 11:22:36.240369+00:00", 
    "title": "libvirt error while taking second snapshot of network type disk", 
    "comments": [
        {
            "content": "Consistently getting the below error from libvirt when I take a second snap of a network type disk ...\n\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18] Traceback (most recent call last):\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 1749, in _volume_snapshot_create\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     domain.snapshotCreateXML(snapshot_xml, snap_flags)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 183, in doit\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 141, in proxy_call\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     rv = execute(f, *args, **kwargs)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 122, in execute\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     six.reraise(c, e, tb)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib/python2.7/site-packages/eventlet/tpool.py\", line 80, in tworker\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     rv = meth(*args, **kwargs)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]   File \"/usr/lib64/python2.7/site-packages/libvirt.py\", line 2472, in snapshotCreateXML\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18]     if ret is None:raise libvirtError('virDomainSnapshotCreateXML() failed', dom=self)\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18] libvirtError: End of file while reading data: Input/output error\n2015-08-12 11:10:30.473 TRACE nova.virt.libvirt.driver [instance: 423192d4-1845-4a14-aae1-1aeb6e0b7d18] \n\n\nMore details will follow in subsequent comments.", 
            "date_created": "2015-08-12 11:22:36.240369+00:00", 
            "author": "https://api.launchpad.net/1.0/~dpkshetty"
        }, 
        {
            "content": "1) Create a VM (nova.conf configured to use gluster storage driver by doing qemu_allowed_storage_drivers = gluster in [libvirt] section)\n     -- See nova.conf in attached .tar\n\n2) Attach a cinder volume (this shows up as vdb in the nova VM). From virsh dumpxml, confirm that it uses disk type=network for the vdb disk.\n\n3) Cinder shows the volume status as 'in-use'\n\n4) Take a first snapshot of cinder volume, which translates to snapshot of vdb disk of nova VM\n\n5) This maps to external snapshot with REUSE_EXT and _RELATIVE flags set. Cinder passes the qcow2 overlay file to Nova, and Nova is supposed to just link this to the active image for vdb device\n\n6) First snapshot (of disk type=network) is successfull! \n       -- Evident from n-cpu_and_c-vol_logs.txt in the attached .tar\n       -- Also evident from virsh-dumpxml-after-snap-error.txt (see backingStore of disk type=network)\n\n7) When taking second snapshot (of disk type=network), libvirt throws the above error (see opening comment of this bug)\n        -- Evident from n-cpu_and_c-vol_logs.txt in the attached .tar\n\nAttaching the relevant logs in a .tar file which has ...\n\ncinder.conf\ncinder-list.txt\ncinder-mnt-dir-files.txt\ncinder-snap-list.txt\ndf-h.txt\nglusterd.vol\ngluster-vol-info.txt\ninstance-00000001.log\nlibvirtd.log\nn-cpu_and_c-vol_logs.txt\nnova.conf\nnova-list.txt\nvirsh-dumpxml-after-snap-error.txt\n\nSince I am using devstack glusterfs plugin, it configures Nova, Glance and Cinder to use GlusterFS as the storage backend, evident from df-h.txt \n\nFrom cinder-mnt-dir-files.txt its clear that Nova is able to link the external qcow2 file's backing pointer to the prev snap\nin the chain, but still fails with the EOF error, so looks like something fishy is happening post the snapshot linking phase, my 2 cents :)\n\nMy devstack setup info:\n\n[stack@devstack-f21 lp-1484081]$ cat /etc/issue\nFedora release 21 (Twenty One)\nKernel \\r on an \\m (\\l)\n\n[stack@devstack-f21 lp-1484081]$ \n[stack@devstack-f21 lp-1484081]$ uname -a\nLinux devstack-f21.localdomain 3.18.9-200.fc21.x86_64 #1 SMP Mon Mar 9 15:10:50 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n[stack@devstack-f21 lp-1484081]$ \n[stack@devstack-f21 lp-1484081]$ rpm -qa| grep qemu\nqemu-kvm-2.1.3-8.fc21.x86_64\nlibvirt-daemon-driver-qemu-1.2.9.3-2.fc21.x86_64\nqemu-common-2.1.3-8.fc21.x86_64\nipxe-roms-qemu-20140303-3.gitff1e7fc7.fc21.noarch\nqemu-img-2.1.3-8.fc21.x86_64\nqemu-system-x86-2.1.3-8.fc21.x86_64\n[stack@devstack-f21 lp-1484081]$ \n[stack@devstack-f21 lp-1484081]$ \n[stack@devstack-f21 lp-1484081]$ rpm -qa| grep libvirt\nlibvirt-daemon-driver-storage-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-vbox-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-config-nwfilter-1.2.9.3-2.fc21.x86_64\nlibvirt-devel-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-qemu-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-libxl-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-nwfilter-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-interface-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-config-network-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-xen-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-kvm-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-network-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-lxc-1.2.9.3-2.fc21.x86_64\nlibvirt-1.2.9.3-2.fc21.x86_64\nlibvirt-python-1.2.9-2.fc21.x86_64\nlibvirt-daemon-driver-nodedev-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-uml-1.2.9.3-2.fc21.x86_64\nlibvirt-client-1.2.9.3-2.fc21.x86_64\nlibvirt-daemon-driver-secret-1.2.9.3-2.fc21.x86_64\nlibvirt-docs-1.2.9.3-2.fc21.x86_64\n[stack@devstack-f21 lp-1484081]$ \n", 
            "date_created": "2015-08-12 11:51:15.861224+00:00", 
            "author": "https://api.launchpad.net/1.0/~dpkshetty"
        }, 
        {
            "content": "Actual cmds I ran, in reaching to the above issue (taken from my history file)\n\n1) nova boot --image 6e5647f5-6408-4cec-885f-4075955da404 --flavor m1.tiny --nic net-id=9a78de6d-cbcb-4962-90f1-f68c3fa05f12 --poll vm1\n\n+--------------------------------------+------+--------+------------+-------------+--------------------------------------------------------+\n| ID                                   | Name | Status | Task State | Power State | Networks                                               |\n+--------------------------------------+------+--------+------------+-------------+--------------------------------------------------------+\n| 423192d4-1845-4a14-aae1-1aeb6e0b7d18 | vm1  | ACTIVE | -          | Running     | private=10.0.0.3, fd8b:1bff:8373:0:f816:3eff:fe41:b68e |\n+--------------------------------------+------+--------+------------+-------------+--------------------------------------------------------+\n\n2) cinder create --display_name cv1 1\n\n+--------------------------------------+--------+--------------+------+-------------+----------+--------------------------------------+\n|                  ID                  | Status | Display Name | Size | Volume Type | Bootable |             Attached to              |\n+--------------------------------------+--------+--------------+------+-------------+----------+--------------------------------------+\n| 062fc1e1-417d-42b9-b6e6-d6dc810e7aaa | in-use |     cv1      |  1   |  glusterfs  |  false   | 423192d4-1845-4a14-aae1-1aeb6e0b7d18 |\n+--------------------------------------+--------+--------------+------+-------------+----------+--------------------------------------+\n\n3) nova volume-attach vm1 062fc1e1-417d-42b9-b6e6-d6dc810e7aaa\n\n(forgot to capture the output of this cmd, but it can be verified by the cmd below)\n\n[stack@devstack-f21 lp-1484081]$ [admin] ssh cirros@10.0.0.3 \"cat /proc/partitions\"\nThe authenticity of host '10.0.0.3 (10.0.0.3)' can't be established.\nRSA key fingerprint is 6d:f5:e0:b2:9c:5c:2a:1f:b5:28:3b:90:1a:a9:4e:28.\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added '10.0.0.3' (RSA) to the list of known hosts.\ncirros@10.0.0.3's password: \nmajor minor  #blocks  name\n\n 253        0    1048576 vda\n  11        0        418 sr0\n 253       16    1048576 vdb        <<<<---- This is the newly attached vdb disk after successfull nova volume-attach\n\n\n4) cinder snapshot-create --display_name cv1-snap1 --force True cv1\n\n5) cinder snapshot-create --display_name cv1-snap2 --force True cv1\n\n*** This is where the libvirt error happens in n-cpu.log ***\n\n6) cinder snapshot-list\n\n+--------------------------------------+--------------------------------------+-----------+--------------+------+\n|                  ID                  |              Volume ID               |   Status  | Display Name | Size |\n+--------------------------------------+--------------------------------------+-----------+--------------+------+\n| 293fd67a-bda0-4c64-8bbd-996efc69f7e9 | 062fc1e1-417d-42b9-b6e6-d6dc810e7aaa |   error   |  cv1-snap2   |  1   |\n| cc76d7d3-8a38-49b4-bb75-6cc7139a3699 | 062fc1e1-417d-42b9-b6e6-d6dc810e7aaa | available |  cv1-snap1   |  1   |\n+--------------------------------------+--------------------------------------+-----------+--------------+------+\n", 
            "date_created": "2015-08-12 12:13:34.454952+00:00", 
            "author": "https://api.launchpad.net/1.0/~dpkshetty"
        }, 
        {
            "content": "Attaching my devstack's localrc, to help re-create the exact same env if needed.", 
            "date_created": "2015-08-12 12:20:03.392652+00:00", 
            "author": "https://api.launchpad.net/1.0/~dpkshetty"
        }, 
        {
            "content": "Attaching a minimalistic localrc (file: localrc_v2) that only configures GlusterFS as a backend for Cinder and leave Nova and Glance w/ default backends. Was able to re-create this issue even with this minimal GlusterFS backend config.\n\n", 
            "date_created": "2015-08-13 10:15:56.761898+00:00", 
            "author": "https://api.launchpad.net/1.0/~dpkshetty"
        }, 
        {
            "content": "I have removed the \"nova\" tag because there is no subteam which watches this tag.", 
            "date_created": "2015-11-26 14:07:34.794157+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "This bug is pretty old, can you still recreate this on the latest release (mitaka) or trunk newton master branch code?", 
            "date_created": "2016-05-14 16:11:27.599976+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "[Expired for OpenStack Compute (nova) because there has been no activity for 60 days.]", 
            "date_created": "2016-08-02 04:17:26.358765+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ]
}