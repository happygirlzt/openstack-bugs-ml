{
    "status": "Won't Fix", 
    "last_updated": "2016-05-08 04:17:50.524163+00:00", 
    "description": "Scenario: Host A and Host B are dedicated compute nodes, separate from the controller which contains the neutron networking component.\n1. Spawn an instance on Host A.\n2. Associate a floating ip to it and verify that it can be reached via floating ip and namespace.\n3. live-migrate the instance to the Host B.\n4. After migration completes, verify that the instance can be reached (ping/ssh floating ip and via namespace).\n\nExpected Behavior:\nNetworking of instance should be working fine (ping/ssh should work).\n\nActual Behavior:\nInstance cannot be reached, however, the instance can reach out to everywhere it cannot be reached from (using the console is the only access to the instance, so somehow its still reached)\n\nFurthermore, if the instance gets live-migrated back to the original host, it can again be reached normally.\n\nBranch: Juno 2014.2.1-1, python-novaclient 2.20.0-1\n\nWhich logs are needed for this?", 
    "tags": [
        "live-migration"
    ], 
    "importance": "Undecided", 
    "heat": 20, 
    "link": "https://bugs.launchpad.net/nova/+bug/1459724", 
    "owner": "None", 
    "id": 1459724, 
    "index": 5566, 
    "created": "2015-05-28 15:30:12.188260+00:00", 
    "title": "live-migration causes lack of access to instance", 
    "comments": [
        {
            "content": "Scenario: Host A and Host B are dedicated compute nodes, separate from the controller which contains the neutron networking component.\n1. Spawn an instance on Host A.\n2. Associate a floating ip to it and verify that it can be reached via floating ip and namespace.\n3. live-migrate the instance to the Host B.\n4. After migration completes, verify that the instance can be reached (ping/ssh floating ip and via namespace).\n\nExpected Behavior:\nNetworking of instance should be working fine (ping/ssh should work).\n\nActual Behavior:\nInstance cannot be reached, however, the instance can reach out to everywhere it cannot be reached from (using the console is the only access to the instance, so somehow its still reached)\n\nFurthermore, if the instance gets live-migrated back to the original host, it can again be reached normally.\n\nBranch: Juno 2014.2.1-1, python-novaclient 2.20.0-1\n\nWhich logs are needed for this?", 
            "date_created": "2015-05-28 15:30:12.188260+00:00", 
            "author": "https://api.launchpad.net/1.0/~smarta94"
        }, 
        {
            "content": "Can you share your neutron configuration so I can prepare the same setup to reproduce it?", 
            "date_created": "2015-05-29 07:37:12.157040+00:00", 
            "author": "https://api.launchpad.net/1.0/~pawel-koniszewski"
        }, 
        {
            "content": "Here is my neutron.conf:\n\n[DEFAULT]\nverbose = True\nrouter_distributed = False\ndebug = True\nuse_syslog = False\nbind_host = 0.0.0.0\nbind_port = 9696\nauth_strategy = keystone\nbase_mac = fa:16:3e:00:00:00\nmac_generation_retries = 16\ndhcp_lease_duration = 86400\ndhcp_agent_notification = True\nallow_bulk = True\nallow_pagination = False\nallow_sorting = False\nallow_overlapping_ips = True\nagent_down_time = 75\nrouter_scheduler_driver = neutron.scheduler.l3_agent_scheduler.ChanceScheduler\ndhcp_agents_per_network = 1\napi_workers = 32\nrpc_workers = 32\nuse_ssl = False\nnotify_nova_on_port_status_changes = True\nnotify_nova_on_port_data_changes = True\nnova_url = http://10.173.3.11:8774/v2\nsend_events_interval = 2\nkombu_reconnect_delay=1.0\nrabbit_hosts=10.173.3.11:5672\nrabbit_use_ssl=False\nrabbit_userid=openstack\nrabbit_password=password\nrabbit_virtual_host=/\nrabbit_ha_queues=True\nrpc_backend=rabbit\ncontrol_exchange=neutron\nlog_dir=/var/log/neutron\nservice_plugins=router\ncore_plugin=ml2\nnova_admin_auth_url=http://10.173.3.11:35357/v2.0\nnova_admin_password=nova_password\nnova_region_name=openstack\nnova_admin_username=nova\nnova_admin_tenant_id=61333bf21b844db9b5d02a6612c7cdc2\n[matchmaker_redis]\n[matchmaker_ring]\n[quotas]\n[agent]\nroot_helper = sudo neutron-rootwrap /etc/neutron/rootwrap.conf\nreport_interval = 30\n[keystone_authtoken]\nauth_host = 10.173.3.11\nauth_port = 35357\nauth_protocol = http\nadmin_tenant_name = services\nadmin_user = neutron\nadmin_password = neutron_pass\nauth_uri=http://10.173.3.11:5000/v2.0\n[database]\nconnection = mysql://neutron:mariadb@10.173.3.11/neutron\nmax_retries = 10\nretry_interval = 10\nmin_pool_size = 1\nmax_pool_size = 10\nidle_timeout = 3600\nmax_overflow = 20\n[service_providers]\nservice_provider=LOADBALANCER:Haproxy:neutron.services.loadbalancer.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default\nservice_provider=VPN:openswan:neutron.services.vpn.service_drivers.ipsec.IPsecVPNDriver:default\n\nand the plugins/ml2/ml2_conf.ini:\n[ml2]\ntype_drivers = flat,gre\ntenant_network_types = gre\nmechanism_drivers=openvswitch\n[ml2_type_flat]\nflat_networks=*\n[ml2_type_vlan]\n[ml2_type_gre]\ntunnel_id_ranges=1:1000\n[ml2_type_vxlan]\n[securitygroup]\nenable_security_group = True\nfirewall_driver=neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver\nenable_ipset=True\n[agent]\nl2_population=False\npolling_interval=2\nenable_distributed_routing=False\narp_responder=False\ntunnel_types=gre\n[ovs]\nenable_tunneling=True\nintegration_bridge=br-int\nlocal_ip=10.173.3.11\ntunnel_bridge=br-tun\n\n", 
            "date_created": "2015-05-29 12:46:19.818300+00:00", 
            "author": "https://api.launchpad.net/1.0/~smarta94"
        }, 
        {
            "content": "Status changed to 'Confirmed' because the bug affects multiple users.", 
            "date_created": "2015-06-30 03:29:12.074134+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }, 
        {
            "content": "please provide more info of nova configuration: do you use shared storages for ephemerals? also provide /etc/nova/nova.conf from compute nodes", 
            "date_created": "2015-08-05 08:31:01.818999+00:00", 
            "author": "https://api.launchpad.net/1.0/~tdurakov"
        }, 
        {
            "content": "Cleanup\n=======\n\nThis bug report has the status \"Incomplete\" since more than 30 days\nand it looks like that there are no open reviews for it. To keep\nthe bug list sane, I close this bug with \"won't fix\". This does not\nmean that it is not a valid bug report, it's more to acknowledge that\nno progress can be expected here anymore. You are still free to push a\nnew patch for this bug. If you could reproduce it on the current master\ncode or on a maintained stable branch, please switch it to \"Confirmed\".\nIf you have the information which got asked when this got switched to\n\"Incomplete\", add a comment and switch the report back to \"New\".", 
            "date_created": "2016-03-08 18:45:39.729812+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "[Expired for neutron (Ubuntu) because there has been no activity for 60 days.]", 
            "date_created": "2016-05-08 04:17:46.522015+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ]
}