{
    "status": "Fix Released", 
    "last_updated": "2014-04-17 09:12:57.443727+00:00", 
    "description": "When using the VMwareVCDriver, spawning large amounts of virtual machines concurrently causes some instances to spawn with status ERROR. The number of machines that fail to build is unpredictable and sometimes all instances do end up spawning successfully. \n\nThe issue can be reproduced by running:\n\n\u00a0\u00a0\u00a0\u00a0nova boot --image debian-2.6.32-i686 --flavor 1 --num-instances 32 nameless\n\nThe number of instances that causes the errors differ from environment to environment. Start with 30-40. There are two errors seen in the logs that are causing the instance spawn failures. The first is the ESX host not finding the image in the nfs datastore (even though it is there, otherwise other instances couldn't be spawned). The second is the ESX host not being able to access the vmdk image because it is locked.\n\nImage not found error:\n\nTraceback (most recent call last):\n\u00a0\u00a0File \"/opt/stack/nova/nova/compute/manager.py\", line 1408, in _spawn\n\u00a0\u00a0\u00a0\u00a0block_device_info)\n\u00a0\u00a0File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 609, in spawn\n\u00a0\u00a0\u00a0\u00a0admin_password, network_info, block_device_info)\n\u00a0\u00a0File \"/opt/stack/nova/nova/virt/vmwareapi/vmops.py\", line 440, in spawn\n\u00a0\u00a0\u00a0\u00a0vmdk_file_size_in_kb, linked_clone)\n\u00a0\u00a0File \"/opt/stack/nova/nova/virt/vmwareapi/volumeops.py\", line 71, in attach_disk_to_vm\n\u00a0\u00a0\u00a0\u00a0self._session._wait_for_task(instance_uuid, reconfig_task)\n\u00a0\u00a0File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 795, in _wait_for_task\n\u00a0\u00a0\u00a0\u00a0ret_val = done.wait()\n\u00a0\u00a0File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 116, in wait\n\u00a0\u00a0\u00a0\u00a0return hubs.get_hub().switch()\n\u00a0\u00a0File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 187, in switch\n\u00a0\u00a0\u00a0\u00a0return self.greenlet.switch()\nNovaException: File [ryan-nfs] vmware_base/e8c42ed8-05e7-45bc-90c3-49a34e5a37c6.vmdk was not found\n\nImage locked error:\n\nTraceback (most recent call last):\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1407, in _spawn\n    block_device_info)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 623, in spawn\n    admin_password, network_info, block_device_info)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/vmops.py\", line 504, in spawn\n    root_gb_in_kb, linked_clone)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/volumeops.py\", line 71, in attach_disk_to_vm\n    self._session._wait_for_task(instance_uuid, reconfig_task)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 900, in _wait_for_task\n    ret_val = done.wait()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 116, in wait\n    return hubs.get_hub().switch()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 187, in switch\n    return self.greenlet.switch()\nNovaException: Unable to access file [ryan-nfs] vmware_base/f110bb94-2170-4a3a-ae0d-760f95eb8b47.0.\n\nEnvironment information:\n\n- 1 datacenter, 1 cluster, 7 hosts\n- NFS shared datastore\n- was able to spawn 7 instances before errors appeared\n- screen log with tracebacks: http://paste.openstack.org/show/47410/", 
    "tags": [
        "havana-backport-potential", 
        "vmware"
    ], 
    "importance": "High", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1230047", 
    "owner": "https://api.launchpad.net/1.0/~garyk", 
    "id": 1230047, 
    "index": 1253, 
    "openned": "2013-09-25 03:35:13.071338+00:00", 
    "created": "2013-09-25 03:35:13.071338+00:00", 
    "title": "VMware: spawning large amounts of VMs concurrently sometimes causes 'VMDK lock' error", 
    "comments": [
        {
            "content": "BUG-DESCRIPTION:\nWhen using the VMwareVCDriver, spawning large amounts of virtual machines concurrently causes some instances to spawn with status ERROR. The number of machines that fail to build is unpredictable and sometimes all instances do end up spawning successfully.\n\nThe issue can be reproduced by running:\n\n    nova boot --image debian-2.6.32-i686 --flavor 1 --num-instances 32 nameless\n\nThe number of instances that causes the errors differ from environment to environment. Start with 30-40. Either of the 2 following error messages can be seen in the logs when an instance fails to build.\n\nTraceback (most recent call last):\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1408, in _spawn\n    block_device_info)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 609, in spawn\n    admin_password, network_info, block_device_info)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/vmops.py\", line 440, in spawn\n    vmdk_file_size_in_kb, linked_clone)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/volumeops.py\", line 71, in attach_disk_to_vm\n    self._session._wait_for_task(instance_uuid, reconfig_task)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 795, in _wait_for_task\n    ret_val = done.wait()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 116, in wait\n    return hubs.get_hub().switch()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 187, in switch\n    return self.greenlet.switch()\nNovaException: File [ryan-nfs] vmware_base/e8c42ed8-05e7-45bc-90c3-49a34e5a37c6.vmdk was not found\n\nTraceback (most recent call last):\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1228, in _allocate_network_async\n    dhcp_options=dhcp_options)\n  File \"/opt/stack/nova/nova/network/api.py\", line 93, in wrapped\n    return func(self, context, *args, **kwargs)\n  File \"/opt/stack/nova/nova/network/api.py\", line 49, in wrapper\n    res = f(self, context, *args, **kwargs)\n  File \"/opt/stack/nova/nova/network/api.py\", line 300, in allocate_for_instance\n    nw_info = self.network_rpcapi.allocate_for_instance(context, **args)\n  File \"/opt/stack/nova/nova/network/rpcapi.py\", line 184, in allocate_for_instance\n    macs=jsonutils.to_primitive(macs))\n  File \"/opt/stack/nova/nova/rpcclient.py\", line 85, in call\n    return self._invoke(self.proxy.call, ctxt, method, **kwargs)\n  File \"/opt/stack/nova/nova/rpcclient.py\", line 63, in _invoke\n    return cast_or_call(ctxt, msg, **self.kwargs)\n  File \"/opt/stack/nova/nova/openstack/common/rpc/proxy.py\", line 130, in call\n    exc.info, real_topic, msg.get('method'))\n\n\nHere information from the 2 environments where the issue was observed:\n\nEnvironment 1:\n- 1 datacenter, 1 cluster, 7 hosts\n- NFS shared datastore\n- was able to spawn 7 instances before errors appeared\n- screen log with tracebacks: http://paste.openstack.org/show/47410/\n\nEnvironment 2:\n- 1 datacenter, 1 cluster, 2 hosts\n- iSCSI shared datastore\n- was able to spawn ~30 instances before errors appeared\n- screen log with tracebacks: http://paste.openstack.org/show/47467/", 
            "date_created": "2013-09-25 03:35:13.071338+00:00", 
            "author": "https://api.launchpad.net/1.0/~rhsu"
        }, 
        {
            "content": "Have you changed the config options of task_poll_interval? the default is 5 seconds, in NFS case, it might be increased to a more appropriate value.", 
            "date_created": "2013-09-25 06:30:30.402152+00:00", 
            "author": "https://api.launchpad.net/1.0/~guohliu"
        }, 
        {
            "content": "I'll try and look at this myself later in the week.", 
            "date_created": "2013-09-25 17:46:21.553316+00:00", 
            "author": "https://api.launchpad.net/1.0/~hartsock"
        }, 
        {
            "content": "Spawning small number of VMs also fails. For example, if you try to spawn 4 VMs at the same time. All will fail except for one VM. The error message for the other VMs is (from vsphere client): \n\nCreate virtual disk\n[datastore1] vmware_base/4a7fd81b-9119-4a86-96d0-c1f6a7753883.vmdk\nCannot complete the operation because the file or folder [datastore1] \nvmware_base/4a7fd81b-9119-4a86-96d0-c1f6a7753883.vmdk already \nexists\n\nIt seems like multiple vmdks with the same name are being created. I have a one node setup and I've tried using both the ESX and VC drivers, I get the same error.", 
            "date_created": "2013-10-29 20:55:07.111760+00:00", 
            "author": "https://api.launchpad.net/1.0/~maithem"
        }, 
        {
            "content": "Maithem, if you are talking about the case when multiple spawning on a datastore that does not yet have the image cached, then it is a different issue ( bug is 1222948 ), and https://review.openstack.org/#/c/46400 is what is supposed to address it. In this case I believe the image is already cached, each spawn operation is just supposed to make use of it, but somehow the cached vmdk is not found for some odd reason.", 
            "date_created": "2013-10-29 21:27:08.484377+00:00", 
            "author": "https://api.launchpad.net/1.0/~vui"
        }, 
        {
            "content": "ryan - was this bug before you increased your ram and pre-populated the cache with the image?", 
            "date_created": "2013-10-29 22:21:29.111555+00:00", 
            "author": "https://api.launchpad.net/1.0/~tjones-i"
        }, 
        {
            "content": "Tracy, I pre-populated the cache before I ran the test to reproduce the issue. As for memory, increasing the RAM seemed to help on some systems but did not help others.", 
            "date_created": "2013-10-29 22:55:30.386974+00:00", 
            "author": "https://api.launchpad.net/1.0/~rhsu"
        }, 
        {
            "content": "Update: we have a possible root cause and a patch in internal development/testing on this problem.", 
            "date_created": "2013-11-27 16:32:00.510686+00:00", 
            "author": "https://api.launchpad.net/1.0/~hartsock"
        }, 
        {
            "content": "Addressed by - https://review.openstack.org/#/c/58598/", 
            "date_created": "2013-12-01 07:31:57.196963+00:00", 
            "author": "https://api.launchpad.net/1.0/~garyk"
        }, 
        {
            "content": "The patch for this seems to be stacked on top of a \"feature change\" (image aging) that will not be backported to Havana.  Would it make sense to merge this change first, so that the backport for Havana is cleaner?  ", 
            "date_created": "2013-12-02 20:46:59.956900+00:00", 
            "author": "https://api.launchpad.net/1.0/~danwent"
        }, 
        {
            "content": "Tracking - This bug is being addressed by https://review.openstack.org/#/c/63933/ - Status: Proposed", 
            "date_created": "2014-01-11 00:10:09.453221+00:00", 
            "author": "https://api.launchpad.net/1.0/~tjones-i"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/63933\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=bf882fbc4aa68cf0191bce70e622d81969617c02\nSubmitter: Jenkins\nBranch:    master\n\ncommit bf882fbc4aa68cf0191bce70e622d81969617c02\nAuthor: Gary Kotton <email address hidden>\nDate:   Tue Dec 24 06:19:26 2013 -0800\n\n    VMware: create datastore utility functions\n    \n    The patch moves datastore interfaces from vmops and vm_util\n    to a separate file - ds_util.\n    \n    This is part of the blueprint vmware-image-cache-management.\n    \n    In the past the datastore methods would poll the task\n    to determine that it had completed. This has beem addressed by\n    making the driver _poll_task return the task information.\n    \n    The patch set also solves the following bugs by checking if\n    the FileAlreadyExistsException exception is raised. This could\n    be due to another process or thread creating the file.\n    \n    Closes-bug: 1230047\n    Closes-bug: 1254128\n    \n    Change-Id: I788e33dbcb3dedc41831b976137607274b1c02ca\n", 
            "date_created": "2014-03-06 13:50:12.543761+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2014-03-31 19:02:57.728716+00:00"
}