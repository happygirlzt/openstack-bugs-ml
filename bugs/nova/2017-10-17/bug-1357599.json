{
    "status": "Fix Released", 
    "last_updated": "2014-10-16 08:55:01.065968+00:00", 
    "description": "The tempest test that does a resize on the instance from time to time fails with a neutron virtual interface timeout error. The reason why this is occurring is because resize_instance() calls:\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0disk_info = self.driver.migrate_disk_and_power_off(\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0context, instance, migration.dest_host,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0instance_type, network_info,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0block_device_info)\n\nwhich calls destory() which unplugs the vifs(). Then,\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0self.driver.finish_migration(context, migration, instance,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0disk_info,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0network_info,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0image, resize_instance,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0block_device_info, power_on)\n\nis called which expects a vif_plugged event. Since this happens on the same host the neutron agent is able to detect that the vif was unplugged then plugged because it happens so fast.  To fix this we should check if we are migrating to the same host if we are we should not expect to get an event.\n\n8d1] Setting instance vm_state to ERROR\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1] Traceback (most recent call last):\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 3714, in finish_resize\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     disk_info, image)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 3682, in _finish_resize\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     old_instance_type, sys_meta)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 82, in __exit__\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     six.reraise(self.type_, self.value, self.tb)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 3677, in _finish_resize\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     block_device_info, power_on)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 5302, in finish_migration\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     block_device_info, power_on)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3792, in _create_domain_and_network\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     raise exception.VirtualInterfaceCreateException()\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1] VirtualInterfaceCreateException: Virtual Interface creation failed", 
    "tags": [
        "in-stable-icehouse"
    ], 
    "importance": "High", 
    "heat": 8, 
    "link": "https://bugs.launchpad.net/nova/+bug/1357599", 
    "owner": "https://api.launchpad.net/1.0/~arosen", 
    "id": 1357599, 
    "index": 1569, 
    "openned": "2014-08-16 00:34:03.179519+00:00", 
    "created": "2014-08-16 00:34:03.179519+00:00", 
    "title": "race condition with neutron in nova migrate code", 
    "comments": [
        {
            "content": "The tempest test that does a resize on the instance from time to time fails with a neutron virtual interface timeout error. The reason why this is occurring is because resize_instance() calls: \n\n            disk_info = self.driver.migrate_disk_and_power_off(\n                    context, instance, migration.dest_host,\n                    instance_type, network_info,\n                    block_device_info)\n\nwhich calls destory() which unplugs the vifs(). Then, \n\n            self.driver.finish_migration(context, migration, instance,\n                                         disk_info,\n                                         network_info,\n                                         image, resize_instance,\n                                         block_device_info, power_on)\n\nis called which expects a vif_plugged event. Since this happens on the same host the neutron agent is able to detect that the vif was unplugged then plugged because it happens so fast.  To fix this we should check if we are migrating to the same host if we are we should not expect to get an event. \n\n\n\n8d1] Setting instance vm_state to ERROR\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1] Traceback (most recent call last):\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 3714, in finish_resize\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     disk_info, image)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 3682, in _finish_resize\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     old_instance_type, sys_meta)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/openstack/common/excutils.py\", line 82, in __exit__\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     six.reraise(self.type_, self.value, self.tb)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 3677, in _finish_resize\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     block_device_info, power_on)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 5302, in finish_migration\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     block_device_info, power_on)\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 3792, in _create_domain_and_network\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1]     raise exception.VirtualInterfaceCreateException()\n2014-08-14 00:03:58.010 1276 TRACE nova.compute.manager [instance: dca468e4-d26f-4ae2-a522-7d02ef7c98d1] VirtualInterfaceCreateException: Virtual Interface creation failed", 
            "date_created": "2014-08-16 00:34:03.179519+00:00", 
            "author": "https://api.launchpad.net/1.0/~arosen"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/116354", 
            "date_created": "2014-08-22 18:07:19.357786+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/icehouse\nReview: https://review.openstack.org/119260", 
            "date_created": "2014-09-05 00:09:05.555555+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/116354\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=80deed660815b9ba69e424b83805a21768b02bb6\nSubmitter: Jenkins\nBranch:    master\n\ncommit 80deed660815b9ba69e424b83805a21768b02bb6\nAuthor: Aaron Rosen <email address hidden>\nDate:   Fri Aug 22 10:35:09 2014 -0700\n\n    Fix race condition with vif plugging in finish migrate\n    \n    The tempest test that does a resize on an instance from time to time fails\n    with neutron with a virtual interface timout error. The reason why this\n    occurs is that nova-compute calls a vifs_unplug() then vifs_plug() fairly\n    quickly and the neutron-agent doesn't realize this happens because the way\n    it detects this is via polling. This patch fixings this problem by passing\n    vifs_already_plugged=True to _create_domain_and_network to avoid waiting\n    for the neutron notifcation.\n    \n    Initially, I thought this problem could be solved by setting\n    vifs_already_plugged=True if migrate.source_host == migrate_desk.dest_host\n    but it turns out that this race condition can still occur if migrated to\n    another host though it's fairly unlikely. Always setting\n    vifs_already_plugged=True ensures we never hit this issue on migrate.\n    \n    Change-Id: I90424ad50ac993c4abb049aa0654a94b225b5ebb\n    Closes-bug: 1357599\n    Closes-bug: 1357476\n", 
            "date_created": "2014-09-05 19:41:44.539507+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/119260\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=0d69163d6a430d95d2bc0b30e111703d536fbcbd\nSubmitter: Jenkins\nBranch:    stable/icehouse\n\ncommit 0d69163d6a430d95d2bc0b30e111703d536fbcbd\nAuthor: Aaron Rosen <email address hidden>\nDate:   Fri Aug 22 10:35:09 2014 -0700\n\n    Fix race condition with vif plugging in finish migrate\n    \n    The tempest test that does a resize on an instance from time to time fails\n    with neutron with a virtual interface timout error. The reason why this\n    occurs is that nova-compute calls a vifs_unplug() then vifs_plug() fairly\n    quickly and the neutron-agent doesn't realize this happens because the way\n    it detects this is via polling. This patch fixings this problem by passing\n    vifs_already_plugged=True to _create_domain_and_network to avoid waiting\n    for the neutron notifcation.\n    \n    Initially, I thought this problem could be solved by setting\n    vifs_already_plugged=True if migrate.source_host == migrate_desk.dest_host\n    but it turns out that this race condition can still occur if migrated to\n    another host though it's fairly unlikely. Always setting\n    vifs_already_plugged=True ensures we never hit this issue on migrate.\n    \n    Change-Id: I90424ad50ac993c4abb049aa0654a94b225b5ebb\n    Closes-bug: 1357599\n    Closes-bug: 1357476\n    (cherry picked from commit 80deed660815b9ba69e424b83805a21768b02bb6)\n", 
            "date_created": "2014-09-06 17:47:55.054792+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2014-10-01 07:37:22.260067+00:00"
}