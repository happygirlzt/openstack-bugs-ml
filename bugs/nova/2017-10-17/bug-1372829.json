{
    "status": "Fix Released", 
    "last_updated": "2014-10-16 08:56:12.301212+00:00", 
    "description": "once enabled vcpu_pin_set=0-9  in nova.conf, got the following exception:\n\n2014-09-23 11:00:41.603 14427 DEBUG nova.openstack.common.processutils [-] Result was 0 execute /opt/stack/nova/nova/openstack/common/processutils.py:195\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 455, in fire_timers\n    timer()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/timer.py\", line 58, in __call__\n    cb(*args, **kw)\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 168, in _do_send\n    waiter.switch(result)\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 212, in main\n    result = function(*args, **kwargs)\n  File \"/opt/stack/nova/nova/openstack/common/service.py\", line 490, in run_service\n    service.start()\n  File \"/opt/stack/nova/nova/service.py\", line 181, in start\n    self.manager.pre_start_hook()\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1152, in pre_start_hook\n    self.update_available_resource(nova.context.get_admin_context())\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 5922, in update_available_resource\n    nodenames = set(self.driver.get_available_nodes())\n  File \"/opt/stack/nova/nova/virt/driver.py\", line 1237, in get_available_nodes\n    stats = self.get_host_stats(refresh=refresh)\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 5760, in get_host_stats\n    return self.host_state.get_host_stats(refresh=refresh)\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 470, in host_state\n    self._host_state = HostState(self)\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6320, in __init__\n    self.update_status()\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6376, in update_status\n    numa_topology = self.driver._get_host_numa_topology()\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 4869, in _get_host_numa_topology\n    cell.cpuset &= allowed_cpus\nTypeError: unsupported operand type(s) for &=: 'set' and 'list'\n2014-09-23 11:00:42.032 14427 ERROR nova.openstack.common.threadgroup [-] unsupported operand type(s) for &=: 'set' and 'list'\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup Traceback (most recent call last):\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/threadgroup.py\", line 125, in wait\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     x.wait()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/threadgroup.py\", line 47, in wait\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return self.thread.wait()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 173, in wait\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return self._exit_event.wait()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 121, in wait\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return hubs.get_hub().switch()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 293, in switch\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return self.greenlet.switch()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 212, in main\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     result = function(*args, **kwargs)\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/service.py\", line 490, in run_service\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     service.start()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/service.py\", line 181, in start\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     self.manager.pre_start_hook()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/manager.py\", line 1152, in pre_start_hook\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     self.update_available_resource(nova.context.get_admin_context())\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/manager.py\", line 5922, in update_available_resource\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     nodenames = set(self.driver.get_available_nodes())\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/driver.py\", line 1237, in get_available_nodes\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     stats = self.get_host_stats(refresh=refresh)\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 5760, in get_host_stats\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return self.host_state.get_host_stats(refresh=refresh)\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 470, in host_state\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     self._host_state = HostState(self)\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6320, in __init__\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     self.update_status()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6376, in update_status\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     numa_topology = self.driver._get_host_numa_topology()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 4869, in _get_host_numa_topology\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     cell.cpuset &= allowed_cpus\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup TypeError: unsupported operand type(s) for &=: 'set' and 'list'\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup", 
    "tags": [
        "libvirt"
    ], 
    "importance": "High", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1372829", 
    "owner": "https://api.launchpad.net/1.0/~boden", 
    "id": 1372829, 
    "index": 1621, 
    "openned": "2014-09-23 08:45:09.287874+00:00", 
    "created": "2014-09-23 08:45:09.287874+00:00", 
    "title": "vcpu_pin_set setting raises exception", 
    "comments": [
        {
            "content": "once enabled vcpu_pin_set=0-9  in nova.conf, got the following exception:\n\n2014-09-23 11:00:41.603 14427 DEBUG nova.openstack.common.processutils [-] Result was 0 execute /opt/stack/nova/nova/openstack/common/processutils.py:195\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 455, in fire_timers\n    timer()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/timer.py\", line 58, in __call__\n    cb(*args, **kw)\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 168, in _do_send\n    waiter.switch(result)\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 212, in main\n    result = function(*args, **kwargs)\n  File \"/opt/stack/nova/nova/openstack/common/service.py\", line 490, in run_service\n    service.start()\n  File \"/opt/stack/nova/nova/service.py\", line 181, in start\n    self.manager.pre_start_hook()\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1152, in pre_start_hook\n    self.update_available_resource(nova.context.get_admin_context())\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 5922, in update_available_resource\n    nodenames = set(self.driver.get_available_nodes())\n  File \"/opt/stack/nova/nova/virt/driver.py\", line 1237, in get_available_nodes\n    stats = self.get_host_stats(refresh=refresh)\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 5760, in get_host_stats\n    return self.host_state.get_host_stats(refresh=refresh)\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 470, in host_state\n    self._host_state = HostState(self)\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6320, in __init__\n    self.update_status()\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6376, in update_status\n    numa_topology = self.driver._get_host_numa_topology()\n  File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 4869, in _get_host_numa_topology\n    cell.cpuset &= allowed_cpus\nTypeError: unsupported operand type(s) for &=: 'set' and 'list'\n2014-09-23 11:00:42.032 14427 ERROR nova.openstack.common.threadgroup [-] unsupported operand type(s) for &=: 'set' and 'list'\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup Traceback (most recent call last):\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/threadgroup.py\", line 125, in wait\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     x.wait()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/threadgroup.py\", line 47, in wait\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return self.thread.wait()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 173, in wait\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return self._exit_event.wait()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 121, in wait\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return hubs.get_hub().switch()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 293, in switch\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return self.greenlet.switch()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 212, in main\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     result = function(*args, **kwargs)\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/openstack/common/service.py\", line 490, in run_service\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     service.start()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/service.py\", line 181, in start\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     self.manager.pre_start_hook()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/manager.py\", line 1152, in pre_start_hook\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     self.update_available_resource(nova.context.get_admin_context())\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/compute/manager.py\", line 5922, in update_available_resource\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     nodenames = set(self.driver.get_available_nodes())\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/driver.py\", line 1237, in get_available_nodes\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     stats = self.get_host_stats(refresh=refresh)\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 5760, in get_host_stats\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     return self.host_state.get_host_stats(refresh=refresh)\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 470, in host_state\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     self._host_state = HostState(self)\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6320, in __init__\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     self.update_status()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6376, in update_status\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     numa_topology = self.driver._get_host_numa_topology()\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 4869, in _get_host_numa_topology\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup     cell.cpuset &= allowed_cpus\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup TypeError: unsupported operand type(s) for &=: 'set' and 'list'\n2014-09-23 11:00:42.032 14427 TRACE nova.openstack.common.threadgroup", 
            "date_created": "2014-09-23 08:45:09.287874+00:00", 
            "author": "https://api.launchpad.net/1.0/~irenab"
        }, 
        {
            "content": "So this happens only on NUMA hosts where we hit the following branch of NUMA fitting code.\n\nif topology:\n                # Host is NUMA capable so try to keep the instance in a cell\n                viable_cells = [cell for cell in topology.cells\n                                if vcpus <= len(cell.cpus) and\n                                memory * 1024 <= cell.memory]\n                if not viable_cells:\n                    # We can't contain the instance in a cell - do nothing for\n                    # now.\n                    # TODO(ndipanov): Attempt to spread the instance accross\n                    # NUMA nodes and expose the topology to the instance as an\n                    # optimisation\n                    return allowed_cpus, None, None\n                else:\n                    cell = random.choice(viable_cells)\n                    pin_cpuset = set(cpu.id for cpu in cell.cpus)\n                    if allowed_cpus:\n                        pin_cpuset &= allowed_cpus\n                    return pin_cpuset, None, None\n\nThe issue is that we pass the return value of hardware.get_vcpu_pin_set() which returns a list directly into this method. which assumes it's an instance of set().\n\nWe need to make sure that we conver it to a set first.\n\nThis bug will break anyone who uses the vcpu_pin_set config option so should be fixed ASAP.", 
            "date_created": "2014-09-23 08:54:48.020318+00:00", 
            "author": "https://api.launchpad.net/1.0/~ndipanov"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/123515", 
            "date_created": "2014-09-23 16:59:25.206764+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/123696", 
            "date_created": "2014-09-24 11:32:08.312680+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Nikola Dipanov (<email address hidden>) on branch: master\nReview: https://review.openstack.org/123696\nReason: Abandoning in favour of https://review.openstack.org/#/c/123515/", 
            "date_created": "2014-09-24 12:08:46.666140+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Nikola Dipanov (<email address hidden>) on branch: master\nReview: https://review.openstack.org/123696\nReason: Actually no - the other fix is better... move along :)", 
            "date_created": "2014-09-24 12:15:55.912407+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/123515\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=021202e80da7ce587a4d36c464c7b6835e5bface\nSubmitter: Jenkins\nBranch:    master\n\ncommit 021202e80da7ce587a4d36c464c7b6835e5bface\nAuthor: Boden R <email address hidden>\nDate:   Tue Sep 23 12:55:54 2014 -0400\n\n    Return vcpu pin set as set rather than list\n    \n    The current implementation of the libvirt driver makes mixed assumptions\n    about the vcpu pin set returned from hardware.get_vcpu_pin_set(). Most\n    places in the code assume its a set and perform set operations on the\n    structure. However a few  places assume it's a list. Given the mixed\n    assumptions about the structure type, the existing code was trying\n    to perform set operations on a list.\n    \n    This patch changes the get_vcpu_pin_set() method to return a set\n    rather than a list and handles any edge cases where consumers need\n    a list. It also updates any relevant unit tests accordingly.\n    \n    Change-Id: I66d5cbc0e2d370d9d2d2ab2bad2c5b348bedba6c\n    Closes-Bug: 1372829\n", 
            "date_created": "2014-09-25 04:57:34.202251+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2014-10-01 07:39:06.126705+00:00"
}