{
    "status": "Fix Released", 
    "last_updated": "2013-10-14 09:09:34.213186+00:00", 
    "description": "Using code written against the Boto client library and originally tested against EC2 I'm finding I have to retrofit all my exception handling because Nova seems to just wrap its own exceptions as EC2ResponseError, so the error codes have no resemblance to the EC2 API error codes:\nhttp://docs.aws.amazon.com/AWSEC2/latest/APIReference/api-error-codes.html\n\nFor example, when I hit Nova quota limits and try to start new instances I get:\n\n  File \"/opt/local/nimrodg/share/nimrod/boto/ec2/connection.py\", line 715, in run_instances\n     verb='POST')\n   File \"/opt/local/nimrodg/share/nimrod/boto/connection.py\", line 1000, in get_object\n     raise self.ResponseError(response.status, response.reason, body)\n EC2ResponseError: EC2ResponseError: 400 Bad Request\n <?xml version=\"1.0\"?>\n <Response><Errors><Error><Code>TooManyInstances</Code><Message>Quota exceeded for cores,ram: Request\ned 4, but already used 80 of 80 cores</Message></Error></Errors><RequestID>req-74d2e517-c99f-43e6-bfc\n1-651ef79737ff</RequestID></Response>\n\n\nBut I'm expecting the error code for this from an EC2 compatible API to be InstanceLimitExceeded.\n\nSeems like it should be possible be add the equivalent ec2_api_error string to all suitable Nova exceptions and then have Nova's EC2 API use that where available?", 
    "tags": [
        "ec2"
    ], 
    "importance": "Undecided", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1203416", 
    "owner": "None", 
    "id": 1203416, 
    "index": 5132, 
    "openned": "2013-07-21 03:20:56.372475+00:00", 
    "created": "2013-07-21 03:20:56.372475+00:00", 
    "title": "EC2 API errors do not match spec", 
    "comments": [
        {
            "content": "Using code written against the Boto client library and originally tested against EC2 I'm finding I have to retrofit all my exception handling because Nova seems to just wrap its own exceptions as EC2ResponseError, so the error codes have no resemblance to the EC2 API error codes:\nhttp://docs.aws.amazon.com/AWSEC2/latest/APIReference/api-error-codes.html\n\nFor example, when I hit Nova quota limits and try to start new instances I get:\n\n  File \"/opt/local/nimrodg/share/nimrod/boto/ec2/connection.py\", line 715, in run_instances\n     verb='POST')\n   File \"/opt/local/nimrodg/share/nimrod/boto/connection.py\", line 1000, in get_object\n     raise self.ResponseError(response.status, response.reason, body)\n EC2ResponseError: EC2ResponseError: 400 Bad Request\n <?xml version=\"1.0\"?>\n <Response><Errors><Error><Code>TooManyInstances</Code><Message>Quota exceeded for cores,ram: Request\ned 4, but already used 80 of 80 cores</Message></Error></Errors><RequestID>req-74d2e517-c99f-43e6-bfc\n1-651ef79737ff</RequestID></Response>\n\n\nBut I'm expecting the error code for this from an EC2 compatible API to be InstanceLimitExceeded.\n\nSeems like it should be possible be add the equivalent ec2_api_error string to all suitable Nova exceptions and then have Nova's EC2 API use that where available?", 
            "date_created": "2013-07-21 03:20:56.372475+00:00", 
            "author": "https://api.launchpad.net/1.0/~blair-bethwaite"
        }, 
        {
            "content": "See https://blueprints.launchpad.net/nova/+spec/ec2-error-codes -- I think Jakub is breaking up the work into smaller patches for review.", 
            "date_created": "2013-07-21 04:34:32.983970+00:00", 
            "author": "https://api.launchpad.net/1.0/~holzman"
        }, 
        {
            "content": "The code for the referenced blueprint has been merged.  If there are still problems, please report them specifically so that we can track and fix each one.", 
            "date_created": "2013-09-09 21:34:12.042483+00:00", 
            "author": "https://api.launchpad.net/1.0/~russellb"
        }, 
        {
            "content": "It's great that there are some improvements coming in Havana, though I probably won't get to test them until we roll it into production. I suppose given the size (or rather, the number) of patches involved it's unlikely this will get back-ported to Grizzly.", 
            "date_created": "2013-10-11 09:05:48.310891+00:00", 
            "author": "https://api.launchpad.net/1.0/~blair-bethwaite"
        }
    ], 
    "closed": "2013-10-14 09:09:31.997721+00:00"
}