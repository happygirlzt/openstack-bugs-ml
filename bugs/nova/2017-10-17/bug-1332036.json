{
    "status": "Invalid", 
    "last_updated": "2014-06-23 02:44:27.836489+00:00", 
    "description": "\n[Issue]\n\nI'm checking the behavior when system failure cases.\nInstance status never changed from BUILD after rabbitmq restarted.\n\n[How to reproduce]\n\n1) boot services that contained nova and rabbit.\n\n2) kill rabbitmq service for simulating system failure.\n\n$ ps aux|grep beam|grep -v grep\nrabbitmq 15816  2.4  1.3 146496 27048 ?        Sl   20:05   0:01 /usr/lib/erlang/erts-5.10.4/bin/beam -W w -K true -A30 -P 1048576 -- -root /usr/lib/erlang -progname erl -- -home /var/lib/rabbitmq -- -pa /usr/lib/rabbitmq/lib/rabbitmq_server-3.2.4/sbin/../ebin -noshell -noinput -s rabbit boot -sname rabbit@interdev -boot start_sasl -kernel inet_default_connect_options [{nodelay,true}] -sasl errlog_type error -sasl sasl_error_logger false -rabbit error_logger {file,\"/<email address hidden>\"} -rabbit sasl_error_logger {file,\"/<email address hidden>\"} -rabbit enabled_plugins_file \"/etc/rabbitmq/enabled_plugins\" -rabbit plugins_dir \"/usr/lib/rabbitmq/lib/rabbitmq_server-3.2.4/sbin/../plugins\" -rabbit plugins_expand_dir \"/var/lib/rabbitmq/mnesia/rabbit@interdev-plugins-expand\" -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir \"/var/lib/rabbitmq/mnesia/rabbit@interdev\"\n$ sudo kill -SIGKILL 15816\n\n3) restart rabbitmq service.\n\n$ sudo /etc/init.d/rabbitmq-server start\n * Starting message broker rabbitmq-server                                                                       [ OK ]\n\n4) request to boot instance\n\n$ nova boot --flavor 1 --image 41793321-51b1-413a-a69f-0c25d7a63b22 aaa\n+--------------------------------------+-------------------------------------------------+\n| Property                             | Value                                           |\n+--------------------------------------+-------------------------------------------------+\n| OS-DCF:diskConfig                    | MANUAL                                          |\n| OS-EXT-AZ:availability_zone          | nova                                            |\n| OS-EXT-SRV-ATTR:host                 | -                                               |\n| OS-EXT-SRV-ATTR:hypervisor_hostname  | -                                               |\n| OS-EXT-SRV-ATTR:instance_name        | instance-00000005                               |\n| OS-EXT-STS:power_state               | 0                                               |\n| OS-EXT-STS:task_state                | scheduling                                      |\n| OS-EXT-STS:vm_state                  | building                                        |\n| OS-SRV-USG:launched_at               | -                                               |\n| OS-SRV-USG:terminated_at             | -                                               |\n| accessIPv4                           |                                                 |\n| accessIPv6                           |                                                 |\n| adminPass                            | 2gV49MZNHLQm                                    |\n| config_drive                         |                                                 |\n| created                              | 2014-06-19T11:06:51Z                            |\n| flavor                               | m1.tiny (1)                                     |\n| hostId                               |                                                 |\n| id                                   | 157f3d5d-5d26-4a55-9d7c-ab0dc3d9fdc9            |\n| image                                | CorePlus (41793321-51b1-413a-a69f-0c25d7a63b22) |\n| key_name                             | -                                               |\n| metadata                             | {}                                              |\n| name                                 | aaa                                             |\n| os-extended-volumes:volumes_attached | []                                              |\n| progress                             | 0                                               |\n| security_groups                      | default                                         |\n| status                               | BUILD                                           |\n| tenant_id                            | 5924ee51bb6945f39dc7010687ef43af                |\n| updated                              | 2014-06-19T11:06:54Z                            |\n| user_id                              | 35b1c3ef8b9d442cad696d049f7b2041                |\n+--------------------------------------+-------------------------------------------------+ \n\n5) however, instance status never changed from BUILD/NOSTATE\n\n$ nova list\n+--------------------------------------+------+--------+------------+-------------+----------+\n| ID                                   | Name | Status | Task State | Power State | Networks |\n+--------------------------------------+------+--------+------------+-------------+----------+\n| 157f3d5d-5d26-4a55-9d7c-ab0dc3d9fdc9 | aaa  | BUILD  | -          | NOSTATE     |          |\n+--------------------------------------+------+--------+------------+-------------+----------+", 
    "tags": [], 
    "importance": "Undecided", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1332036", 
    "owner": "None", 
    "id": 1332036, 
    "index": 6200, 
    "openned": "2014-06-19 11:19:23.960154+00:00", 
    "created": "2014-06-19 11:19:23.960154+00:00", 
    "title": "Instance status would never changed from BUILD after rabbitmq restarted", 
    "comments": [
        {
            "content": "\n[Issue]\n\nI'm checking the behavior when system failure cases.\nInstance status never changed from BUILD after rabbitmq restarted.\n\n[How to reproduce]\n\n1) boot services that contained nova and rabbit.\n\n2) kill rabbitmq service for simulating system failure.\n\n$ ps aux|grep beam|grep -v grep\nrabbitmq 15816  2.4  1.3 146496 27048 ?        Sl   20:05   0:01 /usr/lib/erlang/erts-5.10.4/bin/beam -W w -K true -A30 -P 1048576 -- -root /usr/lib/erlang -progname erl -- -home /var/lib/rabbitmq -- -pa /usr/lib/rabbitmq/lib/rabbitmq_server-3.2.4/sbin/../ebin -noshell -noinput -s rabbit boot -sname rabbit@interdev -boot start_sasl -kernel inet_default_connect_options [{nodelay,true}] -sasl errlog_type error -sasl sasl_error_logger false -rabbit error_logger {file,\"/<email address hidden>\"} -rabbit sasl_error_logger {file,\"/<email address hidden>\"} -rabbit enabled_plugins_file \"/etc/rabbitmq/enabled_plugins\" -rabbit plugins_dir \"/usr/lib/rabbitmq/lib/rabbitmq_server-3.2.4/sbin/../plugins\" -rabbit plugins_expand_dir \"/var/lib/rabbitmq/mnesia/rabbit@interdev-plugins-expand\" -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir \"/var/lib/rabbitmq/mnesia/rabbit@interdev\"\n$ sudo kill -SIGKILL 15816\n\n3) restart rabbitmq service.\n\n$ sudo /etc/init.d/rabbitmq-server start\n * Starting message broker rabbitmq-server                                                                       [ OK ]\n\n4) request to boot instance\n\n$ nova boot --flavor 1 --image 41793321-51b1-413a-a69f-0c25d7a63b22 aaa\n+--------------------------------------+-------------------------------------------------+\n| Property                             | Value                                           |\n+--------------------------------------+-------------------------------------------------+\n| OS-DCF:diskConfig                    | MANUAL                                          |\n| OS-EXT-AZ:availability_zone          | nova                                            |\n| OS-EXT-SRV-ATTR:host                 | -                                               |\n| OS-EXT-SRV-ATTR:hypervisor_hostname  | -                                               |\n| OS-EXT-SRV-ATTR:instance_name        | instance-00000005                               |\n| OS-EXT-STS:power_state               | 0                                               |\n| OS-EXT-STS:task_state                | scheduling                                      |\n| OS-EXT-STS:vm_state                  | building                                        |\n| OS-SRV-USG:launched_at               | -                                               |\n| OS-SRV-USG:terminated_at             | -                                               |\n| accessIPv4                           |                                                 |\n| accessIPv6                           |                                                 |\n| adminPass                            | 2gV49MZNHLQm                                    |\n| config_drive                         |                                                 |\n| created                              | 2014-06-19T11:06:51Z                            |\n| flavor                               | m1.tiny (1)                                     |\n| hostId                               |                                                 |\n| id                                   | 157f3d5d-5d26-4a55-9d7c-ab0dc3d9fdc9            |\n| image                                | CorePlus (41793321-51b1-413a-a69f-0c25d7a63b22) |\n| key_name                             | -                                               |\n| metadata                             | {}                                              |\n| name                                 | aaa                                             |\n| os-extended-volumes:volumes_attached | []                                              |\n| progress                             | 0                                               |\n| security_groups                      | default                                         |\n| status                               | BUILD                                           |\n| tenant_id                            | 5924ee51bb6945f39dc7010687ef43af                |\n| updated                              | 2014-06-19T11:06:54Z                            |\n| user_id                              | 35b1c3ef8b9d442cad696d049f7b2041                |\n+--------------------------------------+-------------------------------------------------+ \n\n5) however, instance status never changed from BUILD/NOSTATE\n\n$ nova list\n+--------------------------------------+------+--------+------------+-------------+----------+\n| ID                                   | Name | Status | Task State | Power State | Networks |\n+--------------------------------------+------+--------+------------+-------------+----------+\n| 157f3d5d-5d26-4a55-9d7c-ab0dc3d9fdc9 | aaa  | BUILD  | -          | NOSTATE     |          |\n+--------------------------------------+------+--------+------------+-------------+----------+", 
            "date_created": "2014-06-19 11:19:23.960154+00:00", 
            "author": "https://api.launchpad.net/1.0/~kanabuchi"
        }, 
        {
            "content": "I am not sure we can consider this as a bug.\nThat really depends on your infrastructure and deployment.\nIf  you have your clients connected to RMQ using KEEPALIVE with some \"aggressive\" values for it, the clients can detect quickly when the connecton is lost and as soon as the server will be back they reconnect, and I am quite sure that in the scenario I described you don't see the problem.\nRegards\n--\nAndrea Rosa\n\n\n", 
            "date_created": "2014-06-19 16:23:46.931972+00:00", 
            "author": "https://api.launchpad.net/1.0/~andrea-rosa-m"
        }, 
        {
            "content": "Hi Andrea, sorry for lacking details.\n\nI haven't thought this behavior related config values.\nPlease see following details:\n\n======================\n1) When rabbitmq received SIGKILL, nova-compute dumped ERROR, but this behavior is normal\n\n2014-06-23 11:23:11.691 ERROR oslo.messaging._drivers.impl_rabbit [-] Failed to consume message from queue: Socket closed\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit Traceback (most recent call last):\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/_drivers/impl_rabbit.py\", line 639, in ensure\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit     return method(*args, **kwargs)\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit   File \"/usr/local/lib/python2.7/dist-packages/oslo/messaging/_drivers/impl_rabbit.py\", line 718, in _consume\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit     return self.connection.drain_events(timeout=timeout)\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit   File \"/usr/local/lib/python2.7/dist-packages/kombu/connection.py\", line 279, in drain_events\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit     return self.transport.drain_events(self.connection, **kwargs)\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit   File \"/usr/local/lib/python2.7/dist-packages/kombu/transport/pyamqp.py\", line 91, in drain_events\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit     return connection.drain_events(**kwargs)\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit   File \"/usr/local/lib/python2.7/dist-packages/amqp/connection.py\", line 299, in drain_events\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit     chanmap, None, timeout=timeout,\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit   File \"/usr/local/lib/python2.7/dist-packages/amqp/connection.py\", line 362, in _wait_multiple\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit     channel, method_sig, args, content = read_timeout(timeout)\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit   File \"/usr/local/lib/python2.7/dist-packages/amqp/connection.py\", line 326, in read_timeout\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit     return self.method_reader.read_method()\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit   File \"/usr/local/lib/python2.7/dist-packages/amqp/method_framing.py\", line 189, in read_method\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit     raise m\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit IOError: Socket closed\n2014-06-23 11:23:11.691 TRACE oslo.messaging._drivers.impl_rabbit\n\n2) nova-compute was starting reconnect immediately, it's good\n\n2014-06-23 11:23:12.414 INFO oslo.messaging._drivers.impl_rabbit [-] Reconnecting to AMQP server on 192.168.10.221:5672\n2014-06-23 11:23:12.414 INFO oslo.messaging._drivers.impl_rabbit [-] Delaying reconnect for 1.0 seconds...\n2014-06-23 11:23:12.844 ERROR oslo.messaging._drivers.impl_rabbit [-] AMQP server on 192.168.10.221:5672 is unreachable: [Errno 111] ECONNREFUSED. Trying again in 1 seconds.\n2014-06-23 11:23:13.428 ERROR oslo.messaging._drivers.impl_rabbit [-] AMQP server on 192.168.10.221:5672 is unreachable: [Errno 111] ECONNREFUSED. Trying again in 1 seconds.\n\n3) after re-started rabbitmq, nova-compute re-connected rabbitmq, it's very nice\n\n2014-06-23 11:24:25.653 INFO oslo.messaging._drivers.impl_rabbit [-] Reconnecting to AMQP server on 192.168.10.221:5672\n2014-06-23 11:24:25.653 INFO oslo.messaging._drivers.impl_rabbit [-] Delaying reconnect for 1.0 seconds...\n2014-06-23 11:24:25.789 INFO oslo.messaging._drivers.impl_rabbit [-] Connected to AMQP server on 192.168.10.221:5672\n2014-06-23 11:24:26.706 INFO oslo.messaging._drivers.impl_rabbit [-] Connected to AMQP server on 192.168.10.221:5672\n2014-06-23 11:24:31.916 INFO oslo.messaging._drivers.impl_rabbit [-] Reconnecting to AMQP server on 192.168.10.221:5672\n2014-06-23 11:24:31.917 INFO oslo.messaging._drivers.impl_rabbit [-] Delaying reconnect for 1.0 seconds...\n2014-06-23 11:24:32.947 INFO oslo.messaging._drivers.impl_rabbit [-] Connected to AMQP server on 192.168.10.221:5672\n\n4) But booting instance is freeze with following log\n\n2014-06-23 11:24:34.012 WARNING nova.openstack.common.loopingcall [-] task run outlasted interval by 63.325336 sec\n2014-06-23 11:25:05.777 DEBUG nova.openstack.common.lockutils [req-b23de1c3-55d8-4d78-9386-621b907f2f25 admin admin] Got semaphore \"7b68d649-cbf4-4e97-aa66-bf9b88199db7\" from (pid=3704) lock /opt/stack/nova/nova/openstack/common/lockutils.py:168\n2014-06-23 11:25:05.777 DEBUG nova.openstack.common.lockutils [req-b23de1c3-55d8-4d78-9386-621b907f2f25 admin admin] Got semaphore / lock \"do_run_instance\" from (pid=3704) inner /opt/stack/nova/nova/openstack/common/lockutils.py:248\n2014-06-23 11:25:05.780 AUDIT nova.compute.manager [req-b23de1c3-55d8-4d78-9386-621b907f2f25 admin admin] [instance: 7b68d649-cbf4-4e97-aa66-bf9b88199db7] Starting instance...\n\n5) VM status and nova-compute's log would never changed\n======================\n\nI thought, this behavior problem is \"VM status never changed after rabbitmq connectivity re-established\".\n\nBUT, I noticed that this behavior never occur currently master(I tested commitid: 73d95d2817452f78c468ce162265be431f625c8a).\nSo I change bug report's status to \"invalid\".\n", 
            "date_created": "2014-06-23 02:44:14.237811+00:00", 
            "author": "https://api.launchpad.net/1.0/~kanabuchi"
        }
    ], 
    "closed": "2014-06-23 02:44:25.413168+00:00"
}