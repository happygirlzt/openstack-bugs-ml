{
    "status": "Invalid", 
    "last_updated": "2017-02-17 14:56:00.086948+00:00", 
    "description": "I've seen this a few times, but start tracking from here:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/console.html#_2017-02-16_22_25_43_645525\n\n2017-02-16 22:25:43.645525 | 2017-02-16 22:25:43.645 | tempest.api.compute.admin.test_live_migration.LiveBlockMigrationTestJSON.test_live_block_migration[id-1dce86b8-eb04-4c03-a9d8-9c1dc3ee0c7b]\n2017-02-16 22:25:43.646587 | 2017-02-16 22:25:43.646 | -------------------------------------------------------------------------------------------------------------------------------------------\n2017-02-16 22:25:43.647903 | 2017-02-16 22:25:43.647 | \n2017-02-16 22:25:43.649473 | 2017-02-16 22:25:43.649 | Captured traceback:\n2017-02-16 22:25:43.651373 | 2017-02-16 22:25:43.650 | ~~~~~~~~~~~~~~~~~~~\n2017-02-16 22:25:43.656802 | 2017-02-16 22:25:43.656 |     Traceback (most recent call last):\n2017-02-16 22:25:43.659061 | 2017-02-16 22:25:43.658 |       File \"tempest/api/compute/admin/test_live_migration.py\", line 122, in test_live_block_migration\n2017-02-16 22:25:43.661006 | 2017-02-16 22:25:43.660 |         self._test_live_migration()\n2017-02-16 22:25:43.671547 | 2017-02-16 22:25:43.671 |       File \"tempest/api/compute/admin/test_live_migration.py\", line 97, in _test_live_migration\n2017-02-16 22:25:43.672889 | 2017-02-16 22:25:43.672 |         volume_backed=volume_backed)['id']\n2017-02-16 22:25:43.674405 | 2017-02-16 22:25:43.673 |       File \"tempest/api/compute/base.py\", line 232, in create_test_server\n2017-02-16 22:25:43.676559 | 2017-02-16 22:25:43.676 |         **kwargs)\n2017-02-16 22:25:43.681637 | 2017-02-16 22:25:43.680 |       File \"tempest/common/compute.py\", line 182, in create_test_server\n2017-02-16 22:25:43.683300 | 2017-02-16 22:25:43.682 |         server['id'])\n2017-02-16 22:25:43.684766 | 2017-02-16 22:25:43.684 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\n2017-02-16 22:25:43.686210 | 2017-02-16 22:25:43.685 |         self.force_reraise()\n2017-02-16 22:25:43.687896 | 2017-02-16 22:25:43.687 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n2017-02-16 22:25:43.689493 | 2017-02-16 22:25:43.689 |         six.reraise(self.type_, self.value, self.tb)\n2017-02-16 22:25:43.691459 | 2017-02-16 22:25:43.691 |       File \"tempest/common/compute.py\", line 164, in create_test_server\n2017-02-16 22:25:43.693741 | 2017-02-16 22:25:43.692 |         clients.servers_client, server['id'], wait_until)\n2017-02-16 22:25:43.695699 | 2017-02-16 22:25:43.695 |       File \"tempest/common/waiters.py\", line 96, in wait_for_server_status\n2017-02-16 22:25:43.697692 | 2017-02-16 22:25:43.697 |         raise lib_exc.TimeoutException(message)\n2017-02-16 22:25:43.699378 | 2017-02-16 22:25:43.698 |     tempest.lib.exceptions.TimeoutException: Request timed out\n2017-02-16 22:25:43.701086 | 2017-02-16 22:25:43.700 |     Details: (LiveBlockMigrationTestJSON:test_live_block_migration) Server 0ee93807-d206-4ddf-878c-efd1dd2eab3c failed to reach ACTIVE status and task state \"None\" within the required time (196 s). Current status: BUILD. Current task state: spawning.\n\nI was looking in the n-cpu logs in the subnode for 0ee93807-d206-4ddf-878c-efd1dd2eab3c and found the last thing we see during the server create is here:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/screen-n-cpu.txt.gz#_2017-02-16_22_22_11_143\n\n2017-02-16 22:22:11.143 14954 DEBUG nova.virt.libvirt.driver [req-025bf4d2-e5ba-4236-a334-f9eb98105ada tempest-LiveBlockMigrationTestJSON-793129345 tempest-LiveBlockMigrationTestJSON-793129345] [instance: 0ee93807-d206-4ddf-878c-efd1dd2eab3c] Instance is running spawn /opt/stack/new/nova/nova/virt/libvirt/driver.py:2689\n\nThat's after we've created the domain:\n\nhttps://github.com/openstack/nova/blob/15.0.0.0rc1/nova/virt/libvirt/driver.py#L2689\n\nAfter that the driver is waiting for the power_state to go to RUNNING.\n\nI see that shortly after that log message we get a libvirt event saying the instance is started:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/screen-n-cpu.txt.gz#_2017-02-16_22_22_11_214\n\nAnd then right after that it's paused:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/screen-n-cpu.txt.gz#_2017-02-16_22_22_11_263\n\nLooking in the QEMU logs for that instance:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/libvirt/qemu/instance-00000001.txt.gz\n\nI see this, which is odd:\n\nKVM: entry failed, hardware error 0x0\n\nIn the libvirtd logs I see:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/libvirt/libvirtd.txt.gz#_2017-02-16_22_22_10_879\n\n2017-02-16 22:22:10.879+0000: 8973: debug : qemuProcessLaunch:4876 : QEMU vm=0x7f68a40035a0 name=instance-00000001 running with pid=16410\n\nAnd later:\n\n2017-02-16 22:22:11.139+0000: 8968: debug : qemuProcessHandleResume:765 : Transitioned guest instance-00000001 out of paused into resumed state\n...\n2017-02-16 22:22:11.140+0000: 8968: debug : qemuProcessHandleStop:716 : Transitioned guest instance-00000001 to paused state\n\nBut I don't see any errors in the libvirt logs.\n\nRight around that time I see this in syslog:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/syslog.txt.gz#_Feb_16_22_22_11\n\nFeb 16 22:22:11 ubuntu-xenial-2-node-ovh-bhs1-7345556-429938 virtlogd[8995]: libvirt version: 1.3.1, package: 1ubuntu10.8 (Christian Ehrhardt <email address hidden> Mon, 06 Feb 2017 14:30:46 +0100)\nFeb 16 22:22:11 ubuntu-xenial-2-node-ovh-bhs1-7345556-429938 virtlogd[8995]: hostname: ubuntu-xenial-2-node-ovh-bhs1-7345556-429938\nFeb 16 22:22:11 ubuntu-xenial-2-node-ovh-bhs1-7345556-429938 virtlogd[8995]: End of file while reading data: Input/output error\n\nI guess the virtlogd i/o error is pretty normal, it's all over syslogs in our CI runs, and maybe is a result of the hw error in the guest?", 
    "tags": [], 
    "importance": "High", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1665487", 
    "owner": "None", 
    "id": 1665487, 
    "index": 2038, 
    "openned": "2017-02-16 23:30:25.351798+00:00", 
    "created": "2017-02-16 23:30:25.351798+00:00", 
    "title": "Live migration tests sometimes timeout waiting for instance to be ACTIVE: 'KVM: entry failed, hardware error 0x0'", 
    "comments": [
        {
            "content": "I've seen this a few times, but start tracking from here:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/console.html#_2017-02-16_22_25_43_645525\n\n2017-02-16 22:25:43.645525 | 2017-02-16 22:25:43.645 | tempest.api.compute.admin.test_live_migration.LiveBlockMigrationTestJSON.test_live_block_migration[id-1dce86b8-eb04-4c03-a9d8-9c1dc3ee0c7b]\n2017-02-16 22:25:43.646587 | 2017-02-16 22:25:43.646 | -------------------------------------------------------------------------------------------------------------------------------------------\n2017-02-16 22:25:43.647903 | 2017-02-16 22:25:43.647 | \n2017-02-16 22:25:43.649473 | 2017-02-16 22:25:43.649 | Captured traceback:\n2017-02-16 22:25:43.651373 | 2017-02-16 22:25:43.650 | ~~~~~~~~~~~~~~~~~~~\n2017-02-16 22:25:43.656802 | 2017-02-16 22:25:43.656 |     Traceback (most recent call last):\n2017-02-16 22:25:43.659061 | 2017-02-16 22:25:43.658 |       File \"tempest/api/compute/admin/test_live_migration.py\", line 122, in test_live_block_migration\n2017-02-16 22:25:43.661006 | 2017-02-16 22:25:43.660 |         self._test_live_migration()\n2017-02-16 22:25:43.671547 | 2017-02-16 22:25:43.671 |       File \"tempest/api/compute/admin/test_live_migration.py\", line 97, in _test_live_migration\n2017-02-16 22:25:43.672889 | 2017-02-16 22:25:43.672 |         volume_backed=volume_backed)['id']\n2017-02-16 22:25:43.674405 | 2017-02-16 22:25:43.673 |       File \"tempest/api/compute/base.py\", line 232, in create_test_server\n2017-02-16 22:25:43.676559 | 2017-02-16 22:25:43.676 |         **kwargs)\n2017-02-16 22:25:43.681637 | 2017-02-16 22:25:43.680 |       File \"tempest/common/compute.py\", line 182, in create_test_server\n2017-02-16 22:25:43.683300 | 2017-02-16 22:25:43.682 |         server['id'])\n2017-02-16 22:25:43.684766 | 2017-02-16 22:25:43.684 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\n2017-02-16 22:25:43.686210 | 2017-02-16 22:25:43.685 |         self.force_reraise()\n2017-02-16 22:25:43.687896 | 2017-02-16 22:25:43.687 |       File \"/opt/stack/new/tempest/.tox/tempest/local/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n2017-02-16 22:25:43.689493 | 2017-02-16 22:25:43.689 |         six.reraise(self.type_, self.value, self.tb)\n2017-02-16 22:25:43.691459 | 2017-02-16 22:25:43.691 |       File \"tempest/common/compute.py\", line 164, in create_test_server\n2017-02-16 22:25:43.693741 | 2017-02-16 22:25:43.692 |         clients.servers_client, server['id'], wait_until)\n2017-02-16 22:25:43.695699 | 2017-02-16 22:25:43.695 |       File \"tempest/common/waiters.py\", line 96, in wait_for_server_status\n2017-02-16 22:25:43.697692 | 2017-02-16 22:25:43.697 |         raise lib_exc.TimeoutException(message)\n2017-02-16 22:25:43.699378 | 2017-02-16 22:25:43.698 |     tempest.lib.exceptions.TimeoutException: Request timed out\n2017-02-16 22:25:43.701086 | 2017-02-16 22:25:43.700 |     Details: (LiveBlockMigrationTestJSON:test_live_block_migration) Server 0ee93807-d206-4ddf-878c-efd1dd2eab3c failed to reach ACTIVE status and task state \"None\" within the required time (196 s). Current status: BUILD. Current task state: spawning.\n\nI was looking in the n-cpu logs in the subnode for 0ee93807-d206-4ddf-878c-efd1dd2eab3c and found the last thing we see during the server create is here:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/screen-n-cpu.txt.gz#_2017-02-16_22_22_11_143\n\n2017-02-16 22:22:11.143 14954 DEBUG nova.virt.libvirt.driver [req-025bf4d2-e5ba-4236-a334-f9eb98105ada tempest-LiveBlockMigrationTestJSON-793129345 tempest-LiveBlockMigrationTestJSON-793129345] [instance: 0ee93807-d206-4ddf-878c-efd1dd2eab3c] Instance is running spawn /opt/stack/new/nova/nova/virt/libvirt/driver.py:2689\n\nThat's after we've created the domain:\n\nhttps://github.com/openstack/nova/blob/15.0.0.0rc1/nova/virt/libvirt/driver.py#L2689\n\nAfter that the driver is waiting for the power_state to go to RUNNING.\n\nI see that shortly after that log message we get a libvirt event saying the instance is started:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/screen-n-cpu.txt.gz#_2017-02-16_22_22_11_214\n\nAnd then right after that it's paused:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/screen-n-cpu.txt.gz#_2017-02-16_22_22_11_263\n\nLooking in the QEMU logs for that instance:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/libvirt/qemu/instance-00000001.txt.gz\n\nI see this, which is odd:\n\nKVM: entry failed, hardware error 0x0\n\nIn the libvirtd logs I see:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/libvirt/libvirtd.txt.gz#_2017-02-16_22_22_10_879\n\n2017-02-16 22:22:10.879+0000: 8973: debug : qemuProcessLaunch:4876 : QEMU vm=0x7f68a40035a0 name=instance-00000001 running with pid=16410\n\nAnd later:\n\n2017-02-16 22:22:11.139+0000: 8968: debug : qemuProcessHandleResume:765 : Transitioned guest instance-00000001 out of paused into resumed state\n...\n2017-02-16 22:22:11.140+0000: 8968: debug : qemuProcessHandleStop:716 : Transitioned guest instance-00000001 to paused state\n\nBut I don't see any errors in the libvirt logs.\n\nRight around that time I see this in syslog:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/syslog.txt.gz#_Feb_16_22_22_11\n\nFeb 16 22:22:11 ubuntu-xenial-2-node-ovh-bhs1-7345556-429938 virtlogd[8995]: libvirt version: 1.3.1, package: 1ubuntu10.8 (Christian Ehrhardt <email address hidden> Mon, 06 Feb 2017 14:30:46 +0100)\nFeb 16 22:22:11 ubuntu-xenial-2-node-ovh-bhs1-7345556-429938 virtlogd[8995]: hostname: ubuntu-xenial-2-node-ovh-bhs1-7345556-429938\nFeb 16 22:22:11 ubuntu-xenial-2-node-ovh-bhs1-7345556-429938 virtlogd[8995]: End of file while reading data: Input/output error\n\nI guess the virtlogd i/o error is pretty normal, it's all over syslogs in our CI runs, and maybe is a result of the hw error in the guest?", 
            "date_created": "2017-02-16 23:30:25.351798+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1329434 looks related.", 
            "date_created": "2017-02-16 23:33:18.109851+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Here is the issue:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/etc/nova/nova.conf.txt.gz\n\n\n[libvirt]\nlive_migration_uri = qemu+ssh://stack@%s/system\ncpu_mode = none\nvirt_type = kvm\n\n\nWe're using kvm with nested virt rather than QEMU in this job for some reason, we should be using QEMU.", 
            "date_created": "2017-02-16 23:36:11.671069+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "clarkb pointed out that the virt_type on the primary node is qemu:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/etc/nova/nova.conf.txt.gz\n\nBecause of devstack-gate setting it:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/localrc.txt.gz\n\nLIBVIRT_TYPE=qemu\n\nBut that's not set on the subnode localrc:\n\nhttp://logs.openstack.org/50/435050/1/check/gate-tempest-dsvm-multinode-live-migration-ubuntu-xenial/49adcde/logs/subnode-2/localrc.txt.gz", 
            "date_created": "2017-02-16 23:39:22.490016+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "The fix is here: https://review.openstack.org/#/c/435154/", 
            "date_created": "2017-02-16 23:52:11.496230+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }
    ], 
    "closed": "2017-02-16 23:51:59.035324+00:00"
}