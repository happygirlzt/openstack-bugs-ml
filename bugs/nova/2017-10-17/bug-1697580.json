{
    "status": "Expired", 
    "last_updated": "2017-09-11 04:17:40.898680+00:00", 
    "description": "Description\n===========\n\nOur application require a number of Cinder volumes to be attached to the Nova instance.  They always need to be attached in the same order, the order matter to the software defined storage application.  How they are presented in our application determines what \"disk\" the Cinder volume becomes in the application (our software defined storage VM has boot, root, coredump, data disks, etc.)\n\nWe use the OpenStack API to create the resources (Cinder, Neutron, Nova, etc.) and attach them with a Nova server create call.\n\nMost of the time the volumes are attached in the correct order, but about 1 out of 10 times, the order of the volumes as they are presented in the nova API call (Python list) is not preserved.  This causes our SDS VM to fail booting because it does not get the disks it expects in the correct order.\n\nMost VMs do not care about the order in which the cinder volumes are presented in the VM, in our case it is significant.\n\nSteps to reproduce\n==================\n\nThis has been done using the OpenStack API, which is the best way to programmatically reproduce the problem, but could likely be done with OS CLI as well.\n\n1. Create a number of Cinder volumes in a way which they can be uniquely identified in the VM instance (different sizes, etc.\n2. Attach volumes to Nova instance and boot.\n3. repeat steps 1 & 2 enough times, and the cinder volumes will be attached to the nova instance in a different order than what was specified.  This can be verified by checking the libvirt XML file that is generated by nova (virsh dumpxml <domain name>).\n\n\nExpected result\n===============\n\nGiven an ordered list of Cinder volumes to be attached to a nova instance, the expected result is that they are attached in the specified order every time.\n\nActual result\n=============\n\nMost times the expected result is true, about 1 out of 10 times, the order the volumes are attached to the nova instance is not what is expected.\n\nEnvironment\n===========\n\nRedHat RDO - Liberty\n\nopenstack-nova-compute-12.0.4-1.el7.noarch\n\n1. Exact version of OpenStack you are running. See the following\n  list for all releases: http://docs.openstack.org/releases/\n\n2. Which hypervisor did you use?\n\n   Libvirt + KVM\n\nlibvirt-daemon-2.0.0-10.el7_3.5.x86_64\nlibvirt-daemon-2.0.0-10.el7_3.5.x86_64\n\nqemu-kvm-common-rhev-2.6.0-28.el7_3.9.x86_64\nqemu-kvm-rhev-2.6.0-28.el7_3.9.x86_64\nlibvirt-daemon-driver-qemu-2.0.0-10.el7_3.5.x86_64\n\n2. Which storage type did you use?\n\nCinder NFS driver for Netapp FAS; Cinder iSCSI driver for SolidFire\n\n3. Which networking type did you use?\n\nNeutron with openvswitch.\n\nLogs & Configs\n==============\n\nN/A", 
    "tags": [
        "libvirt", 
        "volumes"
    ], 
    "importance": "Undecided", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1697580", 
    "owner": "None", 
    "id": 1697580, 
    "index": 8165, 
    "openned": "2017-06-13 03:45:55.812095+00:00", 
    "created": "2017-06-13 03:45:55.812095+00:00", 
    "title": "Cinder volumes not always attached to instance in order presented", 
    "comments": [
        {
            "content": "Description\n===========\n\nOur application require a number of Cinder volumes to be attached to the Nova instance.  They always need to be attached in the same order, the order matter to the software defined storage application.  How they are presented in our application determines what \"disk\" the Cinder volume becomes in the application (our software defined storage VM has boot, root, coredump, data disks, etc.)\n\nWe use the OpenStack API to create the resources (Cinder, Neutron, Nova, etc.) and attach them with a Nova server create call.\n\nMost of the time the volumes are attached in the correct order, but about 1 out of 10 times, the order of the volumes as they are presented in the nova API call (Python list) is not preserved.  This causes our SDS VM to fail booting because it does not get the disks it expects in the correct order.\n\nMost VMs do not care about the order in which the cinder volumes are presented in the VM, in our case it is significant.\n\nSteps to reproduce\n==================\n\nThis has been done using the OpenStack API, which is the best way to programmatically reproduce the problem, but could likely be done with OS CLI as well.\n\n1. Create a number of Cinder volumes in a way which they can be uniquely identified in the VM instance (different sizes, etc.\n2. Attach volumes to Nova instance and boot.\n3. repeat steps 1 & 2 enough times, and the cinder volumes will be attached to the nova instance in a different order than what was specified.  This can be verified by checking the libvirt XML file that is generated by nova (virsh dumpxml <domain name>).\n\n\nExpected result\n===============\n\nGiven an ordered list of Cinder volumes to be attached to a nova instance, the expected result is that they are attached in the specified order every time.\n\nActual result\n=============\n\nMost times the expected result is true, about 1 out of 10 times, the order the volumes are attached to the nova instance is not what is expected.\n\nEnvironment\n===========\n\nRedHat RDO - Liberty\n\nopenstack-nova-compute-12.0.4-1.el7.noarch\n\n1. Exact version of OpenStack you are running. See the following\n  list for all releases: http://docs.openstack.org/releases/\n\n2. Which hypervisor did you use?\n\n   Libvirt + KVM\n\nlibvirt-daemon-2.0.0-10.el7_3.5.x86_64\nlibvirt-daemon-2.0.0-10.el7_3.5.x86_64\n\nqemu-kvm-common-rhev-2.6.0-28.el7_3.9.x86_64\nqemu-kvm-rhev-2.6.0-28.el7_3.9.x86_64\nlibvirt-daemon-driver-qemu-2.0.0-10.el7_3.5.x86_64\n\n2. Which storage type did you use?\n\nCinder NFS driver for Netapp FAS; Cinder iSCSI driver for SolidFire\n\n3. Which networking type did you use?\n\nNeutron with openvswitch.\n\nLogs & Configs\n==============\n\nN/A", 
            "date_created": "2017-06-13 03:45:55.812095+00:00", 
            "author": "https://api.launchpad.net/1.0/~kflambright"
        }, 
        {
            "content": "Are you waiting for each volume to show up as \"in-use\" before attaching another one?\n\nAre you passing in the device_name field and expecting that to be honored when attaching the volume? Because with the libvirt driver it won't be:\n\nhttps://developer.openstack.org/api-ref/compute/?expanded=attach-a-volume-to-an-instance-detail#attach-a-volume-to-an-instance\n\n\"Name of the device such as, /dev/vdb. Omit or set this parameter to null for auto-assignment, if supported. If you specify this parameter, the device must not exist in the guest operating system. Note that as of the 12.0.0 Liberty release, the Nova libvirt driver no longer honors a user-supplied device name. This is the same behavior as if the device name parameter is not supplied on the request.\"\n\nAlso see: https://review.openstack.org/#/c/452546/", 
            "date_created": "2017-06-14 01:37:30.562533+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I was wondering if you could provide details on the calls you use here?  My earlier suggestion (haven't heard anything back) was to use auto-assign, then query with cinder-show to get the device assignment and map them on the Instance via that device (ie /dev/vdb, /dev/vdc...).\n\nIf you avoid auto-assign, and just let Nova/Libvirt do what it does; the device entry in the Cinder volume object should be correct/valid.\n\nMost importantly though, how are you creating these?  Heat Template?  nova boot --block-device-mapping...., nova volume-attach * 10 ????", 
            "date_created": "2017-06-14 04:16:41.225765+00:00", 
            "author": "https://api.launchpad.net/1.0/~john-griffith"
        }, 
        {
            "content": "All volumes are attached using block device mapping.\n\nI am not passing in any device name, just letting it do auto-assignment.  In the software defined storage application, it's not expecting specific device names, rather it relies on the order in which they show up on first boot, which is one of the reasons that we can't boot and then attach the volumes after the fact.\n\n>> Are you waiting for each volume to show up as \"in-use\" before attaching another one?\n\nThe volumes are not explicitly attached to the instance, they are created, we wait until they are in the active state, and they are put in order into a Python list.\n\nThe call to boot the server looks like this:\n\n\tserver = self.nova.servers.create(name=self.name, \n                                          image=self.boot_image_base, \n                                          flavor=self.flavor, \n                                          config_drive=self.config_drive, \n\t\t\t\t\t  userdata=self.userdata_fp,\n                                          block_device_mapping_v2=self.block_device_list, \n\t                                  nics=self.nic_device_list)\n\n\nself.block_device_list is the list of volumes that we want mapped to the instance, in a very specific order.  As stated in the original message, something on the order of 9 times out of 10 that order is preserved.\n\nBTW, we do have a HEAT template - we don't use it for our internal deployments, but it is something that we could give out to customers.  I'm doing a bunch of deployments with the HEAT templates to see if I can get it to fail in the same way.\n\nLet me know what other information should be provided.", 
            "date_created": "2017-06-19 22:18:59.967833+00:00", 
            "author": "https://api.launchpad.net/1.0/~kflambright"
        }, 
        {
            "content": "Since I've added more information, I'm wondering if there's any update to this, or anything else I need to provide - other things I should try?", 
            "date_created": "2017-07-12 17:12:11.500108+00:00", 
            "author": "https://api.launchpad.net/1.0/~kflambright"
        }, 
        {
            "content": "[Expired for OpenStack Compute (nova) because there has been no activity for 60 days.]", 
            "date_created": "2017-09-11 04:17:37.834874+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ], 
    "closed": "2017-09-11 04:17:38.397910+00:00"
}