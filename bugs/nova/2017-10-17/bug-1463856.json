{
    "status": "In Progress", 
    "last_updated": "2017-06-27 15:53:08.053299+00:00", 
    "description": "Description of problem:\nThere is a feature in nova that allow you to restore a SOFT-DELETED instance (nova restore) when an instance is terminated there is a certain amount of time(defined in nova.conf - reclaim_instance_interval) for one to restore the instance including volume and floating IP attachments. Once this timer expire the instance goes to DELETED status and should release all its resources including the attached volume.\nIn this case the volume remain attached to an instance in DELETED state and not usable for a non admin user.\n\nVersion-Release number of selected component (if applicable):\n# rpm -qa | grep -i cinder\nopenstack-cinder-2015.1.0-2.el7ost.noarch\npython-cinder-2015.1.0-2.el7ost.noarch\npython-cinderclient-1.1.1-1.el7ost.noarch\n\n# rpm -qa | grep -i nova\nopenstack-nova-cert-2015.1.0-4.el7ost.noarch\nopenstack-nova-compute-2015.1.0-4.el7ost.noarch\nopenstack-nova-common-2015.1.0-4.el7ost.noarch\npython-nova-2015.1.0-4.el7ost.noarch\nopenstack-nova-conductor-2015.1.0-4.el7ost.noarch\nopenstack-nova-scheduler-2015.1.0-4.el7ost.noarch\nopenstack-nova-console-2015.1.0-4.el7ost.noarch\npython-novaclient-2.23.0-1.el7ost.noarch\nopenstack-nova-api-2015.1.0-4.el7ost.noarch\nopenstack-nova-novncproxy-2015.1.0-4.el7ost.noarch\n\n\nHow reproducible:\n100%\n\nSteps to Reproduce:\n1. Edit /etc/nova/nova.conf and change reclaim_instance_interval=60\n2. Restart nova service\n3. Create a volume and attach it to an instance\n4. Delete instance - make sure its in \"SOFT-DELETE\" state\n5. Wait for the timer to expire and make sure the instance is in \"DELETED\" state\n6. Volume still shown as attached in CLI and in Horizon Its shown as attached to \"None\"\n\nActual results:\nVolume is not usable\n\nExpected results:\nVolume should be released and usable\n\nAdditional info:\nAttaching cinder and nova log dir", 
    "tags": [
        "compute", 
        "openstack-version.kilo", 
        "volumes"
    ], 
    "importance": "Undecided", 
    "heat": 68, 
    "link": "https://bugs.launchpad.net/nova/+bug/1463856", 
    "owner": "https://api.launchpad.net/1.0/~anusha-unnam", 
    "id": 1463856, 
    "index": 6866, 
    "openned": "2015-06-10 14:16:09.865761+00:00", 
    "created": "2015-06-10 14:16:09.865761+00:00", 
    "title": "Cinder volume isn't available after instance soft-deleted timer expired while volume is still attached", 
    "comments": [
        {
            "content": "Description of problem:\nThere is a feature in nova that allow you to restore a SOFT-DELETED instance (nova restore) when an instance is terminated there is a certain amount of time(defined in nova.conf - reclaim_instance_interval) for one to restore the instance including volume and floating IP attachments. Once this timer expire the instance goes to DELETED status and should release all its resources including the attached volume.\nIn this case the volume remain attached to an instance in DELETED state and not usable for a non admin user.\n\nVersion-Release number of selected component (if applicable):\n# rpm -qa | grep -i cinder\nopenstack-cinder-2015.1.0-2.el7ost.noarch\npython-cinder-2015.1.0-2.el7ost.noarch\npython-cinderclient-1.1.1-1.el7ost.noarch\n\n# rpm -qa | grep -i nova\nopenstack-nova-cert-2015.1.0-4.el7ost.noarch\nopenstack-nova-compute-2015.1.0-4.el7ost.noarch\nopenstack-nova-common-2015.1.0-4.el7ost.noarch\npython-nova-2015.1.0-4.el7ost.noarch\nopenstack-nova-conductor-2015.1.0-4.el7ost.noarch\nopenstack-nova-scheduler-2015.1.0-4.el7ost.noarch\nopenstack-nova-console-2015.1.0-4.el7ost.noarch\npython-novaclient-2.23.0-1.el7ost.noarch\nopenstack-nova-api-2015.1.0-4.el7ost.noarch\nopenstack-nova-novncproxy-2015.1.0-4.el7ost.noarch\n\n\nHow reproducible:\n100%\n\nSteps to Reproduce:\n1. Edit /etc/nova/nova.conf and change reclaim_instance_interval=60\n2. Restart nova service\n3. Create a volume and attach it to an instance\n4. Delete instance - make sure its in \"SOFT-DELETE\" state\n5. Wait for the timer to expire and make sure the instance is in \"DELETED\" state\n6. Volume still shown as attached in CLI and in Horizon Its shown as attached to \"None\"\n\nActual results:\nVolume is not usable\n\nExpected results:\nVolume should be released and usable\n\nAdditional info:\nAttaching cinder and nova log dir", 
            "date_created": "2015-06-10 14:16:09.865761+00:00", 
            "author": "https://api.launchpad.net/1.0/~ushkalim"
        }, 
        {
            "content": "", 
            "date_created": "2015-06-10 14:16:09.865761+00:00", 
            "author": "https://api.launchpad.net/1.0/~ushkalim"
        }, 
        {
            "content": "", 
            "date_created": "2015-06-10 14:16:50.916291+00:00", 
            "author": "https://api.launchpad.net/1.0/~ushkalim"
        }, 
        {
            "content": "I think all images attached to an instance should be available right after the delete command, even if the instance goes to soft_deleted state. Then, if restored, all volumes should be manually re-attached. Not sure if this is the best approach anyway. I'm sending a patch for review/discussion.", 
            "date_created": "2015-06-30 17:44:06.969879+00:00", 
            "author": "https://api.launchpad.net/1.0/~apahim"
        }, 
        {
            "content": "[Looks like a Nova-related issue, since it is not requesting a volume detach from Cinder -- so moved this bug to Nova component.]", 
            "date_created": "2016-07-01 14:10:58.717354+00:00", 
            "author": "https://api.launchpad.net/1.0/~kashyapc"
        }, 
        {
            "content": "This was reported against kilo, which is now end of life upstream. Can you reproduce with something newer like mitaka or better yet master?", 
            "date_created": "2016-07-01 14:22:38.727279+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Reproducible on mitaka-9.0\nhttp://paste.openstack.org/show/543309/\n\n", 
            "date_created": "2016-07-28 16:26:43.237893+00:00", 
            "author": "https://api.launchpad.net/1.0/~aallakhverdieva"
        }, 
        {
            "content": "diagnostic snapshot - https://drive.google.com/open?id=0BxmbtGZe1aPtVXJ6RDNsamV0bG8", 
            "date_created": "2016-07-28 16:32:42.618649+00:00", 
            "author": "https://api.launchpad.net/1.0/~aallakhverdieva"
        }, 
        {
            "content": "I was able to reproduce this bug in current master. Steps I followed,\n\n1.Edit /etc/nova/nova.conf and change reclaim_instance_interval=60\n\n2.Restart nova service\n\n3.Create volume:\ncinder create --display_name myvol 2\n\n4.cinder list\n+--------------------------------------+-----------+-------+------+-------------+----------+-------------+\n|                  ID                  |   Status  |  Name | Size | Volume Type | Bootable | Attached to |\n+--------------------------------------+-----------+-------+------+-------------+----------+-------------+\n| a481f9d0-9567-4b84-a529-55766fc275a3 | available | myvol |  2   | lvmdriver-1 |  false   |             |\n+--------------------------------------+-----------+-------+------+-------------+----------+-------------+\n\n5.nova list\n+--------------------------------------+------+--------+------------+-------------+------------------+\n| ID                                   | Name | Status | Task State | Power State | Networks         |\n+--------------------------------------+------+--------+------------+-------------+------------------+\n| 08151afa-bb0c-47d0-bb1c-e276e3c98cfb | test | ACTIVE | -          | Running     | private=10.0.0.2 |\n+--------------------------------------+------+--------+------------+-------------+------------------+\n\n6. nova volume-attach 08151afa-bb0c-47d0-bb1c-e276e3c98cfb a481f9d0-9567-4b84-a529-55766fc275a3\n\n7. cinder list\n+--------------------------------------+--------+-------+------+-------------+----------+--------------------------------------+\n|                  ID                  | Status |  Name | Size | Volume Type | Bootable |             Attached to              |\n+--------------------------------------+--------+-------+------+-------------+----------+--------------------------------------+\n| a481f9d0-9567-4b84-a529-55766fc275a3 | in-use | myvol |  2   | lvmdriver-1 |  false   | 08151afa-bb0c-47d0-bb1c-e276e3c98cfb |\n+--------------------------------------+--------+-------+------+-------------+----------+--------------------------------------+\n\n8. nova delete test\nRequest to delete server test has been accepted.\n\n9. waited 60secs(reclaim_instance_interval)\n\n10. nova list\nnova list\n+----+------+--------+------------+-------------+----------+\n| ID | Name | Status | Task State | Power State | Networks |\n+----+------+--------+------------+-------------+----------+\n+----+------+--------+------------+-------------+----------+\n\n11. cinder list\n+--------------------------------------+--------+-------+------+-------------+----------+--------------------------------------+\n|                  ID                  | Status |  Name | Size | Volume Type | Bootable |             Attached to              |\n+--------------------------------------+--------+-------+------+-------------+----------+--------------------------------------+\n| a481f9d0-9567-4b84-a529-55766fc275a3 | in-use | myvol |  2   | lvmdriver-1 |  false   | 08151afa-bb0c-47d0-bb1c-e276e3c98cfb\n\n12. And also When i tried to attach myvol to another instance I got this error,\n\nnova volume-attach 26147eb0-08d6-4e57-840e-95b8b92e4774 a481f9d0-9567-4b84-a529-55766fc275a3\nERROR (ClientException): Unexpected API Error. Please report this at http://bugs.launchpad.net/nova/ and attach the Nova API log if possible.\n<class 'nova.exception.InvalidInput'> (HTTP 500) (Request-ID: req-0d6f9adb-210a-4de6-9e5f-bad6daad434d)", 
            "date_created": "2016-08-29 17:52:52.020882+00:00", 
            "author": "https://api.launchpad.net/1.0/~anusha-unnam"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/384799", 
            "date_created": "2016-10-11 02:44:11.347393+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Automatically discovered version kilo in description. If this is incorrect, please update the description to include 'nova version: ...'", 
            "date_created": "2017-06-27 15:53:07.272726+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }
    ]
}