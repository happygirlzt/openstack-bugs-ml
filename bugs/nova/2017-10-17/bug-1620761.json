{
    "status": "Confirmed", 
    "last_updated": "2016-09-06 18:04:37.459975+00:00", 
    "description": "I've been noticing this failure more often lately:\n2016-09-02 17:06:30.570025 | tempest.api.compute.images.test_images_oneserver_negative.ImagesOneServerNegativeTestJSON.test_create_second_image_when_first_image_is_being_saved[id-0460efcf-ee88-4f94-acef-1bf658695456,negative]\n2016-09-02 17:06:30.570109 | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n2016-09-02 17:06:30.570116 | \n2016-09-02 17:06:30.570128 | Captured traceback:\n2016-09-02 17:06:30.570140 | ~~~~~~~~~~~~~~~~~~~\n2016-09-02 17:06:30.570158 |     Traceback (most recent call last):\n2016-09-02 17:06:30.570194 |       File \"tempest/api/compute/images/test_images_oneserver_negative.py\", line 38, in tearDown\n2016-09-02 17:06:30.570211 |         self.server_check_teardown()\n2016-09-02 17:06:30.570241 |       File \"tempest/api/compute/base.py\", line 164, in server_check_teardown\n2016-09-02 17:06:30.570267 |         cls.server_id, 'ACTIVE')\n2016-09-02 17:06:30.570295 |       File \"tempest/common/waiters.py\", line 95, in wait_for_server_status\n2016-09-02 17:06:30.570315 |         raise exceptions.TimeoutException(message)\n2016-09-02 17:06:30.570337 |     tempest.exceptions.TimeoutException: Request timed out\n2016-09-02 17:06:30.570429 |     Details: (ImagesOneServerNegativeTestJSON:tearDown) Server 051f6d7d-15b3-459c-a372-902c5da15b40 failed to reach ACTIVE status and task state \"None\" within the required time (196 s). Current status: ACTIVE. Current task state: image_snapshot.\n\nThere are no clear failures from the nova logs from what I see. I'm also not sure if we regressed something that is making this failure more often in the cells v1 job, but cells v1 is inherently racy so I wouldn't be surprised.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=message%3A%5C%22Details%3A%20(ImagesOneServerNegativeTestJSON%3AtearDown)%20Server%5C%22%20AND%20message%3A%5C%22failed%20to%20reach%20ACTIVE%20status%20and%20task%20state%20%5C%5C%5C%22None%5C%5C%5C%22%20within%20the%20required%20time%5C%22%20AND%20message%3A%5C%22Current%20status%3A%20ACTIVE.%20Current%20task%20state%3A%20image_snapshot.%5C%22%20AND%20build_name%3A%5C%22gate-tempest-dsvm-cells%5C%22&from=7d", 
    "tags": [
        "cells"
    ], 
    "importance": "Undecided", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1620761", 
    "owner": "None", 
    "id": 1620761, 
    "index": 7684, 
    "openned": "2016-09-06 18:04:37.459975+00:00", 
    "created": "2016-09-06 18:04:37.459975+00:00", 
    "title": "test_create_second_image_when_first_image_is_being_saved intermittently times out in teardown in cells v1 job", 
    "comments": [
        {
            "content": "I've been noticing this failure more often lately:\n2016-09-02 17:06:30.570025 | tempest.api.compute.images.test_images_oneserver_negative.ImagesOneServerNegativeTestJSON.test_create_second_image_when_first_image_is_being_saved[id-0460efcf-ee88-4f94-acef-1bf658695456,negative]\n2016-09-02 17:06:30.570109 | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n2016-09-02 17:06:30.570116 | \n2016-09-02 17:06:30.570128 | Captured traceback:\n2016-09-02 17:06:30.570140 | ~~~~~~~~~~~~~~~~~~~\n2016-09-02 17:06:30.570158 |     Traceback (most recent call last):\n2016-09-02 17:06:30.570194 |       File \"tempest/api/compute/images/test_images_oneserver_negative.py\", line 38, in tearDown\n2016-09-02 17:06:30.570211 |         self.server_check_teardown()\n2016-09-02 17:06:30.570241 |       File \"tempest/api/compute/base.py\", line 164, in server_check_teardown\n2016-09-02 17:06:30.570267 |         cls.server_id, 'ACTIVE')\n2016-09-02 17:06:30.570295 |       File \"tempest/common/waiters.py\", line 95, in wait_for_server_status\n2016-09-02 17:06:30.570315 |         raise exceptions.TimeoutException(message)\n2016-09-02 17:06:30.570337 |     tempest.exceptions.TimeoutException: Request timed out\n2016-09-02 17:06:30.570429 |     Details: (ImagesOneServerNegativeTestJSON:tearDown) Server 051f6d7d-15b3-459c-a372-902c5da15b40 failed to reach ACTIVE status and task state \"None\" within the required time (196 s). Current status: ACTIVE. Current task state: image_snapshot.\n\nThere are no clear failures from the nova logs from what I see. I'm also not sure if we regressed something that is making this failure more often in the cells v1 job, but cells v1 is inherently racy so I wouldn't be surprised.\n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=message%3A%5C%22Details%3A%20(ImagesOneServerNegativeTestJSON%3AtearDown)%20Server%5C%22%20AND%20message%3A%5C%22failed%20to%20reach%20ACTIVE%20status%20and%20task%20state%20%5C%5C%5C%22None%5C%5C%5C%22%20within%20the%20required%20time%5C%22%20AND%20message%3A%5C%22Current%20status%3A%20ACTIVE.%20Current%20task%20state%3A%20image_snapshot.%5C%22%20AND%20build_name%3A%5C%22gate-tempest-dsvm-cells%5C%22&from=7d", 
            "date_created": "2016-09-06 18:04:37.459975+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }
    ]
}