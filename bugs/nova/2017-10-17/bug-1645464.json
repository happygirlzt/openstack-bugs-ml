{
    "status": "Fix Released", 
    "last_updated": "2017-03-22 10:13:23.447915+00:00", 
    "description": "Seen in a CI run here:\n\nhttp://logs.openstack.org/16/393416/6/check/gate-tempest-dsvm-full-devstack-plugin-ceph-ubuntu-xenial/44f3329/logs/screen-n-cpu.txt.gz?level=TRACE#_2016-11-28_17_34_36_535\n\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server [req-8d784631-28c2-41b4-8175-7cfb59480838 nova service] Exception during message handling\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server Traceback (most recent call last):\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/server.py\", line 155, in _process_incoming\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 225, in dispatch\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 195, in _do_dispatch\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/exception_wrapper.py\", line 75, in wrapped\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     function_name, call_dict, binary)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     self.force_reraise()\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/exception_wrapper.py\", line 66, in wrapped\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 6800, in external_instance_event\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     event.tag)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 6755, in _process_instance_vif_deleted_event\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     network_info = instance.info_cache.network_info\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 67, in getter\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     self.obj_load_attr(name)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/instance.py\", line 1063, in obj_load_attr\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     self._load_generic(attrname)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/instance.py\", line 819, in _load_generic\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     expected_attrs=[attrname])\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 177, in wrapper\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     args, kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/conductor/rpcapi.py\", line 236, in object_class_action_versions\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     args=args, kwargs=kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 169, in call\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     retry=self.retry)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 97, in _send\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     timeout=timeout, retry=retry)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 467, in send\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     retry=retry)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 458, in _send\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     raise result\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server InstanceNotFound_Remote: Instance f2cbed80-0516-4c2a-b575-24b9885ec189 could not be found.\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server Traceback (most recent call last):\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/conductor/manager.py\", line 87, in _object_dispatch\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return getattr(target, method)(*args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 184, in wrapper\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     result = fn(cls, context, *args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/instance.py\", line 463, in get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     use_slave=use_slave)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 226, in wrapper\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/instance.py\", line 455, in _db_instance_get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     columns_to_join=columns_to_join)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/api.py\", line 725, in instance_get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return IMPL.instance_get_by_uuid(context, uuid, columns_to_join)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 170, in wrapper\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 271, in wrapped\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return f(context, *args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 1885, in instance_get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     columns_to_join=columns_to_join)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 1894, in _instance_get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     raise exception.InstanceNotFound(instance_id=uuid)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server InstanceNotFound: Instance f2cbed80-0516-4c2a-b575-24b9885ec189 could not be found.\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n\nWe have a race when deleting an instance and deleting the ports attached to that instance. Neutron sends the vif-deleted event to nova and nova tries to refresh the InstanceInfoCache.network_info field but the instance is already deleted so we fail and log a stacktrace. We should handle the InstanceNotFound so we don't stacktrace in the n-cpu logs.", 
    "tags": [
        "compute"
    ], 
    "importance": "Medium", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1645464", 
    "owner": "https://api.launchpad.net/1.0/~mriedem", 
    "id": 1645464, 
    "index": 4694, 
    "openned": "2016-11-28 20:28:04.454036+00:00", 
    "created": "2016-11-28 20:28:04.454036+00:00", 
    "title": "InstanceNotFound stacktrace in _process_instance_vif_deleted_event", 
    "comments": [
        {
            "content": "Seen in a CI run here:\n\nhttp://logs.openstack.org/16/393416/6/check/gate-tempest-dsvm-full-devstack-plugin-ceph-ubuntu-xenial/44f3329/logs/screen-n-cpu.txt.gz?level=TRACE#_2016-11-28_17_34_36_535\n\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server [req-8d784631-28c2-41b4-8175-7cfb59480838 nova service] Exception during message handling\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server Traceback (most recent call last):\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/server.py\", line 155, in _process_incoming\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 225, in dispatch\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 195, in _do_dispatch\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/exception_wrapper.py\", line 75, in wrapped\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     function_name, call_dict, binary)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     self.force_reraise()\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/exception_wrapper.py\", line 66, in wrapped\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 6800, in external_instance_event\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     event.tag)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 6755, in _process_instance_vif_deleted_event\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     network_info = instance.info_cache.network_info\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 67, in getter\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     self.obj_load_attr(name)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/instance.py\", line 1063, in obj_load_attr\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     self._load_generic(attrname)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/instance.py\", line 819, in _load_generic\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     expected_attrs=[attrname])\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 177, in wrapper\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     args, kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/conductor/rpcapi.py\", line 236, in object_class_action_versions\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     args=args, kwargs=kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 169, in call\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     retry=self.retry)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 97, in _send\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     timeout=timeout, retry=retry)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 467, in send\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     retry=retry)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 458, in _send\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     raise result\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server InstanceNotFound_Remote: Instance f2cbed80-0516-4c2a-b575-24b9885ec189 could not be found.\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server Traceback (most recent call last):\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/conductor/manager.py\", line 87, in _object_dispatch\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return getattr(target, method)(*args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 184, in wrapper\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     result = fn(cls, context, *args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/instance.py\", line 463, in get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     use_slave=use_slave)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 226, in wrapper\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/instance.py\", line 455, in _db_instance_get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     columns_to_join=columns_to_join)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/api.py\", line 725, in instance_get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return IMPL.instance_get_by_uuid(context, uuid, columns_to_join)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 170, in wrapper\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 271, in wrapped\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     return f(context, *args, **kwargs)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 1885, in instance_get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     columns_to_join=columns_to_join)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/db/sqlalchemy/api.py\", line 1894, in _instance_get_by_uuid\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server     raise exception.InstanceNotFound(instance_id=uuid)\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server InstanceNotFound: Instance f2cbed80-0516-4c2a-b575-24b9885ec189 could not be found.\n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n2016-11-28 17:34:36.535 2361 ERROR oslo_messaging.rpc.server \n\nWe have a race when deleting an instance and deleting the ports attached to that instance. Neutron sends the vif-deleted event to nova and nova tries to refresh the InstanceInfoCache.network_info field but the instance is already deleted so we fail and log a stacktrace. We should handle the InstanceNotFound so we don't stacktrace in the n-cpu logs.", 
            "date_created": "2016-11-28 20:28:04.454036+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/403925", 
            "date_created": "2016-11-28 22:12:04.392092+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/403925\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=4fce45f83bd510202fd1cbcdb7694361c41e9400\nSubmitter: Jenkins\nBranch:    master\n\ncommit 4fce45f83bd510202fd1cbcdb7694361c41e9400\nAuthor: Matt Riedemann <email address hidden>\nDate:   Mon Nov 28 17:07:51 2016 -0500\n\n    Pre-load info_cache when handling external events and handle NotFound\n    \n    Before change a5b920a197c70d2ae08a1e1335d979857f923b4f we'd join the\n    info_cache column when getting the instance in the API. Without\n    joining the info_cache column when getting the instance, that has\n    to be lazy-loaded on the compute when processing an external\n    neutron event, like network-vif-deleted. So this change pre-loads\n    the info_cache in the API again as an optimization.\n    \n    There is also a race to contend with here when deleting an instance.\n    Neutron can send the network-vif-deleted event after we've already\n    marked the instance as deleted in the database, at which point\n    lazy-loading info_cache (or updating InstanceInfoCache for that\n    matter), can result in an Instance(InfoCache)NotFound error, so this\n    change handles that also.\n    \n    Change-Id: Ia3b4288691b392d56324e9d13c92e8e0b0d81e76\n    Closes-Bug: #1645464\n", 
            "date_created": "2017-01-31 20:42:22.207959+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/newton\nReview: https://review.openstack.org/427732", 
            "date_created": "2017-02-01 14:25:54.884222+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 15.0.0.0rc1 release candidate.", 
            "date_created": "2017-02-03 19:08:44.433024+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/427732\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=d70d02f4af78ec9026cf172b8bcd11b7c451f17c\nSubmitter: Jenkins\nBranch:    stable/newton\n\ncommit d70d02f4af78ec9026cf172b8bcd11b7c451f17c\nAuthor: Matt Riedemann <email address hidden>\nDate:   Mon Nov 28 17:07:51 2016 -0500\n\n    Pre-load info_cache when handling external events and handle NotFound\n    \n    Before change a5b920a197c70d2ae08a1e1335d979857f923b4f we'd join the\n    info_cache column when getting the instance in the API. Without\n    joining the info_cache column when getting the instance, that has\n    to be lazy-loaded on the compute when processing an external\n    neutron event, like network-vif-deleted. So this change pre-loads\n    the info_cache in the API again as an optimization.\n    \n    There is also a race to contend with here when deleting an instance.\n    Neutron can send the network-vif-deleted event after we've already\n    marked the instance as deleted in the database, at which point\n    lazy-loading info_cache (or updating InstanceInfoCache for that\n    matter), can result in an Instance(InfoCache)NotFound error, so this\n    change handles that also.\n    \n    Change-Id: Ia3b4288691b392d56324e9d13c92e8e0b0d81e76\n    Closes-Bug: #1645464\n    (cherry picked from commit 4fce45f83bd510202fd1cbcdb7694361c41e9400)\n", 
            "date_created": "2017-03-01 09:22:21.916707+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 14.0.5 release.", 
            "date_created": "2017-03-22 10:13:21.902412+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2017-01-31 20:42:18.470471+00:00"
}