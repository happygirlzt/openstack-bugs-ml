{
    "status": "Invalid", 
    "last_updated": "2013-08-01 05:32:39.068323+00:00", 
    "description": "When directive bellow is set to True in nova.conf:\n\nstart_guests_on_host_boot = True\nresume_guests_state_on_host_boot = True\n\nit will result to vm_state=error of ALL instances running on compute node when restarting the nova-compute service. This is because of malformed condiftion in manager.py apparently:\n\n{code}\n               if ((expect_running and FLAGS.resume_guests_state_on_host_boot)\n                     or FLAGS.start_guests_on_host_boot):\n                   LOG.info(\n                           _('Rebooting instance after nova-compute restart.'),\n                           locals(), instance=instance)\n\n                    block_device_info = \\\n                        self._get_instance_volume_block_device_info(\n                            context, instance['uuid'])\n\n                    try:\n                        LOG.info('Resume instance:%s' % str(instance))\n                        self.driver.resume_state_on_host_boot(\n                                context,\n                                instance,\n                                self._legacy_nw_info(net_info),\n                                block_device_info)\n                    except NotImplementedError:\n                        LOG.warning(_('Hypervisor driver does not support '\n                                      'resume guests'), instance=instance)\n                    except Exception:\n                        # NOTE(vish): The instance failed to resume, so we\n                        #             set the instance to error and attempt\n                        #             to continue.\n                        LOG.warning(_('Failed to resume instance'),\n                                    instance=instance)\n\n                        self._set_instance_error_state(context,\n                                                       instance['uuid'])\n {code}\n\nit is obvious that setting start_guests_on_host_boot = True will satisfy the condition and EVERY instance will be passed to resume_state_on_host_boot call. This is malicious and evidently not intended behaviour.\n\nAlso it is questionable whether better catching of thrown Exceptions would help to distinct among different statuses.\n\nRegards, Zdenek Pizl", 
    "tags": [], 
    "importance": "Undecided", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1170657", 
    "owner": "None", 
    "id": 1170657, 
    "index": 4861, 
    "openned": "2013-04-19 10:54:30.564164+00:00", 
    "created": "2013-04-19 10:54:30.564164+00:00", 
    "title": "Setting start_guests_on_host_boot to TRUE results in error of all VMs", 
    "comments": [
        {
            "content": "When directive bellow is set to True in nova.conf:\n\nstart_guests_on_host_boot = True\nresume_guests_state_on_host_boot = True\n\nit will result to vm_state=error of ALL instances running on compute node when restarting the nova-compute service. This is because of malformed condiftion in manager.py apparently:\n\n{code}\n               if ((expect_running and FLAGS.resume_guests_state_on_host_boot)\n                     or FLAGS.start_guests_on_host_boot):\n                   LOG.info(\n                           _('Rebooting instance after nova-compute restart.'),\n                           locals(), instance=instance)\n\n                    block_device_info = \\\n                        self._get_instance_volume_block_device_info(\n                            context, instance['uuid'])\n\n                    try:\n                        LOG.info('Resume instance:%s' % str(instance))\n                        self.driver.resume_state_on_host_boot(\n                                context,\n                                instance,\n                                self._legacy_nw_info(net_info),\n                                block_device_info)\n                    except NotImplementedError:\n                        LOG.warning(_('Hypervisor driver does not support '\n                                      'resume guests'), instance=instance)\n                    except Exception:\n                        # NOTE(vish): The instance failed to resume, so we\n                        #             set the instance to error and attempt\n                        #             to continue.\n                        LOG.warning(_('Failed to resume instance'),\n                                    instance=instance)\n\n                        self._set_instance_error_state(context,\n                                                       instance['uuid'])\n {code}\n\nit is obvious that setting start_guests_on_host_boot = True will satisfy the condition and EVERY instance will be passed to resume_state_on_host_boot call. This is malicious and evidently not intended behaviour.\n\nAlso it is questionable whether better catching of thrown Exceptions would help to distinct among different statuses.\n\nRegards, Zdenek Pizl", 
            "date_created": "2013-04-19 10:54:30.564164+00:00", 
            "author": "https://api.launchpad.net/1.0/~zdenek-pizl"
        }, 
        {
            "content": "Which version is this with?", 
            "date_created": "2013-04-22 14:30:01.993384+00:00", 
            "author": "https://api.launchpad.net/1.0/~zulcss"
        }, 
        {
            "content": "Hi, it's Folsom 2012.2.4\n\nRegards, .zp.\n\n\nOn Mon, Apr 22, 2013 at 4:30 PM, Chuck Short <email address hidden>wrote:\n\n> Which version is this with?\n>\n> ** Changed in: nova\n>        Status: New => Incomplete\n>\n> --\n> You received this bug notification because you are subscribed to the bug\n> report.\n> https://bugs.launchpad.net/bugs/1170657\n>\n> Title:\n>   Setting start_guests_on_host_boot to TRUE results in error of all VMs\n>\n> Status in OpenStack Compute (Nova):\n>   Incomplete\n>\n> Bug description:\n>   When directive bellow is set to True in nova.conf:\n>\n>   start_guests_on_host_boot = True\n>   resume_guests_state_on_host_boot = True\n>\n>   it will result to vm_state=error of ALL instances running on compute\n>   node when restarting the nova-compute service. This is because of\n>   malformed condiftion in manager.py apparently:\n>\n>   {code}\n>                  if ((expect_running and\n> FLAGS.resume_guests_state_on_host_boot)\n>                        or FLAGS.start_guests_on_host_boot):\n>                      LOG.info(\n>                              _('Rebooting instance after nova-compute\n> restart.'),\n>                              locals(), instance=instance)\n>\n>                       block_device_info = \\\n>                           self._get_instance_volume_block_device_info(\n>                               context, instance['uuid'])\n>\n>                       try:\n>                           LOG.info('Resume instance:%s' % str(instance))\n>                           self.driver.resume_state_on_host_boot(\n>                                   context,\n>                                   instance,\n>                                   self._legacy_nw_info(net_info),\n>                                   block_device_info)\n>                       except NotImplementedError:\n>                           LOG.warning(_('Hypervisor driver does not\n> support '\n>                                         'resume guests'),\n> instance=instance)\n>                       except Exception:\n>                           # NOTE(vish): The instance failed to resume, so\n> we\n>                           #             set the instance to error and\n> attempt\n>                           #             to continue.\n>                           LOG.warning(_('Failed to resume instance'),\n>                                       instance=instance)\n>\n>                           self._set_instance_error_state(context,\n>                                                          instance['uuid'])\n>    {code}\n>\n>   it is obvious that setting start_guests_on_host_boot = True will\n>   satisfy the condition and EVERY instance will be passed to\n>   resume_state_on_host_boot call. This is malicious and evidently not\n>   intended behaviour.\n>\n>   Also it is questionable whether better catching of thrown Exceptions\n>   would help to distinct among different statuses.\n>\n>   Regards, Zdenek Pizl\n>\n> To manage notifications about this bug go to:\n> https://bugs.launchpad.net/nova/+bug/1170657/+subscriptions\n>\n\n\n\n-- \n*Zden\u011bk Pi\u017el* | Platform team\n<email address hidden>\n\nGoodData | gooddata.com\nKarolinsk\u00e1 650/1\n186 00 Prague 8\n", 
            "date_created": "2013-04-22 14:38:36+00:00", 
            "author": "https://api.launchpad.net/1.0/~zdenek-pizl"
        }, 
        {
            "content": "start_guests_on_host_boot was removed in grizzly.", 
            "date_created": "2013-05-08 14:43:48.370326+00:00", 
            "author": "https://api.launchpad.net/1.0/~russellb"
        }, 
        {
            "content": "Thanks, mentioning that option in nova.conf really helped me fix this for our folsom deployment.  This was happening to us every time I would restart nova-compute and had to either delete the VM or manually reset the VM status in nova.", 
            "date_created": "2013-06-19 14:24:28.754474+00:00", 
            "author": "https://api.launchpad.net/1.0/~smijar"
        }, 
        {
            "content": "For Folsom deployment, in my case, the reason caused this issue is that the VM is already under 'runnning' status when nova libvirt driver call 'domain.createWithFlags(launch_flags)' from '_create_domain()' when nova-compute service restart with compute host reboot, under the situation the libvirtclient will raise a 'libvirt.VIR_ERR_OPERATION_INVALID' exception with ' domain is already running' message. So for this reason, I can resolve this issue by disable Guest VM autostart mechanism easily by 'chkconfig libvirt-guests off'.", 
            "date_created": "2013-08-01 05:32:38.039487+00:00", 
            "author": "https://api.launchpad.net/1.0/~lzy-dev"
        }
    ], 
    "closed": "2013-05-08 14:44:07.474961+00:00"
}