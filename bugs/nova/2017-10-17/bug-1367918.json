{
    "status": "Fix Released", 
    "last_updated": "2015-04-30 09:12:37.807397+00:00", 
    "description": "As shown by the stack trace below, when a volume is attached but the VM is not present the volume can't be cleaned up by Cinder and will raise an Exception which puts the instance into an error state.  The volume attachment isn't removed because an if statement is hit in the xenapi destroy method which logs \"VM is not present, skipping destroy...\" and then moves on to trying to cleanup the volume in Cinder.  This is because most operations in xen rely on finding the vm_ref and then cleaning up resources that are attached there.  But if the volume is attached to an SR but not associated with an instance it ends up being orphaned.\n\n\n014-08-29 15:54:02.836 8766 DEBUG nova.volume.cinder [req-341cd17d-0f2f-4d64-929f-a94f8c0fa295 None] Cinderclient connection created using URL: https://localhost/v1/<tenant>\ncinderclient /opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/volume/cinder.py:108\n2014-08-29 15:54:03.251 8766 ERROR nova.compute.manager [req-341cd17d-0f2f-4d64-929f-a94f8c0fa295 None] [instance: <uuid>] Setting instance vm_state to ERROR\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] Traceback (most recent call last):\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/compute/manager.py\", line 2443, in do_terminate_instance\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] self._delete_instance(context, instance, bdms, quotas)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/hooks.py\", line 131, in inner\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] rv = f(*args, **kwargs)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/compute/manager.py\", line 2412, in delete_instance\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] quotas.rollback()\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/openstack/common/excutils.py\", line 82, in exit\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] six.reraise(self.type, self.value, self.tb)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/compute/manager.py\", line 2390, in _delete_instance\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] self._shutdown_instance(context, instance, bdms)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/compute/manager.py\", line 2335, in _shutdown_instance\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] connector)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/volume/cinder.py\", line 189, in wrapper\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] res = method(self, ctx, volume_id, *args, **kwargs)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/volume/cinder.py\", line 309, in terminate_connection\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] connector)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/v1/volumes.py\", line 331, in terminate_connection\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] {'connector': connector})\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/v1/volumes.py\", line 250, in _action\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] return self.api.client.post(url, body=body)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/client.py\", line 223, in post\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] return self._cs_request(url, 'POST', **kwargs)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/client.py\", line 187, in _cs_request\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] **kwargs)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/client.py\", line 170, in request\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] raise exceptions.from_response(resp, body)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] ClientException: DELETE on http://localhost:8081/volumes/<volume_uuid>/export?force=False returned '409' with 'Volume '<volume_uuid>' is currently attached to '<ip>'' (HTTP 409) (Request-ID: req-d8a81cfc-5ba2-4bfb-b519-c92a2", 
    "tags": [], 
    "importance": "Medium", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1367918", 
    "owner": "https://api.launchpad.net/1.0/~alaski", 
    "id": 1367918, 
    "index": 4025, 
    "openned": "2014-09-10 20:44:53.356562+00:00", 
    "created": "2014-09-10 20:44:53.356562+00:00", 
    "title": "Xenapi attached volume with no VM leaves instance in undeletable state", 
    "comments": [
        {
            "content": "As shown by the stack trace below, when a volume is attached but the VM is not present the volume can't be cleaned up by Cinder and will raise an Exception which puts the instance into an error state.  The volume attachment isn't removed because an if statement is hit in the xenapi destroy method which logs \"VM is not present, skipping destroy...\" and then moves on to trying to cleanup the volume in Cinder.  This is because most operations in xen rely on finding the vm_ref and then cleaning up resources that are attached there.  But if the volume is attached to an SR but not associated with an instance it ends up being orphaned.\n\n\n014-08-29 15:54:02.836 8766 DEBUG nova.volume.cinder [req-341cd17d-0f2f-4d64-929f-a94f8c0fa295 None] Cinderclient connection created using URL: https://localhost/v1/<tenant>\ncinderclient /opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/volume/cinder.py:108\n2014-08-29 15:54:03.251 8766 ERROR nova.compute.manager [req-341cd17d-0f2f-4d64-929f-a94f8c0fa295 None] [instance: <uuid>] Setting instance vm_state to ERROR\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] Traceback (most recent call last):\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/compute/manager.py\", line 2443, in do_terminate_instance\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] self._delete_instance(context, instance, bdms, quotas)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/hooks.py\", line 131, in inner\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] rv = f(*args, **kwargs)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/compute/manager.py\", line 2412, in delete_instance\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] quotas.rollback()\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/openstack/common/excutils.py\", line 82, in exit\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] six.reraise(self.type, self.value, self.tb)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/compute/manager.py\", line 2390, in _delete_instance\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] self._shutdown_instance(context, instance, bdms)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/compute/manager.py\", line 2335, in _shutdown_instance\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] connector)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/volume/cinder.py\", line 189, in wrapper\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] res = method(self, ctx, volume_id, *args, **kwargs)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/nova/volume/cinder.py\", line 309, in terminate_connection\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] connector)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/v1/volumes.py\", line 331, in terminate_connection\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] {'connector': connector})\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/v1/volumes.py\", line 250, in _action\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] return self.api.client.post(url, body=body)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/client.py\", line 223, in post\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] return self._cs_request(url, 'POST', **kwargs)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/client.py\", line 187, in _cs_request\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] **kwargs)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] File \"/opt/rackstack/879.28/nova/lib/python2.6/site-packages/cinderclient/client.py\", line 170, in request\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] raise exceptions.from_response(resp, body)\n2014-08-29 15:54:03.251 8766 TRACE nova.compute.manager [instance: <uuid>] ClientException: DELETE on http://localhost:8081/volumes/<volume_uuid>/export?force=False returned '409' with 'Volume '<volume_uuid>' is currently attached to '<ip>'' (HTTP 409) (Request-ID: req-d8a81cfc-5ba2-4bfb-b519-c92a2", 
            "date_created": "2014-09-10 20:44:53.356562+00:00", 
            "author": "https://api.launchpad.net/1.0/~alaski"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/120500\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=ba49c5eb387d841d40f81f57d5cefbb00c835bff\nSubmitter: Jenkins\nBranch:    master\n\ncommit ba49c5eb387d841d40f81f57d5cefbb00c835bff\nAuthor: Andrew Laski <email address hidden>\nDate:   Wed Sep 10 14:00:40 2014 -0400\n\n    Xen: Attempt to find and cleanup orphaned SR during delete\n    \n    Before some patches merged to better handle failures to boot an instance\n    from a volume it was possible to have an attached volume with an SR and\n    plugged PBD but no VM.  And the destroy method in xenapi short circuits\n    if no VM is present because everything is looked up from there in order\n    to be cleaned up.\n    \n    This adds a check to see if a volume is supposed to be attached during\n    destroy if no VM is present and attempts to look it up via the SR uuid\n    and clean it up.\n    \n    I would like to say that this patch is unnecessary, as it's sort of\n    hackish, but it's possible that some deployments have instances in this\n    state and this will allow them to cleanup without manually running\n    commands on the hypervisor.\n    \n    Closes-bug: #1367918\n    Change-Id: I7745af7e22164a96af800ae796bda077e49bf291\n", 
            "date_created": "2014-10-20 11:39:29.970210+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2014-12-18 20:02:12.199637+00:00"
}