{
    "status": "Opinion", 
    "last_updated": "2013-10-28 20:57:05.896548+00:00", 
    "description": "this applies to havana master\n\nOne of the biggest stumbling blocks for people using the vSphere driver is that is has very poor flexibility in terms of choosing which datastore a VM will be placed on.  It simply picks the first datastore the API returns.\n\nI see people asking for two improvements:\n- being able to choose the datastore(s) used.\n- being able to \"spread\" disk images across datastore.\n\nOne simple mechanism that seems like it could help a lot would be if the user could specify a \"datastore_regex\", and the behavior of the vSphere driver would be to \"round-robin\" disk images across any datastore in the cluster that matched this regex.  Note, if true round-robin is hard, random + a check for capacity would probably be a good approximation.", 
    "tags": [
        "vmware"
    ], 
    "importance": "Wishlist", 
    "heat": 8, 
    "link": "https://bugs.launchpad.net/nova/+bug/1171930", 
    "owner": "https://api.launchpad.net/1.0/~kiran-kumar-vaddi", 
    "id": 1171930, 
    "index": 2616, 
    "openned": "2013-04-23 16:36:22.361152+00:00", 
    "created": "2013-04-23 16:36:22.361152+00:00", 
    "title": "vsphere driver hardcoded to only use first datastore in cluster", 
    "comments": [
        {
            "content": "please set this to \"wishlist\" \n\nthis applies to havana master\n\nOne of the biggest stumbling blocks for people using the vSphere driver is that is has very poor flexibility in terms of choosing which datastore a VM will be placed on.  It simply picks the first datastore the API returns. \n\nI see people asking for two improvements: \n- being able to choose the datastore(s) used.\n- being able to \"spread\" disk images across datastore.  \n\nOne simple mechanism that seems like it could help a lot would be if the user could specify a \"datastore_regex\", and the behavior of the vSphere driver would be to \"round-robin\" disk images across any datastore in the cluster that matched this regex.  Note, if true round-robin is hard, random + a check for capacity would probably be a good approximation.", 
            "date_created": "2013-04-23 16:36:22.361152+00:00", 
            "author": "https://api.launchpad.net/1.0/~danwent"
        }, 
        {
            "content": "As per discussion on 5/15/13 on IRC, HP is looking into this issue and will be addressing soon.\nBelow is the approach:\nCurrently the first datastore of the cluster is selected for provisioning. This results in the following.\n1. If the first datastore is not accessible, provisioning fails.\n2. If the first datastore is full, provisioning fails.\n3. If the first datastore happens to be a the local volume of the ESX host, cluster capabilities such as DRS cannot be exploited.\n\nThe proposed change is to ensure the method get_datastore_ref_and_name handles:\n1. Select a datastore if it is accessible and meets the memory requirement criteria, depending on the flavor of the VM / image size used for provisioning.\n2. Select a datastore which is sharable between hosts of a cluster instead of selecting a datastore local to a host.\n", 
            "date_created": "2013-05-15 17:26:19.543917+00:00", 
            "author": "https://api.launchpad.net/1.0/~cbananth"
        }, 
        {
            "content": "I think it would be nice to let the scheduler handle all the \"intelligent\" stuff, and the virt driver just report its capabilities honestly to the scheduler.\nHere's the benefits:\n 1. It's more convenient to add a custom filter/weigher than to tweak the vsphere driver.\n 2. The scheduler has better access to the database, which could provide datastore_regex'es.\n 3. Personally I think the scheduler module is easier and more flexible to handle than a virt driver.\n\nFor the scheduler part, a custom filter/weigher could be used to pick a datastore, but we need a good place to pass it to the virt driver. The host manager should also be modified to deal with the capability message change.\n\nFor the virt driver part, instead of selecting only one datastore to report, it should report all the datastores, an additional field might be preferred for now. The `spawn` method might also be modified to leverage the datastore information.\n\nAs for usage reporting, I'm waiting for more details from this bp https://blueprints.launchpad.net/nova/+spec/accurate-capacity-of-clusters-for-scheduler .", 
            "date_created": "2013-05-16 10:46:52.641696+00:00", 
            "author": "https://api.launchpad.net/1.0/~ssshi"
        }, 
        {
            "content": "I like the idea of moving this logic up to the scheduler and I'd like to invest some time in researching that idea. It might make better sense for OpenStack architecturally especially since we were discussing adding user customizable behaviors to how OpenStack + VMware interoperate.", 
            "date_created": "2013-05-16 14:50:22.059647+00:00", 
            "author": "https://api.launchpad.net/1.0/~hartsock"
        }, 
        {
            "content": "After thinking about this a little bit, I'd like this to be broken up into two phases. Phase 1: fix this bug. Phase 2: back out the code for this bug and support a Filter/Weighter feature in the scheduler.", 
            "date_created": "2013-05-16 15:40:34.524040+00:00", 
            "author": "https://api.launchpad.net/1.0/~hartsock"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/29552", 
            "date_created": "2013-05-17 14:19:53.282645+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/30628", 
            "date_created": "2013-05-27 14:57:24.870789+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Is this still a valid concern after this:( https://review.openstack.org/#/c/52815/1/nova/virt/vmwareapi/vm_util.py ) merged?", 
            "date_created": "2013-10-28 20:54:47.442089+00:00", 
            "author": "https://api.launchpad.net/1.0/~hartsock"
        }, 
        {
            "content": "I'm marking this \"Opinion\" because there are still some things in the patches associated with this bug # that might come in handy in discussion but I think the problem is mostly taken care of by other bug fixes at this point. Re-open and discuss if I'm mistaken. Thanks.", 
            "date_created": "2013-10-28 20:57:05.315421+00:00", 
            "author": "https://api.launchpad.net/1.0/~hartsock"
        }
    ], 
    "closed": "2013-10-28 20:55:50.515328+00:00"
}