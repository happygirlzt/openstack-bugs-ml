{
    "status": "Invalid", 
    "last_updated": "2017-05-01 15:32:56.911687+00:00", 
    "description": "Kolla (stable/ocata, 4.0.2) was deployed as multinode (virtualized on Openstack/KVM) environment, but fails to provision instances.\n\nFirst symptom was \n... Starting with 0 host(s) get_filtered_objects /var/lib/kolla/venv/local/lib/python2.7/site-packages/nova/filters.py:70\n... Filtering removed all hosts for the request with instance ID '...'. Filter results: ['RetryFilter: (start: 0, end: 0)']\n... NoValidHost: No valid host was found. There are not enough hosts available.\n\nPlacement API does not return any resource provider\n\nGET /resource_providers\n{\n  \"resource_providers\": []\n}\n\nFollowing the request flow, I reach a point where I confirmed the resource_providers table is empty.\n\nroot@pod09-control01:~# docker exec -ti mariadb mysql -unova_api -p ... nova_api\n...\nMariaDB [nova_api]> select * from resource_providers;\nEmpty set (0.00 sec)\n\nThe only unusual thing, is that initially I deployed with QEMU, as compute node was going to be virtualized over KVM. Later, I enabled KVM nested virtualization in the host, so, now compute is virtualization capable.\n\n(openstack) hypervisor show 1 -fjson\n{\n  \"status\": \"enabled\",\n  \"cpu_info\": \"{\\\"vendor\\\": \\\"Intel\\\", \\\"model\\\": \\\"Skylake-Client\\\", \\\"arch\\\": \\\"x86_64\\\", \\\"features\\\": [\\\"ssse3\\\", \\\"pge\\\", \\\"avx\\\", \\\"xsaveopt\\\", \\\"clflush\\\", \\\"sep\\\", \\\"rtm\\\", \\\"tsc_adjust\\\", \\\"vme\\\", \\\"invpcid\\\", \\\"tsc\\\", \\\"sse\\\", \\\"xsave\\\", \\\"smap\\\", \\\"vmx\\\", \\\"erms\\\", \\\"hle\\\", \\\"cmov\\\", \\\"smep\\\", \\\"fpu\\\", \\\"clflushopt\\\", \\\"pat\\\", \\\"osxsave\\\", \\\"lm\\\", \\\"msr\\\", \\\"adx\\\", \\\"3dnowprefetch\\\", \\\"nx\\\", \\\"fxsr\\\", \\\"syscall\\\", \\\"sse4.1\\\", \\\"pae\\\", \\\"sse4.2\\\", \\\"pclmuldq\\\", \\\"xgetbv1\\\", \\\"fma\\\", \\\"tsc-deadline\\\", \\\"mmx\\\", \\\"arat\\\", \\\"cx8\\\", \\\"mce\\\", \\\"de\\\", \\\"aes\\\", \\\"mca\\\", \\\"pse\\\", \\\"pni\\\", \\\"abm\\\", \\\"rdseed\\\", \\\"popcnt\\\", \\\"pdpe1gb\\\", \\\"apic\\\", \\\"fsgsbase\\\", \\\"f16c\\\", \\\"mpx\\\", \\\"xsavec\\\", \\\"lahf_lm\\\", \\\"rdtscp\\\", \\\"avx2\\\", \\\"sse2\\\", \\\"ss\\\", \\\"hypervisor\\\", \\\"bmi1\\\", \\\"bmi2\\\", \\\"pcid\\\", \\\"cx16\\\", \\\"pse36\\\", \\\"mtrr\\\", \\\"movbe\\\", \\\"rdrand\\\", \\\"x2apic\\\"], \\\"topology\\\": {\\\"cores\\\": 1, \\\"cells\\\": 1, \\\"threads\\\": 1, \\\"sockets\\\": 4}}\",\n  \"free_disk_gb\": 38,\n  \"memory_mb_used\": 540,\n  \"uptime\": \"4:25\",\n  \"host_time\": \"01:46:19\",\n  \"local_gb_used\": 5,\n  \"id\": 1,\n  \"current_workload\": 0,\n  \"state\": \"up\",\n  \"load_average\": \"0.02, 0.02, 0.00\",\n  \"users\": \"0\",\n  \"aggregates\": [],\n  \"host_ip\": \"10.0.0.12\",\n  \"hypervisor_hostname\": \"pod9-compute01\",\n  \"hypervisor_version\": 2008000,\n  \"disk_available_least\": 33,\n  \"local_gb\": 38,\n  \"free_ram_mb\": 7471,\n  \"vcpus_used\": 0,\n  \"hypervisor_type\": \"QEMU\",\n  \"memory_mb\": 7983,\n  \"vcpus\": 4,\n  \"running_vms\": 0,\n  \"service_id\": 6,\n  \"service_host\": \"pod9-compute01\"\n}\n\nAny ideas, how can I make resource providers work?", 
    "tags": [
        "nova-scheduler", 
        "ocata", 
        "placement"
    ], 
    "importance": "Undecided", 
    "heat": 18, 
    "link": "https://bugs.launchpad.net/nova/+bug/1687345", 
    "owner": "None", 
    "id": 1687345, 
    "index": 8096, 
    "openned": "2017-05-01 01:54:23.396097+00:00", 
    "created": "2017-05-01 01:49:40.532304+00:00", 
    "title": "NoValidHosts (resource_providers table is empty)", 
    "comments": [
        {
            "content": "Kolla (stable/ocata, 4.0.2) was deployed as multinode (virtualized on Openstack/KVM) environment, but fails to provision instances.\n\nFirst symptom was \n... Starting with 0 host(s) get_filtered_objects /var/lib/kolla/venv/local/lib/python2.7/site-packages/nova/filters.py:70\n... Filtering removed all hosts for the request with instance ID '...'. Filter results: ['RetryFilter: (start: 0, end: 0)']\n... NoValidHost: No valid host was found. There are not enough hosts available.\n\nPlacement API does not return any resource provider\n\nGET /resource_providers\n{\n  \"resource_providers\": []\n}\n\nFollowing the request flow, I reach a point where I confirmed the resource_providers table is empty.\n\nroot@pod09-control01:~# docker exec -ti mariadb mysql -unova_api -p ... nova_api\n...\nMariaDB [nova_api]> select * from resource_providers;\nEmpty set (0.00 sec)\n\nThe only unusual thing, is that initially I deployed with QEMU, as compute node was going to be virtualized over KVM. Later, I enabled KVM nested virtualization in the host, so, now compute is virtualization capable.\n\n(openstack) hypervisor show 1 -fjson\n{\n  \"status\": \"enabled\",\n  \"cpu_info\": \"{\\\"vendor\\\": \\\"Intel\\\", \\\"model\\\": \\\"Skylake-Client\\\", \\\"arch\\\": \\\"x86_64\\\", \\\"features\\\": [\\\"ssse3\\\", \\\"pge\\\", \\\"avx\\\", \\\"xsaveopt\\\", \\\"clflush\\\", \\\"sep\\\", \\\"rtm\\\", \\\"tsc_adjust\\\", \\\"vme\\\", \\\"invpcid\\\", \\\"tsc\\\", \\\"sse\\\", \\\"xsave\\\", \\\"smap\\\", \\\"vmx\\\", \\\"erms\\\", \\\"hle\\\", \\\"cmov\\\", \\\"smep\\\", \\\"fpu\\\", \\\"clflushopt\\\", \\\"pat\\\", \\\"osxsave\\\", \\\"lm\\\", \\\"msr\\\", \\\"adx\\\", \\\"3dnowprefetch\\\", \\\"nx\\\", \\\"fxsr\\\", \\\"syscall\\\", \\\"sse4.1\\\", \\\"pae\\\", \\\"sse4.2\\\", \\\"pclmuldq\\\", \\\"xgetbv1\\\", \\\"fma\\\", \\\"tsc-deadline\\\", \\\"mmx\\\", \\\"arat\\\", \\\"cx8\\\", \\\"mce\\\", \\\"de\\\", \\\"aes\\\", \\\"mca\\\", \\\"pse\\\", \\\"pni\\\", \\\"abm\\\", \\\"rdseed\\\", \\\"popcnt\\\", \\\"pdpe1gb\\\", \\\"apic\\\", \\\"fsgsbase\\\", \\\"f16c\\\", \\\"mpx\\\", \\\"xsavec\\\", \\\"lahf_lm\\\", \\\"rdtscp\\\", \\\"avx2\\\", \\\"sse2\\\", \\\"ss\\\", \\\"hypervisor\\\", \\\"bmi1\\\", \\\"bmi2\\\", \\\"pcid\\\", \\\"cx16\\\", \\\"pse36\\\", \\\"mtrr\\\", \\\"movbe\\\", \\\"rdrand\\\", \\\"x2apic\\\"], \\\"topology\\\": {\\\"cores\\\": 1, \\\"cells\\\": 1, \\\"threads\\\": 1, \\\"sockets\\\": 4}}\",\n  \"free_disk_gb\": 38,\n  \"memory_mb_used\": 540,\n  \"uptime\": \"4:25\",\n  \"host_time\": \"01:46:19\",\n  \"local_gb_used\": 5,\n  \"id\": 1,\n  \"current_workload\": 0,\n  \"state\": \"up\",\n  \"load_average\": \"0.02, 0.02, 0.00\",\n  \"users\": \"0\",\n  \"aggregates\": [],\n  \"host_ip\": \"10.0.0.12\",\n  \"hypervisor_hostname\": \"pod9-compute01\",\n  \"hypervisor_version\": 2008000,\n  \"disk_available_least\": 33,\n  \"local_gb\": 38,\n  \"free_ram_mb\": 7471,\n  \"vcpus_used\": 0,\n  \"hypervisor_type\": \"QEMU\",\n  \"memory_mb\": 7983,\n  \"vcpus\": 4,\n  \"running_vms\": 0,\n  \"service_id\": 6,\n  \"service_host\": \"pod9-compute01\"\n}\n\nAny ideas, how can I make resource providers work?", 
            "date_created": "2017-05-01 01:49:40.532304+00:00", 
            "author": "https://api.launchpad.net/1.0/~jmguzmanc"
        }, 
        {
            "content": "There are a few different possibilities, most of them related to your compute-node not being able to find or reach the placement service. Since you can list resource providers from the API which it is is not obvious.\n\n* is what's configured in the service catalog for the placement endpoint the same as how the web server that is serving placement configured?\n* does the compute-node have the correct config for [placement] in nova.conf\n\nThe logs for n-cpu will have messages (soon after it starts) about it try to contact the placement service. These will provide some clue on what's going on. Can you share them here?", 
            "date_created": "2017-05-01 10:32:01.576761+00:00", 
            "author": "https://api.launchpad.net/1.0/~cdent"
        }, 
        {
            "content": "Chris\n\nThanks a lot\nYou said something that was key to me \"related to your compute-node not being able to find or reach the placement service\"\n\nCompute could not reach the api VIP, because a port_filter in the control port prevented it (these nodes are virtualized on openstack).\n\nFixed by adding the VIP as a allowed_pair in the control port,\n\nport set --allowed-address ip-address=10.0.0.10 dbd22559-8b49-4305-9eb9-122b67088b57\n\nand voila!!\n\nIt is working now!!\nThanks a lot (I spent almost two days with this one).\n\nJM\n\n\n", 
            "date_created": "2017-05-01 15:31:59.499113+00:00", 
            "author": "https://api.launchpad.net/1.0/~jmguzmanc"
        }
    ], 
    "closed": "2017-05-01 15:32:50.886346+00:00"
}