{
    "status": "Invalid", 
    "last_updated": "2012-07-12 13:11:33.234502+00:00", 
    "description": "Hi,\n\nI have four machines running openstack.\nComputer #1 is running nova-controller, network, api and compute (yes, its work as a computer node too). \nComputer #2 is running another nova-compute node, just it.\nComputer #3 is running glance (connected to swift).\nComputer #4 is running swift.\n\nThe problem is that nova-network is incosistent, each time that i create or start a new instance, i need to try restart the nova-network to instance get access to external network. This bug happen just on nodes that are running out of controller machine, like instances on computer #2.\n\nInstances running on nova-computer that runs on Computer #1 doesn't bug and doesn't need nova-network to works.\nInstances running on nova-computer that runs on Computer #2 have the bug and need to restart the nova-network (on computer #1) to get it works.\n\nOpenStack Version: 2011.3 (2011.3-nova-milestone-tarball:tarmac-20110922115702-k9nkvxqzhj130av2)\n\nNova.conf:\n--ca_path=/var/lib/nova/CA\n--cc_host=192.168.100.241\n--daemonize=1\n--dhcpbridge=/usr/bin/nova-dhcpbridge\n--dhcpbridge_flagfile=/etc/nova/nova.conf\n--ec2_url=http://192.168.100.241:8773/services/Cloud\n--fixed_range=10.0.0.0/24\n--flat_network_bridge=br100\n--flat_interface=eth0\n--flat_network_dhcp_start=10.0.0.2\n--instances_path=/var/lib/nova/instances\n--keys_path=/var/lib/nova/keys\n--libvirt_type=kvm\n--lock_path=/var/lock/nova\n--logdir=/var/log/nova\n--network_manager=nova.network.manager.FlatDHCPManager\n--network_size=8\n--routing_source_ip=192.168.100.241\n--public_interface=eth0\n--rabbit_host=192.168.100.241\n--s3_host=192.168.100.241\n--sql_connection=mysql://nova:cpca@192.168.100.241/nova\n--verbose=True\n--vnc_enabled=True\n--vncproxy_url=http://192.168.100.241:6080\n--vncserver_host=0.0.0.0\n--vnc_token_ttl=300\n--networks_path=/var/lib/nova/networks\n--state_path=/var/lib/nova\n--scheduler_driver=nova.scheduler.simple.SimpleScheduler\n--iscsi_ip_prefix=192.168.\n--image_service=nova.image.glance.GlanceImageService\n--glance_host=192.168.100.242\n--glance_port=9292\n--glance_api_servers=192.168.100.242:9292\n\nLogs are attached.", 
    "tags": [], 
    "importance": "Undecided", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/908809", 
    "owner": "None", 
    "id": 908809, 
    "index": 3719, 
    "openned": "2011-12-26 16:15:08.915972+00:00", 
    "created": "2011-12-26 16:15:08.915972+00:00", 
    "title": "Nova-network with public interface", 
    "comments": [
        {
            "content": "Hi,\n\nI have four machines running openstack.\nComputer #1 is running nova-controller, network, api and compute (yes, its work as a computer node too). \nComputer #2 is running another nova-compute node, just it.\nComputer #3 is running glance (connected to swift).\nComputer #4 is running swift.\n\nThe problem is that nova-network is incosistent, each time that i create or start a new instance, i need to try restart the nova-network to instance get access to external network. This bug happen just on nodes that are running out of controller machine, like instances on computer #2.\n\nInstances running on nova-computer that runs on Computer #1 doesn't bug and doesn't need nova-network to works.\nInstances running on nova-computer that runs on Computer #2 have the bug and need to restart the nova-network (on computer #1) to get it works.\n\nOpenStack Version: 2011.3 (2011.3-nova-milestone-tarball:tarmac-20110922115702-k9nkvxqzhj130av2)\n\nNova.conf:\n--ca_path=/var/lib/nova/CA\n--cc_host=192.168.100.241\n--daemonize=1\n--dhcpbridge=/usr/bin/nova-dhcpbridge\n--dhcpbridge_flagfile=/etc/nova/nova.conf\n--ec2_url=http://192.168.100.241:8773/services/Cloud\n--fixed_range=10.0.0.0/24\n--flat_network_bridge=br100\n--flat_interface=eth0\n--flat_network_dhcp_start=10.0.0.2\n--instances_path=/var/lib/nova/instances\n--keys_path=/var/lib/nova/keys\n--libvirt_type=kvm\n--lock_path=/var/lock/nova\n--logdir=/var/log/nova\n--network_manager=nova.network.manager.FlatDHCPManager\n--network_size=8\n--routing_source_ip=192.168.100.241\n--public_interface=eth0\n--rabbit_host=192.168.100.241\n--s3_host=192.168.100.241\n--sql_connection=mysql://nova:cpca@192.168.100.241/nova\n--verbose=True\n--vnc_enabled=True\n--vncproxy_url=http://192.168.100.241:6080\n--vncserver_host=0.0.0.0\n--vnc_token_ttl=300\n--networks_path=/var/lib/nova/networks\n--state_path=/var/lib/nova\n--scheduler_driver=nova.scheduler.simple.SimpleScheduler\n--iscsi_ip_prefix=192.168.\n--image_service=nova.image.glance.GlanceImageService\n--glance_host=192.168.100.242\n--glance_port=9292\n--glance_api_servers=192.168.100.242:9292\n\nLogs are attached.", 
            "date_created": "2011-12-26 16:15:08.915972+00:00", 
            "author": "https://api.launchpad.net/1.0/~alex-tkd"
        }, 
        {
            "content": "", 
            "date_created": "2011-12-26 16:15:08.915972+00:00", 
            "author": "https://api.launchpad.net/1.0/~alex-tkd"
        }, 
        {
            "content": "Are you using dhcp on eth0?  I have seen inconsistencies where nova moves the address from eth0 to br100 and then dhcp adds it back.  If so, try switching to a static ip.  Also, I have had to set promisc mode on br100 before to get things to work.  That said, you may have more luck using HA network mode.  When you create the network set the --multi_host flag to true.  Then you can run nova-network on all of the hosts and each instance will route out through its own host.", 
            "date_created": "2012-01-27 04:59:23.198393+00:00", 
            "author": "https://api.launchpad.net/1.0/~vishvananda"
        }, 
        {
            "content": "We cannot solve the issue you reported without more information. Could you please provide the requested information ?", 
            "date_created": "2012-06-07 12:22:55.940556+00:00", 
            "author": "https://api.launchpad.net/1.0/~ttx"
        }, 
        {
            "content": "This bug lacks the necessary information to effectively reproduce and fix it, therefore it has been closed. Feel free to reopen the bug by providing the requested information and set the bug status back to ''New''.", 
            "date_created": "2012-07-12 13:11:30.667547+00:00", 
            "author": "https://api.launchpad.net/1.0/~ttx"
        }
    ], 
    "closed": "2012-07-12 13:11:31.905561+00:00"
}