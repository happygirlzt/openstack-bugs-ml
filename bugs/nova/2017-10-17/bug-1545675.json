{
    "status": "Fix Released", 
    "last_updated": "2016-09-02 09:58:19.235338+00:00", 
    "description": "It appears that executing certain resize operations on a pinned instance results in inconsistencies in the \"state machine\" that Nova uses to track instances. This was identified using Tempest and manifests itself in failures in follow up shelve/unshelve operations.\n\n---\n\n# Steps\n\nTesting was conducted on host containing a single-node, Fedora 23-based (4.3.5-300.fc23.x86_64) OpenStack instance (built with DevStack). The '12d224e' commit of Nova was used. The Tempest tests (commit 'e913b82') were run using modified flavors, as seen below:\n\n\u00a0\u00a0\u00a0\u00a0nova flavor-create m1.small_nfv 420 2048 0 2\n\u00a0\u00a0\u00a0\u00a0nova flavor-create m1.medium_nfv 840 4096 0 4\n\u00a0\u00a0\u00a0\u00a0nova flavor-key 420 set \"hw:numa_nodes=2\"\n\u00a0\u00a0\u00a0\u00a0nova flavor-key 840 set \"hw:numa_nodes=2\"\n\u00a0\u00a0\u00a0\u00a0nova flavor-key 420 set \"hw:cpu_policy=dedicated\"\n\u00a0\u00a0\u00a0\u00a0nova flavor-key 840 set \"hw:cpu_policy=dedicated\"\n\n\u00a0\u00a0\u00a0\u00a0cd $TEMPEST_DIR\n\u00a0\u00a0\u00a0\u00a0cp etc/tempest.conf etc/tempest.conf.orig\n\u00a0\u00a0\u00a0\u00a0sed -i \"s/flavor_ref = .*/flavor_ref = 420/\" etc/tempest.conf\n\u00a0\u00a0\u00a0\u00a0sed -i \"s/flavor_ref_alt = .*/flavor_ref_alt = 840/\" etc/tempest.conf\n\nTests were run in the order given below.\n\n1. tempest.scenario.test_shelve_instance.TestShelveInstance.test_shelve_instance\n2. tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_shelve_unshelve_server\n3. tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_resize_server_revert\n4. tempest.scenario.test_shelve_instance.TestShelveInstance.test_shelve_instance\n5. tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_shelve_unshelve_server\n\nLike so:\n\n\u00a0\u00a0\u00a0\u00a0./run_tempest.sh -- tempest.scenario.test_shelve_instance.TestShelveInstance.test_shelve_instance\n\n# Expected Result\n\nThe tests should pass.\n\n# Actual Result\n\n\u00a0\u00a0\u00a0\u00a0+---+--------------------------------------+--------+\n\u00a0\u00a0\u00a0\u00a0| # |                 test id              | status |\n\u00a0\u00a0\u00a0\u00a0+---+--------------------------------------+--------+\n\u00a0\u00a0\u00a0\u00a0| 1 | 1164e700-0af0-4a4c-8792-35909a88743c |   ok   |\n\u00a0\u00a0\u00a0\u00a0| 2 | 77eba8e0-036e-4635-944b-f7a8f3b78dc9 |   ok   |\n\u00a0\u00a0\u00a0\u00a0| 3 | c03aab19-adb1-44f5-917d-c419577e9e68 |   ok   |\n\u00a0\u00a0\u00a0\u00a0| 4 | 1164e700-0af0-4a4c-8792-35909a88743c |  FAIL  |\n\u00a0\u00a0\u00a0\u00a0| 5 | c03aab19-adb1-44f5-917d-c419577e9e68 |   ok*  |\n\n* this test reports as passing but is actually generating errors. Bad test! :)\n\nOne test fails while the other \"passes\" but raises errors. The failures, where raised, are CPUPinningInvalid exceptions:\n\n\u00a0\u00a0\u00a0\u00a0CPUPinningInvalid: Cannot pin/unpin cpus [1] from the following pinned set [0, 25]\n\n**NOTE:** I also think there are issues with the non-reverted resize test, though I've yet to investigate this:\n\n* tempest.scenario.test_server_advanced_ops.TestServerAdvancedOps.test_resize_server_confirm\n\nWhat's worse, this error \"snowballs\" on successive runs. Because of the nature of the failure (a failure to pin/unpin CPUs), we're left with a list of CPUs that Nova thinks to be pinned but which are no longer actually used. This is reflected by the resource tracker.\n\n    $ openstack server list\n\n    $ cat /opt/stack/logs/screen/n-cpu.log | grep 'Total usable vcpus' | tail -1\n    *snip* INFO nova.compute.resource_tracker [*snip*] Total usable vcpus: 40, total allocated vcpus: 8\n\nThe error messages for both are given below, along with examples of this \"snowballing\" CPU list:\n\n{0} tempest.scenario.test_shelve_instance.TestShelveInstance.test_shelve_instance [36.713046s] ... FAILED\n\n\u00a0Setting instance vm_state to ERROR\n\u00a0Traceback (most recent call last):\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/manager.py\", line 2474, in do_terminate_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0self._delete_instance(context, instance, bdms, quotas)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/hooks.py\", line 149, in inner\n\u00a0\u00a0\u00a0\u00a0\u00a0rv = f(*args, **kwargs)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/manager.py\", line 2437, in _delete_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0quotas.rollback()\n\u00a0\u00a0\u00a0File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\n\u00a0\u00a0\u00a0\u00a0\u00a0self.force_reraise()\n\u00a0\u00a0\u00a0File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n\u00a0\u00a0\u00a0\u00a0\u00a0six.reraise(self.type_, self.value, self.tb)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/manager.py\", line 2432, in _delete_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0self._update_resource_tracker(context, instance)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/manager.py\", line 751, in _update_resource_tracker\n\u00a0\u00a0\u00a0\u00a0\u00a0rt.update_usage(context, instance)\n\u00a0\u00a0\u00a0File \"/usr/lib/python2.7/site-packages/oslo_concurrency/lockutils.py\", line 271, in inner\n\u00a0\u00a0\u00a0\u00a0\u00a0return f(*args, **kwargs)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 376, in update_usage\n\u00a0\u00a0\u00a0\u00a0\u00a0self._update_usage_from_instance(context, instance)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 863, in _update_usage_from_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0self._update_usage(instance, sign=sign)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 705, in _update_usage\n\u00a0\u00a0\u00a0\u00a0\u00a0self.compute_node, usage, free)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/virt/hardware.py\", line 1441, in get_host_numa_usage_from_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0host_numa_topology, instance_numa_topology, free=free))\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/virt/hardware.py\", line 1307, in numa_usage_from_instances\n\u00a0\u00a0\u00a0\u00a0\u00a0newcell.unpin_cpus(pinned_cpus)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/objects/numa.py\", line 93, in unpin_cpus\n\u00a0\u00a0\u00a0\u00a0\u00a0pinned=list(self.pinned_cpus))\n\u00a0CPUPinningInvalid: Cannot pin/unpin cpus [0] from the following pinned set [1]\n\n{0} tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_shelve_unshelve_server [29.131132s] ... ok\n\n\u00a0Traceback (most recent call last):\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/manager.py\", line 2474, in do_terminate_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0self._delete_instance(context, instance, bdms, quotas)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/hooks.py\", line 149, in inner\n\u00a0\u00a0\u00a0\u00a0\u00a0rv = f(*args, **kwargs)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/manager.py\", line 2437, in _delete_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0quotas.rollback()\n\u00a0\u00a0\u00a0File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\n\u00a0\u00a0\u00a0\u00a0\u00a0self.force_reraise()\n\u00a0\u00a0\u00a0File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n\u00a0\u00a0\u00a0\u00a0\u00a0six.reraise(self.type_, self.value, self.tb)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/manager.py\", line 2432, in _delete_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0self._update_resource_tracker(context, instance)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/manager.py\", line 751, in _update_resource_tracker\n\u00a0\u00a0\u00a0\u00a0\u00a0rt.update_usage(context, instance)\n\u00a0\u00a0\u00a0File \"/usr/lib/python2.7/site-packages/oslo_concurrency/lockutils.py\", line 271, in inner\n\u00a0\u00a0\u00a0\u00a0\u00a0return f(*args, **kwargs)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 376, in update_usage\n\u00a0\u00a0\u00a0\u00a0\u00a0self._update_usage_from_instance(context, instance)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 863, in _update_usage_from_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0self._update_usage(instance, sign=sign)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 705, in _update_usage\n\u00a0\u00a0\u00a0\u00a0\u00a0self.compute_node, usage, free)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/virt/hardware.py\", line 1441, in get_host_numa_usage_from_instance\n\u00a0\u00a0\u00a0\u00a0\u00a0host_numa_topology, instance_numa_topology, free=free))\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/virt/hardware.py\", line 1307, in numa_usage_from_instances\n\u00a0\u00a0\u00a0\u00a0\u00a0newcell.unpin_cpus(pinned_cpus)\n\u00a0\u00a0\u00a0File \"/opt/stack/nova/nova/objects/numa.py\", line 93, in unpin_cpus\n\u00a0\u00a0\u00a0\u00a0\u00a0pinned=list(self.pinned_cpus))\n\u00a0CPUPinningInvalid: Cannot pin/unpin cpus [1] from the following pinned set [0, 25]\n\nThe nth run (n ~= 6):\n\nCPUPinningInvalid: Cannot pin/unpin cpus [24] from the following pinned set [0, 1, 9, 8, 25]\n\nThe nth+1 run:\n\nCPUPinningInvalid: Cannot pin/unpin cpus [27] from the following pinned set [0, 1, 24, 25, 8, 9]\n\nThe nth+2 run:\n\nCPUPinningInvalid: Cannot pin/unpin cpus [2] from the following pinned set [0, 1, 24, 25, 8, 9, 27]", 
    "tags": [
        "in-stable-mitaka", 
        "libvirt", 
        "numa"
    ], 
    "importance": "High", 
    "heat": 34, 
    "link": "https://bugs.launchpad.net/nova/+bug/1545675", 
    "owner": "https://api.launchpad.net/1.0/~stephenfinucane", 
    "id": 1545675, 
    "index": 1880, 
    "openned": "2016-02-15 11:13:17.595667+00:00", 
    "created": "2016-02-15 11:13:17.595667+00:00", 
    "title": "Resizing a pinned VM results in inconsistent state", 
    "comments": [
        {
            "content": "It appears the shelve/unshelve operation does not work when an instance is pinned. A CPUPinningInvalid exception is raised when one attempts to do so.\n\n    CPUPinningInvalid: Cannot pin/unpin cpus [1] from the following pinned set [0, 25]\n\n---\n\n# Steps\n\nTesting was conducted on host containing a single-node, Fedora 23-based (4.3.5-300.fc23.x86_64) OpenStack instance (built with DevStack). The '12d224e' commit of Nova was used. The Tempest tests (commit 'e913b82') were run using modified flavors, as seen below:\n\n    nova flavor-create m1.small_nfv 420 2048 0 2\n    nova flavor-create m1.medium_nfv 840 4096 0 4\n    nova flavor-key 420 set \"hw:numa_nodes=2\"\n    nova flavor-key 840 set \"hw:numa_nodes=2\"\n    nova flavor-key 420 set \"hw:cpu_policy=dedicated\"\n    nova flavor-key 840 set \"hw:cpu_policy=dedicated\"\n\n    cd $TEMPEST_DIR\n    cp etc/tempest.conf etc/tempest.conf.orig\n    sed -i \"s/flavor_ref = .*/flavor_ref = 420/\" etc/tempest.conf\n    sed -i \"s/flavor_ref_alt = .*/flavor_ref_alt = 840/\" etc/tempest.conf\n\nThe following tests were run:\n\n* tempest.scenario.test_shelve_instance.TestShelveInstance.test_shelve_instance\n* tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_shelve_unshelve_server\n\n# Expected Result\n\nThe tests should pass.\n\n# Actual Result\n\nThe tests fail. Both failing tests result in similar error messages. The error messages for both are given below.\n\n{0} tempest.scenario.test_shelve_instance.TestShelveInstance.test_shelve_instance [36.713046s] ... FAILED\n\n Setting instance vm_state to ERROR\n Traceback (most recent call last):\n   File \"/opt/stack/nova/nova/compute/manager.py\", line 2474, in do_terminate_instance\n     self._delete_instance(context, instance, bdms, quotas)\n   File \"/opt/stack/nova/nova/hooks.py\", line 149, in inner\n     rv = f(*args, **kwargs)\n   File \"/opt/stack/nova/nova/compute/manager.py\", line 2437, in _delete_instance\n     quotas.rollback()\n   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\n     self.force_reraise()\n   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n     six.reraise(self.type_, self.value, self.tb)\n   File \"/opt/stack/nova/nova/compute/manager.py\", line 2432, in _delete_instance\n     self._update_resource_tracker(context, instance)\n   File \"/opt/stack/nova/nova/compute/manager.py\", line 751, in _update_resource_tracker\n     rt.update_usage(context, instance)\n   File \"/usr/lib/python2.7/site-packages/oslo_concurrency/lockutils.py\", line 271, in inner\n     return f(*args, **kwargs)\n   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 376, in update_usage\n     self._update_usage_from_instance(context, instance)\n   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 863, in _update_usage_from_instance\n     self._update_usage(instance, sign=sign)\n   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 705, in _update_usage\n     self.compute_node, usage, free)\n   File \"/opt/stack/nova/nova/virt/hardware.py\", line 1441, in get_host_numa_usage_from_instance\n     host_numa_topology, instance_numa_topology, free=free))\n   File \"/opt/stack/nova/nova/virt/hardware.py\", line 1307, in numa_usage_from_instances\n     newcell.unpin_cpus(pinned_cpus)\n   File \"/opt/stack/nova/nova/objects/numa.py\", line 93, in unpin_cpus\n     pinned=list(self.pinned_cpus))\n CPUPinningInvalid: Cannot pin/unpin cpus [0] from the following pinned set [1]\n\n{0} tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_shelve_unshelve_server [29.131132s] ... ok\n\n Traceback (most recent call last):\n   File \"/opt/stack/nova/nova/compute/manager.py\", line 2474, in do_terminate_instance\n     self._delete_instance(context, instance, bdms, quotas)\n   File \"/opt/stack/nova/nova/hooks.py\", line 149, in inner\n     rv = f(*args, **kwargs)\n   File \"/opt/stack/nova/nova/compute/manager.py\", line 2437, in _delete_instance\n     quotas.rollback()\n   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\n     self.force_reraise()\n   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n     six.reraise(self.type_, self.value, self.tb)\n   File \"/opt/stack/nova/nova/compute/manager.py\", line 2432, in _delete_instance\n     self._update_resource_tracker(context, instance)\n   File \"/opt/stack/nova/nova/compute/manager.py\", line 751, in _update_resource_tracker\n     rt.update_usage(context, instance)\n   File \"/usr/lib/python2.7/site-packages/oslo_concurrency/lockutils.py\", line 271, in inner\n     return f(*args, **kwargs)\n   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 376, in update_usage\n     self._update_usage_from_instance(context, instance)\n   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 863, in _update_usage_from_instance\n     self._update_usage(instance, sign=sign)\n   File \"/opt/stack/nova/nova/compute/resource_tracker.py\", line 705, in _update_usage\n     self.compute_node, usage, free)\n   File \"/opt/stack/nova/nova/virt/hardware.py\", line 1441, in get_host_numa_usage_from_instance\n     host_numa_topology, instance_numa_topology, free=free))\n   File \"/opt/stack/nova/nova/virt/hardware.py\", line 1307, in numa_usage_from_instances\n     newcell.unpin_cpus(pinned_cpus)\n   File \"/opt/stack/nova/nova/objects/numa.py\", line 93, in unpin_cpus\n     pinned=list(self.pinned_cpus))\n CPUPinningInvalid: Cannot pin/unpin cpus [1] from the following pinned set [0, 25]", 
            "date_created": "2016-02-15 11:13:17.595667+00:00", 
            "author": "https://api.launchpad.net/1.0/~stephenfinucane"
        }, 
        {
            "content": "So just by looking at the code - I can see that we probably want to call resource_tracker.update_usage() in the shelve_offload method so that we immediately unpin CPUs once that happens and not wait for the  RT periodic task which in case of a speedy tempest test likely never happens.\n\nThis _might_ be the cause of the stack trace in the cleanup delete in case the spawn failed during unshelving for example. \n\nHere's what would happen:\n\nhttps://github.com/openstack/nova/blob/7616c88ad3a2769e9c9ee8a51ac55ddeed0bfd84/nova/compute/manager.py#L4368\n\nWhen unshelving a shelve-offloaded instance, we would first run the claim_instance which  does a new claim against the current state of the NumaTopology of the compute host (keep in mind that we never dropped the usage when we did shelve-offloading so we are actually leaking resources here). A successful claim here means the instance and compute node are update with the new pinning information (and we leak resources on the compute node until the next RT periodic update).\n\nNow suppose the spawn on the next line fails for whatever reason that may or may not be related to a CPU pinning bug - this calls the __exit__ method of the claim, which in turn calls the abort() method of the claim unpinning the CPUs  that were pinned during (see: https://github.com/openstack/nova/blob/7616c88ad3a2769e9c9ee8a51ac55ddeed0bfd84/nova/compute/claims.py#L121)\n\nThis will unpin the CPUs as tracked by the host NumaTopology, but it will not clear the mapping to host CPUs in the Instance object.\n\nFinally - the test cleanup attempts to delete the instance, which attempts to unpin the already unpinned CPUs and fails.\n\nIn case the above makes sense - I think we need to do 2 things:\n\n* Make sure offloading an instance also updates the resource_tracker in the same manner deleting it does immediately.\n* Make sure that aborting the claim clears both the host field, and NUMA information of the Instance (host is problematic here as this is why the delete request ends up RPCed to the host instead of being done locally in the API, even though the instance is clearly not there since the claim failed and is being aborted).\n\nI propose we start there and see if it fixes things.\n\nPS - it is worth noting (if it was not clear from the text) that the above bugs impact mostly shelve functionality - nova spawn clears these things as part of the retry process so is not affected.\n\n", 
            "date_created": "2016-02-16 16:00:14.023899+00:00", 
            "author": "https://api.launchpad.net/1.0/~ndipanov"
        }, 
        {
            "content": "As someone with familiarity with the shelve/unshelve process that analysis makes sense to me. Updating resource usage on offload is something that should be done since resources are not in use, or \"reserved\", at that point. Clearing the host on a failed claim makes sense as well since as was pointed out there is nothing on the host at that point and therefore no real association with that host.\n\nSomething else to note is that shelving code leverages much of what resize did at the time it was written, so any issues discovered in that path may also affect resize. Though Tempest tests may not be resizing instances so shelving tests tend to find issues first.", 
            "date_created": "2016-02-16 17:46:30.604898+00:00", 
            "author": "https://api.launchpad.net/1.0/~alaski"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/280914", 
            "date_created": "2016-02-16 20:48:17.997376+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/281482", 
            "date_created": "2016-02-17 19:36:08.902117+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/281483", 
            "date_created": "2016-02-17 19:36:24.298409+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/280914\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=a54997c62f1422c592dbabc28ea71d0a34e70b74\nSubmitter: Jenkins\nBranch:    master\n\ncommit a54997c62f1422c592dbabc28ea71d0a34e70b74\nAuthor: Nikola Dipanov <email address hidden>\nDate:   Tue Feb 16 19:14:50 2016 +0000\n\n    RT: Decrese usage for offloaded instances\n    \n    Allow for update_usage to consider SHELVED_OFFLOADED instances as\n    removed and update the resource usage accordingly. This means we want to\n    make sure that the stats class does the same.\n    \n    We can now make sure that RT is updated immediately once the instance\n    has been shelved offloaded.\n    \n    Change-Id: Ia22963021995c71758a18b21070dfdf6a950da09\n    Partial-bug: #1545675\n", 
            "date_created": "2016-02-21 16:40:03.953690+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Set to High because it seems to be impacting the NFV CI", 
            "date_created": "2016-02-29 10:56:27.087837+00:00", 
            "author": "https://api.launchpad.net/1.0/~ndipanov"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/281482\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=521decbe9f79e337fb14571367c6008969a7133a\nSubmitter: Jenkins\nBranch:    master\n\ncommit 521decbe9f79e337fb14571367c6008969a7133a\nAuthor: Nikola Dipanov <email address hidden>\nDate:   Wed Feb 17 19:24:06 2016 +0000\n\n    objects: Allow instance to reset the NUMA topology\n    \n    This will be used when aborting claims, since the claim will (if\n    successful) update the instance with the claimed topology,\n    \n    In case of an abort - we want to make sure it's clear for consistency\n    sake. This will be done in the follow up patch.\n    \n    Change-Id: I2989446fdaa44a30d90ae2ab29fc27fb2ad03c4a\n    Partial-bug: 1545675\n", 
            "date_created": "2016-03-02 23:29:27.230503+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/281483\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=c7a6673fd5621d1c121c20376634ec49644fae59\nSubmitter: Jenkins\nBranch:    master\n\ncommit c7a6673fd5621d1c121c20376634ec49644fae59\nAuthor: Nikola Dipanov <email address hidden>\nDate:   Wed Feb 17 19:27:36 2016 +0000\n\n    RT: aborting claims clears instance host and NUMA info\n    \n    When the claim is aborted, this information is no longer correct for the\n    instance, so we clear it to avoid inconsistencies.\n    \n    Change-Id: I83a5f06adb22c21392d5fc867728181ea4b0454d\n    Resolves-bug: 1545675\n", 
            "date_created": "2016-03-07 12:56:45.924773+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/289342", 
            "date_created": "2016-03-07 14:06:57.178580+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/289972", 
            "date_created": "2016-03-08 15:27:40.608619+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/289972\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=d969169022b32fc98a0a7af4891e75bc072269c6\nSubmitter: Jenkins\nBranch:    master\n\ncommit d969169022b32fc98a0a7af4891e75bc072269c6\nAuthor: Stephen Finucane <email address hidden>\nDate:   Tue Mar 8 15:24:18 2016 +0000\n\n    Address nits in Ia2296302\n    \n    Be consistent in which functions are called in tests to reinforce\n    what's being checked.\n    \n    Change-Id: I54f0abda8db65d633189b31684467bae87016738\n    Related-Bug: #1545675\n", 
            "date_created": "2016-03-08 19:19:33.207356+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/289342\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=0469f71181c724480f3b3f12cb7eea97321ca79e\nSubmitter: Jenkins\nBranch:    master\n\ncommit 0469f71181c724480f3b3f12cb7eea97321ca79e\nAuthor: Stephen Finucane <email address hidden>\nDate:   Mon Mar 7 13:40:21 2016 +0000\n\n    Address nits in I83a5f06ad\n    \n    Make functions a little more coherent by ensuring they do one thing and\n    one thing only. Similarly ensure we don't use \"private\" variables in\n    other files.\n    \n    Change-Id: Ib916e01f655d59bcc7cd0932d909e56bb1d4af8a\n    Related-Bug: #1545675\n", 
            "date_created": "2016-03-10 14:12:50.302542+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/332243", 
            "date_created": "2016-06-21 16:42:19.915099+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/323269\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=f1320a7c2debf127a93773046adffb80563fd20b\nSubmitter: Jenkins\nBranch:    master\n\ncommit f1320a7c2debf127a93773046adffb80563fd20b\nAuthor: Stephen Finucane <email address hidden>\nDate:   Mon May 30 16:03:35 2016 +0100\n\n    Evaluate 'task_state' in resource (de)allocation\n    \n    There are two types of VM states associated with shelving. The first,\n    'shelved' indicates that the VM has been powered off but the resources\n    remain allocated on the hypervisor. The second, 'shelved_offloaded',\n    indicates that the VM has been powered off and the resources freed.\n    When \"unshelving\" VMs in the latter state, the VM state does not change\n    from 'shelved_offloaded' until some time after the VM has been\n    \"unshelved\".\n    \n    Change I83a5f06 introduced a change that allowed for deallocation of\n    resources when they were set to the 'shelved_offloaded' state. However,\n    the resource (de)allocation code path assumes any VM with a state of\n    'shelved_offloaded' should have resources deallocated from it, rather\n    than allocated to it. As the VM state has not changed when this code\n    path is executed, resources are incorrectly deallocated from the\n    instance twice.\n    \n    Enhance the aformentioned check to account for task state in addition to\n    VM state. This ensures a VM that's still in 'shelved_offloaded' state,\n    but is in fact being unshelved, does not trigger deallocation.\n    \n    Change-Id: Ie2e7b91937fc3d61bb1197fffc3549bebc65e8aa\n    Signed-off-by: Stephen Finucane <email address hidden>\n    Resolves-bug: #1587386\n    Related-bug: #1545675\n", 
            "date_created": "2016-06-28 16:07:26.306412+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/332243\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=59f55a14b5f5396e653d9eb1e5ded31db72f620b\nSubmitter: Jenkins\nBranch:    master\n\ncommit 59f55a14b5f5396e653d9eb1e5ded31db72f620b\nAuthor: Stephen Finucane <email address hidden>\nDate:   Tue Jun 21 15:47:50 2016 +0100\n\n    Don't immediately null host/node when shelving\n    \n    When offloading a shelved instance, resources should be freed. However,\n    the ability to free resources is dependant on being able to find the\n    resource tracker for an instance's node. At present, the instance node\n    and host are nulled before attempting to update the resource tracker,\n    meaning the resources are never actually freed. Fix this by nullifying\n    these values *after* resources updates.\n    \n    Change-Id: I8f91367aacca0c7c673b28b3c844c70c0d12f0a5\n    Related-bug: #1545675\n", 
            "date_created": "2016-06-29 16:24:51.099419+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: stable/mitaka\nReview: https://review.openstack.org/337107", 
            "date_created": "2016-07-04 10:04:38.395769+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: stable/mitaka\nReview: https://review.openstack.org/337108", 
            "date_created": "2016-07-04 10:04:50.429846+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/337107\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=2703a3d80bcbd49eaafaae624289d00c521b5192\nSubmitter: Jenkins\nBranch:    stable/mitaka\n\ncommit 2703a3d80bcbd49eaafaae624289d00c521b5192\nAuthor: Stephen Finucane <email address hidden>\nDate:   Mon May 30 16:03:35 2016 +0100\n\n    Evaluate 'task_state' in resource (de)allocation\n    \n    There are two types of VM states associated with shelving. The first,\n    'shelved' indicates that the VM has been powered off but the resources\n    remain allocated on the hypervisor. The second, 'shelved_offloaded',\n    indicates that the VM has been powered off and the resources freed.\n    When \"unshelving\" VMs in the latter state, the VM state does not change\n    from 'shelved_offloaded' until some time after the VM has been\n    \"unshelved\".\n    \n    Change I83a5f06 introduced a change that allowed for deallocation of\n    resources when they were set to the 'shelved_offloaded' state. However,\n    the resource (de)allocation code path assumes any VM with a state of\n    'shelved_offloaded' should have resources deallocated from it, rather\n    than allocated to it. As the VM state has not changed when this code\n    path is executed, resources are incorrectly deallocated from the\n    instance twice.\n    \n    Enhance the aformentioned check to account for task state in addition to\n    VM state. This ensures a VM that's still in 'shelved_offloaded' state,\n    but is in fact being unshelved, does not trigger deallocation.\n    \n    Change-Id: Ie2e7b91937fc3d61bb1197fffc3549bebc65e8aa\n    Signed-off-by: Stephen Finucane <email address hidden>\n    Resolves-bug: #1587386\n    Related-bug: #1545675\n    (cherry picked from commit f1320a7c2debf127a93773046adffb80563fd20b)\n", 
            "date_created": "2016-08-08 17:46:03.935380+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/337108\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=c455c82dac32f5a0313077ec3bd8aca1f7db1bcb\nSubmitter: Jenkins\nBranch:    stable/mitaka\n\ncommit c455c82dac32f5a0313077ec3bd8aca1f7db1bcb\nAuthor: Stephen Finucane <email address hidden>\nDate:   Tue Jun 21 15:47:50 2016 +0100\n\n    Don't immediately null host/node when shelving\n    \n    When offloading a shelved instance, resources should be freed. However,\n    the ability to free resources is dependant on being able to find the\n    resource tracker for an instance's node. At present, the instance node\n    and host are nulled before attempting to update the resource tracker,\n    meaning the resources are never actually freed. Fix this by nullifying\n    these values *after* resources updates.\n    \n    Change-Id: I8f91367aacca0c7c673b28b3c844c70c0d12f0a5\n    Related-bug: #1545675\n    (cherry picked from commit 59f55a14b5f5396e653d9eb1e5ded31db72f620b)\n", 
            "date_created": "2016-08-08 18:03:36.005882+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2016-03-07 12:56:43.911306+00:00"
}