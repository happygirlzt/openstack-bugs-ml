{
    "status": "Fix Released", 
    "last_updated": "2014-12-02 16:20:22.384222+00:00", 
    "description": "It's not clear if n-cpu is dying trying to acquire the lock \"lock_bridge\" or if it's just hanging.\n\nhttp://logs.openstack.org/08/109108/1/check/check-tempest-dsvm-full/4417111/logs/screen-n-cpu.txt.gz\n\nThe logs for n-cpu stop about 15 minutes before the rest of the test run, and all tests doing things that require the hypervisor executed after that point fail with different errors.", 
    "tags": [
        "compute"
    ], 
    "importance": "Critical", 
    "heat": 22, 
    "link": "https://bugs.launchpad.net/nova/+bug/1349452", 
    "owner": "https://api.launchpad.net/1.0/~dims-v", 
    "id": 1349452, 
    "index": 199, 
    "openned": "2014-07-28 14:38:41.340083+00:00", 
    "created": "2014-07-28 14:38:41.340083+00:00", 
    "title": "apparent deadlock on lock_bridge in n-cpu", 
    "comments": [
        {
            "content": "It's not clear if n-cpu is dying trying to acquire the lock \"lock_bridge\" or if it's just hanging.\n\nhttp://logs.openstack.org/08/109108/1/check/check-tempest-dsvm-full/4417111/logs/screen-n-cpu.txt.gz\n\nThe logs for n-cpu stop about 15 minutes before the rest of the test run, and all tests doing things that require the hypervisor executed after that point fail with different errors.", 
            "date_created": "2014-07-28 14:38:41.340083+00:00", 
            "author": "https://api.launchpad.net/1.0/~doug-hellmann"
        }, 
        {
            "content": "seeing this happening in the gate, but no good fingerprint for this in the logs.\n\nhttps://gist.githubusercontent.com/cburgess/cde23a2129f75ac20000/raw/6538ccbebfa281484cccd81a267f0a27542f182f/gistfile1.txt", 
            "date_created": "2014-08-19 01:00:52.315060+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "As vishy pointed out it looks like iptables-save is never returning, or the locks are blocking greenthread from switching and thus returning the data and releasing the lock.\n\n\n2014-08-18 16:21:25.183 DEBUG nova.openstack.common.lockutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Got semaphore \"4afac4bc-f7d8-470f-9c16-af270582e48e\" internal_lock /opt/stack/new/nova/nova/openstack/common/lockutils.py:263\n2014-08-18 16:21:25.183 DEBUG nova.openstack.common.lockutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Got semaphore / lock \"do_terminate_instance\" inner /opt/stack/new/nova/nova/openstack/common/lockutils.py:324\n2014-08-18 16:21:25.183 DEBUG nova.openstack.common.lockutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Got semaphore \"4afac4bc-f7d8-470f-9c16-af270582e48e-events\" internal_lock /opt/stack/new/nova/nova/openstack/common/lockutils.py:263\n2014-08-18 16:21:25.184 DEBUG nova.openstack.common.lockutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Got semaphore / lock \"_clear_events\" inner /opt/stack/new/nova/nova/openstack/common/lockutils.py:324\n2014-08-18 16:21:25.184 DEBUG nova.openstack.common.lockutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Released semaphore \"4afac4bc-f7d8-470f-9c16-af270582e48e-events\" lock /opt/stack/new/nova/nova/openstack/common/lockutils.py:291\n2014-08-18 16:21:25.184 DEBUG nova.openstack.common.lockutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Semaphore / lock released \"_clear_events\" inner /opt/stack/new/nova/nova/openstack/common/lockutils.py:328\n2014-08-18 16:21:25.277 AUDIT nova.compute.manager [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] [instance: 4afac4bc-f7d8-470f-9c16-af270582e48e] Terminating instance\n2014-08-18 16:21:27.759 DEBUG nova.virt.libvirt.vif [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] vif_type=bridge instance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone=None,cell_name=None,cleaned=False,config_drive='',created_at=2014-08-18T16:21:07Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,disable_terminate=False,display_description='floating_server-1914203176',display_name='floating_server-1914203176',ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,host='devstack-trusty-hpcloud-b1-1523392',hostname='floating-server-1914203176',id=22,image_ref='af86fee1-9d89-4003-bcfe-7bf1213c8d9a',info_cache=InstanceInfoCache,instance_type_id=6,kernel_id='ccbbcd46-394e-4875-b6eb-245467adf1e4',key_data=None,key_name=None,launch_index=0,launched_at=2014-08-18T16:21:16Z,launched_on='devstack-trusty-hpcloud-b1-1523392',locked=False,locked_by=None,memory_mb=64,metadata={},node='devstack-trusty-hpcloud-b1-1523392',os_type=None,pci_devices=<?>,power_state=1,progress=0,project_id='9200e2f35fbd487dbd3d649f5743323b',ramdisk_id='1a54094c-e7c9-4832-9ba5-031fc1a4b791',reservation_id='r-6z442mvk',root_device_name='/dev/vda',root_gb=0,scheduled_at=None,security_groups=SecurityGroupList,shutdown_terminate=False,system_metadata={image_base_image_ref='af86fee1-9d89-4003-bcfe-7bf1213c8d9a',image_container_format='ami',image_disk_format='ami',image_kernel_id='ccbbcd46-394e-4875-b6eb-245467adf1e4',image_min_disk='0',image_min_ram='0',image_ramdisk_id='1a54094c-e7c9-4832-9ba5-031fc1a4b791',instance_type_ephemeral_gb='0',instance_type_flavorid='42',instance_type_id='6',instance_type_memory_mb='64',instance_type_name='m1.nano',instance_type_root_gb='0',instance_type_rxtx_factor='1.0',instance_type_swap='0',instance_type_vcpu_weight=None,instance_type_vcpus='1'},task_state='deleting',terminated_at=None,updated_at=2014-08-18T16:21:24Z,user_data=None,user_id='d368b303dc3f4577b1885182797e743b',uuid=4afac4bc-f7d8-470f-9c16-af270582e48e,vcpus=1,vm_mode=None,vm_state='active') vif=VIF({'ovs_interfaceid': None, 'network': Network({'bridge': u'br100', 'subnets': [Subnet({'ips': [FixedIP({'meta': {}, 'version': 4, 'type': u'fixed', 'floating_ips': [], 'address': u'10.1.0.4'})], 'version': 4, 'meta': {u'dhcp_server': u'10.1.0.1'}, 'dns': [IP({'meta': {}, 'version': 4, 'type': u'dns', 'address': u'8.8.4.4'})], 'routes': [], 'cidr': u'10.1.0.0/20', 'gateway': IP({'meta': {}, 'version': 4, 'type': u'gateway', 'address': u'10.1.0.1'})}), Subnet({'ips': [], 'version': None, 'meta': {u'dhcp_server': None}, 'dns': [], 'routes': [], 'cidr': None, 'gateway': IP({'meta': {}, 'version': None, 'type': u'gateway', 'address': None})})], 'meta': {u'tenant_id': None, u'should_create_bridge': True, u'bridge_interface': u'eth0'}, 'id': u'86a4cead-7210-40d3-8b96-504df2d189d6', 'label': u'private'}), 'devname': None, 'qbh_params': None, 'meta': {}, 'details': {}, 'address': u'fa:16:3e:93:d4:de', 'active': False, 'type': u'bridge', 'id': u'a8643eb4-b07f-423a-a2b0-6d2dfa9c2ab3', 'qbg_params': None}) unplug /opt/stack/new/nova/nova/virt/libvirt/vif.py:648\n2014-08-18 16:21:27.761 DEBUG nova.openstack.common.lockutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Got semaphore \"iptables\" internal_lock /opt/stack/new/nova/nova/openstack/common/lockutils.py:263\n2014-08-18 16:21:27.762 DEBUG nova.openstack.common.lockutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Attempting to grab external lock \"iptables\" external_lock /opt/stack/new/nova/nova/openstack/common/lockutils.py:230\n2014-08-18 16:21:27.762 DEBUG nova.openstack.common.lockutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Got semaphore / lock \"_apply\" inner /opt/stack/new/nova/nova/openstack/common/lockutils.py:324\n2014-08-18 16:21:27.763 DEBUG nova.openstack.common.processutils [req-fb34143f-be74-4719-a062-a9a041a46098 FloatingIPsTestXML-369233022 FloatingIPsTestXML-175936678] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf iptables-save -c execute /opt/stack/new/nova/nova/openstack/common/processutils.py:160", 
            "date_created": "2014-08-19 01:03:42.075544+00:00", 
            "author": "https://api.launchpad.net/1.0/~cfb-n"
        }, 
        {
            "content": "It looks like iptables-save  may be hanging\n\nhttp://logs.openstack.org/77/109177/2/gate/gate-tempest-dsvm-full/97f2cde/logs/screen-n-cpu.txt.gz#_2014-08-18_16_21_27_763", 
            "date_created": "2014-08-19 01:07:17.131335+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "01:21 < cburgess> As far as I can tell we always use this threading.Semaphore. We should use to an eventlet \n                  one back in the day but we don't anymore.\n01:22 < cburgess> I think vishy might be onto something..\n01:22 < cburgess> if debugger.enabled():\n01:22 < cburgess>     # turn off thread patching to enable the remote debugger\n01:22 < cburgess>     eventlet.monkey_patch(os=False, thread=False)\n01:22 < cburgess> else:\n01:22 < cburgess>     eventlet.monkey_patch(os=False)\n01:22 < cburgess> We don't pass thread=false unless the debugger is on.\n01:23 < vishy> cburgess: right but the semaphore is way broke anyway\n01:23 < vishy> so i think we are monkeypatching it but hitting the deadlock from the bug\n01:24 < cburgess> Possibly...\n01:26 < vishy> so it used to use eventlet.semaphore.Semaphore\n01:27 < cburgess> Yup\n01:27 < cburgess> Looks like it got changed a while back.\n01:27 < cburgess> This change.\n01:27 < cburgess> https://github.com/openstack/nova/commit/a0bcd7b90c38b104cb278223679cedf5cc11c74c\n01:28 < vishy> it also added a specific lock\n01:29 < vishy> around the threading semaphore\n01:29 < vishy> not sure when tht was added\n01:30 < cburgess> This one https://github.com/openstack/nova/commit/4b6ea1e1b87241918baf21a16817417226a9fc62", 
            "date_created": "2014-08-19 02:09:25.043272+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Oslo patch https://review.openstack.org/#/c/43895/", 
            "date_created": "2014-08-19 02:12:04.888911+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Isn't eventlet.monkey_patch(os=False, thread=False) wrought with madness?\n\nIt's so simple to deadlock when that is done.\n\nExample @ https://gist.github.com/harlowja/9c35e443dfa136a4f965", 
            "date_created": "2014-08-19 04:56:48.917446+00:00", 
            "author": "https://api.launchpad.net/1.0/~harlowja"
        }, 
        {
            "content": "vishy postulated that it could be a by-product of this old bug (still not fixed in eventlet we believe).\n\nhttps://bitbucket.org/eventlet/eventlet/issue/137/use-of-threading-locks-causes-deadlock\n\n\nIt looks like one or both of these changes is causing the issue.\nhttps://github.com/openstack/nova/commit/a0bcd7b90c38b104cb278223679cedf5cc11c74c\nhttps://github.com/openstack/nova/commit/4b6ea1e1b87241918baf21a16817417226a9fc62\n\nCorresponding oslo reviews:\nhttps://review.openstack.org/#/c/43895/\nhttps://review.openstack.org/#/c/54581/", 
            "date_created": "2014-08-19 17:18:01.634160+00:00", 
            "author": "https://api.launchpad.net/1.0/~cfb-n"
        }, 
        {
            "content": "This really seems to be back on lock utils as the core issue, and Nova is just getting this behavior because lockutils is deadlocking.", 
            "date_created": "2014-09-03 11:36:37.299258+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "Okay, so we're still thinking this is due to the mismatch of eventlet/threading locks in lockutils?  I think we do have an issue there even when eventlet is monkey_patched fully:\n\n>>> import threading\n>>> threading.Lock\n<built-in function allocate_lock>\n>>> threading.Semaphore\n<function Semaphore at 0x2355c08>\n>>> import eventlet\n>>> eventlet.monkey_patch()\n>>> threading.Lock\n<function allocate_lock at 0x25dd0c8>\n>>> threading.Semaphore\n<function Semaphore at 0x2355c08>\n\nApparently eventlet doesn't monkey_patch Semaphore, so we're using an eventlet Lock with a stdlib Semaphore.\n\nSo, to fix this without introducing an eventlet dep to lockutils we need to do the following:\n\n1) Conditionally import eventlet\n2) Any time we create a semaphore, check if we have eventlet and if it has monkeypatched thread, and explicitly use an eventlet semaphore if so.\n\nIs my understanding of the current situation correct?", 
            "date_created": "2014-09-03 17:37:02.236122+00:00", 
            "author": "https://api.launchpad.net/1.0/~bnemec"
        }, 
        {
            "content": "Just fyi the sempahore object is based on a condition and lock:\n\nhttp://hg.python.org/releasing/2.7.6/file/ba31940588b6/Lib/threading.py#l422\n\nSo if how all this monkey patches works is correct then self.__cond = Condition(Lock()) would be monkey patched by eventlet so that the Sempahore there would actually use a eventlet Lock(), maybe that's not how it turns out to work though?", 
            "date_created": "2014-09-03 18:00:06.710197+00:00", 
            "author": "https://api.launchpad.net/1.0/~harlowja"
        }, 
        {
            "content": "A little test of this:\n\n>>> import eventlet\n>>> eventlet.monkey_patch()\n>>> import threading\n>>> b = threading.Semaphore()\n>>> b._Semaphore__cond\n<Condition(<Semaphore c=1 _w[0]>, 0)>\n>>> b._Semaphore__cond._Condition__lock\n<Semaphore at 0x8704dcc c=1 _w[0]>\n>>> a = b._Semaphore__cond._Condition__lock \n>>> a.__module__\n'eventlet.semaphore'\n>>> b.__module__\n'threading'\n>>> ", 
            "date_created": "2014-09-03 18:03:45.835635+00:00", 
            "author": "https://api.launchpad.net/1.0/~harlowja"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/119586", 
            "date_created": "2014-09-07 02:42:35.054334+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/119586\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=58d48ded2bbb90b8639a31b47e37e97c276eac87\nSubmitter: Jenkins\nBranch:    master\n\ncommit 58d48ded2bbb90b8639a31b47e37e97c276eac87\nAuthor: Davanum Srinivas <email address hidden>\nDate:   Sat Sep 6 22:37:44 2014 -0400\n\n    Sync oslo lockutils to nova\n    \n    The commit to be merged:\n    \n    942e1aa Use file locks by default again\n    ac995be Fix E126 pep8 errors\n    15b8352 Remove oslo.log from lockutils\n    \n    942e1aa is hopefully the fix for the \"n-cpu stop about 15 minutes\n    before the rest of the test run\" problem at the gate. We need to\n    make sure this actually fixes the gate problem\n    \n    Closes-Bug: #1349452\n    \n    Change-Id: I31265d4e08245879ad72d3e91dcd8be2359ca811\n", 
            "date_created": "2014-09-10 08:35:06.065263+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2014-10-01 07:34:49.857585+00:00"
}