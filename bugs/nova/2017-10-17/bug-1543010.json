{
    "status": "Invalid", 
    "last_updated": "2016-06-15 21:22:11.644241+00:00", 
    "description": "I had 12 ESX nova-compute cluster with 100 ESX hypervisor. For some reason one of nova-compute node went down.\nAfter couple of attempt nova-compute came up fine. But,\n\n1. Nova deleted all the instances running on that particular( esx-compute11) from its DB\n2. All the instances were deleted from the backend as well.\n\nFiling this bug to track if there is any issue with nova scheduler on ESX setup.\n\nLogs:\n\nstack@runner:~/nsbu_cqe_openstack/nested$ nova service-list | grep nova-compute | grep esx\n| 6 | nova-compute | esx-compute2 | nova | enabled | up | 2016-02-03T09:45:15.000000 | - |\n| 7 | nova-compute | esx-compute1 | nova | enabled | up | 2016-02-03T09:45:17.000000 | - |\n| 8 | nova-compute | esx-compute4 | nova | enabled | up | 2016-02-03T09:45:18.000000 | - |\n| 9 | nova-compute | esx-compute3 | nova | enabled | up | 2016-02-03T09:45:21.000000 | - |\n| 10 | nova-compute | esx-compute8 | nova | enabled | up | 2016-02-03T09:45:20.000000 | - |\n| 11 | nova-compute | esx-compute7 | nova | enabled | up | 2016-02-03T09:45:19.000000 | - |\n| 12 | nova-compute | esx-compute12 | nova | enabled | up | 2016-02-03T09:45:19.000000 | - |\n| 13 | nova-compute | esx-compute5 | nova | enabled | up | 2016-02-03T09:45:19.000000 | - |\n| 14 | nova-compute | esx-compute9 | nova | enabled | up | 2016-02-03T09:45:17.000000 | - |\n| 15 | nova-compute | esx-compute6 | nova | enabled | up | 2016-02-03T09:45:19.000000 | - |\n| 16 | nova-compute | esx-compute10 | nova | enabled | up | 2016-02-03T09:45:20.000000 | - |\n| 17 | nova-compute | esx-compute11 | nova | enabled | down | 2016-02-03T09:26:53.000000 | - |\nstack@runner:~/nsbu_cqe_openstack/nested$\n\n\nstack@controller:~$ sudo netstat -anp | grep 62.24.1.87\ntcp6 0 0 62.24.1.111:5672 62.24.1.87:58180 ESTABLISHED 8687/beam.smp\ntcp6 0 0 62.24.1.111:5672 62.24.1.87:58179 ESTABLISHED 8687/beam.smp\nstack@controller:~$\n\n\n2016-02-03 01:27:03.217 INFO nova.service [-] Starting compute node (version 13.0.0)\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 457, in fire_timers\n    timer()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/timer.py\", line 58, in __call__\n    cb(*args, **kw)\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 214, in main\n    result = function(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_service/service.py\", line 671, in run_service\n    service.start()\n  File \"/opt/stack/nova/nova/service.py\", line 183, in start\n    self.manager.init_host()\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1313, in init_host\n    context, self.host, expected_attrs=['info_cache', 'metadata'])\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 172, in wrapper\n    args, kwargs)\n  File \"/opt/stack/nova/nova/conductor/rpcapi.py\", line 241, in object_class_action_versions\n    args=args, kwargs=kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 158, in call\n    retry=self.retry)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 90, in _send\n    timeout=timeout, retry=retry)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 464, in send\n    retry=retry)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 453, in _send\n    result = self._waiter.wait(msg_id, timeout)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 336, in wait\n    message = self.waiters.get(msg_id, timeout=timeout)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 239, in get\n    'to message ID %s' % msg_id)\nMessagingTimeout: Timed out waiting for a reply to message ID 5a19ba4d2a694453b5db95fb2f73f9e8\n2016-02-03 01:28:58.448 INFO oslo_messaging._drivers.amqpdriver [-] No calling threads waiting for msg_id : 5a19ba4d2a694453b5db95fb2f73f9e8\n\n\nLogs:\n\nM-Release, master branch\n\nstack@esx-compute3:/opt/stack/nova$ git log -1\ncommit 197bd6dd1231f1f57cdd6c0acb1dfbdc3b2b0989\nMerge: 1ec0b56 5f5590f\nAuthor: Jenkins <email address hidden>\nDate:   Sun Feb 7 04:08:54 2016 +0000\n\n    Merge \"libvirt: use osinfo when configuring the disk bus\"\nstack@esx-compute3:/opt/stack/nova$", 
    "tags": [
        "vmware"
    ], 
    "importance": "Undecided", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1543010", 
    "owner": "https://api.launchpad.net/1.0/~rgerganov", 
    "id": 1543010, 
    "index": 7294, 
    "openned": "2016-02-08 07:52:12.225494+00:00", 
    "created": "2016-02-08 07:52:12.225494+00:00", 
    "title": "Nova clears DB if ESX nova-compute node restarted", 
    "comments": [
        {
            "content": "I had 12 ESX nova-compute cluster with 100 ESX hypervisor. For some reason one of nova-compute node went down.\nAfter couple of attempt nova-compute came up fine. But,\n\n1. Nova deleted all the instances running on that particular( esx-compute11) from its DB\n2. All the instances were deleted from the backend as well.\n\nFiling this bug to track if there is any issue with nova scheduler on ESX setup.\n\nLogs:\n\nstack@runner:~/nsbu_cqe_openstack/nested$ nova service-list | grep nova-compute | grep esx\n| 6 | nova-compute | esx-compute2 | nova | enabled | up | 2016-02-03T09:45:15.000000 | - |\n| 7 | nova-compute | esx-compute1 | nova | enabled | up | 2016-02-03T09:45:17.000000 | - |\n| 8 | nova-compute | esx-compute4 | nova | enabled | up | 2016-02-03T09:45:18.000000 | - |\n| 9 | nova-compute | esx-compute3 | nova | enabled | up | 2016-02-03T09:45:21.000000 | - |\n| 10 | nova-compute | esx-compute8 | nova | enabled | up | 2016-02-03T09:45:20.000000 | - |\n| 11 | nova-compute | esx-compute7 | nova | enabled | up | 2016-02-03T09:45:19.000000 | - |\n| 12 | nova-compute | esx-compute12 | nova | enabled | up | 2016-02-03T09:45:19.000000 | - |\n| 13 | nova-compute | esx-compute5 | nova | enabled | up | 2016-02-03T09:45:19.000000 | - |\n| 14 | nova-compute | esx-compute9 | nova | enabled | up | 2016-02-03T09:45:17.000000 | - |\n| 15 | nova-compute | esx-compute6 | nova | enabled | up | 2016-02-03T09:45:19.000000 | - |\n| 16 | nova-compute | esx-compute10 | nova | enabled | up | 2016-02-03T09:45:20.000000 | - |\n| 17 | nova-compute | esx-compute11 | nova | enabled | down | 2016-02-03T09:26:53.000000 | - |\nstack@runner:~/nsbu_cqe_openstack/nested$\n\n\nstack@controller:~$ sudo netstat -anp | grep 62.24.1.87\ntcp6 0 0 62.24.1.111:5672 62.24.1.87:58180 ESTABLISHED 8687/beam.smp\ntcp6 0 0 62.24.1.111:5672 62.24.1.87:58179 ESTABLISHED 8687/beam.smp\nstack@controller:~$\n\n\n2016-02-03 01:27:03.217 INFO nova.service [-] Starting compute node (version 13.0.0)\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 457, in fire_timers\n    timer()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/timer.py\", line 58, in __call__\n    cb(*args, **kw)\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line 214, in main\n    result = function(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_service/service.py\", line 671, in run_service\n    service.start()\n  File \"/opt/stack/nova/nova/service.py\", line 183, in start\n    self.manager.init_host()\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1313, in init_host\n    context, self.host, expected_attrs=['info_cache', 'metadata'])\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 172, in wrapper\n    args, kwargs)\n  File \"/opt/stack/nova/nova/conductor/rpcapi.py\", line 241, in object_class_action_versions\n    args=args, kwargs=kwargs)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 158, in call\n    retry=self.retry)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 90, in _send\n    timeout=timeout, retry=retry)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 464, in send\n    retry=retry)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 453, in _send\n    result = self._waiter.wait(msg_id, timeout)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 336, in wait\n    message = self.waiters.get(msg_id, timeout=timeout)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 239, in get\n    'to message ID %s' % msg_id)\nMessagingTimeout: Timed out waiting for a reply to message ID 5a19ba4d2a694453b5db95fb2f73f9e8\n2016-02-03 01:28:58.448 INFO oslo_messaging._drivers.amqpdriver [-] No calling threads waiting for msg_id : 5a19ba4d2a694453b5db95fb2f73f9e8\n\n\nLogs:\n\nM-Release, master branch\n\nstack@esx-compute3:/opt/stack/nova$ git log -1\ncommit 197bd6dd1231f1f57cdd6c0acb1dfbdc3b2b0989\nMerge: 1ec0b56 5f5590f\nAuthor: Jenkins <email address hidden>\nDate:   Sun Feb 7 04:08:54 2016 +0000\n\n    Merge \"libvirt: use osinfo when configuring the disk bus\"\nstack@esx-compute3:/opt/stack/nova$", 
            "date_created": "2016-02-08 07:52:12.225494+00:00", 
            "author": "https://api.launchpad.net/1.0/~prashantshetty"
        }, 
        {
            "content": "Hi Prashant,\n\nDid the hostname changed in that host ?", 
            "date_created": "2016-02-08 08:21:32.439772+00:00", 
            "author": "https://api.launchpad.net/1.0/~jjohnsonkoilraj"
        }, 
        {
            "content": "No, hostname didn\u00b9t change. After couple of attempt nova-compute restart\nworked fine.\n\nThanks,\nPrashant\n\n\n\n\nOn 2/8/16, 1:51 PM, \"<email address hidden> on behalf of Johnson koil raj\"\n<<email address hidden> on behalf of <email address hidden>> wrote:\n\n>Hi Prashant,\n>\n>Did the hostname changed in that host ?\n>\n>-- \n>You received this bug notification because you are subscribed to the bug\n>report.\n>https://bugs.launchpad.net/bugs/1543010\n>\n>Title:\n>  Nova clears DB if ESX nova-compute node restarted\n>\n>Status in OpenStack Compute (nova):\n>  New\n>\n>Bug description:\n>  I had 12 ESX nova-compute cluster with 100 ESX hypervisor. For some\n>reason one of nova-compute node went down.\n>  After couple of attempt nova-compute came up fine. But,\n>\n>  1. Nova deleted all the instances running on that particular(\n>esx-compute11) from its DB\n>  2. All the instances were deleted from the backend as well.\n>\n>  Filing this bug to track if there is any issue with nova scheduler on\n>  ESX setup.\n>\n>  Logs:\n>\n>  stack@runner:~/nsbu_cqe_openstack/nested$ nova service-list | grep\n>nova-compute | grep esx\n>  | 6 | nova-compute | esx-compute2 | nova | enabled | up |\n>2016-02-03T09:45:15.000000 | - |\n>  | 7 | nova-compute | esx-compute1 | nova | enabled | up |\n>2016-02-03T09:45:17.000000 | - |\n>  | 8 | nova-compute | esx-compute4 | nova | enabled | up |\n>2016-02-03T09:45:18.000000 | - |\n>  | 9 | nova-compute | esx-compute3 | nova | enabled | up |\n>2016-02-03T09:45:21.000000 | - |\n>  | 10 | nova-compute | esx-compute8 | nova | enabled | up |\n>2016-02-03T09:45:20.000000 | - |\n>  | 11 | nova-compute | esx-compute7 | nova | enabled | up |\n>2016-02-03T09:45:19.000000 | - |\n>  | 12 | nova-compute | esx-compute12 | nova | enabled | up |\n>2016-02-03T09:45:19.000000 | - |\n>  | 13 | nova-compute | esx-compute5 | nova | enabled | up |\n>2016-02-03T09:45:19.000000 | - |\n>  | 14 | nova-compute | esx-compute9 | nova | enabled | up |\n>2016-02-03T09:45:17.000000 | - |\n>  | 15 | nova-compute | esx-compute6 | nova | enabled | up |\n>2016-02-03T09:45:19.000000 | - |\n>  | 16 | nova-compute | esx-compute10 | nova | enabled | up |\n>2016-02-03T09:45:20.000000 | - |\n>  | 17 | nova-compute | esx-compute11 | nova | enabled | down |\n>2016-02-03T09:26:53.000000 | - |\n>  stack@runner:~/nsbu_cqe_openstack/nested$\n>\n>  \n>  stack@controller:~$ sudo netstat -anp | grep 62.24.1.87\n>  tcp6 0 0 62.24.1.111:5672 62.24.1.87:58180 ESTABLISHED 8687/beam.smp\n>  tcp6 0 0 62.24.1.111:5672 62.24.1.87:58179 ESTABLISHED 8687/beam.smp\n>  stack@controller:~$\n>\n>  \n>  2016-02-03 01:27:03.217 INFO nova.service [-] Starting compute node\n>(version 13.0.0)\n>  Traceback (most recent call last):\n>    File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\",\n>line 457, in fire_timers\n>      timer()\n>    File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/timer.py\",\n>line 58, in __call__\n>      cb(*args, **kw)\n>    File \n>\"/usr/local/lib/python2.7/dist-packages/eventlet/greenthread.py\", line\n>214, in main\n>      result = function(*args, **kwargs)\n>    File \n>\"/usr/local/lib/python2.7/dist-packages/oslo_service/service.py\", line\n>671, in run_service\n>      service.start()\n>    File \"/opt/stack/nova/nova/service.py\", line 183, in start\n>      self.manager.init_host()\n>    File \"/opt/stack/nova/nova/compute/manager.py\", line 1313, in\n>init_host\n>      context, self.host, expected_attrs=['info_cache', 'metadata'])\n>    File \n>\"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\",\n>line 172, in wrapper\n>      args, kwargs)\n>    File \"/opt/stack/nova/nova/conductor/rpcapi.py\", line 241, in\n>object_class_action_versions\n>      args=args, kwargs=kwargs)\n>    File \n>\"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\",\n>line 158, in call\n>      retry=self.retry)\n>    File \n>\"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\",\n>line 90, in _send\n>      timeout=timeout, retry=retry)\n>    File \n>\"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver\n>.py\", line 464, in send\n>      retry=retry)\n>    File \n>\"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver\n>.py\", line 453, in _send\n>      result = self._waiter.wait(msg_id, timeout)\n>    File \n>\"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver\n>.py\", line 336, in wait\n>      message = self.waiters.get(msg_id, timeout=timeout)\n>    File \n>\"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver\n>.py\", line 239, in get\n>      'to message ID %s' % msg_id)\n>  MessagingTimeout: Timed out waiting for a reply to message ID\n>5a19ba4d2a694453b5db95fb2f73f9e8\n>  2016-02-03 01:28:58.448 INFO oslo_messaging._drivers.amqpdriver [-] No\n>calling threads waiting for msg_id : 5a19ba4d2a694453b5db95fb2f73f9e8\n>\n>  \n>  Logs:\n>\n>  M-Release, master branch\n>\n>  stack@esx-compute3:/opt/stack/nova$ git log -1\n>  commit 197bd6dd1231f1f57cdd6c0acb1dfbdc3b2b0989\n>  Merge: 1ec0b56 5f5590f\n>  Author: Jenkins <email address hidden>\n>  Date:   Sun Feb 7 04:08:54 2016 +0000\n>\n>      Merge \"libvirt: use osinfo when configuring the disk bus\"\n>  stack@esx-compute3:/opt/stack/nova$\n>\n>To manage notifications about this bug go to:\n>https://bugs.launchpad.net/nova/+bug/1543010/+subscriptions\n\n", 
            "date_created": "2016-02-08 08:49:45+00:00", 
            "author": "https://api.launchpad.net/1.0/~prashantshetty"
        }, 
        {
            "content": "No Johnson. Was considering host name change as last option to recover. Luckily after couple of attempts(had left in same fail state for couple of hours, as nova-compute restart was failing initially) nova-compute came up fine.", 
            "date_created": "2016-02-08 08:53:40.186989+00:00", 
            "author": "https://api.launchpad.net/1.0/~prashantshetty"
        }, 
        {
            "content": "We need relevant nova-compute logs for the failed system at DEBUG level to figure out why it did this.", 
            "date_created": "2016-02-17 15:21:27.671814+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "", 
            "date_created": "2016-02-17 18:31:35.635475+00:00", 
            "author": "https://api.launchpad.net/1.0/~prashantshetty"
        }, 
        {
            "content": "So the first thing I thought of when I read this was:\n\nhttp://specs.openstack.org/openstack/nova-specs/specs/liberty/implemented/robustify_evacuate.html#problem-description\n\nThat was implemented in liberty though.  Was the failed compute node a kilo node?  Was there a misconfiguration in nova.conf where it was pointing at the wrong vcenter?", 
            "date_created": "2016-03-03 22:18:50.315639+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Well there are messaging timeout errors and other connection failures all over the logs, it doesn't really help pinpoint the issue.", 
            "date_created": "2016-03-03 22:28:58.751567+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Hi Matt,  We are running nova master branch(its from M-Release)", 
            "date_created": "2016-03-04 07:43:32.866219+00:00", 
            "author": "https://api.launchpad.net/1.0/~prashantshetty"
        }, 
        {
            "content": "Hi Prashant,\n\nHave you been able to reproduce this issue?  If so, could you set your logging level to DEBUG and provide us with those logs when you reproduce the issue? If you are unable to reproduce this then it will be very difficult for us to determine a root cause based on the information we currently have available.\n\nThanks!\n", 
            "date_created": "2016-03-30 00:01:40.332177+00:00", 
            "author": "https://api.launchpad.net/1.0/~auggy"
        }, 
        {
            "content": "It's been almost 3 months with no activity on this issue. I'm closing this out as we don't have enough information to reproduce it. Please feel free to reopen this bug or file a new one once you are able to provide us with the additional information we've requested.", 
            "date_created": "2016-06-15 21:21:55.799650+00:00", 
            "author": "https://api.launchpad.net/1.0/~auggy"
        }
    ], 
    "closed": "2016-06-15 21:22:09.502086+00:00"
}