{
    "status": "Fix Released", 
    "last_updated": "2017-06-16 17:27:33.950453+00:00", 
    "description": "Seen here:\n\nhttp://logs.openstack.org/91/327191/22/check/gate-tempest-dsvm-full-ubuntu-xenial/6a11005/logs/screen-n-api.txt.gz?level=TRACE#_2016-08-06_23_42_20_711\n\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions [req-86f8ef99-a9e4-49f0-8258-a0f40dea4a51 tempest-ServersNegativeTestJSON-16764714 tempest-ServersNegativeTestJSON-16764714] Unexpected exception in API method\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions Traceback (most recent call last):\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/api/openstack/extensions.py\", line 338, in wrapped\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     return f(*args, **kwargs)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/api/openstack/compute/suspend_server.py\", line 41, in _suspend\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     self.compute_api.suspend(context, server)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/api.py\", line 164, in inner\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     return function(self, context, instance, *args, **kwargs)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/api.py\", line 171, in _wrapped\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     return fn(self, context, instance, *args, **kwargs)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/api.py\", line 145, in inner\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     return f(self, context, instance, *args, **kw)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/api.py\", line 2782, in suspend\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     self.compute_rpcapi.suspend_instance(context, instance)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/rpcapi.py\", line 953, in suspend_instance\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     server=_compute_host(None, instance), version=version)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/rpcapi.py\", line 53, in _compute_host\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     'Instance %s') % instance.uuid)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions NovaException: Unable to find host for Instance 480c8b6f-ab2d-4a49-8344-a3a679b01472\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions \n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=message%3A%5C%22NovaException%3A%20Unable%20to%20find%20host%20for%20Instance%5C%22%20AND%20tags%3A%5C%22screen-n-api.txt%5C%22&from=7d\n\nThere are 4 hits in 7 days, check and gate, all failures, all on the master branch.", 
    "tags": [], 
    "importance": "High", 
    "heat": 14, 
    "link": "https://bugs.launchpad.net/nova/+bug/1611008", 
    "owner": "https://api.launchpad.net/1.0/~mriedem", 
    "id": 1611008, 
    "index": 1967, 
    "openned": "2016-08-08 15:13:08.969323+00:00", 
    "created": "2016-08-08 15:13:08.969323+00:00", 
    "title": "ServersNegativeTestJSON.test_suspend_server_invalid_state fails with 'NovaException: Unable to find host for Instance'", 
    "comments": [
        {
            "content": "Seen here:\n\nhttp://logs.openstack.org/91/327191/22/check/gate-tempest-dsvm-full-ubuntu-xenial/6a11005/logs/screen-n-api.txt.gz?level=TRACE#_2016-08-06_23_42_20_711\n\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions [req-86f8ef99-a9e4-49f0-8258-a0f40dea4a51 tempest-ServersNegativeTestJSON-16764714 tempest-ServersNegativeTestJSON-16764714] Unexpected exception in API method\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions Traceback (most recent call last):\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/api/openstack/extensions.py\", line 338, in wrapped\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     return f(*args, **kwargs)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/api/openstack/compute/suspend_server.py\", line 41, in _suspend\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     self.compute_api.suspend(context, server)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/api.py\", line 164, in inner\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     return function(self, context, instance, *args, **kwargs)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/api.py\", line 171, in _wrapped\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     return fn(self, context, instance, *args, **kwargs)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/api.py\", line 145, in inner\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     return f(self, context, instance, *args, **kw)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/api.py\", line 2782, in suspend\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     self.compute_rpcapi.suspend_instance(context, instance)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/rpcapi.py\", line 953, in suspend_instance\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     server=_compute_host(None, instance), version=version)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions   File \"/opt/stack/new/nova/nova/compute/rpcapi.py\", line 53, in _compute_host\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions     'Instance %s') % instance.uuid)\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions NovaException: Unable to find host for Instance 480c8b6f-ab2d-4a49-8344-a3a679b01472\n2016-08-06 23:42:20.711 10592 ERROR nova.api.openstack.extensions \n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=message%3A%5C%22NovaException%3A%20Unable%20to%20find%20host%20for%20Instance%5C%22%20AND%20tags%3A%5C%22screen-n-api.txt%5C%22&from=7d\n\nThere are 4 hits in 7 days, check and gate, all failures, all on the master branch.", 
            "date_created": "2016-08-08 15:13:08.969323+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "From the test code this re-uses a single VM and if it's gone for some reason the VM is rebuilt.", 
            "date_created": "2016-08-08 15:17:16.624237+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Looks like there is a shelved offloading test right before this one, and I'm seeing this 2 seconds before the suspend test fails:\n\nhttp://logs.openstack.org/91/327191/22/check/gate-tempest-dsvm-full-ubuntu-xenial/6a11005/logs/screen-n-cpu.txt.gz#_2016-08-06_23_42_18_623\n\n2016-08-06 23:42:18.623 12034 INFO nova.compute.manager [req-a65de09d-272b-4df3-ae2b-95f7d341ce0c - -] [instance: 480c8b6f-ab2d-4a49-8344-a3a679b01472] During the sync_power process the instance has moved from host None to host ubuntu-xenial-rax-ord-3248933\n\nBut that's showing that the db instance.host isn't set:\n\n        if self.host != db_instance.host:\n            # on the sending end of nova-compute _sync_power_state\n            # may have yielded to the greenthread performing a live\n            # migration; this in turn has changed the resident-host\n            # for the VM; However, the instance is still active, it\n            # is just in the process of migrating to another host.\n            # This implies that the compute source must relinquish\n            # control to the compute destination.\n            LOG.info(_LI(\"During the sync_power process the \"\n                         \"instance has moved from \"\n                         \"host %(src)s to host %(dst)s\"),\n                     {'src': db_instance.host,\n                      'dst': self.host},\n                     instance=db_instance)\n            return\n\n\nI'm also seeing this:\n\nhttp://logs.openstack.org/91/327191/22/check/gate-tempest-dsvm-full-ubuntu-xenial/6a11005/logs/screen-n-cpu.txt.gz#_2016-08-06_23_42_09_098\n\n2016-08-06 23:42:09.098 12034 WARNING nova.compute.resource_tracker [req-54812c9d-aa68-4743-b53c-ae4cd8a0b75b tempest-ServersNegativeTestJSON-16764714 tempest-ServersNegativeTestJSON-16764714] [instance: 480c8b6f-ab2d-4a49-8344-a3a679b01472] Host field should not be set on the instance until resources have been claimed.\n2016-08-06 23:42:09.099 12034 WARNING nova.compute.resource_tracker [req-54812c9d-aa68-4743-b53c-ae4cd8a0b75b tempest-ServersNegativeTestJSON-16764714 tempest-ServersNegativeTestJSON-16764714] [instance: 480c8b6f-ab2d-4a49-8344-a3a679b01472] Node field should not be set on the instance until resources have been claimed.", 
            "date_created": "2016-08-08 15:34:16.887484+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Looks like Tempest is re-using the same shared test server between two different test classes/modules, because the server is shelved (which is immediately offloaded) here:\n\nhttp://logs.openstack.org/91/327191/22/check/gate-tempest-dsvm-full-ubuntu-xenial/6a11005/logs/tempest.txt.gz#_2016-08-06_23_42_05_262\n\n2016-08-06 23:42:05.262 18269 INFO tempest.lib.common.rest_client [req-e5b97c22-033d-4170-9dbb-855af94dbf7d ] Request (ServersNegativeTestJSON:test_shelve_shelved_server): 200 GET http://127.0.0.1:8774/v2.1/servers/480c8b6f-ab2d-4a49-8344-a3a679b01472 0.361s\n2016-08-06 23:42:05.262 18269 DEBUG tempest.lib.common.rest_client [req-e5b97c22-033d-4170-9dbb-855af94dbf7d ] Request - Headers: {'Content-Type': 'application/json', 'X-Auth-Token': '<omitted>', 'Accept': 'application/json'}\n        Body: None\n    Response - Headers: {'x-compute-request-id': 'req-e5b97c22-033d-4170-9dbb-855af94dbf7d', 'date': 'Sat, 06 Aug 2016 23:42:05 GMT', 'vary': 'X-OpenStack-Nova-API-Version', 'content-location': 'http://127.0.0.1:8774/v2.1/servers/480c8b6f-ab2d-4a49-8344-a3a679b01472', 'content-type': 'application/json', 'openstack-api-version': 'compute 2.1', 'status': '200', 'x-openstack-nova-api-version': '2.1', 'connection': 'close', 'content-length': '1436'}\n        Body: {\"server\": {\"OS-EXT-STS:task_state\": \"shelving_offloading\", \"addresses\": {\"private\": [{\"OS-EXT-IPS-MAC:mac_addr\": \"fa:16:3e:e4:3e:93\", \"version\": 4, \"addr\": \"10.1.9.1\", \"OS-EXT-IPS:type\": \"fixed\"}]}, \"links\": [{\"href\": \"http://127.0.0.1:8774/v2.1/servers/480c8b6f-ab2d-4a49-8344-a3a679b01472\", \"rel\": \"self\"}, {\"href\": \"http://127.0.0.1:8774/servers/480c8b6f-ab2d-4a49-8344-a3a679b01472\", \"rel\": \"bookmark\"}], \"image\": {\"id\": \"58ef0441-c37e-4691-9ce4-9ea30b071aba\", \"links\": [{\"href\": \"http://127.0.0.1:8774/images/58ef0441-c37e-4691-9ce4-9ea30b071aba\", \"rel\": \"bookmark\"}]}, \"OS-EXT-STS:vm_state\": \"shelved\", \"OS-SRV-USG:launched_at\": \"2016-08-06T23:41:34.000000\", \"flavor\": {\"id\": \"42\", \"links\": [{\"href\": \"http://127.0.0.1:8774/flavors/42\", \"rel\": \"bookmark\"}]}, \"id\": \"480c8b6f-ab2d-4a49-8344-a3a679b01472\", \"security_groups\": [{\"name\": \"default\"}], \"user_id\": \"707a3c38bf0e4a36a286ccfeb4a2b13a\", \"OS-DCF:diskConfig\": \"MANUAL\", \"accessIPv4\": \"\", \"accessIPv6\": \"\", \"OS-EXT-STS:power_state\": 4, \"OS-EXT-AZ:availability_zone\": \"nova\", \"metadata\": {}, \"status\": \"SHELVED\", \"updated\": \"2016-08-06T23:42:05Z\", \"hostId\": \"9cd5a3fb9d2cb48a8e1a51a0a0d16ddc285451fc1a29bff0b0e1e2f2\", \"OS-SRV-USG:terminated_at\": null, \"key_name\": null, \"name\": \"tempest.common.compute-instance-1034238505\", \"created\": \"2016-08-06T23:41:23Z\", \"tenant_id\": \"79ff191035e240be962ea4992a46a11e\", \"os-extended-volumes:volumes_attached\": [], \"config_drive\": \"True\"}} _log_request_full tempest/lib/common/rest_client.py:433", 
            "date_created": "2016-08-08 15:47:46.289698+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I guess it is the same test class, just a different test, but it's coming after the suspend one that fails, so they must run in a random order:\n\nhttps://github.com/openstack/tempest/blob/master/tempest/api/compute/servers/test_servers_negative.py#L455", 
            "date_created": "2016-08-08 15:49:55.205719+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "On teardown this method is called:\n\nhttps://github.com/openstack/tempest/blob/master/tempest/api/compute/base.py#L152\n\nThat waits for the shared server to be active, which it should be after the unshelve runs:\n\n    def server_check_teardown(cls):\n        \"\"\"Checks is the shared server clean enough for subsequent test.\n           Method will delete the server when it's dirty.\n           The setUp method is responsible for creating a new server.\n           Exceptions raised in tearDown class are fails the test case,\n           This method supposed to use only by tearDown methods, when\n           the shared server_id is stored in the server_id of the class.\n        \"\"\"\n        if getattr(cls, 'server_id', None) is not None:\n            try:\n                waiters.wait_for_server_status(cls.servers_client,\n                                               cls.server_id, 'ACTIVE')\n            except Exception as exc:\n                LOG.exception(exc)\n                cls.servers_client.delete_server(cls.server_id)\n                waiters.wait_for_server_termination(cls.servers_client,\n                                                    cls.server_id)\n                cls.server_id = None\n                raise\n\nBut then right before the suspend fails, the server is ACTIVE with no task_state but it doesn't have a host assigned:\n\n2016-08-06 23:42:20.558 18269 DEBUG tempest.lib.common.rest_client [req-eeea93df-9dc5-4b51-8cea-15a5f8ae9a3f ] Request - Headers: {'Content-Type': 'application/json', 'X-Auth-Token': '<omitted>', 'Accept': 'application/json'}\n        Body: None\n    Response - Headers: {'x-compute-request-id': 'req-eeea93df-9dc5-4b51-8cea-15a5f8ae9a3f', 'date': 'Sat, 06 Aug 2016 23:42:20 GMT', 'vary': 'X-OpenStack-Nova-API-Version', 'content-location': 'http://127.0.0.1:8774/v2.1/servers/480c8b6f-ab2d-4a49-8344-a3a679b01472', 'content-type': 'application/json', 'openstack-api-version': 'compute 2.1', 'status': '200', 'x-openstack-nova-api-version': '2.1', 'connection': 'close', 'content-length': '1372'}\n        Body: {\"server\": {\"OS-EXT-STS:task_state\": null, \"addresses\": {\"private\": [{\"OS-EXT-IPS-MAC:mac_addr\": \"fa:16:3e:e4:3e:93\", \"version\": 4, \"addr\": \"10.1.9.1\", \"OS-EXT-IPS:type\": \"fixed\"}]}, \"links\": [{\"href\": \"http://127.0.0.1:8774/v2.1/servers/480c8b6f-ab2d-4a49-8344-a3a679b01472\", \"rel\": \"self\"}, {\"href\": \"http://127.0.0.1:8774/servers/480c8b6f-ab2d-4a49-8344-a3a679b01472\", \"rel\": \"bookmark\"}], \"image\": {\"id\": \"58ef0441-c37e-4691-9ce4-9ea30b071aba\", \"links\": [{\"href\": \"http://127.0.0.1:8774/images/58ef0441-c37e-4691-9ce4-9ea30b071aba\", \"rel\": \"bookmark\"}]}, \"OS-EXT-STS:vm_state\": \"active\", \"OS-SRV-USG:launched_at\": \"2016-08-06T23:42:19.000000\", \"flavor\": {\"id\": \"42\", \"links\": [{\"href\": \"http://127.0.0.1:8774/flavors/42\", \"rel\": \"bookmark\"}]}, \"id\": \"480c8b6f-ab2d-4a49-8344-a3a679b01472\", \"security_groups\": [{\"name\": \"default\"}], \"user_id\": \"707a3c38bf0e4a36a286ccfeb4a2b13a\", \"OS-DCF:diskConfig\": \"MANUAL\", \"accessIPv4\": \"\", \"accessIPv6\": \"\", \"progress\": 0, \"OS-EXT-STS:power_state\": 1, \"OS-EXT-AZ:availability_zone\": \"\", \"metadata\": {}, \"status\": \"ACTIVE\", \"updated\": \"2016-08-06T23:42:19Z\", \"hostId\": \"\", \"OS-SRV-USG:terminated_at\": null, \"key_name\": null, \"name\": \"tempest.common.compute-instance-1034238505\", \"created\": \"2016-08-06T23:41:23Z\", \"tenant_id\": \"79ff191035e240be962ea4992a46a11e\", \"os-extended-volumes:volumes_attached\": [], \"config_drive\": \"True\"}} _log_request_full tempest/lib/common/rest_client.py:433\n\nWe shouldn't have an ACTIVE server with no host...so this is probably a race bug in nova with the unshelve code.", 
            "date_created": "2016-08-08 15:55:28.626998+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "The resource_tracker.instance_claim is where the instance.host should be set during unshelve:\n\nhttps://github.com/openstack/nova/blob/8e0b98f54ec382fbebc2fcd83f4b951a3cc40c33/nova/compute/manager.py#L4334\n\nAnd then once the instance is spawned on the hypervisor the compute sets it to ACTIVE:\n\nhttps://github.com/openstack/nova/blob/8e0b98f54ec382fbebc2fcd83f4b951a3cc40c33/nova/compute/manager.py#L4351\n\nThis is what sets the instance.host and instance.node fields in the RT:\n\nhttps://github.com/openstack/nova/blob/8e0b98f54ec382fbebc2fcd83f4b951a3cc40c33/nova/compute/resource_tracker.py#L146", 
            "date_created": "2016-08-08 16:24:06.214415+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I think this is where the compute manager stops the instance during the shelve process:\n\nhttp://logs.openstack.org/91/327191/22/check/gate-tempest-dsvm-full-ubuntu-xenial/6a11005/logs/screen-n-cpu.txt.gz#_2016-08-06_23_41_54_563\n\nThen it does the snapshot:\n\nhttp://logs.openstack.org/91/327191/22/check/gate-tempest-dsvm-full-ubuntu-xenial/6a11005/logs/screen-n-cpu.txt.gz#_2016-08-06_23_41_59_507\n\nThis is where the instance is destroyed on the hypervisor:\n\nhttp://logs.openstack.org/91/327191/22/check/gate-tempest-dsvm-full-ubuntu-xenial/6a11005/logs/screen-n-cpu.txt.gz#_2016-08-06_23_42_05_126\n\nThis is the instance at that point:\n\ninstance=Instance(access_ip_v4=None,access_ip_v6=None,architecture=None,auto_disk_config=False,availability_zone=None,cell_name=None,cleaned=False,config_drive='True',created_at=2016-08-06T23:41:23Z,default_ephemeral_device=None,default_swap_device=None,deleted=False,deleted_at=None,device_metadata=<?>,disable_terminate=False,display_description='tempest.common.compute-instance-1034238505',display_name='tempest.common.compute-instance-1034238505',ec2_ids=<?>,ephemeral_gb=0,ephemeral_key_uuid=None,fault=<?>,flavor=Flavor(11),host='ubuntu-xenial-rax-ord-3248933',hostname='tempest.common.compute-instance-1034238505',id=42,image_ref='58ef0441-c37e-4691-9ce4-9ea30b071aba',info_cache=InstanceInfoCache,instance_type_id=11,kernel_id='2bd9842e-206a-4e93-b36e-930bbfbc8981',key_data=None,key_name=None,keypairs=<?>,launch_index=0,launched_at=2016-08-06T23:41:34Z,launched_on='ubuntu-xenial-rax-ord-3248933',locked=False,locked_by=None,memory_mb=64,metadata={},migration_context=<?>,new_flavor=None,node='ubuntu-xenial-rax-ord-3248933',numa_topology=<?>,old_flavor=None,os_type=None,pci_devices=<?>,pci_requests=<?>,power_state=4,progress=0,project_id='79ff191035e240be962ea4992a46a11e',ramdisk_id='6e59da14-d4c0-4ffb-befe-42d56d2ee4bf',reservation_id='r-s43tv20y',root_device_name='/dev/vda',root_gb=0,security_groups=SecurityGroupList,services=<?>,shutdown_terminate=False,system_metadata={image_base_image_ref='58ef0441-c37e-4691-9ce4-9ea30b071aba',image_container_format='ami',image_disk_format='ami',image_kernel_id='2bd9842e-206a-4e93-b36e-930bbfbc8981',image_min_disk='0',image_min_ram='0',image_ramdisk_id='6e59da14-d4c0-4ffb-befe-42d56d2ee4bf',shelved_at='2016-08-06T23:42:04.587233',shelved_host='ubuntu-xenial-rax-ord-3248933',shelved_image_id='d2587e71-ee99-4e73-adc7-58026c8b9f3a'},tags=<?>,task_state='shelving_offloading',terminated_at=None,updated_at=2016-08-06T23:42:03Z,user_data=None,user_id='707a3c38bf0e4a36a286ccfeb4a2b13a',uuid=480c8b6f-ab2d-4a49-8344-a3a679b01472,vcpu_model=<?>,vcpus=1,vm_mode=None,vm_state='shelved') vif=VIF({'profile': None, 'ovs_interfaceid': None, 'preserve_on_delete': False, 'network': Network({'bridge': u'br100', 'subnets': [Subnet({'ips': [FixedIP({'meta': {}, 'version': 4, 'type': u'fixed', 'floating_ips': [], 'address': u'10.1.9.1'})], 'version': 4, 'meta': {u'dhcp_server': u'10.1.0.1'}, 'dns': [IP({'meta': {}, 'version': 4, 'type': u'dns', 'address': u'8.8.4.4'})], 'routes': [], 'cidr': u'10.1.0.0/20', 'gateway': IP({'meta': {}, 'version': 4, 'type': u'gateway', 'address': u'10.1.0.1'})}), Subnet({'ips': [], 'version': None, 'meta': {u'dhcp_server': None}, 'dns': [], 'routes': [], 'cidr': None, 'gateway': IP({'meta': {}, 'version': None, 'type': u'gateway', 'address': None})})], 'meta': {u'tenant_id': None, u'should_create_bridge': True, u'bridge_interface': u'br_flat'}, 'id': u'd4ea4ca0-85ca-44b8-ab96-10f61b030486', 'label': u'private'}), 'devname': None, 'vnic_type': u'normal', 'qbh_params': None, 'meta': {}, 'details': {}, 'address': u'fa:16:3e:e4:3e:93', 'active': False, 'type': u'bridge', 'id': u'34d6be98-361f-4df9-a6b5-22d4ba975272', 'qbg_params': None})\n\nWhich has the host set:\n\nhost='ubuntu-xenial-rax-ord-3248933'\n\nAnd I think before the instance.host is nulled out, unshelve starts:\n\nhttp://logs.openstack.org/91/327191/22/check/gate-tempest-dsvm-full-ubuntu-xenial/6a11005/logs/screen-n-cpu.txt.gz#_2016-08-06_23_42_08_729\n\nThat's because tempest isn't waiting for the instance to be in shelved_offloaded state:\n\nhttps://github.com/openstack/tempest/blob/master/tempest/api/compute/servers/test_servers_negative.py#L455\n\nIt just shelves the server, then tries to shelve it again, which returns a 409, and then tries to unshelve it.\n\nThere is a semaphore lock in the unshelve_instance method in the compute manager but not unshelve_instance, so the instance.host and node are still set when unshelve tries to claim resources, which is why we get these warnings in the resource tracker:\n\nhttps://github.com/openstack/tempest/blob/master/tempest/api/compute/servers/test_servers_negative.py#L455\n\nSo unshelve probably sets the instance.host in the resource tracker but then because unshelve doesn't have a lock, it nulls out the instance host and node:\n\nhttps://github.com/openstack/nova/blob/8e0b98f54ec382fbebc2fcd83f4b951a3cc40c33/nova/compute/manager.py#L4257", 
            "date_created": "2016-08-08 17:37:55.696667+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "So a few issues:\n\n1. Tempest should probably wait for the instance to be in shelved or shelved_offloaded state before it does the unshelve.\n\n2. https://review.openstack.org/#/c/332243/ actually exposes a race where the instance goes to shelved_offloaded state before the instance.host is nulled out, so even with #1 we'd have a race window.\n\n3. The shelve_instance method in the compute manager should probably have a semaphore lock on the instance.uuid like unshelve_instance does. That would at least prevent a race between shelve_offload_instance and unshelve updating the instance.host out of order.", 
            "date_created": "2016-08-08 17:43:30.554702+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "I guess we can't do #2 because the resource tracker actually makes decisions based on the instance.vm_state:\n\nhttps://github.com/openstack/nova/blob/8e0b98f54ec382fbebc2fcd83f4b951a3cc40c33/nova/compute/resource_tracker.py#L840\n\nALLOW_RESOURCE_REMOVAL = [DELETED, SHELVED_OFFLOADED]\n\nSo we have to set the vm_state before calling the resource tracker which has to happen before nulling out the instance.host and instance.node values.\n\nI'll add the semaphore to shelve_instance in the compute manager though, that should fix this race.", 
            "date_created": "2016-08-08 17:47:55.735094+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/352554", 
            "date_created": "2016-08-08 18:42:53.910570+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/352556", 
            "date_created": "2016-08-08 18:49:56.609261+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/352554\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=e285eb1a382e6d3ce1cc596eeb5cecb3b165a228\nSubmitter: Jenkins\nBranch:    master\n\ncommit e285eb1a382e6d3ce1cc596eeb5cecb3b165a228\nAuthor: Matt Riedemann <email address hidden>\nDate:   Mon Aug 8 14:33:37 2016 -0400\n\n    Run shelve/shelve_offload_instance in a semaphore\n    \n    When an instance is shelved, by default it is immediately\n    offloaded because CONF.shelved_offload_time defaults to 0.\n    \n    When a shelved instance is offloaded, it's destroyed and it's\n    host/node values are nulled out.\n    \n    Unshelving an instance is basically the same flow as building\n    an instance for the first time. The instance.host/node values\n    are set in the resource tracker when claiming resources.\n    \n    Tempest has some tests which use a shared server resource and\n    perform actions on that shared server. These tests are triggering\n    a race when unshelve is called while the compute is offloading\n    the shelved instance. The race hits a window where unshelve is\n    running before shelve_offload_instance nulls out the instance\n    host/node values. The resource claim during unshelve sets the\n    host/node values (which were actually already set) and then\n    shelve_offload_instance nulls them out. The unshelve operation\n    sets the instance.vm_state to ACTIVE, however. So Tempest sees\n    an instance that's ACTIVE and thinks it can run the next action\n    test on it, for example 'suspend'. This fails because the\n    instance.host isn't set (from shelve_offload_instance) and the\n    test fails in the compute API.\n    \n    To close the race window, we add a lock to shelve_instance and\n    shelve_offload_instance to match the lock that's in\n    unshelve_instance. This way when unshelve is called it will\n    wait until the shelve_offload_instance operation is complete\n    and the instance.host value is nulled out.\n    \n    Closes-Bug: #1611008\n    \n    Change-Id: Id36b3b9516d72d28519c18c38d98b646b47d288d\n", 
            "date_created": "2016-08-09 01:20:43.314709+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/352556\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=c1bc4696b3ea6c5317a82e5e5d77dbf1ca0eb923\nSubmitter: Jenkins\nBranch:    master\n\ncommit c1bc4696b3ea6c5317a82e5e5d77dbf1ca0eb923\nAuthor: Matt Riedemann <email address hidden>\nDate:   Mon Aug 8 14:47:56 2016 -0400\n\n    Add some logging and a comment for shelve/unshelve operations\n    \n    Since shelve_instance calls shelve_offload_instance it would\n    be useful to have some logging when we start those operations.\n    Do the same for unshelve since that is currently being called\n    during a Tempest run while shelve_offload_instance is still\n    running.\n    \n    Also add a comment about why we have to set the instance.vm_state\n    before updating the resource tracker in shelve_offload_instance.\n    \n    Change-Id: Ib9c08e4f9becf9500599d20e8f93ac75f2a77b5f\n    Related-Bug: #1611008\n", 
            "date_created": "2016-08-09 10:22:48.608397+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/mitaka\nReview: https://review.openstack.org/352884", 
            "date_created": "2016-08-09 13:01:15.720771+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 14.0.0.0b3 development milestone.", 
            "date_created": "2016-09-02 01:14:54.436973+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/352884\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=c7b2664645d3b30b3a07f546c149fde547f80065\nSubmitter: Jenkins\nBranch:    stable/mitaka\n\ncommit c7b2664645d3b30b3a07f546c149fde547f80065\nAuthor: Matt Riedemann <email address hidden>\nDate:   Mon Aug 8 14:33:37 2016 -0400\n\n    Run shelve/shelve_offload_instance in a semaphore\n    \n    When an instance is shelved, by default it is immediately\n    offloaded because CONF.shelved_offload_time defaults to 0.\n    \n    When a shelved instance is offloaded, it's destroyed and it's\n    host/node values are nulled out.\n    \n    Unshelving an instance is basically the same flow as building\n    an instance for the first time. The instance.host/node values\n    are set in the resource tracker when claiming resources.\n    \n    Tempest has some tests which use a shared server resource and\n    perform actions on that shared server. These tests are triggering\n    a race when unshelve is called while the compute is offloading\n    the shelved instance. The race hits a window where unshelve is\n    running before shelve_offload_instance nulls out the instance\n    host/node values. The resource claim during unshelve sets the\n    host/node values (which were actually already set) and then\n    shelve_offload_instance nulls them out. The unshelve operation\n    sets the instance.vm_state to ACTIVE, however. So Tempest sees\n    an instance that's ACTIVE and thinks it can run the next action\n    test on it, for example 'suspend'. This fails because the\n    instance.host isn't set (from shelve_offload_instance) and the\n    test fails in the compute API.\n    \n    To close the race window, we add a lock to shelve_instance and\n    shelve_offload_instance to match the lock that's in\n    unshelve_instance. This way when unshelve is called it will\n    wait until the shelve_offload_instance operation is complete\n    and the instance.host value is nulled out.\n    \n    Closes-Bug: #1611008\n    \n    Change-Id: Id36b3b9516d72d28519c18c38d98b646b47d288d\n    (cherry picked from commit e285eb1a382e6d3ce1cc596eeb5cecb3b165a228)\n", 
            "date_created": "2016-09-08 14:03:51.951822+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 13.1.2 release.", 
            "date_created": "2016-10-10 13:20:09.931586+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by jichenjc (<email address hidden>) on branch: master\nReview: https://review.openstack.org/352486", 
            "date_created": "2016-10-19 15:55:49.074890+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 13.1.2 release.", 
            "date_created": "2016-11-10 02:06:19.074792+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2016-08-09 01:20:39.690834+00:00"
}