{
    "status": "Opinion", 
    "last_updated": "2015-03-30 13:05:32.917608+00:00", 
    "description": "The conductor is consuming messages form single queue which has performance limitation due to various reasons.:\n- per queue lock\n- Some broker also limiting same part of the message handling to single CPU thread/queue\n- Multiple broker instances needs to synchronise to queue content, which causes additional delays die to the tcp request/response times\n\nThe single queue limitation is much greater than the limits getting by single mysql server, the rate is even worse when you consider slave reads.\n\nThis can be workarounded by explicitly or implicit distributing the rpc calls to multiple different queue.\n\nThe message broker provides additional message durability properties which is not needed just for an rpc_call,\nwe spend resource on what we actually do not need.\n\nFor TCP/HTTP traffic load balancing we have many-many tools even hardware assisted options are available providing virtually unlimited scalability.\nAt TCP level also possible to exclude the loadbalancer node(s) form the response traffic.\n\nWhy HTTP?\nBasically any protocol which can do request/response `thing` with arbitrary  type and size of data with keep-alive connection and with ssl option, could be used.\nHTTP is a simple and well know protocol, with already existing many-many load balancing tool.\n\nWhy not have the agents to do a regular API call?\nThe regular API calls needs to do policy check, which in this case is not required, every authenticated user can be considered as admin.\n\nThe  the conductor clients needs to use at least a single shared key configured in every nova host.\nIt has similar security as openstack used with the brokers, basically all nova node had credentials in one rabbitmq virtual host,\nconfigured in the /etc/nova/nova.conf . If any of those credentials stolen it provided access to the whole virtual host.\n\nNOTE.: HTTPs can be used with certificate or kerberos based authentication as well.\n\nI think the for `rpc_calls` which are served by the agents using something like AMQP is still the better option, this bug is just about the situation when the conductor itself serves  rpc_call(s).\n\nNOTE.: The 1 Million msq/sec rabbitmq benchmark is done 186 queues, in a way which does not hits the single queue limitations.", 
    "tags": [], 
    "importance": "Wishlist", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1438113", 
    "owner": "None", 
    "id": 1438113, 
    "index": 2945, 
    "openned": "2015-03-30 10:15:37.660310+00:00", 
    "created": "2015-03-30 10:15:37.660310+00:00", 
    "title": "Use plain HTTP listeners in the conductor", 
    "comments": [
        {
            "content": "The conductor is consuming messages form single queue which has performance limitation due to various reasons.:\n- per queue lock\n- Some broker also limiting same part of the message handling to single CPU thread/queue\n- Multiple broker instances needs to synchronise to queue content, which causes additional delays die to the tcp request/response times\n\nThe single queue limitation is much greater than the limits getting by single mysql server, the rate is even worse when you consider slave reads. \n\nThis can be workarounded by explicitly or implicit distributing the rpc calls to multiple different queue. \n\nThe message broker provides additional message durability properties which is not needed just for an rpc_call,\nwe spend resource on what we actually do not need.\n\nFor TCP/HTTP traffic load balancing we have many-many tools even hardware assisted options are available providing virtually unlimited scalability.\nAt TCP level also possible to exclude the loadbalancer node(s) form the response traffic.\n\nWhy HTTP?\nBasically any protocol which can do request/response `thing` with arbitrary  type and size of data with keep-alive connection and with ssl option, could be used.\nHTTP is a simple and well know protocol, with already existing many-many load balancing tool.\n\nWhy not have the agents to do a regular API call?\nThe regular API calls needs to do policy check, which in this case is not required, every authenticated user can be considered as admin.  \n\nThe  the conductor clients needs to use at least a single shared key configured in every nova host.\nIt has similar security as openstack used with the brokers, basically all nova node had credentials in one rabbitmq virtual host,\nconfigured in the /etc/nova/nova.conf . If any of those credentials stolen it provided access to the whole virtual host. \n\nNOTE.: HTTPs can be used with certificate or kerberos based authentication as well.\n\n\nI think the for `rpc_calls` which are served by the agents using AMQP is still better option,  this bug is just about the situation when the conductor itself serves  rpc_call(s). \n\nNOTE.: The 1 Million msq/sec rabbitmq benchmark is done 186 queues, in way which does not hits the single queue limitations.", 
            "date_created": "2015-03-30 10:15:37.660310+00:00", 
            "author": "https://api.launchpad.net/1.0/~afazekas"
        }, 
        {
            "content": "This is definitely way beyond a bug, it should be done as a nova-spec", 
            "date_created": "2015-03-30 11:07:19.937200+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }
    ], 
    "closed": "2015-03-30 11:06:50.252856+00:00"
}