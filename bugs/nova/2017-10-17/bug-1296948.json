{
    "status": "Expired", 
    "last_updated": "2015-12-06 04:17:23.407676+00:00", 
    "description": "Some instances are failing to spawn with the following error message: \n\nVMwareDriverException: Cannot complete operation due to concurrent modification by another operation.\n\nIt's possible this is due to a race condition in the VC driver as this does not happen frequently. This was encountered a few times by the Minesweeper CI. Affected builds include:\n\nhttp://208.91.1.172/logs/81905/6\nhttp://208.91.1.172/logs/80220/3\n\nThe Traceback seen in the scheduler log is:\n\nTraceback (most recent call last):\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1306, in _build_instance\n    set_access_ip=set_access_ip)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 394, in decorated_function\n    return function(self, context, *args, **kwargs)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1718, in _spawn\n    LOG.exception(_('Instance failed to spawn'), instance=instance)\n  File \"/opt/stack/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n    six.reraise(self.type_, self.value, self.tb)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1715, in _spawn\n    block_device_info)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 611, in spawn\n    admin_password, network_info, block_device_info)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/vmops.py\", line 593, in spawn\n    root_gb_in_kb, linked_clone)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/volumeops.py\", line 75, in attach_disk_to_vm\n    self._session._wait_for_task(reconfig_task)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 940, in _wait_for_task\n    ret_val = done.wait()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 116, in wait\n    return hubs.get_hub().switch()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 187, in switch\n    return self.greenlet.switch()\nVMwareDriverException: Cannot complete operation due to concurrent modification by another operation.", 
    "tags": [
        "driver", 
        "vmware"
    ], 
    "importance": "Medium", 
    "heat": 8, 
    "link": "https://bugs.launchpad.net/nova/+bug/1296948", 
    "owner": "None", 
    "id": 1296948, 
    "index": 3852, 
    "openned": "2014-03-24 20:55:56.671072+00:00", 
    "created": "2014-03-24 20:55:56.671072+00:00", 
    "title": "VMware: Instance fails to spawn due to 'Concurrent modification by another operation'", 
    "comments": [
        {
            "content": "Some instances are failing to spawn with the following error message: \n\nVMwareDriverException: Cannot complete operation due to concurrent modification by another operation.\n\nIt's possible this is due to a race condition in the VC driver as this does not happen frequently. This was encountered a few times by the Minesweeper CI. Affected builds include:\n\nhttp://208.91.1.172/logs/81905/6\nhttp://208.91.1.172/logs/80220/3\n\nThe Traceback seen in the scheduler log is:\n\nTraceback (most recent call last):\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1306, in _build_instance\n    set_access_ip=set_access_ip)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 394, in decorated_function\n    return function(self, context, *args, **kwargs)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1718, in _spawn\n    LOG.exception(_('Instance failed to spawn'), instance=instance)\n  File \"/opt/stack/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n    six.reraise(self.type_, self.value, self.tb)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 1715, in _spawn\n    block_device_info)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 611, in spawn\n    admin_password, network_info, block_device_info)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/vmops.py\", line 593, in spawn\n    root_gb_in_kb, linked_clone)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/volumeops.py\", line 75, in attach_disk_to_vm\n    self._session._wait_for_task(reconfig_task)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 940, in _wait_for_task\n    ret_val = done.wait()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 116, in wait\n    return hubs.get_hub().switch()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 187, in switch\n    return self.greenlet.switch()\nVMwareDriverException: Cannot complete operation due to concurrent modification by another operation.", 
            "date_created": "2014-03-24 20:55:56.671072+00:00", 
            "author": "https://api.launchpad.net/1.0/~rhsu"
        }, 
        {
            "content": "I also see following traceback in logs:\n\nTraceback (most recent call last):\n  File \"/opt/stack/oslo.messaging/oslo/messaging/rpc/dispatcher.py\", line 133, in _dispatch_and_reply\n    incoming.message))\n  File \"/opt/stack/oslo.messaging/oslo/messaging/rpc/dispatcher.py\", line 176, in _dispatch\n    return self._do_dispatch(endpoint, method, ctxt, args)\n  File \"/opt/stack/oslo.messaging/oslo/messaging/rpc/dispatcher.py\", line 122, in _do_dispatch\n    result = getattr(endpoint, method)(ctxt, **new_args)\n  File \"/opt/stack/nova/nova/exception.py\", line 88, in wrapped\n    payload)\n  File \"/opt/stack/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n    six.reraise(self.type_, self.value, self.tb)\n  File \"/opt/stack/nova/nova/exception.py\", line 71, in wrapped\n    return f(self, context, *args, **kw)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 280, in decorated_function\n    pass\n  File \"/opt/stack/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n    six.reraise(self.type_, self.value, self.tb)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 266, in decorated_function\n    return function(self, context, *args, **kwargs)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 333, in decorated_function\n    function(self, context, *args, **kwargs)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 309, in decorated_function\n    e, sys.exc_info())\n  File \"/opt/stack/nova/nova/openstack/common/excutils.py\", line 68, in __exit__\n    six.reraise(self.type_, self.value, self.tb)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 296, in decorated_function\n    return function(self, context, *args, **kwargs)\n  File \"/opt/stack/nova/nova/compute/manager.py\", line 3764, in shelve_instance\n    self.driver.snapshot(context, instance, image_id, update_task_state)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 645, in snapshot\n    _vmops.snapshot(context, instance, name, update_task_state)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/vmops.py\", line 872, in snapshot\n    self._delete_vm_snapshot(instance, vm_ref, snapshot)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/vmops.py\", line 779, in _delete_vm_snapshot\n    self._session._wait_for_task(delete_snapshot_task)\n  File \"/opt/stack/nova/nova/virt/vmwareapi/driver.py\", line 948, in _wait_for_task\n    ret_val = done.wait()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 116, in wait\n    return hubs.get_hub().switch()\n  File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 187, in switch\n    return self.greenlet.switch()\nVMwareDriverException: A general system error occurred: concurrent access", 
            "date_created": "2014-03-27 02:06:52.239789+00:00", 
            "author": "https://api.launchpad.net/1.0/~syerrapragada"
        }, 
        {
            "content": "I haven't seen this problem for a very long time. Could you point out any recent MS run that has this error?", 
            "date_created": "2015-10-06 07:06:50.671688+00:00", 
            "author": "https://api.launchpad.net/1.0/~rgerganov"
        }, 
        {
            "content": "[Expired for OpenStack Compute (nova) because there has been no activity for 60 days.]", 
            "date_created": "2015-12-06 04:17:20.269598+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ], 
    "closed": "2015-12-06 04:17:20.936583+00:00"
}