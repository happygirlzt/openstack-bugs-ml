{
    "status": "Expired", 
    "last_updated": "2015-09-18 04:17:36.213851+00:00", 
    "description": "tested on Juno with Cell enabled. \n\nThe race condition happens as follows:\n1. send a detach request to an existing VM with a volume; \n2. send an attach request to attach the same volume to the same VM immediately after #1 in another process.\n\nExpected result:\na.  #2 get refused due to #1 is in progress, or\nb. #2 finishes after #1 finished. \n\nHowever race may happen with following sequences:\n\n Req #1 finished physical action of detach >> \n Req #1 finished cinder call (setting volume to available) >>  \n Req #2 came into Nova API and got through the call flow since volume is available now >> \n Req #2 ran faster then Req #1 and updated Nova DB BDMs  with volume info >> \n Req #2 finished and removed the existing volume info in BDMs >> \n now cinder volume status and nova bdm states went mismatched. The volume became inoperable of either attaching or detaching that both operations will be refused.\n\nAlso in our test case, child cell nova db and parent cell nova db went mismatched since Req #2 passed Req#1 when Req#1 is call updating from child cell to parent cell. \n\nThis issue is caused by no guard check against nova bdm table in attach process. The suggested fix is to add a volume id check against nova bdm table in the beginning of the request to guarantee so that for 1 single volume/instance pair, no parallel modification will happen. \n\nThe attachment is a slice of logs show the message disorder triggered in the test case", 
    "tags": [
        "volumes"
    ], 
    "importance": "Undecided", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1457359", 
    "owner": "None", 
    "id": 1457359, 
    "index": 6818, 
    "openned": "2015-05-21 07:34:20.219749+00:00", 
    "created": "2015-05-21 07:34:20.219749+00:00", 
    "title": "race condition in quick detach/attach to the same volume and vm", 
    "comments": [
        {
            "content": "tested on Juno with Cell enabled. \n\nThe race condition happens as follows:\n1. send a detach request to an existing VM with a volume; \n2. send an attach request to attach the same volume to the same VM immediately after #1 in another process.\n\nExpected result:\na.  #2 get refused due to #1 is in progress, or\nb. #2 finishes after #1 finished. \n\nHowever race may happen with following sequences:\n\n Req #1 finished physical action of detach >> \n Req #1 finished cinder call (setting volume to available) >>  \n Req #2 came into Nova API and got through the call flow since volume is available now >> \n Req #2 ran faster then Req #1 and updated Nova DB BDMs  with volume info >> \n Req #2 finished and removed the existing volume info in BDMs >> \n now cinder volume status and nova bdm states went mismatched. The volume became inoperable of either attaching or detaching that both operations will be refused.\n\nAlso in our test case, child cell nova db and parent cell nova db went mismatched since Req #2 passed Req#1 when Req#1 is call updating from child cell to parent cell. \n\nThis issue is caused by no guard check against nova bdm table in attach process. The suggested fix is to add a volume id check against nova bdm table in the beginning of the request to guarantee so that for 1 single volume/instance pair, no parallel modification will happen. \n\nThe attachment is a slice of logs show the message disorder triggered in the test case", 
            "date_created": "2015-05-21 07:34:20.219749+00:00", 
            "author": "https://api.launchpad.net/1.0/~huangxiwei"
        }, 
        {
            "content": "", 
            "date_created": "2015-05-21 07:34:20.219749+00:00", 
            "author": "https://api.launchpad.net/1.0/~huangxiwei"
        }, 
        {
            "content": "@Chung Chih, Hung (lyanchih) :\n\nSince you are set as assignee, I switch the status to \"In Progress\".", 
            "date_created": "2015-06-24 15:26:06.836609+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "This bug looks like it was fixed at following review\nhttps://review.openstack.org/#/c/88416/\nPlease offer your nova branch sum", 
            "date_created": "2015-06-29 10:04:05.410223+00:00", 
            "author": "https://api.launchpad.net/1.0/~lyanchih"
        }, 
        {
            "content": "[Expired for OpenStack Compute (nova) because there has been no activity for 60 days.]", 
            "date_created": "2015-09-18 04:17:33.740333+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ], 
    "closed": "2015-09-18 04:17:34.311520+00:00"
}