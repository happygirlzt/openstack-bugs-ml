{
    "status": "Expired", 
    "last_updated": "2017-08-23 04:17:48.301396+00:00", 
    "description": "If Nova tries to check resources on newly added ironic hypervisor during instance spawning, where resources are not updated yet, instance build failed with the following error:\n\nhttp://paste.openstack.org/show/493321/\nhttp://paste.openstack.org/show/493322/\n\nThe following operation is failed, since free_disk_space = None.\n\nself.free_disk_mb = compute.free_disk_gb * 1024\n\nIt was reproduced on Liberty nova code.", 
    "tags": [
        "ironic"
    ], 
    "importance": "Medium", 
    "heat": 18, 
    "link": "https://bugs.launchpad.net/nova/+bug/1567434", 
    "owner": "None", 
    "id": 1567434, 
    "index": 4507, 
    "openned": "2016-04-07 12:55:45.273793+00:00", 
    "created": "2016-04-07 12:55:45.273793+00:00", 
    "title": "new hypervisor should appear with available resources set to 0", 
    "comments": [
        {
            "content": "If nova tries to check resources on newly added ironic hypervisor, where resources are not updated yet.\nInstance build failed with the following error:\n\nhttp://paste.openstack.org/show/493321/\nhttp://paste.openstack.org/show/493322/\n\nThe following operation is failed, since free_disk_space = None.\n\nself.free_disk_mb = compute.free_disk_gb * 1024\n\nIt was reproduced on Liberty nova code.", 
            "date_created": "2016-04-07 12:55:45.273793+00:00", 
            "author": "https://api.launchpad.net/1.0/~vsaienko"
        }, 
        {
            "content": "So, the nova-compute ResourceTracker is updating this field and persisting it in DB (so that the scheduler can get it) in 3 cases :\n - when the ResourceTracker (there is one per node) is initiated\n - everytime a new instance is claimed for that node\n - every 60 secs\n\nWhat is strange is that the scheduler is getting the list of compute nodes when a request comes in, but that list is created by each ResourceTracker, which means that the RT wouldn't run update_available_resources.\n\nCould you please provide us both the nova-compute logs and the nova-scheduler logs at the same time so we could verify if free_disk_gb is set ?", 
            "date_created": "2016-04-08 15:07:39.256439+00:00", 
            "author": "https://api.launchpad.net/1.0/~sylvain-bauza"
        }, 
        {
            "content": "The logs are huge, and can't be added to attach here. I have uploaded the to dropbox. There is the link https://www.dropbox.com/sh/3k1j0ewurizayc4/AADEzGQPpqpP4v83EdOijDwBa?dl=0", 
            "date_created": "2016-04-11 09:50:28.709722+00:00", 
            "author": "https://api.launchpad.net/1.0/~vsaienko"
        }, 
        {
            "content": "Couldn't you just truncate the n-cpu and n-sch logs by the time (within a 5-min time window) you saw the stack trace ?\n\nI don't need a full log, just to get the audit and debug traces at the time the issue is appearing.\n\n\nTBH, I don't really see how you can possibly set a value to None, the code is pretty defensive about that.", 
            "date_created": "2016-04-11 15:57:31.094049+00:00", 
            "author": "https://api.launchpad.net/1.0/~sylvain-bauza"
        }, 
        {
            "content": "From a duplicate bug https://bugs.launchpad.net/nova/+bug/1572472\n\nThere is a timeout issue that I see when running the Cisco Ironic Third party CI:\n\n    Traceback (most recent call last):\n      File \"tempest/test.py\", line 113, in wrapper\n        return f(self, *func_args, **func_kwargs)\n      File \"/opt/stack/ironic/ironic_tempest_plugin/tests/scenario/test_baremetal_basic_ops.py\", line 113, in test_baremetal_server_ops\n        self.boot_instance()\n      File \"/opt/stack/ironic/ironic_tempest_plugin/tests/scenario/baremetal_manager.py\", line 150, in boot_instance\n        self.wait_node(self.instance['id'])\n      File \"/opt/stack/ironic/ironic_tempest_plugin/tests/scenario/baremetal_manager.py\", line 116, in wait_node\n        raise lib_exc.TimeoutException(msg)\n    tempest.lib.exceptions.TimeoutException: Request timed out\n    Details: Timed out waiting to get Ironic node by instance id 0a252cd1-a020-40da-911b-2becd1820306\n\nOn further investigation into the issue I see this error in the n-sch.log, which I expect is leading to the node not being available in nova, so the instance never gets assigned to the Ironic node:\n\n2016-04-20 08:41:02.953 ERROR oslo_messaging.rpc.dispatcher [req-e5ae7418-e311-491e-99b3-86aeaa0b4e3c tempest-BaremetalBasicOps-171486249 tempest-BaremetalBasicOps-1004295680] Exception during message handling: unsupported operand type(s) for *: 'NoneType' and 'int'\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher Traceback (most recent call last):\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 138, in _dispatch_and_reply\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher incoming.message))\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 185, in _dispatch\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher return self._do_dispatch(endpoint, method, ctxt, args)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 127, in _do_dispatch\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher result = func(ctxt, **new_args)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/server.py\", line 150, in inner\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher return func(*args, **kwargs)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/opt/stack/nova/nova/scheduler/manager.py\", line 104, in select_destinations\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher dests = self.driver.select_destinations(ctxt, spec_obj)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/opt/stack/nova/nova/scheduler/filter_scheduler.py\", line 53, in select_destinations\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher selected_hosts = self._schedule(context, spec_obj)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/opt/stack/nova/nova/scheduler/filter_scheduler.py\", line 104, in _schedule\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher hosts = self._get_all_host_states(elevated)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/opt/stack/nova/nova/scheduler/filter_scheduler.py\", line 145, in _get_all_host_states\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher return self.host_manager.get_all_host_states(context)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/opt/stack/nova/nova/scheduler/host_manager.py\", line 574, in get_all_host_states\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher self._get_instance_info(context, compute))\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/opt/stack/nova/nova/scheduler/host_manager.py\", line 180, in update\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher return _locked_update(self, compute, service, aggregates, inst_dict)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/usr/local/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py\", line 271, in inner\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher return f(*args, **kwargs)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/opt/stack/nova/nova/scheduler/host_manager.py\", line 169, in _locked_update\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher self._update_from_compute_node(compute)\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher File \"/opt/stack/nova/nova/scheduler/ironic_host_manager.py\", line 44, in _update_from_compute_node\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher self.free_disk_mb = compute.free_disk_gb * 1024\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher TypeError: unsupported operand type(s) for *: 'NoneType' and 'int'\n2016-04-20 08:41:02.953 TRACE oslo_messaging.rpc.dispatcher\n2016-04-20 08:41:03.478 ERROR oslo_messaging._drivers.common [req-e5ae7418-e311-491e-99b3-86aeaa0b4e3c tempest-BaremetalBasicOps-171486249 tempest-BaremetalBasicOps-1004295680] Returning exception unsupported operand type(s) for *: 'NoneType' and 'int' to caller\n2016-04-20 08:41:03.478 ERROR oslo_messaging._drivers.common [req-e5ae7418-e311-491e-99b3-86aeaa0b4e3c tempest-BaremetalBasicOps-171486249 tempest-BaremetalBasicOps-1004295680] ['Traceback (most recent call last):\\n', ' File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 138, in _dispatch_and_reply\\n incoming.message))\\n', ' File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 185, in _dispatch\\n return self._do_dispatch(endpoint, method, ctxt, args)\\n', ' File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 127, in _do_dispatch\\n result = func(ctxt, **new_args)\\n', ' File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/server.py\", line 150, in inner\\n return func(*args, **kwargs)\\n', ' File \"/opt/stack/nova/nova/scheduler/manager.py\", line 104, in select_destinations\\n dests = self.driver.select_destinations(ctxt, spec_obj)\\n', ' File \"/opt/stack/nova/nova/scheduler/filter_scheduler.py\", line 53, in select_destinations\\n selected_hosts = self._schedule(context, spec_obj)\\n', ' File \"/opt/stack/nova/nova/scheduler/filter_scheduler.py\", line 104, in _schedule\\n hosts = self._get_all_host_states(elevated)\\n', ' File \"/opt/stack/nova/nova/scheduler/filter_scheduler.py\", line 145, in _get_all_host_states\\n return self.host_manager.get_all_host_states(context)\\n', ' File \"/opt/stack/nova/nova/scheduler/host_manager.py\", line 574, in get_all_host_states\\n self._get_instance_info(context, compute))\\n', ' File \"/opt/stack/nova/nova/scheduler/host_manager.py\", line 180, in update\\n return _locked_update(self, compute, service, aggregates, inst_dict)\\n', ' File \"/usr/local/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py\", line 271, in inner\\n return f(*args, **kwargs)\\n', ' File \"/opt/stack/nova/nova/scheduler/host_manager.py\", line 169, in _locked_update\\n self._update_from_compute_node(compute)\\n', ' File \"/opt/stack/nova/nova/scheduler/ironic_host_manager.py\", line 44, in _update_from_compute_node\\n self.free_disk_mb = compute.free_disk_gb * 1024\\n', \"TypeError: unsupported operand type(s) for *: 'NoneType' and 'int'\\n\"]\n\nThis log seems to document the ComputeNode update that's causing this error:\n\n2016-04-20 08:41:02.952 DEBUG nova.scheduler.host_manager [req-e5ae7418-e311-491e-99b3-86aeaa0b4e3c tempest-BaremetalBasicOps-171486249 tempest-BaremetalBasicOps-1004295680] Update host state from compute node: ComputeNode(cpu_allocation_ratio=16.0,cpu_info='',created_at=2016-04-20T08:41:02Z,current_workload=None,deleted=False,deleted_at=None,disk_allocation_ratio=1.0,disk_available_least=0,free_disk_gb=None,free_ram_mb=None,host='ironic-ucsm-ironic-ucsm-provider-33459',host_ip=10.0.199.6,hypervisor_hostname='e5657c2c-f776-4c19-b537-4957376409d9',hypervisor_type='ironic',hypervisor_version=1,id=26,local_gb=0,local_gb_used=0,memory_mb=0,memory_mb_used=0,metrics=None,numa_topology=None,pci_device_pools=None,ram_allocation_ratio=1.0,running_vms=None,service_id=None,stats={cpu_arch='x86'},supported_hv_specs=[],updated_at=None,uuid=b5dc8328-fad6-497d-be3d-4a2d76a27e30,vcpus=0,vcpus_used=0) from (pid=25619) _locked_update /opt/stack/nova/nova/scheduler/host_manager.py:168\n\nAs you can see free_disk_gb is None for some reason... for reference other ComputeNode update calls look like:\n\nUpdate host state from compute node: ComputeNode(cpu_allocation_ratio=16.0,cpu_info='',created_at=2016-04-20T08:41:01Z,current_workload=0,deleted=False,deleted_at=None,disk_allocation_ratio=1.0,disk_available_least=0,free_disk_gb=0,free_ram_mb=0,host='ironic-ucsm-ironic-ucsm-provider-33459',host_ip=10.0.199.6,hypervisor_hostname='82a1afd6-db7c-47bc-b44f-36cc30e46f58',hypervisor_type='ironic',hypervisor_version=1,id=25,local_gb=0,local_gb_used=0,memory_mb=0,memory_mb_used=0,metrics='[]',numa_topology=None,pci_device_pools=PciDevicePoolList,ram_allocation_ratio=1.0,running_vms=0,service_id=None,stats={cpu_arch='x86'},supported_hv_specs=[],updated_at=2016-04-20T08:41:02Z,uuid=dcd97316-8f0c-4363-961e-56ee17ae1953,vcpus=0,vcpus_used=0) from (pid=25619) _locked_update /opt/stack/nova/nova/scheduler/host_manager.py:168\n\nWhich as you can see free_disk_gb is 0, which is how the other node should be also.", 
            "date_created": "2016-04-20 11:15:22.278056+00:00", 
            "author": "https://api.launchpad.net/1.0/~jim-rollenhagen"
        }, 
        {
            "content": "n-cpu.log:\n\n2016-04-20 08:41:02.913 INFO nova.compute.resource_tracker [req-fd249d93-8a71-41cb-881e-734c1edc4911 None None] Final resource view: name=e5657c2c-f776-4c19-b537-4957376409d9 phys_ram=0MB used_ram=0MB phys_disk=0GB used_disk=0GB total_vcpus=0 used_vcpus=0 pci_stats=[]\n2016-04-20 08:41:02.918 DEBUG oslo_messaging._drivers.amqpdriver [req-fd249d93-8a71-41cb-881e-734c1edc4911 None None] CALL msg_id: 14b7af32ef66444da0f5e5118e5f741d exchange 'nova' topic 'conductor' from (pid=9434) _send /usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py:454\n2016-04-20 08:41:03.063 DEBUG oslo_messaging._drivers.amqpdriver [-] CALL msg_id: 5d487f2909f24005ae31cc6632bad181 exchange 'nova' topic 'conductor' from (pid=9434) _send /usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py:454\n2016-04-20 08:41:03.071 DEBUG oslo_messaging._drivers.amqpdriver [-] received reply msg_id: 14b7af32ef66444da0f5e5118e5f741d from (pid=9434) __call__ /usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py:302\n2016-04-20 08:41:03.072 INFO nova.compute.resource_tracker [req-fd249d93-8a71-41cb-881e-734c1edc4911 None None] Compute_service record updated for ironic-ucsm-ironic-ucsm-provider-33459:e5657c2c-f776-4c19-b537-4957376409d9\n\nn-sch.log:\n\n2016-04-20 08:41:02.953 ERROR oslo_messaging.rpc.dispatcher [req-e5ae7418-e311-491e-99b3-86aeaa0b4e3c tempest-BaremetalBasicOps-171486249 tempest-BaremetalBasicOps-1004295680] Exception during message handling: unsupported operand type(s) for *: 'NoneType' and 'int'\n\nBased on comparing the n-sch and n-cpu logs, I can see that the nova scheduler starts dealing with this node, inbetween the the logs from the resource tracker handling this ComputeNode.", 
            "date_created": "2016-04-20 11:39:10.911596+00:00", 
            "author": "https://api.launchpad.net/1.0/~sambetts"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/308348", 
            "date_created": "2016-04-20 14:02:16.170501+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Michael Still (<email address hidden>) on branch: master\nReview: https://review.openstack.org/308348\nReason: This patch has been sitting unchanged for more than 12 weeks. I am therefore going to abandon it to keep the nova review queue sane. Please feel free to restore the change if you're still working on it.", 
            "date_created": "2016-10-27 07:35:02.699665+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Problem just appeared on ironic-multinode CI:\n\nhttp://logs.openstack.org/36/404436/4/check/gate-tempest-dsvm-ironic-ipa-wholedisk-agent_ssh-tinyipa-multinode-nv/d13d19c/logs/screen-n-sch.txt.gz?level=ERROR", 
            "date_created": "2016-12-01 10:11:58.505570+00:00", 
            "author": "https://api.launchpad.net/1.0/~vsaienko"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/413631", 
            "date_created": "2016-12-21 13:42:52.347257+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Vasyl Saienko (<email address hidden>) on branch: master\nReview: https://review.openstack.org/413631", 
            "date_created": "2017-01-07 14:57:31.254805+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "\nThere are no currently open reviews on this bug, changing\nthe status back to the previous state and unassigning. If\nthere are active reviews related to this bug, please include\nlinks in comments.\n", 
            "date_created": "2017-06-23 12:48:50.157828+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "[Expired for OpenStack Compute (nova) because there has been no activity for 60 days.]", 
            "date_created": "2017-08-23 04:17:45.694452+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }
    ], 
    "closed": "2017-08-23 04:17:46.196039+00:00"
}