{
    "status": "Triaged", 
    "last_updated": "2017-08-11 18:37:44.016739+00:00", 
    "description": "The test in on XenServer.\nnova  live-migration <VM>\n\nIf we run the live-migration without the option of \"--block-migrate\", it will failed with error as:\n\u00a0\u00a0\u00a0RemoteError: Remote error: RemoteError Remote error: CantStartEngineError No sql_connection parameter is established\"\n\n- The trace for nova-conductor:\nAug 09 10:12:55 DevStackOSDomU nova-conductor[13365]: line 990, in wrapper\\\\n    with self._transaction_scope(context):\\\\n\\', u\\'  \nFile \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\\\\n    return self.gen.next()\\\\n\\', u\\'  \nFile \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 1040, in _transaction_scope\\\\n    context=context) as resource:\\\\n\\', u\\'  \nFile \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\\\\n    return self.gen.next()\\\\n\\', u\\' \n File \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 645, in _session\\\\n    bind=self.connection, mode=self.mode)\\\\n\\', u\\'  \nFile \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 402, in _create_session\\\\n    self._start()\\\\n\\', u\\'  \nFile \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 496, in _start\\\\n    engine_args, maker_args)\\\\n\\', u\\'  \nFile \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 518, in _setup_for_connection\\\\n    \"No sql_connection parameter is established\")\\\\n\\', u\\'CantStartEngineError: No sql_connection parameter is established\\\\n\\'].\\n'].\n\n\n- The trace from nova-compute:\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 211, in decorated_function\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     kwargs['instance'], e, sys.exc_info())\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     self.force_reraise()\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 199, in decorated_function\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 5253, in check_can_live_migrate_destination\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     disk_over_commit)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 5264, in _do_check_can_live_migrate_destination\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     block_migration, disk_over_commit)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/virt/xenapi/driver.py\", line 465, in check_can_live_migrate_destination\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     disk_over_commit)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 2281, in check_can_live_migrate_destination\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     self._ensure_host_in_aggregate(ctxt, src)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 2203, in _ensure_host_in_aggregate\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     self._get_host_uuid_from_aggregate(context, hostname)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 2189, in _get_host_uuid_from_aggregate\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     aggregate_list = objects.AggregateList.get_by_host(context, CONF.host)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 177, in wrapper\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     args, kwargs)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/conductor/rpcapi.py\", line 240, in object_class_action_versions\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     args=args, kwargs=kwargs)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 169, in call\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     retry=self.retry)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 123, in _send\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     timeout=timeout, retry=retry)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 578, in send\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     retry=retry)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 569, in _send\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     raise result\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server RemoteError: Remote error: CantStartEngineError No sql_connection parameter is established", 
    "tags": [
        "cellsv2", 
        "openstack-version.pike", 
        "xenserver"
    ], 
    "importance": "High", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1709594", 
    "owner": "None", 
    "id": 1709594, 
    "index": 2125, 
    "openned": "2017-08-09 10:40:06.744876+00:00", 
    "created": "2017-08-09 10:40:06.744876+00:00", 
    "title": "xen: live-migration without '--block-migrate' failed with 'No sql_connection parameter is established' (cells v2 aggregate up-call in superconductor mode)", 
    "comments": [
        {
            "content": "The test in on XenServer.\nnova  live-migration <VM>\n\nIf we run the live-migration without the option of \"--block-migrate\", it will failed with error as:\n   RemoteError: Remote error: RemoteError Remote error: CantStartEngineError No sql_connection parameter is established\"\n\n- The trace for nova-conductor:\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager   File \"/opt/stack/nova/nova/conductor/tasks/base.py\", line 42, in execute\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager     return self._execute()\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager   File \"/opt/stack/nova/nova/conductor/tasks/live_migrate.py\", line 56, in _execute\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager     self._check_requested_destination()\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager   File \"/opt/stack/nova/nova/conductor/tasks/live_migrate.py\", line 96, in _check_requested_destination\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager     self._call_livem_checks_on_host(self.destination)\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager   File \"/opt/stack/nova/nova/conductor/tasks/live_migrate.py\", line 147, in _call_livem_checks_on_host\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager     destination, self.block_migration, self.disk_over_commit)\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager   File \"/opt/stack/nova/nova/compute/rpcapi.py\", line 479, in check_can_live_migrate_destination\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager     disk_over_commit=disk_over_commit)\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 169, in call\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager     retry=self.retry)\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 123, in _send\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager     timeout=timeout, retry=retry)\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 578, in send\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager     retry=retry)\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 569, in _send\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager     raise result\nAug 09 03:26:36 DevStackOSDomU nova-conductor[1753]: ERROR nova.conductor.manager RemoteError: Remote error: RemoteError Remote error: CantStartEngineError No sql_connection parameter is established\n\n- The trace from nova-compute:\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 211, in decorated_function\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     kwargs['instance'], e, sys.exc_info())\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     self.force_reraise()\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 199, in decorated_function\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 5253, in check_can_live_migrate_destination\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     disk_over_commit)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 5264, in _do_check_can_live_migrate_destination\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     block_migration, disk_over_commit)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/virt/xenapi/driver.py\", line 465, in check_can_live_migrate_destination\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     disk_over_commit)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 2281, in check_can_live_migrate_destination\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     self._ensure_host_in_aggregate(ctxt, src)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 2203, in _ensure_host_in_aggregate\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     self._get_host_uuid_from_aggregate(context, hostname)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 2189, in _get_host_uuid_from_aggregate\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     aggregate_list = objects.AggregateList.get_by_host(context, CONF.host)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_versionedobjects/base.py\", line 177, in wrapper\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     args, kwargs)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/conductor/rpcapi.py\", line 240, in object_class_action_versions\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     args=args, kwargs=kwargs)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/rpc/client.py\", line 169, in call\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     retry=self.retry)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/transport.py\", line 123, in _send\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     timeout=timeout, retry=retry)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 578, in send\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     retry=retry)\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python2.7/dist-packages/oslo_messaging/_drivers/amqpdriver.py\", line 569, in _send\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server     raise result\nAug 09 03:26:17 DevStackOSDomU nova-compute[1762]: ERROR oslo_messaging.rpc.server RemoteError: Remote error: CantStartEngineError No sql_connection parameter is established", 
            "date_created": "2017-08-09 10:40:06.744876+00:00", 
            "author": "https://api.launchpad.net/1.0/~wjh-fresh"
        }, 
        {
            "content": "I have no idea why the connection is None when trying to query AggregateList:\n  rpc.server aggregate_list = objects.AggregateList.get_by_host(context, CONF.host)\n\nstack@DevStackOSDomU:~/tempest$ nova-manage cell_v2 list_cells\n+-------+--------------------------------------+------------------------------------------------------+-------------------------------------------------------------+\n|  Name |                 UUID                 |                    Transport URL                     |                     Database Connection                     |\n+-------+--------------------------------------+------------------------------------------------------+-------------------------------------------------------------+\n| cell0 | 00000000-0000-0000-0000-000000000000 |                        none:/                        | mysql+pymysql://root:****@127.0.0.1/nova_cell0?charset=utf8 |\n| cell1 | f057988d-91a0-4869-9549-b237d6e17cf6 | rabbit://stackrabbit:****@10.62.34.3:5672/nova_cell1 | mysql+pymysql://root:****@127.0.0.1/nova_cell1?charset=utf8 |\n+-------+--------------------------------------+------------------------------------------------------+-------------------------------------------------------------+\n\n- The data configure in /etc/nova/nova_cell1.conf:\n[database]\nconnection = mysql+pymysql://root:citrix@127.0.0.1/nova_cell1?charset=utf8\n\n- The database configure in /etc/nova/nova.conf:\nconnection = mysql+pymysql://root:citrix@127.0.0.1/nova_cell0?charset=utf8\n\n", 
            "date_created": "2017-08-09 10:52:55.418278+00:00", 
            "author": "https://api.launchpad.net/1.0/~wjh-fresh"
        }, 
        {
            "content": "At line:https://github.com/openstack/oslo.db/blob/master/oslo_db/sqlalchemy/enginefacade.py#L471\nit will load the database section. The connection option loaded is None for the above test. But the configuration in the nova*.conf seems correct. And other attempts connecting database, it can get the correct connection also.", 
            "date_created": "2017-08-09 11:00:02.525915+00:00", 
            "author": "https://api.launchpad.net/1.0/~wjh-fresh"
        }, 
        {
            "content": "Is this a devstack configuration? I'm assuming running in superconductor mode (the default)? That is set on the CELLSV2_SETUP variable in stackrc.\n\nAggregates were migrated to the API database, so do you have the correct settings for the nova_api database connection in nova.conf? That would be the [api_database]/connection field.", 
            "date_created": "2017-08-10 02:09:31.815567+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Matt, thanks for the comments.\n\nYes, this is a devstack configuration and it's running in superconductor mode.\n\nThe database relative settings in nova.conf is:\n\n[database]\nconnection = mysql+pymysql://root:citrix@127.0.0.1/nova_cell0?charset=utf8\n\n[api_database]\nconnection = mysql+pymysql://root:citrix@127.0.0.1/nova_api?charset=utf8\n\nLooks like the settings are correct. Or could you advise what I should check? Thanks for the help.", 
            "date_created": "2017-08-10 05:25:58.116590+00:00", 
            "author": "https://api.launchpad.net/1.0/~wjh-fresh"
        }, 
        {
            "content": "I tried to print the stack in enginefacade.py.\nChecking source code: \n  https://github.com/openstack/oslo.db/blob/master/oslo_db/sqlalchemy/enginefacade.py#L471\n  conf.register_opts(options.database_opts, 'database')\n\nIt seems will try to get the connection from settings database/connection; but not api_database/connection. Is this wrong by considering the Aggregates were migrated to API database?\n\nSee the following stack \n\n  File \"/opt/stack/nova/nova/objects/aggregate.py\", line 541, in get_by_host\n    _get_by_host_from_db(context, host, key=key)]\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 992, in wrapper\n    with self._transaction_scope(context):\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n    return self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 1042, in _transaction_scope\n    context=context) as resource:\n  File \"/usr/lib/python2.7/contextlib.py\", line 17, in __enter__\n    return self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 647, in _session\n    bind=self.connection, mode=self.mode)\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 402, in _create_session\n    self._start()\n  File \"/usr/local/lib/python2.7/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 477, in _start\n    traceback.print_stack(file=f)\nconf is not None: conf=<oslo_config.cfg.ConfigOpts object at 0x7f279c064950>\n\nurl_args={'connection': None, 'slave_connection': None}\n", 
            "date_created": "2017-08-10 05:36:06.120236+00:00", 
            "author": "https://api.launchpad.net/1.0/~wjh-fresh"
        }, 
        {
            "content": "That's your nova.conf, but what about the nova-cpu.conf? That's not going to have the [api_database]/connection set, and that's probably your issue. The AggregateList.get_by_host code is looking up aggregates in the API database, and there is no connection set in the context for that, it's an up-call from the compute service, which is running isolated in the cell, to the API DB, and that's blocked in super-conductor mode.\n\ne.g. http://logs.openstack.org/42/492242/1/check/gate-tempest-dsvm-neutron-multinode-full-ubuntu-xenial-nv/cfb2cad/logs/subnode-2/etc/nova/nova-cpu.conf.txt.gz\n\nThere is no database connection in there. The compute service is talking to the local cell conductor, which is using nova_cell1.conf:\n\nhttp://logs.openstack.org/42/492242/1/check/gate-tempest-dsvm-neutron-multinode-full-ubuntu-xenial-nv/cfb2cad/logs/etc/nova/nova_cell1.conf.txt.gz\n\nWhich only has access to the cell database, not the API database.\n\nThe up-call limitations are described here:\n\nhttps://docs.openstack.org/nova/latest/user/cellsv2_layout.html#operations-requiring-upcalls\n\nSo to workaround this in devstack, set CELLSV2_SETUP=singleconductor in your local.conf.", 
            "date_created": "2017-08-10 15:26:45.133806+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Matt thanks for your analysis and suggestions. It works well if we put the api_database in /etc/nova/nova_cell1.conf to allow local conductor accessing API database.", 
            "date_created": "2017-08-11 11:44:02.318155+00:00", 
            "author": "https://api.launchpad.net/1.0/~wjh-fresh"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/493006", 
            "date_created": "2017-08-11 13:25:46.038265+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "> Matt thanks for your analysis and suggestions. It works well if we put the api_database in /etc/nova/nova_cell1.conf to allow local conductor accessing API database.\n\nThat defeats the purpose of running in superconductor mode, so you might as well run devstack in singleconductor mode as I pointed out. The point of superconductor mode is that the cell is isolated from the top-level API database. See:\n\nhttps://docs.openstack.org/nova/latest/user/cellsv2_layout.html", 
            "date_created": "2017-08-11 13:47:22.515353+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/493006\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=904c4a1d9ac25119bb3100a349e19fef8d318527\nSubmitter: Jenkins\nBranch:    master\n\ncommit 904c4a1d9ac25119bb3100a349e19fef8d318527\nAuthor: Matt Riedemann <email address hidden>\nDate:   Fri Aug 11 09:05:14 2017 -0400\n\n    doc: add another up-call caveat for cells v2 for xenapi aggregates\n    \n    There is an up-call from the xenapi driver when performing a live\n    migration and --block-migrate is not specified such that the driver\n    checks to see if the source and destination hosts are in the same\n    aggregate. This fails in a super-conductor setup because the\n    aggregates are now in the API database and the cell conductor\n    won't be able to access that database by design.\n    \n    Change-Id: I6c880c72d87eb0116cb57371e5d600dced2915f7\n    Related-Bug: #1709594\n", 
            "date_created": "2017-08-11 15:49:40.859985+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Was there a reason that we needed this change?\n\nI85047d44e388c89938f80ad8be1724bd11ed0225\n\nIn other words, why don't the other virt drivers have this same change to auto-detect if block migration should be performed during live migration?", 
            "date_created": "2017-08-11 16:00:25.153879+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Matt,\n Understood. It works well after switching to singleconductor mode.\n R.g.t. I85047d44e388c89938f80ad8be1724bd11ed0225\n Live migration without block migration requires the source and destination hosts are on the same shared storage. For xenapi driver, the implement in the above commit is to check the shared storage basing on aggregate.\n See the spec: https://specs.openstack.org/openstack/nova-specs/specs/mitaka/implemented/making_live_migration_api_friendly.html#the-detection-of-block-migration\n\n Instead of querying the api database, I think we can using the xenapi API to determine if the hosts are in the same host pool.\n", 
            "date_created": "2017-08-11 18:37:43.432196+00:00", 
            "author": "https://api.launchpad.net/1.0/~wjh-fresh"
        }
    ]
}