{
    "status": "Confirmed", 
    "last_updated": "2017-06-23 12:40:56.044018+00:00", 
    "description": "It appears that if nova-api receives simultaneous requests to add a server to a host aggregate, then a race occurs that can lead to nova-scheduler having incorrect aggregate information in memory.\n\nOne observed effect of this is that sometimes nova-scheduler will think a smaller number of hosts are a member of the aggregate than is in the nova database and will filter out a host that should not be filtered.\n\nRestarting nova-scheduler fixes the issue, as it reloads the aggregate information on startup.\n\nNova package versions: 1:2015.1.2-0ubuntu2~cloud0\n\nReproduce steps:\n\nCreate a new os-aggregate and then populate an os-aggregate with simultaneous API POSTs, note timestamps:\n\n2016-02-04 20:17:08.538 13648 INFO nova.osapi_compute.wsgi.server [req-d07a006e-134a-46d8-9815-6becec5b185c 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.3 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates HTTP/1.1\" status: 200 len: 439 time: 0.1865470\n2016-02-04 20:17:09.204 13648 INFO nova.osapi_compute.wsgi.server [req-a0402297-9337-46d6-96d2-066e230e45e1 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.2 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates/1/action HTTP/1.1\" status: 200 len: 506 time: 0.2995598\n2016-02-04 20:17:09.243 13648 INFO nova.osapi_compute.wsgi.server [req-0f543525-c34e-418a-91a9-894d714ee95b 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.2 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates/1/action HTTP/1.1\" status: 200 len: 519 time: 0.3140590\n2016-02-04 20:17:09.273 13649 INFO nova.osapi_compute.wsgi.server [req-2f8d80b0-726f-4126-a8ab-a2eae3f1a385 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.2 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates/1/action HTTP/1.1\" status: 200 len: 506 time: 0.3759601\n2016-02-04 20:17:09.275 13649 INFO nova.osapi_compute.wsgi.server [req-80ab6c86-e521-4bf0-ab67-4de9d0eccdd3 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.1 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates/1/action HTTP/1.1\" status: 200 len: 506 time: 0.3433032\n\nSchedule a VM\n\nExpected Result:\nnova-scheduler Availability Zone filter returns all members of the aggregate\n\nActual Result:\nnova-scheduler believes there is only one hypervisor in the aggregate. The number will vary as it is a race:\n\n2016-02-05 07:48:04.411 13600 DEBUG nova.filters [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Starting with 4 host(s) get_filtered_objects /usr/lib/python2.7/dist-packages/nova/filters.py:70\n2016-02-05 07:48:04.411 13600 DEBUG nova.filters [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Filter RetryFilter returned 4 host(s) get_filtered_objects /usr/lib/python2.7/dist-packages/nova/filters.py:84\n2016-02-05 07:48:04.412 13600 DEBUG nova.scheduler.filters.availability_zone_filter [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Availability Zone 'temp' requested. (oshv0, oshv0) ram:122691 disk:13404160 io_ops:0 instances:0 has AZs: nova host_passes /usr/lib/python2.7/dist-packages/nova/scheduler/filters/availability_zone_filter.py:62\n2016-02-05 07:48:04.412 13600 DEBUG nova.scheduler.filters.availability_zone_filter [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Availability Zone 'temp' requested. (oshv2, oshv2) ram:122691 disk:13403136 io_ops:0 instances:0 has AZs: nova host_passes /usr/lib/python2.7/dist-packages/nova/scheduler/filters/availability_zone_filter.py:62\n2016-02-05 07:48:04.413 13600 DEBUG nova.scheduler.filters.availability_zone_filter [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Availability Zone 'temp' requested. (oshv1, oshv1) ram:122691 disk:13404160 io_ops:0 instances:0 has AZs: nova host_passes /usr/lib/python2.7/dist-packages/nova/scheduler/filters/availability_zone_filter.py:62\n2016-02-05 07:48:04.413 13600 DEBUG nova.filters [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Filter AvailabilityZoneFilter returned 1 host(s) get_filtered_objects /usr/lib/python2.7/dist-packages/nova/filters.py:84\n\nNova API calls show the correct number of members.\n\n\nI suspect that it is caused by the simultaneous processing or out-of-order receipt of update_aggregates RPC calls.", 
    "tags": [
        "scheduler"
    ], 
    "importance": "Undecided", 
    "heat": 10, 
    "link": "https://bugs.launchpad.net/nova/+bug/1542491", 
    "owner": "None", 
    "id": 1542491, 
    "index": 7293, 
    "openned": "2016-02-05 21:30:29.544169+00:00", 
    "created": "2016-02-05 21:30:29.544169+00:00", 
    "title": "Scheduler update_aggregates race causes incorrect aggregate information", 
    "comments": [
        {
            "content": "It appears that if nova-api receives simultaneous requests to add a server to a host aggregate, then a race occurs that can lead to nova-scheduler having incorrect aggregate information in memory.\n\nOne observed effect of this is that sometimes nova-scheduler will think a smaller number of hosts are a member of the aggregate than is in the nova database and will filter out a host that should not be filtered.\n\nRestarting nova-scheduler fixes the issue, as it reloads the aggregate information on startup.\n\nNova package versions: 1:2015.1.2-0ubuntu2~cloud0\n\nReproduce steps:\n\nCreate a new os-aggregate and then populate an os-aggregate with simultaneous API POSTs, note timestamps:\n\n2016-02-04 20:17:08.538 13648 INFO nova.osapi_compute.wsgi.server [req-d07a006e-134a-46d8-9815-6becec5b185c 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.3 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates HTTP/1.1\" status: 200 len: 439 time: 0.1865470\n2016-02-04 20:17:09.204 13648 INFO nova.osapi_compute.wsgi.server [req-a0402297-9337-46d6-96d2-066e230e45e1 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.2 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates/1/action HTTP/1.1\" status: 200 len: 506 time: 0.2995598\n2016-02-04 20:17:09.243 13648 INFO nova.osapi_compute.wsgi.server [req-0f543525-c34e-418a-91a9-894d714ee95b 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.2 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates/1/action HTTP/1.1\" status: 200 len: 519 time: 0.3140590\n2016-02-04 20:17:09.273 13649 INFO nova.osapi_compute.wsgi.server [req-2f8d80b0-726f-4126-a8ab-a2eae3f1a385 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.2 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates/1/action HTTP/1.1\" status: 200 len: 506 time: 0.3759601\n2016-02-04 20:17:09.275 13649 INFO nova.osapi_compute.wsgi.server [req-80ab6c86-e521-4bf0-ab67-4de9d0eccdd3 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] 10.120.13.1 \"POST /v2.1/326d453c2bd440b4a7160489b632d0a8/os-aggregates/1/action HTTP/1.1\" status: 200 len: 506 time: 0.3433032\n\nSchedule a VM\n\nExpected Result:\nnova-scheduler Availability Zone filter returns all members of the aggregate\n\nActual Result:\nnova-scheduler believes there is only one hypervisor in the aggregate. The number will vary as it is a race:\n\n2016-02-05 07:48:04.411 13600 DEBUG nova.filters [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Starting with 4 host(s) get_filtered_objects /usr/lib/python2.7/dist-packages/nova/filters.py:70\n2016-02-05 07:48:04.411 13600 DEBUG nova.filters [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Filter RetryFilter returned 4 host(s) get_filtered_objects /usr/lib/python2.7/dist-packages/nova/filters.py:84\n2016-02-05 07:48:04.412 13600 DEBUG nova.scheduler.filters.availability_zone_filter [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Availability Zone 'temp' requested. (oshv0, oshv0) ram:122691 disk:13404160 io_ops:0 instances:0 has AZs: nova host_passes /usr/lib/python2.7/dist-packages/nova/scheduler/filters/availability_zone_filter.py:62\n2016-02-05 07:48:04.412 13600 DEBUG nova.scheduler.filters.availability_zone_filter [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Availability Zone 'temp' requested. (oshv2, oshv2) ram:122691 disk:13403136 io_ops:0 instances:0 has AZs: nova host_passes /usr/lib/python2.7/dist-packages/nova/scheduler/filters/availability_zone_filter.py:62\n2016-02-05 07:48:04.413 13600 DEBUG nova.scheduler.filters.availability_zone_filter [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Availability Zone 'temp' requested. (oshv1, oshv1) ram:122691 disk:13404160 io_ops:0 instances:0 has AZs: nova host_passes /usr/lib/python2.7/dist-packages/nova/scheduler/filters/availability_zone_filter.py:62\n2016-02-05 07:48:04.413 13600 DEBUG nova.filters [req-c24338b5-a3b8-4864-8140-04ea6fbcf68f 41812fc01c6549ac8ed15c6dab05c670 326d453c2bd440b4a7160489b632d0a8 - - -] Filter AvailabilityZoneFilter returned 1 host(s) get_filtered_objects /usr/lib/python2.7/dist-packages/nova/filters.py:84\n\nNova API calls show the correct number of members.\n\n\nI suspect that it is caused by the simultaneous processing or out-of-order receipt of update_aggregates RPC calls.", 
            "date_created": "2016-02-05 21:30:29.544169+00:00", 
            "author": "https://api.launchpad.net/1.0/~jtmes"
        }, 
        {
            "content": "Could you please tell us which Nova version is corresponding to the Ubuntu package 1:2015.1.2-0ubuntu2~cloud0 ?\n\nAlso, could you please tell us if another request coming in would get the accurate number of hosts within the Aggregate ? In general, you don't need to restart the scheduler service, because updates are RPC'd (fanout) to the scheduler which should get the update anyway.\n\n", 
            "date_created": "2016-02-16 10:27:01.833088+00:00", 
            "author": "https://api.launchpad.net/1.0/~sylvain-bauza"
        }, 
        {
            "content": "It's nova version 2015.1.2 \n\nAll requests to create a VM are scheduled using the wrong aggregate members until nova-scheduler is restarted. \n\nMy understanding is that the scheduler only receives an update via RPC when an aggregate's members change. Therefore if no further changes are made it will continue to use the incorrect aggregate members.", 
            "date_created": "2016-02-16 19:44:21.615420+00:00", 
            "author": "https://api.launchpad.net/1.0/~jtmes"
        }, 
        {
            "content": "@James Dennis (jtmes) \nI believe your understanding on #2 is correct.\n\nThe root cause for this issue is that the  aggregate's operation sequence on DB may not exactly as same as on scheduler.\n\nfor example:\noperation on DB:\n1. add host\n2. del host\n\nhowever, on scheduler, if the operation's sequence  reversed as:\n1. del host\n2. add host \n\nit will case the DB/scheduler outer-sync.\n", 
            "date_created": "2016-02-23 08:52:48.295554+00:00", 
            "author": "https://api.launchpad.net/1.0/~yuntongjin"
        }, 
        {
            "content": "propose solution:\npass DB operation timestamp to scheduler, set it as scheduler update timestamp, if the timestamps of a new update is older than scheduler update timestamp, drop this update.\n", 
            "date_created": "2016-02-25 06:34:49.962807+00:00", 
            "author": "https://api.launchpad.net/1.0/~yuntongjin"
        }, 
        {
            "content": "Timestamps do have the benefit of being simple to implement, but also have some flaws:\n\n1. Relying on the standard system clock means they aren't monotonic, i.e. if the clock is adjusted backwards no updates may be accepted by nova-scheduler\n2. If you have nova-api running on two different hosts it requires the hosts times to be synchronized or updates could be lost\n3. Very unlikely with microsecond precision but two updates could have the same identifier.\n\nWhile more complex, and requiring a database change, an integer that is updated by nova-api in the database, and sent every time with the scheduler message would avoid the above problems. The use of the database would guarantee monotonic increase for every update, and also the durability of the value across nova-api restarts. Without durability some notification to nova-scheduler that it needs to reset its expected sequence number would be needed.\n\nIt would probably make sense to make this sequence number larger in scope than just host aggregation changes so that it can be reused for other future scheduler messages.", 
            "date_created": "2016-02-28 09:40:01.924960+00:00", 
            "author": "https://api.launchpad.net/1.0/~jtmes"
        }, 
        {
            "content": "your considering make lots of sense, and they are common issues in distributed system, \nOpenStack use timestamp update method all over the codes like:  \nhttps://github.com/openstack/nova/blob/master/nova/scheduler/host_manager.py#L185\nfor your considering:\n#1, synchronized timing is a basic assumption in  distributed system like OS, even it make system prone to going wrong.\n#2, timestamp is from DB operation, as long as mutli nova-api service operate to same single DB, this won't be a problem.\n#3, very helpful heads up, the logic will be updating cache as long as DB timestamps = cache timestamps.", 
            "date_created": "2016-02-29 06:24:45.038016+00:00", 
            "author": "https://api.launchpad.net/1.0/~yuntongjin"
        }, 
        {
            "content": "Is it correct that the example use of a timestamp is for a message that will only be sent by one agent, i.e. the nova-compute instance? If so then I don't think it is a comparable scenario.\n\n#1 I agree that typically synchronized timing is expected, but I wouldn't expect timing to be used as the basis of versioning data that can be updated at high frequency as it can be non-deterministic due to clock jitter etc.\n#2 I missed the detail of a DB-derived timestamp, which means there is a \"master lock\". I have not tested this but use of MariaDB Galera Cluster might return the timestamp of whatever node executes the query?\n\nI am not familiar with the nova code; if the use of timestamps is prevalent in this scenario then this particular bug is unlikely to be severe enough to warrant a change in approach. ", 
            "date_created": "2016-02-29 08:16:06.035374+00:00", 
            "author": "https://api.launchpad.net/1.0/~jtmes"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/289207", 
            "date_created": "2016-03-07 07:55:12.398514+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Change abandoned by Michael Still (<email address hidden>) on branch: master\nReview: https://review.openstack.org/289207\nReason: This patch is quite old, so I am abandoning it to keep the review queue manageable. Feel free to restore the change if you're still interested in working on it.", 
            "date_created": "2016-08-25 13:31:19.229829+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "\nThere are no currently open reviews on this bug, changing\nthe status back to the previous state and unassigning. If\nthere are active reviews related to this bug, please include\nlinks in comments.\n", 
            "date_created": "2017-06-23 12:40:49.941519+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }
    ]
}