{
    "status": "Fix Released", 
    "last_updated": "2017-06-08 21:52:02.912546+00:00", 
    "description": "Noticed this in the nova-scheduler logs during a failed test run today:\n\nhttp://logs.openstack.org/16/453916/4/check/gate-tempest-dsvm-py35-ubuntu-xenial/09850e6/logs/screen-n-sch.txt.gz?level=TRACE#_2017-04-06_23_11_45_834\n\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server [req-36e4db2a-38e1-4810-9309-8893598e195a - -] Exception during message handling\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server Traceback (most recent call last):\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_messaging/rpc/server.py\", line 157, in _process_incoming\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 213, in dispatch\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 183, in _do_dispatch\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/scheduler/manager.py\", line 125, in update_instance_info\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     instance_info)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_concurrency/lockutils.py\", line 271, in inner\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/scheduler/host_manager.py\", line 774, in update_instance_info\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     self._recreate_instance_info(context, host_name)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/scheduler/host_manager.py\", line 745, in _recreate_instance_info\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     inst_dict = self._get_instances_by_host(context, host_name)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/scheduler/host_manager.py\", line 717, in _get_instances_by_host\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     hm = objects.HostMapping.get_by_host(context, host_name)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_versionedobjects/base.py\", line 184, in wrapper\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     result = fn(cls, context, *args, **kwargs)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/host_mapping.py\", line 100, in get_by_host\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     db_mapping = cls._get_by_host_from_db(context, host)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 963, in wrapper\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     return fn(*args, **kwargs)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/host_mapping.py\", line 95, in _get_by_host_from_db\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     raise exception.HostMappingNotFound(name=host)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server nova.exception.HostMappingNotFound: Host 'ubuntu-xenial-internap-mtl01-8316357' is not mapped to any cell\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server \n\nThis is most likely a side effect of this change: https://review.openstack.org/#/c/439891/\n\nThis could be a race on startup where the compute node is sending it's instance information to the scheduler before the compute host is mapped to a cell, in which case it wouldn't have any instances to send so the scheduler will try to look them up from the database and blow up because the host isn't mapped yet.\n\nI see from the log:\n\nTotal number of compute nodes: 0 _async_init_instance_info /opt/stack/new/nova/nova/scheduler/host_manager.py:439\n\nAdding 0 instances for hosts 10-20 _async_init_instance_info /opt/stack/new/nova/nova/scheduler/host_manager.py:459\n\nIt's definitely happening on startup.", 
    "tags": [
        "cells", 
        "scheduler"
    ], 
    "importance": "Medium", 
    "heat": 18, 
    "link": "https://bugs.launchpad.net/nova/+bug/1680661", 
    "owner": "https://api.launchpad.net/1.0/~mriedem", 
    "id": 1680661, 
    "index": 4792, 
    "openned": "2017-04-07 01:56:45.274545+00:00", 
    "created": "2017-04-07 01:56:45.274545+00:00", 
    "title": "HostMappingNotFound during update_instance_info on n-cpu startup", 
    "comments": [
        {
            "content": "Noticed this in the nova-scheduler logs during a failed test run today:\n\nhttp://logs.openstack.org/16/453916/4/check/gate-tempest-dsvm-py35-ubuntu-xenial/09850e6/logs/screen-n-sch.txt.gz?level=TRACE#_2017-04-06_23_11_45_834\n\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server [req-36e4db2a-38e1-4810-9309-8893598e195a - -] Exception during message handling\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server Traceback (most recent call last):\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_messaging/rpc/server.py\", line 157, in _process_incoming\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 213, in dispatch\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_messaging/rpc/dispatcher.py\", line 183, in _do_dispatch\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/scheduler/manager.py\", line 125, in update_instance_info\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     instance_info)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_concurrency/lockutils.py\", line 271, in inner\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     return f(*args, **kwargs)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/scheduler/host_manager.py\", line 774, in update_instance_info\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     self._recreate_instance_info(context, host_name)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/scheduler/host_manager.py\", line 745, in _recreate_instance_info\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     inst_dict = self._get_instances_by_host(context, host_name)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/scheduler/host_manager.py\", line 717, in _get_instances_by_host\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     hm = objects.HostMapping.get_by_host(context, host_name)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_versionedobjects/base.py\", line 184, in wrapper\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     result = fn(cls, context, *args, **kwargs)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/host_mapping.py\", line 100, in get_by_host\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     db_mapping = cls._get_by_host_from_db(context, host)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/usr/local/lib/python3.5/dist-packages/oslo_db/sqlalchemy/enginefacade.py\", line 963, in wrapper\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     return fn(*args, **kwargs)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server   File \"/opt/stack/new/nova/nova/objects/host_mapping.py\", line 95, in _get_by_host_from_db\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server     raise exception.HostMappingNotFound(name=host)\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server nova.exception.HostMappingNotFound: Host 'ubuntu-xenial-internap-mtl01-8316357' is not mapped to any cell\n2017-04-06 23:11:45.834 24111 ERROR oslo_messaging.rpc.server \n\nThis is most likely a side effect of this change: https://review.openstack.org/#/c/439891/\n\nThis could be a race on startup where the compute node is sending it's instance information to the scheduler before the compute host is mapped to a cell, in which case it wouldn't have any instances to send so the scheduler will try to look them up from the database and blow up because the host isn't mapped yet.\n\nI see from the log:\n\nTotal number of compute nodes: 0 _async_init_instance_info /opt/stack/new/nova/nova/scheduler/host_manager.py:439\n\nAdding 0 instances for hosts 10-20 _async_init_instance_info /opt/stack/new/nova/nova/scheduler/host_manager.py:459\n\nIt's definitely happening on startup.", 
            "date_created": "2017-04-07 01:56:45.274545+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/454426", 
            "date_created": "2017-04-07 02:12:38.689605+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/454426\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=aa943499128ba77b062dff75ec9b48e54f7d5021\nSubmitter: Jenkins\nBranch:    master\n\ncommit aa943499128ba77b062dff75ec9b48e54f7d5021\nAuthor: Matt Riedemann <email address hidden>\nDate:   Thu Apr 6 22:08:52 2017 -0400\n\n    Handle new hosts for updating instance info in scheduler\n    \n    As of change 791cf0643401f72ce834e580938057e325945169 we have\n    to go through host and cell mappings to get to a cell database\n    for host (compute node) and instance information.\n    \n    When a new compute service starts up it casts to update_instance_info\n    and sends an empty list, which triggers the scheduler to try and\n    lookup all instances on that host. If the new compute host is not\n    yet mapped in a cell, we'll get a HostMappingNotFound error.\n    \n    We can handle this case in both the HostManager and ComputeManager\n    by not casting from the compute if there is no information to send,\n    and we can also handle it in the HostManager (for older computes)\n    but just dealing with the HostMappingNotFound gracefully.\n    \n    This information eventually self-heals via normal operation.\n    \n    Change-Id: I7cec2eff35c0615534fcb4d5148f75721824172e\n    Closes-Bug: #1680661\n", 
            "date_created": "2017-06-03 00:57:44.967061+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 16.0.0.0b2 development milestone.", 
            "date_created": "2017-06-08 21:52:02.606094+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2017-06-03 00:57:41.287092+00:00"
}