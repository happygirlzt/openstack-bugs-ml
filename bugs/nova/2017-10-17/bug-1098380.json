{
    "status": "Fix Released", 
    "last_updated": "2013-04-04 11:16:01.811994+00:00", 
    "description": "Environment: devstack  stable/folsom\n\nQuotas adjusted to 2VMs, 4 Cores.\n\n\nWhen I run the following script, the quotas start reporting resources in_use when no VMs are running.\n\n#!/bin/bash\nfor i in {1..20}\ndo\n  euca-run-instances -n 2 -t m1.tiny ami-00000001\n  sleep 2\n  for i in `euca-describe-instances | grep i- | awk '{print $2}'`; do euca-terminate-instances $i; done\ndone\n\n\n\n\n$ ./burn.sh                                                                                                                                                                              [53/357]\nRESERVATION     r-d5cfxois      2e4aa23119dd4f86ad810675885ae4a2        default\nINSTANCE        i-0000002e      ami-00000001    server-537fb7fe-9e96-42e8-9083-4bb2c36fbdb9     server-537fb7fe-9e96-42e8-9083-4bb2c36fbdb9     pending         0               m1.tiny 2013-01-11T00:34:50.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-0000002f      ami-00000001    server-4c8d1518-b269-4a50-b15e-a31034e93352     server-4c8d1518-b269-4a50-b15e-a31034e93352     pending         0               m1.tiny 2013-01-11T00:34:50.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nRESERVATION     r-861rhb54      2e4aa23119dd4f86ad810675885ae4a2        default\nINSTANCE        i-00000030      ami-00000001    server-6454449d-4207-4ca2-a95d-03ac6c07f480     server-6454449d-4207-4ca2-a95d-03ac6c07f480     pending         0               m1.tiny 2013-01-11T00:34:54.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-00000031      ami-00000001    server-70a5d87d-739c-40df-b5b9-4afe703710ae     server-70a5d87d-739c-40df-b5b9-4afe703710ae     pending         0               m1.tiny 2013-01-11T00:34:54.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nTooManyInstances: Quota exceeded for cores,instances: Requested 2, but already used 3 of 4 cores\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nTooManyInstances: Quota exceeded for instances: Requested 2, but already used 2 of 2 instances\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nRESERVATION     r-akz712u9      2e4aa23119dd4f86ad810675885ae4a2        default\nINSTANCE        i-00000032      ami-00000001    server-1fd4f0bd-e49e-4637-8e7b-875aa78cff8e     server-1fd4f0bd-e49e-4637-8e7b-875aa78cff8e     pending         0               m1.tiny 2013-01-11T00:35:09.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-00000033      ami-00000001    server-030e0016-7356-4eff-a25d-f03397405422     server-030e0016-7356-4eff-a25d-f03397405422     pending         0               m1.tiny 2013-01-11T00:35:09.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nINSTANCE        i-00000032\nINSTANCE        i-00000033\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nTooManyInstances: Quota exceeded for cores,instances: Requested 2, but already used 6 of 4 cores\nINSTANCE        i-0000002e\nINSTANCE        i-00000032\nINSTANCE        i-00000033\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nTooManyInstances: Quota exceeded for cores,instances: Requested 2, but already used 5 of 4 cores\n\n\n\n\n\nmysql> select * from quota_usages where project_id = \"2e4aa23119dd4f86ad810675885ae4a2\";\n+---------------------+---------------------+------------+---------+----+----------------------------------+-----------+--------+----------+---------------+\n| created_at          | updated_at          | deleted_at | deleted | id | project_id                       | resource  | in_use | reserved | until_refresh |\n+---------------------+---------------------+------------+---------+----+----------------------------------+-----------+--------+----------+---------------+\n| 2013-01-10 23:55:17 | 2013-01-11 00:35:24 | NULL       |       0 |  1 | 2e4aa23119dd4f86ad810675885ae4a2 | instances |      4 |        0 |          NULL |\n| 2013-01-10 23:55:17 | 2013-01-11 00:35:24 | NULL       |       0 |  2 | 2e4aa23119dd4f86ad810675885ae4a2 | ram       |   2048 |        0 |          NULL |\n| 2013-01-10 23:55:17 | 2013-01-11 00:35:24 | NULL       |       0 |  3 | 2e4aa23119dd4f86ad810675885ae4a2 | cores     |      4 |        0 |          NULL |\n+---------------------+---------------------+------------+---------+----+----------------------------------+-----------+--------+----------+---------------+\n3 rows in set (0.00 sec)\n\nmysql> select id from instances where project_id = \"2e4aa23119dd4f86ad810675885ae4a2\" and deleted = \"NULL\";\nEmpty set, 1 warning (0.00 sec)", 
    "tags": [
        "folsom-backport-potential"
    ], 
    "importance": "Critical", 
    "heat": 30, 
    "link": "https://bugs.launchpad.net/nova/+bug/1098380", 
    "owner": "https://api.launchpad.net/1.0/~cbehrens", 
    "id": 1098380, 
    "index": 108, 
    "openned": "2013-01-11 00:36:31.314710+00:00", 
    "created": "2013-01-11 00:36:31.314710+00:00", 
    "title": "Quotas showing in use when no VMs are running", 
    "comments": [
        {
            "content": "Environment: devstack  stable/folsom\n\nQuotas adjusted to 2VMs, 4 Cores.\n\n\nWhen I run the following script, the quotas start reporting resources in_use when no VMs are running.\n\n#!/bin/bash\nfor i in {1..20}\ndo\n  euca-run-instances -n 2 -t m1.tiny ami-00000001\n  sleep 2\n  for i in `euca-describe-instances | grep i- | awk '{print $2}'`; do euca-terminate-instances $i; done\ndone\n\n\n\n\n$ ./burn.sh                                                                                                                                                                              [53/357]\nRESERVATION     r-d5cfxois      2e4aa23119dd4f86ad810675885ae4a2        default\nINSTANCE        i-0000002e      ami-00000001    server-537fb7fe-9e96-42e8-9083-4bb2c36fbdb9     server-537fb7fe-9e96-42e8-9083-4bb2c36fbdb9     pending         0               m1.tiny 2013-01-11T00:34:50.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-0000002f      ami-00000001    server-4c8d1518-b269-4a50-b15e-a31034e93352     server-4c8d1518-b269-4a50-b15e-a31034e93352     pending         0               m1.tiny 2013-01-11T00:34:50.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nRESERVATION     r-861rhb54      2e4aa23119dd4f86ad810675885ae4a2        default\nINSTANCE        i-00000030      ami-00000001    server-6454449d-4207-4ca2-a95d-03ac6c07f480     server-6454449d-4207-4ca2-a95d-03ac6c07f480     pending         0               m1.tiny 2013-01-11T00:34:54.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-00000031      ami-00000001    server-70a5d87d-739c-40df-b5b9-4afe703710ae     server-70a5d87d-739c-40df-b5b9-4afe703710ae     pending         0               m1.tiny 2013-01-11T00:34:54.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nTooManyInstances: Quota exceeded for cores,instances: Requested 2, but already used 3 of 4 cores\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nTooManyInstances: Quota exceeded for instances: Requested 2, but already used 2 of 2 instances\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nRESERVATION     r-akz712u9      2e4aa23119dd4f86ad810675885ae4a2        default\nINSTANCE        i-00000032      ami-00000001    server-1fd4f0bd-e49e-4637-8e7b-875aa78cff8e     server-1fd4f0bd-e49e-4637-8e7b-875aa78cff8e     pending         0               m1.tiny 2013-01-11T00:35:09.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-00000033      ami-00000001    server-030e0016-7356-4eff-a25d-f03397405422     server-030e0016-7356-4eff-a25d-f03397405422     pending         0               m1.tiny 2013-01-11T00:35:09.000Z        unkno\nwn zone aki-00000002    ari-00000003            monitoring-disabled                                     instance-store\nINSTANCE        i-0000002e\nINSTANCE        i-0000002f\nINSTANCE        i-00000032\nINSTANCE        i-00000033\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nTooManyInstances: Quota exceeded for cores,instances: Requested 2, but already used 6 of 4 cores\nINSTANCE        i-0000002e\nINSTANCE        i-00000032\nINSTANCE        i-00000033\nINSTANCE        i-00000030\nINSTANCE        i-00000031\nTooManyInstances: Quota exceeded for cores,instances: Requested 2, but already used 5 of 4 cores\n\n\n\n\n\nmysql> select * from quota_usages where project_id = \"2e4aa23119dd4f86ad810675885ae4a2\";\n+---------------------+---------------------+------------+---------+----+----------------------------------+-----------+--------+----------+---------------+\n| created_at          | updated_at          | deleted_at | deleted | id | project_id                       | resource  | in_use | reserved | until_refresh |\n+---------------------+---------------------+------------+---------+----+----------------------------------+-----------+--------+----------+---------------+\n| 2013-01-10 23:55:17 | 2013-01-11 00:35:24 | NULL       |       0 |  1 | 2e4aa23119dd4f86ad810675885ae4a2 | instances |      4 |        0 |          NULL |\n| 2013-01-10 23:55:17 | 2013-01-11 00:35:24 | NULL       |       0 |  2 | 2e4aa23119dd4f86ad810675885ae4a2 | ram       |   2048 |        0 |          NULL |\n| 2013-01-10 23:55:17 | 2013-01-11 00:35:24 | NULL       |       0 |  3 | 2e4aa23119dd4f86ad810675885ae4a2 | cores     |      4 |        0 |          NULL |\n+---------------------+---------------------+------------+---------+----+----------------------------------+-----------+--------+----------+---------------+\n3 rows in set (0.00 sec)\n\nmysql> select id from instances where project_id = \"2e4aa23119dd4f86ad810675885ae4a2\" and deleted = \"NULL\";\nEmpty set, 1 warning (0.00 sec)", 
            "date_created": "2013-01-11 00:36:31.314710+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Able to reproduce in Grizzly as well.", 
            "date_created": "2013-01-11 01:13:30.683876+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Not sure if this is the cause, but the quota code uses task state to detect if it should trigger a new quota reservation.  So when two tasks are running on a single VM (task is property of the instance), the task state can go from deleting to something else.\n\n\nIn the paste below I added some logging (search for 'task -'), in nova.compute.api:_delete that displays the vm_state and task_state that is used to decide if another QUOTA reservation should be made.  The paste shows the state goes into delete and then into block_device_mapping.  all while the vm_state is still building.\n\nhttp://paste.openstack.org/show/29491/\n\nThis causes the quota values to go negative.\n\nWhen a negative value is detected the quota values are recalculated, but it looks like the recalculation doesn't handle VMs in flight well. The paste below is from polling the DB while the shell script above was run.  Once the quota usage goes negative it jumps to an invalid number which, directly correlates to the number of VMs in flight.\n\n\n\nhttp://paste.openstack.org/show/29492/\n", 
            "date_created": "2013-01-16 01:45:36.850189+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "When the quotas are negative, it runs _sync_instances (https://github.com/openstack/nova/blob/master/nova/quota.py#L1036), which is not aware of task or vm state.", 
            "date_created": "2013-01-16 02:01:29.073569+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "For one...  the commit for instance delete needs to be moved to the manager side when the instance is actually deleted...to prevent it being done more than once.", 
            "date_created": "2013-02-13 02:59:00.728066+00:00", 
            "author": "https://api.launchpad.net/1.0/~cbehrens"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/22482", 
            "date_created": "2013-02-20 21:23:31.144003+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This can be reset by setting the quota usage to -1.\n'update quota_usages set in_use=-1;'", 
            "date_created": "2013-02-20 23:12:25.573023+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/22482\nCommitted: http://github.com/openstack/nova/commit/652a487ed9daba9ae97f7df77ae35720322d1af3\nSubmitter: Jenkins\nBranch:    master\n\ncommit 652a487ed9daba9ae97f7df77ae35720322d1af3\nAuthor: Chris Behrens <email address hidden>\nDate:   Mon Mar 11 00:20:23 2013 -0700\n\n    Fix quota issues with instance deletes.\n    \n    In order to keep quotas in sync as much as possible, only commit quota\n    changes for delete when:\n    \n    1) An instance's vm_state is updated to be SOFT_DELETED.\n    2) The DB record is marked as deleted (and the instance's vm_state is\n       not SOFT_DELETED)\n    \n    If a host is down and we delete the instance in the API, this means\n    quotas are committed within the API.  Otherwise, quotas are committed\n    on the manager side.\n    \n    Fixes bug 1098380\n    \n    Also needed for proper testing: Fixed compute cells tests so that pseudo\n    child cells use NoopQuotaDriver.  This uncovered inconsistencies in the\n    NoopQuotaDriver wrt the DBQuotaDriver.  Those issues were fixed as well.\n    \n    Change-Id: Ib72de1a457f0c5056d55a5c7dd4d8d7c69708996\n", 
            "date_created": "2013-03-12 23:13:10.273350+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2013-03-20 16:04:41.518101+00:00"
}