{
    "status": "Opinion", 
    "last_updated": "2015-04-01 13:53:38.362769+00:00", 
    "description": "nova-conductor will lose the queue and not able to get requests anymore after running workload for some time. This also occured in process nova-compute. They share same impl_qpid.py.\n\nWhen nova-conductor with heavy workload,  a  exception HeartbeatTimeout will be raised.  The exceptin will be caught and try to reconnect to qpid server.  logs shows we can't reconnect qoid  in method iterconsume , but can reconnect qpid server in method publisher_send. That means we can't only send message to the qpid queue, but can't receive message from qpid queue.\n\nimpl_qpid.py \n    def ensure(self, error_callback, method, *args, **kwargs):\n        while True:\n            try:\n                return method(*args, **kwargs)          ---------------------------> raise  HeartbeatTimeout\n            except (qpid_exceptions.Empty,\n                    qpid_exceptions.ConnectionError), e:\n                if error_callback:\n                    error_callback(e)\n                self.reconnect()     ------------------------------> retry \n\n\nmethod ensure is used in \n\n    def iterconsume(self, limit=None, timeout=None):\n        \"\"\"Return an iterator that will consume from all queues/consumers\"\"\"\n\n        def _error_callback(exc):\n            if isinstance(exc, qpid_exceptions.Empty):\n                LOG.debug(_('Timed out waiting for RPC response: %s') %\n                          str(exc))\n                raise rpc_common.Timeout()\n            else:\n                LOG.exception(_('Failed to consume message from queue: %s') %\n                              str(exc))\n\n        def _consume():\n            nxt_receiver = self.session.next_receiver(timeout=timeout)\n            try:\n                self._lookup_consumer(nxt_receiver).consume()\n            except Exception:\n                LOG.exception(_(\"Error processing message.  Skipping it.\"))\n\n        for iteration in itertools.count(0):\n            if limit and iteration >= limit:\n                raise StopIteration\n            yield self.ensure(_error_callback, _consume)   ---------------------->   here can't reconnect \n\n\nand \n\n    def publisher_send(self, cls, topic, msg):\n        \"\"\"Send to a publisher based on the publisher class\"\"\"\n\n        def _connect_error(exc):\n            log_info = {'topic': topic, 'err_str': str(exc)}\n            LOG.exception(_(\"Failed to publish message to topic \"\n                          \"'%(topic)s': %(err_str)s\") % log_info)\n\n        def _publisher_send():\n            publisher = cls(self.conf, self.session, topic)\n            publisher.send(msg)\n\n        return self.ensure(_connect_error, _publisher_send) ------------------> here can reconnect.", 
    "tags": [
        "conductor", 
        "qpid"
    ], 
    "importance": "Low", 
    "heat": 14, 
    "link": "https://bugs.launchpad.net/nova/+bug/1247603", 
    "owner": "None", 
    "id": 1247603, 
    "index": 1059, 
    "openned": "2013-11-03 15:45:06.732024+00:00", 
    "created": "2013-11-03 15:45:06.732024+00:00", 
    "title": "nova-conductor process can't create cosumer connection to qpid after HeartbeatTimeout in heavy workload", 
    "comments": [
        {
            "content": "nova-conductor will lose the queue and not able to get requests anymore after running workload for some time. This also occured in process nova-compute. They share same impl_qpid.py.\n\nWhen nova-conductor with heavy workload,  a  exception HeartbeatTimeout will be raised.  The exceptin will be caught and try to reconnect to qpid server.  logs shows we can't reconnect qoid  in method iterconsume , but can reconnect qpid server in method publisher_send. That means we can't only send message to the qpid queue, but can't receive message from qpid queue.\n\nimpl_qpid.py \n    def ensure(self, error_callback, method, *args, **kwargs):\n        while True:\n            try:\n                return method(*args, **kwargs)          ---------------------------> raise  HeartbeatTimeout\n            except (qpid_exceptions.Empty,\n                    qpid_exceptions.ConnectionError), e:\n                if error_callback:\n                    error_callback(e)\n                self.reconnect()     ------------------------------> retry \n\n\nmethod ensure is used in \n\n    def iterconsume(self, limit=None, timeout=None):\n        \"\"\"Return an iterator that will consume from all queues/consumers\"\"\"\n\n        def _error_callback(exc):\n            if isinstance(exc, qpid_exceptions.Empty):\n                LOG.debug(_('Timed out waiting for RPC response: %s') %\n                          str(exc))\n                raise rpc_common.Timeout()\n            else:\n                LOG.exception(_('Failed to consume message from queue: %s') %\n                              str(exc))\n\n        def _consume():\n            nxt_receiver = self.session.next_receiver(timeout=timeout)\n            try:\n                self._lookup_consumer(nxt_receiver).consume()\n            except Exception:\n                LOG.exception(_(\"Error processing message.  Skipping it.\"))\n\n        for iteration in itertools.count(0):\n            if limit and iteration >= limit:\n                raise StopIteration\n            yield self.ensure(_error_callback, _consume)   ---------------------->   here can't reconnect \n\n\nand \n\n    def publisher_send(self, cls, topic, msg):\n        \"\"\"Send to a publisher based on the publisher class\"\"\"\n\n        def _connect_error(exc):\n            log_info = {'topic': topic, 'err_str': str(exc)}\n            LOG.exception(_(\"Failed to publish message to topic \"\n                          \"'%(topic)s': %(err_str)s\") % log_info)\n\n        def _publisher_send():\n            publisher = cls(self.conf, self.session, topic)\n            publisher.send(msg)\n\n        return self.ensure(_connect_error, _publisher_send) ------------------> here can reconnect.", 
            "date_created": "2013-11-03 15:45:06.732024+00:00", 
            "author": "https://api.launchpad.net/1.0/~glongwave"
        }, 
        {
            "content": "Search  second \"Failed to consume message from queue: heartbeat timeout\", It only show create connection , but doesn't show  \"Connected to AMQP server on\" or \"Unable to connect to AMQP server:\"\n\nBut search \"Failed to publish message to topic\"  it can show \"Connected to AMQP server on\" . It seems thread fo \"consume\" disapear.\n\n    def reconnect(self):\n        \"\"\"Handles reconnecting and re-establishing sessions and queues\"\"\"\n        attempt = 0\n        delay = 1\n        while True:\n            # Close the session if necessary\n            if self.connection.opened():\n                try:\n                    self.connection.close()\n                except qpid_exceptions.ConnectionError:\n                    pass\n\n            broker = self.brokers[attempt % len(self.brokers)]\n            attempt += 1\n\n            try:\n                self.connection_create(broker)\n                self.connection.open()\n            except qpid_exceptions.ConnectionError, e:\n                msg_dict = dict(e=e, delay=delay)\n                msg = _(\"Unable to connect to AMQP server: %(e)s. \"\n                        \"Sleeping %(delay)s seconds\") % msg_dict\n                LOG.error(msg)\n                time.sleep(delay)\n                delay = min(2 * delay, 60)\n            else:\n                LOG.info(_('Connected to AMQP server on %s'), broker)\n                break\n", 
            "date_created": "2013-11-03 15:54:27.398115+00:00", 
            "author": "https://api.launchpad.net/1.0/~glongwave"
        }, 
        {
            "content": "This file add some logs to get log  of conductor.", 
            "date_created": "2013-11-03 15:55:28.150401+00:00", 
            "author": "https://api.launchpad.net/1.0/~glongwave"
        }, 
        {
            "content": "This  can be reproduced by following steps:\n\n1. Modify  conductor.manager.py to make it with heavy workload. this will take about 12 minutes ,will lead  a exception HeartbeatTimeout.\n\n    @rpc_common.client_exceptions(exception.InstanceNotFound)\n    def instance_get_by_uuid(self, context, instance_uuid):\n        LOG.info(\"hill===============computing  print the logs\")\n        if instance_uuid == \"04f84fb0-c458-4623-afff-9f6e4de26f40\" :\n            long = 1000000000 * 8\n            while long>0:\n                long -=1 \n        LOG.info(\"hill==============end computing print logs\")\n\n        return jsonutils.to_primitive(\n            self.db.instance_get_by_uuid(context, instance_uuid))\n\n\n2. run test.sh ,just show one instance.\nwhile true;\ndo\n  . ~/keystonerc && nova  show 04f84fb0-c458-4623-afff-9f6e4de26f40\n  sleep 1\ndone\n\n\n3. checkout the conductor.log , find  consume method will can't connect to Qpid server ,but publiser_end can connect to Qpid server.", 
            "date_created": "2013-11-03 15:59:58.663096+00:00", 
            "author": "https://api.launchpad.net/1.0/~glongwave"
        }, 
        {
            "content": "In fact ,  the consume connection can be created .  the create thread is interrupted by period task ,and can resume to connect to qpid\n.", 
            "date_created": "2013-11-04 09:21:37.434172+00:00", 
            "author": "https://api.launchpad.net/1.0/~glongwave"
        }, 
        {
            "content": "When i conducting snapshot, this bug often has been raised.\n\n# nova availivility-zone-list \n\nAll compute node's status were 'xxx'.", 
            "date_created": "2014-03-25 01:49:15.829406+00:00", 
            "author": "https://api.launchpad.net/1.0/~joonsikjang"
        }, 
        {
            "content": "Hit this today on latest Havana build, logs below.  I reproduced doing some stress testing; create 50 instances boot from volume in one operation.  Need to try it in my Icehouse setup next.\n\n2014-03-20 00:42:51.725 17580 INFO nova.compute.manager [req-ef61a326-288b-494d-9d30-f533e7739949 None None] Updating bandwidth usage cache\n2014-03-20 00:43:51.843 17580 AUDIT nova.compute.resource_tracker [-] Auditing locally available compute resources\n2014-03-20 00:43:52.607 17580 AUDIT nova.compute.resource_tracker [-] Free ram (MB): 257773\n2014-03-20 00:43:52.607 17580 AUDIT nova.compute.resource_tracker [-] Free disk (GB): 49\n2014-03-20 00:43:52.607 17580 AUDIT nova.compute.resource_tracker [-] Free VCPUS: 48\n2014-03-20 00:43:52.677 17580 INFO nova.compute.resource_tracker [-] Compute_service record updated for os-1.solidfire.net:os-1.solidfire.net\n2014-03-20 00:44:52.808 17580 AUDIT nova.compute.resource_tracker [-] Auditing locally available compute resources\n2014-03-20 00:44:53.589 17580 AUDIT nova.compute.resource_tracker [-] Free ram (MB): 257773\n2014-03-20 00:44:53.589 17580 AUDIT nova.compute.resource_tracker [-] Free disk (GB): 49\n2014-03-20 00:44:53.590 17580 AUDIT nova.compute.resource_tracker [-] Free VCPUS: 48\n2014-03-20 00:44:53.657 17580 INFO nova.compute.resource_tracker [-] Compute_service record updated for os-1.solidfire.net:os-1.solidfire.net\n2014-03-20 08:47:05.277 17580 ERROR nova.openstack.common.rpc.impl_qpid [-] Failed to publish message to topic 'conductor': heartbeat timeout\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid Traceback (most recent call last):\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/nova/openstack/common/rpc/impl_qpid.py\", line 540, in ensure\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     return method(*args, **kwargs)\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/nova/openstack/common/rpc/impl_qpid.py\", line 632, in _publisher_send\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     publisher = cls(self.conf, self.session, topic)\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/nova/openstack/common/rpc/impl_qpid.py\", line 398, in __init__\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     super(TopicPublisher, self).__init__(conf, session, node_name)\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/nova/openstack/common/rpc/impl_qpid.py\", line 328, in __init__\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     self.reconnect(session)\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/nova/openstack/common/rpc/impl_qpid.py\", line 332, in reconnect\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     self.sender = session.sender(self.address)\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"<string>\", line 6, in sender\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 592, in sender\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     sender._ewait(lambda: sender.linked)\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 799, in _ewait\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     result = self.session._ewait(lambda: self.error or predicate(), timeout)\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 566, in _ewait\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     result = self.connection._ewait(lambda: self.error or predicate(), timeout)\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 209, in _ewait\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     self.check_error()\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 202, in check_error\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid     raise self.error\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid HeartbeatTimeout: heartbeat timeout\n2014-03-20 08:47:05.277 17580 TRACE nova.openstack.common.rpc.impl_qpid\n2014-03-20 08:47:05.295 17580 ERROR nova.openstack.common.rpc.impl_qpid [-] Failed to consume message from queue: heartbeat timeout\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid Traceback (most recent call last):\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/nova/openstack/common/rpc/impl_qpid.py\", line 540, in ensure\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid     return method(*args, **kwargs)\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/nova/openstack/common/rpc/impl_qpid.py\", line 597, in _consume\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid     nxt_receiver = self.session.next_receiver(timeout=timeout)\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"<string>\", line 6, in next_receiver\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 660, in next_receiver\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid     if self._ecwait(lambda: self.incoming, timeout):\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 50, in _ecwait\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid     result = self._ewait(lambda: self.closed or predicate(), timeout)\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 566, in _ewait\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid     result = self.connection._ewait(lambda: self.error or predicate(), timeout)\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 209, in _ewait\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid     self.check_error()\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 202, in check_error\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid     raise self.error\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid HeartbeatTimeout: heartbeat timeout\n2014-03-20 08:47:05.295 17580 TRACE nova.openstack.common.rpc.impl_qpid\n2014-03-20 08:47:05.301 17580 ERROR nova.openstack.common.rpc.impl_qpid [-] Failed to consume message from queue: heartbeat timeout\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid Traceback (most recent call last):\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/nova/openstack/common/rpc/impl_qpid.py\", line 540, in ensure\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid     return method(*args, **kwargs)\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/nova/openstack/common/rpc/impl_qpid.py\", line 597, in _consume\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid     nxt_receiver = self.session.next_receiver(timeout=timeout)\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"<string>\", line 6, in next_receiver\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 660, in next_receiver\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid     if self._ecwait(lambda: self.incoming, timeout):\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 50, in _ecwait\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid     result = self._ewait(lambda: self.closed or predicate(), timeout)\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 566, in _ewait\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid     result = self.connection._ewait(lambda: self.error or predicate(), timeout)\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 209, in _ewait\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid     self.check_error()\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid   File \"/usr/lib/python2.6/site-packages/qpid/messaging/endpoints.py\", line 202, in check_error\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid     raise self.error\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid HeartbeatTimeout: heartbeat timeout\n2014-03-20 08:47:05.301 17580 TRACE nova.openstack.common.rpc.impl_qpid\n2014-03-20 08:47:05.326 17580 INFO nova.openstack.common.rpc.impl_qpid [-] Connected to AMQP server on 172.27.33.21:5672\n2014-03-20 08:47:05.330 17580 INFO nova.openstack.common.rpc.impl_qpid [-] Connected to AMQP server on 172.27.33.21:5672\n2014-03-20 08:47:05.332 17580 INFO nova.openstack.common.rpc.impl_qpid [-] Connected to AMQP server on 172.27.33.21:5672\n2014-03-20 08:47:05.335 17580 INFO nova.openstack.common.rpc.impl_qpid [-] Connected to AMQP server on 172.27.33.21:5672\n2014-03-20 08:47:05.458 17580 INFO nova.compute.manager [-] Running instance usage audit for host os-1.solidfire.net from 2014-03-20 13:00:00 to 2014-03-20 14:00:00. 0 instances.\n2014-03-20 08:47:05.532 17580 AUDIT nova.compute.resource_tracker [-] Auditing locally available compute resources\n2014-03-20 08:47:06.269 17580 AUDIT nova.compute.resource_tracker [-] Free ram (MB): 257773\n2014-03-20 08:47:06.269 17580 AUDIT nova.compute.resource_tracker [-] Free disk (GB): 49\n2014-03-20 08:47:06.269 17580 AUDIT nova.compute.resource_tracker [-] Free VCPUS: 48\n2014-03-20 08:47:06.336 17580 INFO nova.compute.resource_tracker [-] Compute_service record updated for os-1.solidfire.net:os-1.solidfire.net\n2014-03-20 08:47:06.482 17580 INFO nova.compute.manager [-] Updating bandwidth usage cache\n2014-03-20 08:48:06.692 17580 AUDIT nova.compute.resource_tracker [-] Auditing locally available compute resources", 
            "date_created": "2014-03-26 23:47:24.704238+00:00", 
            "author": "https://api.launchpad.net/1.0/~john-griffith"
        }, 
        {
            "content": "Which version of qpid are you using (server and client)?  Are you using durable queues?  What are your rpc configuration values in nova.conf?  What version of oslo.messaging are you using?", 
            "date_created": "2014-06-05 23:05:05.267919+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "What is the number of workers for conductor service in nova.conf\n\n[conductor]\n\n#\n# Options defined in nova.conductor.api\n#\n\n# Perform nova-conductor operations locally (boolean value)\n#use_local=false\n\n# the topic conductor nodes listen on (string value)\n#topic=conductor\n\n# full class name for the Manager for conductor (string value)\n#manager=nova.conductor.manager.ConductorManager\n\n# Number of workers for OpenStack Conductor service (integer\n# value)\n#workers=<None>\nworkers=24", 
            "date_created": "2014-07-31 09:10:34.879096+00:00", 
            "author": "https://api.launchpad.net/1.0/~mrz001com"
        }, 
        {
            "content": "Information requested, also because it's qpid I think it's by definition low, as qpid is not the recommended backend here.", 
            "date_created": "2014-09-03 12:49:06.467170+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }
    ], 
    "closed": "2015-04-01 13:53:36.891942+00:00"
}