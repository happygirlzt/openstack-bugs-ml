{
    "status": "Invalid", 
    "last_updated": "2013-03-14 18:52:12.005320+00:00", 
    "description": "We use 'unicode' to turn a lot of exceptions into unicode strings throughout nova.\n\nFor example: https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/servers.py#L882\n\nAs the exception's message may be generated by the gettext translation system, it could hold unicode encoded data.\n\nThe way we try to turn that into a unicode string, assumes that the input is 7-bit ascii.\n\nThe output encoding of each language may be a different encoding.\n\nIf the translated string is not 7 bit ascii. Our code will raise a:\n\n\"UnicodeDecodeError: 'ascii' codec can't decode byte 0xe5 in position 0: ordinal not in range(128)\"\n\nWhen the gettext system is installed, the '_' function is 'gettext.gettext' for whatever locale is installed.\n\n----\n\nThis is the suggested fix:\n\nWe should remove all uses of 'unicode' and replace it with 'str'.\n\nThat way it doesn't matter what encoding the .po file was in, it'll just leave it in that encoding and output it in that encoding.\n\nSo if, for example the chinese translator decides to use the GB18030 encoding because it's more popular in their region/culture than utf-8 .. by using only 'str' the text will be output in the language and encoding that the translator intended, so it'll work on all machines that are set up with GB18030 support.\n\n----\n\nDemonstration:\n\nIf you run this from the nova source dir:\n\nmkdir -p tmp/ja/LC_MESSAGES\nmsgfmt nova/locale/ja/LC_MESSAGES/nova.po -o tmp/ja/LC_MESSAGES/nova.mo\npython\n>>> ja = gettext.translation('nova', 'tmp', ['ja'])\n>>> s = ''FAKE ISCSI: %s''\n>>> t = ja.gettext(s)  # This simulates calling _('FAKE ISCSI: %s'); in nova code\n>>> print t\n\u507d\u306eISCSI: %s\n>>> t\n'\\xe5\\x81\\xbd\\xe3\\x81\\xaeISCSI: %s'\n>>> unicode(t)\nTraceback (most recent call last):\n\u00a0\u00a0File \"<stdin>\", line 1, in <module>\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe5 in position 0: ordinal not in range(128)\n>>> t.decode('utf-8')\nu'\\u507d\\u306eISCSI: %s'\n>>> unicode(t, 'utf-8')\nu'\\u507d\\u306eISCSI: %s'\n>>> print t.decode('utf-8')\n\u507d\u306eISCSI: %s", 
    "tags": [
        "i18n"
    ], 
    "importance": "Medium", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1152188", 
    "owner": "None", 
    "id": 1152188, 
    "index": 3265, 
    "openned": "2013-03-07 14:13:14.280629+00:00", 
    "created": "2013-03-07 14:13:14.280629+00:00", 
    "title": "unicode is used wrongly throughout nova", 
    "comments": [
        {
            "content": "We use 'unicode' to turn a lot of exceptions into unicode strings throughout nova.\n\nFor example: https://github.com/openstack/nova/blob/master/nova/api/openstack/compute/servers.py#L882\n\nAs the exception's message may be generated by the gettext translation system, it could hold unicode encoded data.\n\nThe way we try to turn that into a unicode string, assumes that the input is 7-bit ascii.\n\nThe output encoding of each language may be a different encoding.\n\nIf the translated string is not 7 bit ascii. Our code will raise a:\n\n\"UnicodeDecodeError: 'ascii' codec can't decode byte 0xe5 in position 0: ordinal not in range(128)\"\n\nWhen the gettext system is installed, the '_' function is 'gettext.gettext' for whatever locale is installed.\n\n----\n\nThis is the suggested fix:\n\n * There should be a policy that all translations (all .po files in nova/locale) output 'utf-8' encoded text.\n * Whenever we want to get a unicode string, we should use: some_string.decode('utf-8')  .. or unicode(some_string, 'utf-8')\n\n----\n\nDemonstration:\n\nIf you run this from the nova source dir:\n\nmkdir -p tmp/ja/LC_MESSAGES\nmsgfmt nova/locale/ja/LC_MESSAGES/nova.po -o tmp/ja/LC_MESSAGES/nova.mo\npython\n>>> ja = gettext.translation('nova', 'tmp', ['ja'])\n>>> s = ''FAKE ISCSI: %s''\n>>> t = ja.gettext(s)  # This simulates calling _('FAKE ISCSI: %s'); in nova code\n>>> print t\n\u507d\u306eISCSI: %s\n>>> t\n'\\xe5\\x81\\xbd\\xe3\\x81\\xaeISCSI: %s'\n>>> unicode(t)\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe5 in position 0: ordinal not in range(128)\n>>> t.decode('utf-8')\nu'\\u507d\\u306eISCSI: %s'\n>>> print t.decode('utf-8')\n\u507d\u306eISCSI: %s", 
            "date_created": "2013-03-07 14:13:14.280629+00:00", 
            "author": "https://api.launchpad.net/1.0/~msherborne+openstack"
        }, 
        {
            "content": "I'm changing the proposed solution to:\n\nAs much as possible we should avoid using 'unicode' and use just 'str', especially for getting the mesages out of exceptions.\n\nThat way it doesn't matter what encoding the .po file was in, it'll just leave it in that encoding and output it in that encoding.\n\nSo if, for example the chinese translator decides to use the GB18030 encoding because it's more popular in their region/culture, than utf-8 .. by using only 'str' the string will be output in that raw encoding.", 
            "date_created": "2013-03-14 12:50:53.588617+00:00", 
            "author": "https://api.launchpad.net/1.0/~msherborne+openstack"
        }, 
        {
            "content": "I understand the problem here, but I disagree with the fix. This is a gettext bug if anything.\n\nAll strings should be maintained as unicode within nova and only converted to a particular encoding (usually utf-8) at the edges (into the logs, output via HTTP response, etc).\n\nThe reason is that you can't sensibly mix two different encodings of a string, so we want everything normalized to a unicode string.\n\nTake this example for instance:\n\n>>> message = u'\\u2122%s'.encode('utf-8')\n>>> message\n'\\xe2\\x84\\xa2%s'\n>>> message % u'\\u2022'\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 0: ordinal not in range(128)\n\nSince everything is stored as a unicode string in nova, if we try to interpolate that into a UTF-8 encoded format string, it explodes. This is exactly what will happen with exception messages if one of the interpolated values is unicode and uses non-ascii characters.\n\ngettext (or our wrappers) should be decoding whatever is returned from the .po files into unicode so we don't have this problem.", 
            "date_created": "2013-03-14 15:17:31.213014+00:00", 
            "author": "https://api.launchpad.net/1.0/~johannes.erdfelt"
        }, 
        {
            "content": "Thanks Johannes. That was my original proposed solution.\n\nI've done some experimenting and discovered this is a non-bug. I'll close this bug and report a new one.\n\nThe reason it's not a bug is that in nova/__init__.py - where gettext is installed, they pass 1 to the unicode flag, which means all encodings will come in already in unicode.\n\nand of course all output that's in unicode will automatically be printed in locale.getpreferredencoding().\n\nSo the new proposed solution is to use make sure that we use unicode(exc) everywhere, and never use str(exc)", 
            "date_created": "2013-03-14 18:39:43.592284+00:00", 
            "author": "https://api.launchpad.net/1.0/~msherborne+openstack"
        }, 
        {
            "content": "Bug reposted and fixed up as: https://bugs.launchpad.net/nova/+bug/1155280", 
            "date_created": "2013-03-14 18:52:10.967725+00:00", 
            "author": "https://api.launchpad.net/1.0/~msherborne+openstack"
        }
    ], 
    "closed": "2013-03-14 18:39:58.143961+00:00"
}