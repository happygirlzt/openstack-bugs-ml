{
    "status": "Fix Released", 
    "last_updated": "2014-08-20 04:42:56.197085+00:00", 
    "description": "This text appears in compute log:\n\nDEBUG nova.virt.xenapi.vm_utils [req-909291ef-dbf7-4ed7-a1f4-f4b613117ac9 demo demo] Plugging VBD OpaqueRef:8d37c8d2-5a00-1442-8f19-3c97c3d9a751 ...  from (pid=26384) vdi_attached_here /opt/stack/nova/nova/virt/xenapi/vm_utils.py:1911\n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] ['INTERNAL_ERROR', 'File \"xapi_xenops.ml\", line 2088, characters 3-9: Assertion failed']\nTraceback (most recent call last):\n  File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 352, in unplug_vbd\n    session.call_xenapi('VBD.unplug', vbd_ref)\n  File \"/opt/stack/nova/nova/virt/xenapi/driver.py\", line 719, in call_xenapi\n    return session.xenapi_request(method, args)\n  File \"/usr/local/lib/python2.7/dist-packages/XenAPI.py\", line 133, in xenapi_request\n    result = _parse_result(getattr(self, methodname)(*full_params))\n  File \"/usr/local/lib/python2.7/dist-packages/XenAPI.py\", line 203, in _parse_result\n    raise Failure(result['ErrorDescription'])\nFailure: ['INTERNAL_ERROR', 'File \"xapi_xenops.ml\", line 2088, characters 3-9: Assertion failed']\n...\n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] ['OPERATION_NOT_ALLOWED', \"VBD '0d03a77b-6ae3-2e16-1a63-d771e374f513' still attached to '98bbd5ba-dc99-6c96-32be-b170cf8c9dd6'\"]\nTraceback (most recent call last):\n  File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 379, in destroy_vbd\n    session.call_xenapi('VBD.destroy', vbd_ref)\n  File \"/opt/stack/nova/nova/virt/xenapi/driver.py\", line 719, in call_xenapi\n    return session.xenapi_request(method, args)\n  File \"/usr/local/lib/python2.7/dist-packages/XenAPI.py\", line 133, in xenapi_request\n    result = _parse_result(getattr(self, methodname)(*full_params))\n  File \"/usr/local/lib/python2.7/dist-packages/XenAPI.py\", line 203, in _parse_result\n    raise Failure(result['ErrorDescription'])\nFailure: ['OPERATION_NOT_ALLOWED', \"VBD '0d03a77b-6ae3-2e16-1a63-d771e374f513' still attached to '98bbd5ba-dc99-6c96-32be-b170cf8c9dd6'\"]\n\n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] Destroying VBD for VDI OpaqueRef:d93e1482-aba5-e919-7733-7db2f3d2ccd6 done. from (pid=26384) vdi_attached_here /opt/stack/nova/nova/virt/xenapi/vm_utils.py:1934\n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] [instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Failed to spawn, rolling back\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Traceback (most recent call last):\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 498, in spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     kernel_file, ramdisk_file = create_kernel_ramdisk_step(undo_mgr)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 153, in inner\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     rv = f(*args, **kwargs)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 390, in create_kernel_ramdisk_step\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     instance, context, name_label)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 191, in _create_kernel_and_ramdisk\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     vm_utils.ImageType.KERNEL)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1019, in create_kernel_image\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     image_id, image_type)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1331, in _fetch_disk_image\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     session, image.stream_to, image_type, virtual_size, dev)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     self.gen.next()\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1927, in vdi_attached_here\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     unplug_vbd(session, vbd_ref)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 367, in unplug_vbd\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     _('Unable to unplug VBD %s') % vbd_ref)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] StorageError: Unable to unplug VBD OpaqueRef:f0fafa75-763d-db2d-d022-6e16b9808e44\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] \n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] [instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Instance failed to spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Traceback (most recent call last):\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/compute/manager.py\", line 1286, in _spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     block_device_info)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/driver.py\", line 180, in spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     admin_password, network_info, block_device_info)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 514, in spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     undo_mgr.rollback_and_reraise(msg=msg, instance=instance)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/utils.py\", line 981, in rollback_and_reraise\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     self._rollback()\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 498, in spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     kernel_file, ramdisk_file = create_kernel_ramdisk_step(undo_mgr)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 153, in inner\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     rv = f(*args, **kwargs)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 390, in create_kernel_ramdisk_step\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     instance, context, name_label)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 191, in _create_kernel_and_ramdisk\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     vm_utils.ImageType.KERNEL)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1019, in create_kernel_image\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     image_id, image_type)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1331, in _fetch_disk_image\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     session, image.stream_to, image_type, virtual_size, dev)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     self.gen.next()\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1927, in vdi_attached_here\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     unplug_vbd(session, vbd_ref)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 367, in unplug_vbd\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     _('Unable to unplug VBD %s') % vbd_ref)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] StorageError: Unable to unplug VBD OpaqueRef:f0fafa75-763d-db2d-d022-6e16b9808e44\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] \n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] [instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Aborting claim: [Claim: 512 MB memory, 1 GB disk, 1 VCPUS] from (pid=26384) abort /opt/stack/nova/nova/compute/claims.py:97\n\nLooking at vm_utils.py:\n\ndef unplug_vbd(session, vbd_ref):\n    \"\"\"Unplug VBD from VM.\"\"\"\n    # Call VBD.unplug on the given VBD, with a retry if we get\n    # DEVICE_DETACH_REJECTED.  For reasons which we don't understand,\n    # we're seeing the device still in use, even when all processes\n    # using the device should be dead.\n    max_attempts = CONF.xenapi_num_vbd_unplug_retries + 1\n    for num_attempt in xrange(1, max_attempts + 1):\n        try:\n            session.call_xenapi('VBD.unplug', vbd_ref)\n            return\n        except session.XenAPI.Failure as exc:\n            err = len(exc.details) > 0 and exc.details[0]\n            if err == 'DEVICE_ALREADY_DETACHED':\n                LOG.info(_('VBD %s already detached'), vbd_ref)\n                return\n            elif err == 'DEVICE_DETACH_REJECTED':\n                LOG.info(_('VBD %(vbd_ref)s detach rejected, attempt'\n                           ' %(num_attempt)d/%(max_attempts)d'),\n                         {'vbd_ref': vbd_ref, 'num_attempt': num_attempt,\n                          'max_attempts': max_attempts})\n            else:\n                LOG.exception(exc)\n                raise volume_utils.StorageError(\n                        _('Unable to unplug VBD %s') % vbd_ref)\n\n        greenthread.sleep(1)\n\n    raise volume_utils.StorageError(\n            _('Reached maximum number of retries trying to unplug VBD %s')\n            % vbd_ref)\n\nIt is prepared to handle such situations. Maybe xapi returns with a different error code?\n\nMy XenServer is 6.2:\n\n[root@megadodo ~]# cat /etc/xensource-inventory \nBUILD_NUMBER='70446c'\nPLATFORM_VERSION='1.8.0'\nDOM0_VCPUS='4'\nINSTALLATION_UUID='4d944fd3-8b48-47a1-9b13-155ae6923a37'\nMANAGEMENT_ADDRESS_TYPE='IPv4'\nPRODUCT_VERSION_TEXT_SHORT='6.2'\nBRAND_CONSOLE='XenCenter'\nPRIMARY_DISK='/dev/disk/by-id/scsi-SATA_SAMSUNG_HE253GJ_S2B5J90ZC12322'\nPRODUCT_BRAND='XenServer'\nINSTALLATION_DATE='2013-08-21 08:05:18.227510'\nPLATFORM_NAME='XCP'\nCOMPANY_NAME_SHORT='Citrix'\nPRODUCT_VERSION_TEXT='6.2'\nBACKUP_PARTITION='/dev/disk/by-id/scsi-SATA_SAMSUNG_HE253GJ_S2B5J90ZC12322-part2'\nPRODUCT_VERSION='6.2.0'\nXEN_VERSION='4.1.5'\nKERNEL_VERSION='2.6.32.43-0.4.1.xs1.8.0.835.170778xen'\nMANAGEMENT_INTERFACE='xenbr0'\nDOM0_MEM='752'\nCOMPANY_NAME='Citrix Systems, Inc.'\nPRODUCT_NAME='xenenterprise'\nCONTROL_DOMAIN_UUID='4e04643c-0506-408c-9a84-e45fe055ce90'", 
    "tags": [
        "xenserver"
    ], 
    "importance": "Medium", 
    "heat": 16, 
    "link": "https://bugs.launchpad.net/nova/+bug/1217972", 
    "owner": "https://api.launchpad.net/1.0/~johngarbutt", 
    "id": 1217972, 
    "index": 3546, 
    "openned": "2013-08-28 16:31:27.553499+00:00", 
    "created": "2013-08-28 16:31:27.553499+00:00", 
    "title": "xenapi: VBD detach failure", 
    "comments": [
        {
            "content": "This text appears in compute log:\n\nDEBUG nova.virt.xenapi.vm_utils [req-909291ef-dbf7-4ed7-a1f4-f4b613117ac9 demo demo] Plugging VBD OpaqueRef:8d37c8d2-5a00-1442-8f19-3c97c3d9a751 ...  from (pid=26384) vdi_attached_here /opt/stack/nova/nova/virt/xenapi/vm_utils.py:1911\n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] ['INTERNAL_ERROR', 'File \"xapi_xenops.ml\", line 2088, characters 3-9: Assertion failed']\nTraceback (most recent call last):\n  File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 352, in unplug_vbd\n    session.call_xenapi('VBD.unplug', vbd_ref)\n  File \"/opt/stack/nova/nova/virt/xenapi/driver.py\", line 719, in call_xenapi\n    return session.xenapi_request(method, args)\n  File \"/usr/local/lib/python2.7/dist-packages/XenAPI.py\", line 133, in xenapi_request\n    result = _parse_result(getattr(self, methodname)(*full_params))\n  File \"/usr/local/lib/python2.7/dist-packages/XenAPI.py\", line 203, in _parse_result\n    raise Failure(result['ErrorDescription'])\nFailure: ['INTERNAL_ERROR', 'File \"xapi_xenops.ml\", line 2088, characters 3-9: Assertion failed']\n...\n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] ['OPERATION_NOT_ALLOWED', \"VBD '0d03a77b-6ae3-2e16-1a63-d771e374f513' still attached to '98bbd5ba-dc99-6c96-32be-b170cf8c9dd6'\"]\nTraceback (most recent call last):\n  File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 379, in destroy_vbd\n    session.call_xenapi('VBD.destroy', vbd_ref)\n  File \"/opt/stack/nova/nova/virt/xenapi/driver.py\", line 719, in call_xenapi\n    return session.xenapi_request(method, args)\n  File \"/usr/local/lib/python2.7/dist-packages/XenAPI.py\", line 133, in xenapi_request\n    result = _parse_result(getattr(self, methodname)(*full_params))\n  File \"/usr/local/lib/python2.7/dist-packages/XenAPI.py\", line 203, in _parse_result\n    raise Failure(result['ErrorDescription'])\nFailure: ['OPERATION_NOT_ALLOWED', \"VBD '0d03a77b-6ae3-2e16-1a63-d771e374f513' still attached to '98bbd5ba-dc99-6c96-32be-b170cf8c9dd6'\"]\n\n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] Destroying VBD for VDI OpaqueRef:d93e1482-aba5-e919-7733-7db2f3d2ccd6 done. from (pid=26384) vdi_attached_here /opt/stack/nova/nova/virt/xenapi/vm_utils.py:1934\n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] [instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Failed to spawn, rolling back\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Traceback (most recent call last):\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 498, in spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     kernel_file, ramdisk_file = create_kernel_ramdisk_step(undo_mgr)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 153, in inner\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     rv = f(*args, **kwargs)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 390, in create_kernel_ramdisk_step\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     instance, context, name_label)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 191, in _create_kernel_and_ramdisk\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     vm_utils.ImageType.KERNEL)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1019, in create_kernel_image\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     image_id, image_type)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1331, in _fetch_disk_image\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     session, image.stream_to, image_type, virtual_size, dev)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     self.gen.next()\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1927, in vdi_attached_here\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     unplug_vbd(session, vbd_ref)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 367, in unplug_vbd\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     _('Unable to unplug VBD %s') % vbd_ref)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] StorageError: Unable to unplug VBD OpaqueRef:f0fafa75-763d-db2d-d022-6e16b9808e44\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] \n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] [instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Instance failed to spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Traceback (most recent call last):\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/compute/manager.py\", line 1286, in _spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     block_device_info)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/driver.py\", line 180, in spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     admin_password, network_info, block_device_info)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 514, in spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     undo_mgr.rollback_and_reraise(msg=msg, instance=instance)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/utils.py\", line 981, in rollback_and_reraise\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     self._rollback()\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 498, in spawn\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     kernel_file, ramdisk_file = create_kernel_ramdisk_step(undo_mgr)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 153, in inner\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     rv = f(*args, **kwargs)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 390, in create_kernel_ramdisk_step\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     instance, context, name_label)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vmops.py\", line 191, in _create_kernel_and_ramdisk\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     vm_utils.ImageType.KERNEL)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1019, in create_kernel_image\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     image_id, image_type)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1331, in _fetch_disk_image\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     session, image.stream_to, image_type, virtual_size, dev)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     self.gen.next()\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 1927, in vdi_attached_here\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     unplug_vbd(session, vbd_ref)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]   File \"/opt/stack/nova/nova/virt/xenapi/vm_utils.py\", line 367, in unplug_vbd\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8]     _('Unable to unplug VBD %s') % vbd_ref)\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] StorageError: Unable to unplug VBD OpaqueRef:f0fafa75-763d-db2d-d022-6e16b9808e44\n[instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] \n[req-e64ceb14-3cd9-4734-b1d1-9cb416034503 demo demo] [instance: f2b36c4f-0c67-4a26-954c-aef3d2b9f7d8] Aborting claim: [Claim: 512 MB memory, 1 GB disk, 1 VCPUS] from (pid=26384) abort /opt/stack/nova/nova/compute/claims.py:97\n\nLooking at vm_utils.py:\n\ndef unplug_vbd(session, vbd_ref):\n    \"\"\"Unplug VBD from VM.\"\"\"\n    # Call VBD.unplug on the given VBD, with a retry if we get\n    # DEVICE_DETACH_REJECTED.  For reasons which we don't understand,\n    # we're seeing the device still in use, even when all processes\n    # using the device should be dead.\n    max_attempts = CONF.xenapi_num_vbd_unplug_retries + 1\n    for num_attempt in xrange(1, max_attempts + 1):\n        try:\n            session.call_xenapi('VBD.unplug', vbd_ref)\n            return\n        except session.XenAPI.Failure as exc:\n            err = len(exc.details) > 0 and exc.details[0]\n            if err == 'DEVICE_ALREADY_DETACHED':\n                LOG.info(_('VBD %s already detached'), vbd_ref)\n                return\n            elif err == 'DEVICE_DETACH_REJECTED':\n                LOG.info(_('VBD %(vbd_ref)s detach rejected, attempt'\n                           ' %(num_attempt)d/%(max_attempts)d'),\n                         {'vbd_ref': vbd_ref, 'num_attempt': num_attempt,\n                          'max_attempts': max_attempts})\n            else:\n                LOG.exception(exc)\n                raise volume_utils.StorageError(\n                        _('Unable to unplug VBD %s') % vbd_ref)\n\n        greenthread.sleep(1)\n\n    raise volume_utils.StorageError(\n            _('Reached maximum number of retries trying to unplug VBD %s')\n            % vbd_ref)\n\nIt is prepared to handle such situations. Maybe xapi returns with a different error code?\n\nMy XenServer is 6.2:\n\n[root@megadodo ~]# cat /etc/xensource-inventory \nBUILD_NUMBER='70446c'\nPLATFORM_VERSION='1.8.0'\nDOM0_VCPUS='4'\nINSTALLATION_UUID='4d944fd3-8b48-47a1-9b13-155ae6923a37'\nMANAGEMENT_ADDRESS_TYPE='IPv4'\nPRODUCT_VERSION_TEXT_SHORT='6.2'\nBRAND_CONSOLE='XenCenter'\nPRIMARY_DISK='/dev/disk/by-id/scsi-SATA_SAMSUNG_HE253GJ_S2B5J90ZC12322'\nPRODUCT_BRAND='XenServer'\nINSTALLATION_DATE='2013-08-21 08:05:18.227510'\nPLATFORM_NAME='XCP'\nCOMPANY_NAME_SHORT='Citrix'\nPRODUCT_VERSION_TEXT='6.2'\nBACKUP_PARTITION='/dev/disk/by-id/scsi-SATA_SAMSUNG_HE253GJ_S2B5J90ZC12322-part2'\nPRODUCT_VERSION='6.2.0'\nXEN_VERSION='4.1.5'\nKERNEL_VERSION='2.6.32.43-0.4.1.xs1.8.0.835.170778xen'\nMANAGEMENT_INTERFACE='xenbr0'\nDOM0_MEM='752'\nCOMPANY_NAME='Citrix Systems, Inc.'\nPRODUCT_NAME='xenenterprise'\nCONTROL_DOMAIN_UUID='4e04643c-0506-408c-9a84-e45fe055ce90'", 
            "date_created": "2013-08-28 16:31:27.553499+00:00", 
            "author": "https://api.launchpad.net/1.0/~mate-lakat"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/44099", 
            "date_created": "2013-08-28 17:23:08.745205+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "progress has stalled, review is abandoned. \nde-assigning for now.", 
            "date_created": "2013-10-10 13:36:27.373097+00:00", 
            "author": "https://api.launchpad.net/1.0/~johngarbutt"
        }, 
        {
            "content": "Let me handle this. This is important, to keep the builds stable.", 
            "date_created": "2013-10-10 21:20:27.287455+00:00", 
            "author": "https://api.launchpad.net/1.0/~mate-lakat"
        }, 
        {
            "content": "See: https://review.openstack.org/#/c/51218", 
            "date_created": "2013-10-11 13:53:41.809072+00:00", 
            "author": "https://api.launchpad.net/1.0/~johngarbutt"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/51218\nCommitted: http://github.com/openstack/nova/commit/f9d2b06c6c6fd9cac91993bb38f0d96edc385366\nSubmitter: Jenkins\nBranch:    master\n\ncommit f9d2b06c6c6fd9cac91993bb38f0d96edc385366\nAuthor: John Garbutt <email address hidden>\nDate:   Fri Oct 11 14:46:40 2013 +0100\n\n    xenapi: workaround for failing vbd detach\n    \n    Sometimes xapi returns with an internal error during unplug_vbd. This\n    patch adds a workaround for XenServer 6.2 by inspecting the error\n    message, and retry the unplug.\n    \n    In addition, this also ensures that sleep is no longer called after the\n    last retry before raising an exception.\n    \n    Fixes bug 1217972\n    Change-Id: I7b86325714e38b00a2f51bbf083b5532a6c51fa9\n", 
            "date_created": "2013-10-30 16:45:56.039935+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "The fix uploaded above does not fully address this issue;  The root cause of the issue is multiple plug/unplugs occurring simultaneously.\n\nComplete patch at https://review.openstack.org/59856", 
            "date_created": "2013-12-03 22:35:17.399867+00:00", 
            "author": "https://api.launchpad.net/1.0/~bob-ball"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/59856\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=766dff6b70c0dd5cfe4bd42ba654ec7964bc6128\nSubmitter: Jenkins\nBranch:    master\n\ncommit 766dff6b70c0dd5cfe4bd42ba654ec7964bc6128\nAuthor: Bob Ball <email address hidden>\nDate:   Tue Dec 3 22:27:38 2013 +0000\n\n    XenAPI: Synchronize on all VBD plug/unplug per VM\n    \n    Dynamically adding or removing a device needs to be synchronized\n    to work around a bug in XenServer 6.1 and 6.2 where simultaneous\n    events can be partially ignored, leading to a failure to plug or\n    unplug.  The bug is between two internal components in XenServer\n    which pass messages - the first component will ignore all messages\n    from the second while a plug/unplug is in progress, expecting\n    only one message to be received.  If two plug/unplugs occur in\n    this time, an internal assertion is raised as XAPIs internal state\n    is inconsistent.\n    \n    Change I7b86325714e38b00a2f51bbf083b5532a6c51fa9 attempted to\n    work around the issue by retrying - however that does not catch\n    all failures.  This change should eliminate some of the known\n    INTERNAL_ERROR failures, but not all, so I7b8 need not be\n    reverted.\n    \n    Change Ie7a64c481a9e3874df9d5924fbb050ac7ab117db does the same\n    as this, but only for VBD.plug.\n    \n    Change-Id: If78d4e5f1dd84f1d4a588f25b8f887a7b125bbea\n    Closes-bug: 1217972\n", 
            "date_created": "2013-12-13 08:57:40.259317+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "I have the same log when i boot a vm first time by 2014.1.2 version. Is this bug fixed or is there something wrong else in my config file?", 
            "date_created": "2014-08-20 04:02:27.444205+00:00", 
            "author": "https://api.launchpad.net/1.0/~3630034-y"
        }, 
        {
            "content": "sorry, it is not all the same with this bug. i will post a new question.", 
            "date_created": "2014-08-20 04:42:55.318555+00:00", 
            "author": "https://api.launchpad.net/1.0/~3630034-y"
        }
    ], 
    "closed": "2014-01-22 16:14:39.232071+00:00"
}