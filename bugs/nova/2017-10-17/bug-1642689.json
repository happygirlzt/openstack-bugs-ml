{
    "status": "Fix Released", 
    "last_updated": "2016-12-19 12:02:12.532780+00:00", 
    "description": "Seeing this failure in this job:\n\ntempest.api.volume.test_volumes_snapshots.VolumesV1SnapshotTestJSON.test_snapshot_create_with_volume_in_use[compute,id-b467b54c-07a4-446d-a1cf-651dedcc3ff1]\n\nWhile detaching a volume on cleanup it times out waiting for the volume status to go from 'in-use' back to 'available':\n\n2016-11-17 11:58:59.110301 | Captured traceback:\n2016-11-17 11:58:59.110310 | ~~~~~~~~~~~~~~~~~~~\n2016-11-17 11:58:59.110322 |     Traceback (most recent call last):\n2016-11-17 11:58:59.110342 |       File \"tempest/common/waiters.py\", line 189, in wait_for_volume_status\n2016-11-17 11:58:59.110356 |         raise lib_exc.TimeoutException(message)\n2016-11-17 11:58:59.110373 |     tempest.lib.exceptions.TimeoutException: Request timed out\n2016-11-17 11:58:59.110405 |     Details: Volume db12eda4-4ce6-4f00-a4e0-9df115f230e5 failed to reach available status (current in-use) within the required time (196 s).\n\nThe volume detach request is here:\n\n2016-11-17 11:58:59.031058 |     2016-11-17 11:38:55,018 8316 INFO     [tempest.lib.common.rest_client] Request (VolumesV1SnapshotTestJSON:_run_cleanups): 202 DELETE http://127.0.0.1:8774/v2.1/servers/584a65b5-07fa-4994-a2d5-1676d0e13a8c/os-volume_attachments/db12eda4-4ce6-4f00-a4e0-9df115f230e5 0.277s\n2016-11-17 11:58:59.031103 |     2016-11-17 11:38:55,018 8316 DEBUG    [tempest.lib.common.rest_client] Request - Headers: {'X-Auth-Token': '<omitted>', 'Accept': 'application/json', 'Content-Type': 'application/json'}\n2016-11-17 11:58:59.031113 |             Body: None\n2016-11-17 11:58:59.031235 |         Response - Headers: {'content-location': 'http://127.0.0.1:8774/v2.1/servers/584a65b5-07fa-4994-a2d5-1676d0e13a8c/os-volume_attachments/db12eda4-4ce6-4f00-a4e0-9df115f230e5', 'content-type': 'application/json', 'x-openstack-nova-api-version': '2.1', 'date': 'Thu, 17 Nov 2016 11:38:55 GMT', 'content-length': '0', 'status': '202', 'connection': 'close', 'x-compute-request-id': 'req-9f0541d3-6eec-4793-8852-7bd01708932e', 'openstack-api-version': 'compute 2.1', 'vary': 'X-OpenStack-Nova-API-Version'}\n2016-11-17 11:58:59.031248 |             Body: \n\nFollowing the req-9f0541d3-6eec-4793-8852-7bd01708932e request ID to the compute logs we see this detach failure:\n\nhttp://logs.openstack.org/00/398800/1/gate/gate-tempest-dsvm-full-devstack-plugin-ceph-ubuntu-xenial/a387fb0/logs/screen-n-cpu.txt.gz?level=TRACE#_2016-11-17_11_39_00_649\n\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [req-9f0541d3-6eec-4793-8852-7bd01708932e tempest-VolumesV1SnapshotTestJSON-1819335716 tempest-VolumesV1SnapshotTestJSON-1819335716] [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c] Failed to detach volume db12eda4-4ce6-4f00-a4e0-9df115f230e5 from /dev/vdb\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c] Traceback (most recent call last):\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 4757, in _driver_detach_volume\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     encryption=encryption)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 1307, in detach_volume\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     wait_for_detach()\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/oslo_service/loopingcall.py\", line 385, in func\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     return evt.wait()\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 121, in wait\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     return hubs.get_hub().switch()\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 294, in switch\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     return self.greenlet.switch()\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/oslo_service/loopingcall.py\", line 136, in _run_loop\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     result = func(*self.args, **self.kw)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/oslo_service/loopingcall.py\", line 356, in _func\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     result = f(*args, **kwargs)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/opt/stack/new/nova/nova/virt/libvirt/guest.py\", line 380, in _do_wait_and_retry_detach\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     self.detach_device(config, persistent=False, live=live)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/opt/stack/new/nova/nova/virt/libvirt/guest.py\", line 401, in detach_device\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     self._domain.detachDeviceFlags(device_xml, flags=flags)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 186, in doit\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 144, in proxy_call\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     rv = execute(f, *args, **kwargs)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 125, in execute\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     six.reraise(c, e, tb)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 83, in tworker\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     rv = meth(*args, **kwargs)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/libvirt.py\", line 1190, in detachDeviceFlags\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     if ret == -1: raise libvirtError ('virDomainDetachDeviceFlags() failed', dom=self)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c] libvirtError: operation failed: disk vdb not found\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c] \n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=message%3A%5C%22Failed%20to%20detach%20volume%5C%22%20AND%20message%3A%5C%22_do_wait_and_retry_detach%5C%22%20AND%20message%3A%5C%22libvirtError%3A%20operation%20failed%3A%20disk%5C%22%20AND%20message%3A%5C%22not%20found%5C%22%20AND%20tags%3A%5C%22screen-n-cpu.txt%5C%22&from=7d\n\n21 hits in the last 7 days, check and gate, all failures, 90% in ceph jobs.\n\nLooks like that wait for detach code should be handling the not found from libvirt and considering the job complete.", 
    "tags": [
        "ceph", 
        "libvirt", 
        "volumes"
    ], 
    "importance": "Medium", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1642689", 
    "owner": "https://api.launchpad.net/1.0/~int32bit", 
    "id": 1642689, 
    "index": 4685, 
    "openned": "2016-11-17 18:03:32.378925+00:00", 
    "created": "2016-11-17 18:03:32.378925+00:00", 
    "title": "ceph: volume detach fails with 'libvirtError: operation failed: disk vdb not found'", 
    "comments": [
        {
            "content": "Seeing this failure in this job:\n\ntempest.api.volume.test_volumes_snapshots.VolumesV1SnapshotTestJSON.test_snapshot_create_with_volume_in_use[compute,id-b467b54c-07a4-446d-a1cf-651dedcc3ff1]\n\nWhile detaching a volume on cleanup it times out waiting for the volume status to go from 'in-use' back to 'available':\n\n2016-11-17 11:58:59.110301 | Captured traceback:\n2016-11-17 11:58:59.110310 | ~~~~~~~~~~~~~~~~~~~\n2016-11-17 11:58:59.110322 |     Traceback (most recent call last):\n2016-11-17 11:58:59.110342 |       File \"tempest/common/waiters.py\", line 189, in wait_for_volume_status\n2016-11-17 11:58:59.110356 |         raise lib_exc.TimeoutException(message)\n2016-11-17 11:58:59.110373 |     tempest.lib.exceptions.TimeoutException: Request timed out\n2016-11-17 11:58:59.110405 |     Details: Volume db12eda4-4ce6-4f00-a4e0-9df115f230e5 failed to reach available status (current in-use) within the required time (196 s).\n\nThe volume detach request is here:\n\n2016-11-17 11:58:59.031058 |     2016-11-17 11:38:55,018 8316 INFO     [tempest.lib.common.rest_client] Request (VolumesV1SnapshotTestJSON:_run_cleanups): 202 DELETE http://127.0.0.1:8774/v2.1/servers/584a65b5-07fa-4994-a2d5-1676d0e13a8c/os-volume_attachments/db12eda4-4ce6-4f00-a4e0-9df115f230e5 0.277s\n2016-11-17 11:58:59.031103 |     2016-11-17 11:38:55,018 8316 DEBUG    [tempest.lib.common.rest_client] Request - Headers: {'X-Auth-Token': '<omitted>', 'Accept': 'application/json', 'Content-Type': 'application/json'}\n2016-11-17 11:58:59.031113 |             Body: None\n2016-11-17 11:58:59.031235 |         Response - Headers: {'content-location': 'http://127.0.0.1:8774/v2.1/servers/584a65b5-07fa-4994-a2d5-1676d0e13a8c/os-volume_attachments/db12eda4-4ce6-4f00-a4e0-9df115f230e5', 'content-type': 'application/json', 'x-openstack-nova-api-version': '2.1', 'date': 'Thu, 17 Nov 2016 11:38:55 GMT', 'content-length': '0', 'status': '202', 'connection': 'close', 'x-compute-request-id': 'req-9f0541d3-6eec-4793-8852-7bd01708932e', 'openstack-api-version': 'compute 2.1', 'vary': 'X-OpenStack-Nova-API-Version'}\n2016-11-17 11:58:59.031248 |             Body: \n\nFollowing the req-9f0541d3-6eec-4793-8852-7bd01708932e request ID to the compute logs we see this detach failure:\n\nhttp://logs.openstack.org/00/398800/1/gate/gate-tempest-dsvm-full-devstack-plugin-ceph-ubuntu-xenial/a387fb0/logs/screen-n-cpu.txt.gz?level=TRACE#_2016-11-17_11_39_00_649\n\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [req-9f0541d3-6eec-4793-8852-7bd01708932e tempest-VolumesV1SnapshotTestJSON-1819335716 tempest-VolumesV1SnapshotTestJSON-1819335716] [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c] Failed to detach volume db12eda4-4ce6-4f00-a4e0-9df115f230e5 from /dev/vdb\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c] Traceback (most recent call last):\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/opt/stack/new/nova/nova/compute/manager.py\", line 4757, in _driver_detach_volume\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     encryption=encryption)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/opt/stack/new/nova/nova/virt/libvirt/driver.py\", line 1307, in detach_volume\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     wait_for_detach()\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/oslo_service/loopingcall.py\", line 385, in func\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     return evt.wait()\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/event.py\", line 121, in wait\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     return hubs.get_hub().switch()\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/hubs/hub.py\", line 294, in switch\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     return self.greenlet.switch()\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/oslo_service/loopingcall.py\", line 136, in _run_loop\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     result = func(*self.args, **self.kw)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/oslo_service/loopingcall.py\", line 356, in _func\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     result = f(*args, **kwargs)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/opt/stack/new/nova/nova/virt/libvirt/guest.py\", line 380, in _do_wait_and_retry_detach\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     self.detach_device(config, persistent=False, live=live)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/opt/stack/new/nova/nova/virt/libvirt/guest.py\", line 401, in detach_device\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     self._domain.detachDeviceFlags(device_xml, flags=flags)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 186, in doit\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 144, in proxy_call\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     rv = execute(f, *args, **kwargs)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 125, in execute\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     six.reraise(c, e, tb)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/eventlet/tpool.py\", line 83, in tworker\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     rv = meth(*args, **kwargs)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]   File \"/usr/local/lib/python2.7/dist-packages/libvirt.py\", line 1190, in detachDeviceFlags\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c]     if ret == -1: raise libvirtError ('virDomainDetachDeviceFlags() failed', dom=self)\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c] libvirtError: operation failed: disk vdb not found\n2016-11-17 11:39:00.649 2249 ERROR nova.compute.manager [instance: 584a65b5-07fa-4994-a2d5-1676d0e13a8c] \n\nhttp://logstash.openstack.org/#dashboard/file/logstash.json?query=message%3A%5C%22Failed%20to%20detach%20volume%5C%22%20AND%20message%3A%5C%22_do_wait_and_retry_detach%5C%22%20AND%20message%3A%5C%22libvirtError%3A%20operation%20failed%3A%20disk%5C%22%20AND%20message%3A%5C%22not%20found%5C%22%20AND%20tags%3A%5C%22screen-n-cpu.txt%5C%22&from=7d\n\n21 hits in the last 7 days, check and gate, all failures, 90% in ceph jobs.\n\nLooks like that wait for detach code should be handling the not found from libvirt and considering the job complete.", 
            "date_created": "2016-11-17 18:03:32.378925+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "@int32bit, are you working on a fix for this? If not, please remove yourself as assignee so someone else can try to fix this.", 
            "date_created": "2016-11-22 14:22:51.184529+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Yes, I'm working on it, but if someone have fixed it, please free to re-assign it.", 
            "date_created": "2016-11-23 06:47:49.926249+00:00", 
            "author": "https://api.launchpad.net/1.0/~int32bit"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/401375", 
            "date_created": "2016-11-23 18:17:03.216015+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: stable/newton\nReview: https://review.openstack.org/404508", 
            "date_created": "2016-11-30 02:47:28.089596+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/401375\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=d079f37f7ccb8da9e74416cedce4f194b66ee1d0\nSubmitter: Jenkins\nBranch:    master\n\ncommit d079f37f7ccb8da9e74416cedce4f194b66ee1d0\nAuthor: int32bit <email address hidden>\nDate:   Wed Nov 23 18:21:16 2016 +0800\n\n    Fix wait for detach code to handle 'disk not found error'\n    \n    Currently, the code does an initial detach from the persistent and\n    transient domains in one call, then follows up with a call of the\n    retryable function, which first checks the domain xml before retrying\n    the transient domain detach. If the transient domain detach (which is\n    asynchronous) completes after we checked the domain xml, trying to\n    detach it again will raise a LibvirtError exception. Then, our loop\n    code in `_do_wait_and_retry_detach` doesn't catch it and will respond\n    with error. We should be handling the `disk not found error` from\n    libvirt and consider the job complete.\n    \n    Closes-Bug: #1642689\n    \n    Change-Id: I131aaf28d2f5d5d964d4045e3d7d62207079cfb0\n", 
            "date_created": "2016-11-30 04:41:33.537600+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/404508\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=93599acb968e15b3bd977dafc294e1b48d50c8f0\nSubmitter: Jenkins\nBranch:    stable/newton\n\ncommit 93599acb968e15b3bd977dafc294e1b48d50c8f0\nAuthor: int32bit <email address hidden>\nDate:   Wed Nov 23 18:21:16 2016 +0800\n\n    Fix wait for detach code to handle 'disk not found error'\n    \n    Currently, the code does an initial detach from the persistent and\n    transient domains in one call, then follows up with a call of the\n    retryable function, which first checks the domain xml before retrying\n    the transient domain detach. If the transient domain detach (which is\n    asynchronous) completes after we checked the domain xml, trying to\n    detach it again will raise a LibvirtError exception. Then, our loop\n    code in `_do_wait_and_retry_detach` doesn't catch it and will respond\n    with error. We should be handling the `disk not found error` from\n    libvirt and consider the job complete.\n    \n    Closes-Bug: #1642689\n    \n    Change-Id: I131aaf28d2f5d5d964d4045e3d7d62207079cfb0\n    (cherry picked from commit d079f37f7ccb8da9e74416cedce4f194b66ee1d0)\n", 
            "date_created": "2016-12-02 08:43:35.045709+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 15.0.0.0b2 development milestone.", 
            "date_created": "2016-12-15 17:34:58.717154+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "This issue was fixed in the openstack/nova 14.0.3 release.", 
            "date_created": "2016-12-19 12:02:11.946784+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2016-11-30 04:41:30.451715+00:00"
}