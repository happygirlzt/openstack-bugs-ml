{
    "status": "Fix Released", 
    "last_updated": "2012-04-05 10:08:41.129226+00:00", 
    "description": "I was using devstack on trunk. I attached a volume at /dev/sdb to a vm using nova client but that device already existed. The nova command returned without error but obviously did not do anything and the following showed up in the nova logs:\n\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,164 ERROR nova.compute.manager [aa780ef5-4591-4d5f-b113-9ae63568647b demo 2] insta\\\nnce 3d37d21e-8fba-46a4-a0e1-d137f1d17597: attach failed /dev/vdb, removing#012(nova.compute.manager): TRACE: Traceback (most rec\\\nent call last):#012(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 1529, in attach_volume#\\\n012(nova.compute.manager): TRACE:     mountpoint)#012(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/exception.py\", \\\nline 130, in wrapped#012(nova.compute.manager): TRACE:     return f(*args, **kw)#012(nova.compute.manager): TRACE:   File \"/opt/\\\nstack/nova/nova/virt/libvirt/connection.py\", line 428, in attach_volume#012(nova.compute.manager): TRACE:     virt_dom.attachDev\\\nice(xml)#012(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 298, in attachDevice#012(n\\\nova.compute.manager): TRACE:     if ret == -1: raise libvirtError ('virDomainAttachDevice() failed', dom=self)#012(nova.compute.\\\nmanager): TRACE: libvirtError: operation failed: target vdb already exists#012(nova.compute.manager): TRACE:\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,194 DEBUG nova.rpc [-] Making asynchronous call on volume.xg06 ... from (pid=8603)\\\n multicall /opt/stack/nova/nova/rpc/impl_kombu.py:759\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,195 DEBUG nova.rpc [-] MSG_ID is 6735676270c241c4859384769641ca56 from (pid=8603) \\\nmulticall /opt/stack/nova/nova/rpc/impl_kombu.py:762\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,202 DEBUG nova.rpc [-] received {u'_context_roles': [u'Member', u'sysadmin', u'net\\\nadmin'], u'_msg_id': u'6735676270c241c4859384769641ca56', u'_context_read_deleted': u'no', u'_context_request_id': u'aa780ef5-45\\\n91-4d5f-b113-9ae63568647b', u'args': {u'volume_id': 1, u'address': u'172.18.0.146'}, u'_context_auth_token': u'07302338-e85e-49c\\\nf-a50c-c230a30ad637', u'_context_strategy': u'keystone', u'_context_is_admin': True, u'_context_project_id': u'2', u'_context_ti\\\nmestamp': u'2012-01-11T19:14:42.636546', u'_context_user_id': u'demo', u'method': u'terminate_connection', u'_context_remote_add\\\nress': u'172.18.0.146'} from (pid=8709) __call__ /opt/stack/nova/nova/rpc/impl_kombu.py:629\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,202 DEBUG nova.rpc [-] unpacked context: {'user_id': u'demo', 'roles': [u'Member',\\\n u'sysadmin', u'netadmin'], 'timestamp': u'2012-01-11T19:14:42.636546', 'auth_token': u'07302338-e85e-49cf-a50c-c230a30ad637', '\\\nmsg_id': u'6735676270c241c4859384769641ca56', 'remote_address': u'172.18.0.146', 'strategy': u'keystone', 'is_admin': True, 'req\\\nuest_id': u'aa780ef5-4591-4d5f-b113-9ae63568647b', 'project_id': u'2', 'read_deleted': u'no'} from (pid=8709) _unpack_context /o\\\npt/stack/nova/nova/rpc/impl_kombu.py:675\nJan 11 14:14:45 xg06eth0 2012-01-11 14:14:45,245 ERROR nova.rpc [-] Exception during message handling#012(nova.rpc): TRACE: Trac\\\neback (most recent call last):#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/rpc/impl_kombu.py\", line 649, in _process_data\\\n#012(nova.rpc): TRACE:     rval = node_func(context=ctxt, **node_args)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/except\\\nion.py\", line 130, in wrapped#012(nova.rpc): TRACE:     return f(*args, **kw)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova\\\n/compute/manager.py\", line 126, in decorated_function#012(nova.rpc): TRACE:     function(self, context, instance_uuid, *args, **\\\nkwargs)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 149, in decorated_function#012(nova.rpc): T\\\nRACE:     self.add_instance_fault_from_exc(context, instance_uuid, e)#012(nova.rpc): TRACE:   File \"/usr/lib/python2.7/contextli\\\nb.py\", line 24, in __exit__#012(nova.rpc): TRACE:     self.gen.next()#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/compute\\\n/manager.py\", line 144, in decorated_function#012(nova.rpc): TRACE:     return function(self, context, instance_uuid, *args, **k\\\nwargs)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 1536, in attach_volume#012(nova.rpc): TRACE:\\\n     address)#012(nova.rpc): TRACE:   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__#012(nova.rpc): TRACE:     se\\\nlf.gen.next()#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 1529, in attach_volume#012(nova.rpc):\\\n TRACE:     mountpoint)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/exception.py\", line 130, in wrapped#012(nova.rpc): TR\\\nACE:     return f(*args, **kw)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 428, in atta\\\nch_volume#012(nova.rpc): TRACE:     virt_dom.attachDevice(xml)#012(nova.rpc): TRACE:   File \"/usr/lib/python2.7/dist-packages/li\\\nbvirt.py\", line 298, in attachDevice#012(nova.rpc): TRACE:     if ret == -1: raise libvirtError ('virDomainAttachDevice() failed\\\n', dom=self)#012(n", 
    "tags": [], 
    "importance": "High", 
    "heat": 8, 
    "link": "https://bugs.launchpad.net/nova/+bug/914974", 
    "owner": "https://api.launchpad.net/1.0/~bcwaldon", 
    "id": 914974, 
    "index": 552, 
    "openned": "2012-01-11 19:31:54.815564+00:00", 
    "created": "2012-01-11 19:31:54.815564+00:00", 
    "title": "Nova backtrace in log when attaching a volume at an already existing drive", 
    "comments": [
        {
            "content": "I was using devstack on trunk. I attached a volume at /dev/sdb to a vm using nova client but that device already existed. The nova command returned without error but obviously did not do anything and the following showed up in the nova logs:\n\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,164 ERROR nova.compute.manager [aa780ef5-4591-4d5f-b113-9ae63568647b demo 2] insta\\\nnce 3d37d21e-8fba-46a4-a0e1-d137f1d17597: attach failed /dev/vdb, removing#012(nova.compute.manager): TRACE: Traceback (most rec\\\nent call last):#012(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 1529, in attach_volume#\\\n012(nova.compute.manager): TRACE:     mountpoint)#012(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/exception.py\", \\\nline 130, in wrapped#012(nova.compute.manager): TRACE:     return f(*args, **kw)#012(nova.compute.manager): TRACE:   File \"/opt/\\\nstack/nova/nova/virt/libvirt/connection.py\", line 428, in attach_volume#012(nova.compute.manager): TRACE:     virt_dom.attachDev\\\nice(xml)#012(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 298, in attachDevice#012(n\\\nova.compute.manager): TRACE:     if ret == -1: raise libvirtError ('virDomainAttachDevice() failed', dom=self)#012(nova.compute.\\\nmanager): TRACE: libvirtError: operation failed: target vdb already exists#012(nova.compute.manager): TRACE:\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,194 DEBUG nova.rpc [-] Making asynchronous call on volume.xg06 ... from (pid=8603)\\\n multicall /opt/stack/nova/nova/rpc/impl_kombu.py:759\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,195 DEBUG nova.rpc [-] MSG_ID is 6735676270c241c4859384769641ca56 from (pid=8603) \\\nmulticall /opt/stack/nova/nova/rpc/impl_kombu.py:762\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,202 DEBUG nova.rpc [-] received {u'_context_roles': [u'Member', u'sysadmin', u'net\\\nadmin'], u'_msg_id': u'6735676270c241c4859384769641ca56', u'_context_read_deleted': u'no', u'_context_request_id': u'aa780ef5-45\\\n91-4d5f-b113-9ae63568647b', u'args': {u'volume_id': 1, u'address': u'172.18.0.146'}, u'_context_auth_token': u'07302338-e85e-49c\\\nf-a50c-c230a30ad637', u'_context_strategy': u'keystone', u'_context_is_admin': True, u'_context_project_id': u'2', u'_context_ti\\\nmestamp': u'2012-01-11T19:14:42.636546', u'_context_user_id': u'demo', u'method': u'terminate_connection', u'_context_remote_add\\\nress': u'172.18.0.146'} from (pid=8709) __call__ /opt/stack/nova/nova/rpc/impl_kombu.py:629\nJan 11 14:14:45 xg06eth0  2012-01-11 14:14:45,202 DEBUG nova.rpc [-] unpacked context: {'user_id': u'demo', 'roles': [u'Member',\\\n u'sysadmin', u'netadmin'], 'timestamp': u'2012-01-11T19:14:42.636546', 'auth_token': u'07302338-e85e-49cf-a50c-c230a30ad637', '\\\nmsg_id': u'6735676270c241c4859384769641ca56', 'remote_address': u'172.18.0.146', 'strategy': u'keystone', 'is_admin': True, 'req\\\nuest_id': u'aa780ef5-4591-4d5f-b113-9ae63568647b', 'project_id': u'2', 'read_deleted': u'no'} from (pid=8709) _unpack_context /o\\\npt/stack/nova/nova/rpc/impl_kombu.py:675\nJan 11 14:14:45 xg06eth0 2012-01-11 14:14:45,245 ERROR nova.rpc [-] Exception during message handling#012(nova.rpc): TRACE: Trac\\\neback (most recent call last):#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/rpc/impl_kombu.py\", line 649, in _process_data\\\n#012(nova.rpc): TRACE:     rval = node_func(context=ctxt, **node_args)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/except\\\nion.py\", line 130, in wrapped#012(nova.rpc): TRACE:     return f(*args, **kw)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova\\\n/compute/manager.py\", line 126, in decorated_function#012(nova.rpc): TRACE:     function(self, context, instance_uuid, *args, **\\\nkwargs)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 149, in decorated_function#012(nova.rpc): T\\\nRACE:     self.add_instance_fault_from_exc(context, instance_uuid, e)#012(nova.rpc): TRACE:   File \"/usr/lib/python2.7/contextli\\\nb.py\", line 24, in __exit__#012(nova.rpc): TRACE:     self.gen.next()#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/compute\\\n/manager.py\", line 144, in decorated_function#012(nova.rpc): TRACE:     return function(self, context, instance_uuid, *args, **k\\\nwargs)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 1536, in attach_volume#012(nova.rpc): TRACE:\\\n     address)#012(nova.rpc): TRACE:   File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__#012(nova.rpc): TRACE:     se\\\nlf.gen.next()#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 1529, in attach_volume#012(nova.rpc):\\\n TRACE:     mountpoint)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/exception.py\", line 130, in wrapped#012(nova.rpc): TR\\\nACE:     return f(*args, **kw)#012(nova.rpc): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 428, in atta\\\nch_volume#012(nova.rpc): TRACE:     virt_dom.attachDevice(xml)#012(nova.rpc): TRACE:   File \"/usr/lib/python2.7/dist-packages/li\\\nbvirt.py\", line 298, in attachDevice#012(nova.rpc): TRACE:     if ret == -1: raise libvirtError ('virDomainAttachDevice() failed\\\n', dom=self)#012(n", 
            "date_created": "2012-01-11 19:31:54.815564+00:00", 
            "author": "https://api.launchpad.net/1.0/~david-kranz"
        }, 
        {
            "content": "I was also not able to attach to vdc which was not already there. There were no errors while devstack was doing the nova volume stuff.\n\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,190 AUDIT nova.api.openstack.v2.contrib.volumes [229ab0dc-3085-4f4c-bb80-d8104c96b\\\nef8 demo 2] Attach volume 1 to instance 3d37d21e-8fba-46a4-a0e1-d137f1d17597 at /dev/vdc\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,265 DEBUG nova.rpc [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] Making asynchrono\\\nus cast on compute.xg06... from (pid=8466) cast /opt/stack/nova/nova/rpc/impl_kombu.py:784\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,268 DEBUG nova.rpc [-] received {u'_context_roles': [u'Member', u'sysadmin', u'net\\\nadmin'], u'_context_request_id': u'229ab0dc-3085-4f4c-bb80-d8104c96bef8', u'_context_read_deleted': u'no', u'args': {u'instance_\\\nuuid': u'3d37d21e-8fba-46a4-a0e1-d137f1d17597', u'mountpoint': u'/dev/vdc', u'volume_id': 1}, u'_context_auth_token': u'07302338\\\n-e85e-49cf-a50c-c230a30ad637', u'_context_strategy': u'keystone', u'_context_is_admin': False, u'_context_project_id': u'2', u'_\\\ncontext_timestamp': u'2012-01-11T19:41:58.186031', u'_context_user_id': u'demo', u'method': u'attach_volume', u'_context_remote_\\\naddress': u'172.18.0.146'} from (pid=8603) __call__ /opt/stack/nova/nova/rpc/impl_kombu.py:629\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,268 INFO nova.api.openstack.wsgi [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] htt\\\np://172.18.0.146:8774/v1.1/2/servers/3d37d21e-8fba-46a4-a0e1-d137f1d17597/os-volume_attachments returned with HTTP 200\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,268 DEBUG nova.rpc [-] unpacked context: {'user_id': u'demo', 'roles': [u'Member',\\\n u'sysadmin', u'netadmin'], 'timestamp': u'2012-01-11T19:41:58.186031', 'auth_token': u'07302338-e85e-49cf-a50c-c230a30ad637', '\\\nmsg_id': None, 'remote_address': u'172.18.0.146', 'strategy': u'keystone', 'is_admin': False, 'request_id': u'229ab0dc-3085-4f4c\\\n-bb80-d8104c96bef8', 'project_id': u'2', 'read_deleted': u'no'} from (pid=8603) _unpack_context /opt/stack/nova/nova/rpc/impl_ko\\\nmbu.py:675\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,269 INFO nova.compute.manager [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] check_\\\ninstance_lock: decorating: |<function attach_volume at 0x3393ed8>|\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,269 INFO nova.compute.manager [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] check_\\\ninstance_lock: arguments: |<nova.compute.manager.ComputeManager object at 0x31a96d0>| |<nova.rpc.impl_kombu.RpcContext object at\\\n 0x4a51fd0>| |3d37d21e-8fba-46a4-a0e1-d137f1d17597|\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,270 DEBUG nova.compute.manager [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] insta\\\nnce 3d37d21e-8fba-46a4-a0e1-d137f1d17597: getting locked state from (pid=8603) get_lock /opt/stack/nova/nova/compute/manager.py:\\\n1426\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,320 INFO nova.compute.manager [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] check_\\\ninstance_lock: locked: |False|\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,320 INFO nova.compute.manager [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] check_\\\ninstance_lock: admin: |False|\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,320 INFO nova.compute.manager [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] check_\\\ninstance_lock: executing: |<function attach_volume at 0x3393ed8>|\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,368 AUDIT nova.compute.manager [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] insta\\\nnce 3d37d21e-8fba-46a4-a0e1-d137f1d17597: attaching volume 1 to /dev/vdc\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,388 DEBUG nova.rpc [-] Making asynchronous call on volume.xg06 ... from (pid=8603)\\\n multicall /opt/stack/nova/nova/rpc/impl_kombu.py:759\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,388 DEBUG nova.rpc [-] MSG_ID is e23a4350fc494265ad48fde056b02613 from (pid=8603) \\\nmulticall /opt/stack/nova/nova/rpc/impl_kombu.py:762\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,395 DEBUG nova.rpc [-] received {u'_context_roles': [u'Member', u'sysadmin', u'net\\\nadmin'], u'_msg_id': u'e23a4350fc494265ad48fde056b02613', u'_context_read_deleted': u'no', u'_context_request_id': u'229ab0dc-30\\\n85-4f4c-bb80-d8104c96bef8', u'args': {u'volume_id': 1, u'address': u'172.18.0.146'}, u'_context_auth_token': u'07302338-e85e-49c\\\nf-a50c-c230a30ad637', u'_context_strategy': u'keystone', u'_context_is_admin': True, u'_context_project_id': u'2', u'_context_ti\\\nmestamp': u'2012-01-11T19:41:58.186031', u'_context_user_id': u'demo', u'method': u'initialize_connection', u'_context_remote_ad\\\ndress': u'172.18.0.146'} from (pid=8709) __call__ /opt/stack/nova/nova/rpc/impl_kombu.py:629\nJan 11 14:41:58 xg06eth0  2012-01-11 14:41:58,396 DEBUG nova.rpc [-] unpacked context: {'user_id': u'demo', 'roles': [u'Member',\\\n u'sysadmin', u'netadmin'], 'timestamp': u'2012-01-11T19:41:58.186031', 'auth_token': u'07302338-e85e-49cf-a50c-c230a30ad637', '\\\nmsg_id': u'e23a4350fc494265ad48fde056b02613', 'remote_address': u'172.18.0.146', 'strategy': u'keystone', 'is_admin': True, 'req\\\nuest_id': u'229ab0dc-3085-4f4c-bb80-d8104c96bef8', 'project_id': u'2', 'read_deleted': u'no'} from (pid=8709) _unpack_context /o\\\npt/stack/nova/nova/rpc/impl_kombu.py:675\nJan 11 14:41:59 xg06eth0  2012-01-11 14:41:59,288 DEBUG nova.utils [-] Running cmd (subprocess): sudo iscsiadm -m node -T iqn.20\\\n10-10.org.openstack:volume-00000001 -p 172.18.0.146:3260 from (pid=8603) execute /opt/stack/nova/nova/utils.py:199\nJan 11 14:41:59 xg06eth0 2012-01-11 14:41:59,303 DEBUG nova.virt.libvirt.volume [-] iscsiadm (): stdout=# BEGIN RECORD 2.0-871#0\\\n12node.name = iqn.2010-10.org.openstack:volume-00000001#012node.tpgt = -1#012node.startup = automatic#012iface.hwaddress = <empt\\\ny>#012iface.ipaddress = <empty>#012iface.iscsi_ifacename = default#012iface.net_ifacename = <empty>#012iface.transport_name = tc\\\np#012iface.initiatorname = <empty>#012node.discovery_address = <empty>#012node.discovery_port = 0#012node.discovery_type = stati\\\nc#012node.session.initial_cmdsn = 0#012node.session.initial_login_retry_max = 8#012node.session.xmit_thread_priority = -20#012no\\\nde.session.cmds_max = 128#012node.session.queue_depth = 32#012node.session.auth.authmethod = None#012node.session.auth.username \\\n= <empty>#012node.session.auth.password = <empty>#012node.session.auth.username_in = <empty>#012node.session.auth.password_in = \\\n<empty>#012node.session.timeo.replacement_timeout = 120#012node.session.err_timeo.abort_timeout = 15#012node.session.err_timeo.l\\\nu_reset_timeout = 20#012node.session.err_timeo.host_reset_timeout = 60#012node.session.iscsi.FastAbort = Yes#012node.session.isc\\\nsi.InitialR2T = No#012node.session.iscsi.ImmediateData = Yes#012node.session.iscsi.FirstBurstLength = 262144#012node.session.isc\\\nsi.MaxBurstLength = 16776192#012node.session.iscsi.DefaultTime2Retain = 0#012node.session.iscsi.DefaultTime2Wait = 2#012node.ses\\\nsion.iscsi.MaxConnections = 1#012node.session.iscsi.MaxOutstandingR2T = 1#012node.session.iscsi.ERL = 0#012node.conn[0].address \\\n= 172.18.0.146#012node.conn[0].port = 3260#012node.conn[0].startup = manual#012node.conn[0].tcp.window_size = 524288#012node.con\\\nn[0].tcp.type_of_service = 0#012node.conn[0].timeo.logout_timeout = 15#012node.conn[0].timeo.login_timeout = 15#012node.conn[0].\\\ntimeo.auth_timeout = 45#012node.conn[0].timeo.noop_out_interval = 5#012node.conn[0].timeo.noop_out_timeout = 5#012node.conn[0].i\\\nscsi.MaxRecvDataSegmentLength = 262144#012node.conn[0].iscsi.HeaderDigest = None#012node.conn[0].iscsi.DataDigest = None#012node\\\n.conn[0].iscsi.IFM\nJan 11 14:41:59 xg06eth0  2012-01-11 14:41:59,305 DEBUG nova.utils [-] Running cmd (subprocess): sudo iscsiadm -m node -T iqn.20\\\n10-10.org.openstack:volume-00000001 -p 172.18.0.146:3260 --login from (pid=8603) execute /opt/stack/nova/nova/utils.py:199\nJan 11 14:41:59 xg06eth0  2012-01-11 14:41:59,319 DEBUG nova.utils [-] Result was 255 from (pid=8603) execute /opt/stack/nova/no\\\nva/utils.py:215\nJan 11 14:41:59 xg06eth0  2012-01-11 14:41:59,320 ERROR nova.compute.manager [229ab0dc-3085-4f4c-bb80-d8104c96bef8 demo 2] insta\\\nnce 3d37d21e-8fba-46a4-a0e1-d137f1d17597: attach failed /dev/vdc, removing#012(nova.compute.manager): TRACE: Traceback (most rec\\\nent call last):#012(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/compute/manager.py\", line 1529, in attach_volume#\\\n012(nova.compute.manager): TRACE:     mountpoint)#012(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/exception.py\", \\\nline 130, in wrapped#012(nova.compute.manager): TRACE:     return f(*args, **kw)#012(nova.compute.manager): TRACE:   File \"/opt/\\\nstack/nova/nova/virt/libvirt/connection.py\", line 427, in attach_volume#012(nova.compute.manager): TRACE:     mount_device)#012(\\\nnova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/connection.py\", line 419, in volume_driver_method#012(no\\\nva.compute.manager): TRACE:     return method(connection_info, *args, **kwargs)#012(nova.compute.manager): TRACE:   File \"/opt/s\\\ntack/nova/nova/virt/libvirt/volume.py\", line 128, in connect_volume#012(nova.compute.manager): TRACE:     self._run_iscsiadm(isc\\\nsi_properties, (\"--login\",))#012(nova.compute.manager): TRACE:   File \"/opt/stack/nova/nova/virt/libvirt/volume.py\", line 96, in\\\n _run_iscsiadm#012(nova.compute.manager): TRACE:     check_exit_code=check_exit_code)#012(nova.compute.manager): TRACE:   File \"\\\n/opt/stack/nova/nova/utils.py\", line 223, in execute#012(nova.compute.manager): TRACE:     cmd=' '.join(cmd))#012(nova.compute.m\\\nanager): TRACE: ProcessExecutionError: Unexpected error while running command.#012(nova.compute.manager): TRACE: Command: sudo i\\\nscsiadm -m node -T iqn.2010-10.org.openstack:volume-00000001 -p 172.18.0.146:3260 --login#012(nova.compute.manager): TRACE: Exit\\\n code: 255#012(nova.compute.manager): TRACE: Stdout: 'Logging in to [iface: default, target: iqn.2010-10.org.openstack:volume-00\\\n000001, portal: 172.18.0.146,3260]\\n'#012(nova.compute.manager): TRACE: Stderr: 'iscsiadm: Could not login to [iface: default, t\\\narget: iqn.2010-\nJan 11 14:41:59 xg06eth0  2012-01-11 14:41:59,351 DEBUG nova.rpc [-] Making asynchronous call on volume.xg06 ... from (pid=8603)\\\n multicall /opt/stack/nova/nova/rpc/impl_kombu.py:759\n-UUU:----F1  syslog         99% L??    (Fundamental)---------------------------------------------------------------------------", 
            "date_created": "2012-01-11 19:44:34.006649+00:00", 
            "author": "https://api.launchpad.net/1.0/~david-kranz"
        }, 
        {
            "content": "After some more experimenting it seems that after attempting to mount an already existing virtual disk the volumes get totally messed up. Trying to delete the volume fails and a list shows \"error_deleting\" as the state of the volume. I had to reboot the machine and rerun stack.sh to get back to working.", 
            "date_created": "2012-01-12 20:36:36.390269+00:00", 
            "author": "https://api.launchpad.net/1.0/~david-kranz"
        }, 
        {
            "content": "David, is this a duplicate of https://bugs.launchpad.net/nova/+bug/884635?", 
            "date_created": "2012-01-29 04:51:10.216805+00:00", 
            "author": "https://api.launchpad.net/1.0/~bcwaldon"
        }, 
        {
            "content": "I'm not sure. I think that bug is saying that volume-list claimed that a volume was not attached but it actually was. The grammar of that bug report is a little off so I can't quite tell.", 
            "date_created": "2012-01-30 12:57:53.474259+00:00", 
            "author": "https://api.launchpad.net/1.0/~david-kranz"
        }, 
        {
            "content": "Ok, I can reproduce this. The other bug report has a different traceback which I believe may have been fixed.", 
            "date_created": "2012-02-27 19:15:39.172093+00:00", 
            "author": "https://api.launchpad.net/1.0/~bcwaldon"
        }, 
        {
            "content": "The real problem here is that we need to leave the volume in a good state and communicate to the user what happened. Currently, this will prevent us from being able to delete the volume.", 
            "date_created": "2012-02-27 19:16:21.356367+00:00", 
            "author": "https://api.launchpad.net/1.0/~bcwaldon"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/4611", 
            "date_created": "2012-02-28 03:35:13.237784+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/4611\nCommitted: http://github.com/openstack/nova/commit/44067ba758b378c4c2c2ff88b0d1b7a3c27ac812\nSubmitter: Jenkins\nBranch:    master\n\ncommit 44067ba758b378c4c2c2ff88b0d1b7a3c27ac812\nAuthor: Brian Waldon <email address hidden>\nDate:   Mon Feb 27 17:37:57 2012 -0800\n\n    Call detach_volume when attach fails\n    \n    * Fixes bug 914974\n    * Raise exception.DeviceBusy when volume cannot attach\n    \n    Change-Id: Ie18377ba6acd6226612c70fa209185cc579c2d85\n", 
            "date_created": "2012-02-28 16:09:55.157945+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2012-02-29 10:20:42.866243+00:00"
}