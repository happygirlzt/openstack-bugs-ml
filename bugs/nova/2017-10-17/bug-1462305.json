{
    "status": "Invalid", 
    "last_updated": "2015-08-26 18:09:34.732499+00:00", 
    "description": "Its not very clear whats going on here, but here is the symptom.\n\nOne of the nova-compute nodes appears to lock up:\nhttp://logs.openstack.org/67/175067/2/check/check-tempest-dsvm-multinode-full/7a95fb0/logs/screen-n-cpu.txt.gz#_2015-05-29_23_27_48_296\nIt was just completing the termination of an instance:\nhttp://logs.openstack.org/67/175067/2/check/check-tempest-dsvm-multinode-full/7a95fb0/logs/screen-n-cpu.txt.gz#_2015-05-29_23_27_48_153\n\nThis is also seen in the scheduler reporting the node as down:\nhttp://logs.openstack.org/67/175067/2/check/check-tempest-dsvm-multinode-full/7a95fb0/logs/screen-n-sch.txt.gz#_2015-05-29_23_31_02_711\n\nOn further inspection it seems like the other nova compute node had just started a migration:\nhttp://logs.openstack.org/67/175067/2/check/check-tempest-dsvm-multinode-full/7a95fb0/logs/subnode-2/screen-n-cpu.txt.gz#_2015-05-29_23_27_48_079\n\n\nWe have had issues in the past where olso.locks can lead to deadlocks, its not totally clear if thats happening here. all the periodic tasks happen in the same greenlet, so you can stop them happening if you hold a lock in an RPC call thats being processed, etc. No idea if thats happening here though.", 
    "tags": [
        "testing"
    ], 
    "importance": "High", 
    "heat": 8, 
    "link": "https://bugs.launchpad.net/nova/+bug/1462305", 
    "owner": "https://api.launchpad.net/1.0/~dims-v", 
    "id": 1462305, 
    "index": 1752, 
    "openned": "2015-06-05 10:40:51.386651+00:00", 
    "created": "2015-06-05 10:40:51.386651+00:00", 
    "title": "multi-node test causes nova-compute to lockup", 
    "comments": [
        {
            "content": "Its not very clear whats going on here, but here is the symptom.\n\nOne of the nova-compute nodes appears to lock up:\nhttp://logs.openstack.org/67/175067/2/check/check-tempest-dsvm-multinode-full/7a95fb0/logs/screen-n-cpu.txt.gz#_2015-05-29_23_27_48_296\nIt was just completing the termination of an instance:\nhttp://logs.openstack.org/67/175067/2/check/check-tempest-dsvm-multinode-full/7a95fb0/logs/screen-n-cpu.txt.gz#_2015-05-29_23_27_48_153\n\nThis is also seen in the scheduler reporting the node as down:\nhttp://logs.openstack.org/67/175067/2/check/check-tempest-dsvm-multinode-full/7a95fb0/logs/screen-n-sch.txt.gz#_2015-05-29_23_31_02_711\n\nOn further inspection it seems like the other nova compute node had just started a migration:\nhttp://logs.openstack.org/67/175067/2/check/check-tempest-dsvm-multinode-full/7a95fb0/logs/subnode-2/screen-n-cpu.txt.gz#_2015-05-29_23_27_48_079\n\n\nWe have had issues in the past where olso.locks can lead to deadlocks, its not totally clear if thats happening here. all the periodic tasks happen in the same greenlet, so you can stop them happening if you hold a lock in an RPC call thats being processed, etc. No idea if thats happening here though.", 
            "date_created": "2015-06-05 10:40:51.386651+00:00", 
            "author": "https://api.launchpad.net/1.0/~johngarbutt"
        }, 
        {
            "content": "It looks like the delete operation is coming from tempest. But the command never finishes since the lock do_terminate_instance uses is never released\n\n' Lock \"e701630a-e0f0-4228-ac9b-475604ac3479\" acquired by \"do_terminate_instance\"'\n\nhttp://logs.openstack.org/67/175067/2/check/check-tempest-dsvm-multinode-full/7a95fb0/logs/screen-n-cpu.txt.gz#_2015-05-29_23_27_47_445", 
            "date_created": "2015-06-06 10:29:55.276055+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Fingerprint: message:\"has not been heard from in a while\" AND tags:\"screen-n-sch.txt\" AND build_name:\"check-tempest-dsvm-multinode-full\"", 
            "date_created": "2015-06-06 10:32:08.762454+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "http://logstash.openstack.org/#eyJzZWFyY2giOiJtZXNzYWdlOlwiaGFzIG5vdCBiZWVuIGhlYXJkIGZyb20gaW4gYSB3aGlsZVwiIEFORCB0YWdzOlwic2NyZWVuLW4tc2NoLnR4dFwiIEFORCBidWlsZF9uYW1lOlwiY2hlY2stdGVtcGVzdC1kc3ZtLW11bHRpbm9kZS1mdWxsXCIiLCJmaWVsZHMiOltdLCJvZmZzZXQiOjAsInRpbWVmcmFtZSI6IjE3MjgwMCIsImdyYXBobW9kZSI6ImNvdW50IiwidGltZSI6eyJ1c2VyX2ludGVydmFsIjowfSwic3RhbXAiOjE0MzM1ODY2NzI3NjEsIm1vZGUiOiIiLCJhbmFseXplX2ZpZWxkIjoiIn0=\n", 
            "date_created": "2015-06-06 10:32:15.142135+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "After looking into this further, looks this happens on either node in the multinode job, always ending in the same place (an error in delete causing nova-compute to hang).", 
            "date_created": "2015-06-06 13:33:45.177104+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "Making this high, because ti blocking making multi-node voting", 
            "date_created": "2015-06-11 14:37:33.972072+00:00", 
            "author": "https://api.launchpad.net/1.0/~johngarbutt"
        }, 
        {
            "content": "I'm setting it to \"in progress\" because \"jogo\" is set as assignee. Or does the combination \"incomplete\" + \"assignee\" have a special meaning?", 
            "date_created": "2015-06-12 13:22:07.950797+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "Attempted to run guru meditation report (by sending a SIGUSR1) to the hung nova-compute but it doesn't respond", 
            "date_created": "2015-06-23 18:31:14.801235+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "next step is to attach gdb and get a stacktrace", 
            "date_created": "2015-06-23 19:01:36.049645+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }
    ], 
    "closed": "2015-08-26 18:09:32.994391+00:00"
}