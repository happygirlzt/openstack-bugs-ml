{
    "status": "Invalid", 
    "last_updated": "2016-09-07 19:42:15.864324+00:00", 
    "description": "=========================================\nSRU Justification:\n1. Impact: networking breaks after awhile in kvm guests using virtio networking\n2. Development fix: The bug was fixed upstream and the fix picked up in a new\n   merge.\n3. Stable fix: 3 virtio patches are cherrypicked from upstream:\n   a821ce5 virtio: order index/descriptor reads\n   92045d8 virtio: add missing mb() on enable notification\n   a281ebc virtio: add missing mb() on notification\n4. Test case: Create a bridge enslaving the real NIC, and use that as the bridge\n   for a kvm instance with virtio networking.  See comment #44 for specific test\n   case.\n5. Regression potential: Should be low as several people have tested the fixed\n   package under heavy load.\n=========================================\n\nSystem:\n-----------\nDell R410 Dual processor 2.4Ghz w/16G RAM\nDistributor ID: Ubuntu\nDescription:    Ubuntu 12.04 LTS\nRelease:        12.04\nCodename:       precise\n\nSetup:\n---------\nWe're running 3 KVM guests, all Ubuntu 12.04 LTS using bridged networking.\n\nFrom the host:\n# cat /etc/network/interfaces\nauto br0\niface br0 inet static\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0address 212.XX.239.98\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0netmask 255.255.255.240\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0gateway 212.XX.239.97\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_ports eth0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_fd 9\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_hello 2\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_maxage 12\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_stp off\n\n# ifconfig eth0\neth0      Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX packets:11278363 errors:0 dropped:3128 overruns:0 frame:0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TX packets:14437384 errors:0 dropped:0 overruns:0 carrier:0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0collisions:0 txqueuelen:1000\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX bytes:4115980743 (4.1 GB)  TX bytes:5451961979 (5.4 GB)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Interrupt:36 Memory:da000000-da012800\n\n# ifconfig br0\nbr0       Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0inet addr:212.XX.239.98  Bcast:212.XX.239.111  Mask:255.255.255.240\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0inet6 addr: fe80::d6ae:52ff:fe84:2d5a/64 Scope:Link\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX packets:1720861 errors:0 dropped:0 overruns:0 frame:0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TX packets:1708622 errors:0 dropped:0 overruns:0 carrier:0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0collisions:0 txqueuelen:0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX bytes:210152198 (210.1 MB)  TX bytes:300858508 (300.8 MB)\n\n# brctl show\nbridge name     bridge id               STP enabled     interfaces\nbr0             8000.d4ae52842d5a       no              eth0\n\nI have no default network configured to autostart in libvirt as we're using bridged networking:\n# virsh net-list --all\nName                 State      Autostart\n-----------------------------------------\ndefault              inactive   no\n\n# arp\nAddress                  HWtype  HWaddress           Flags Mask            Iface\nmailer03.xxxx.com       ether   52:54:00:82:5f:0f   C                     br0\nmailer01.xxxx.com       ether   52:54:00:d2:f7:31   C                     br0\nmailer02.xxxx.com       ether   52:54:00:d3:8f:91   C                     br0\ndxi-gw2.xxxx.com        ether   00:1a:30:2a:b1:c0   C                     br0\n\nFrom one of the guests:\n<domain type='kvm' id='4'>\n\u00a0\u00a0<name>mailer01</name>\n\u00a0\u00a0<uuid>d41d1355-84e8-ae23-e84e-227bc0231b97</uuid>\n\u00a0\u00a0<memory>2097152</memory>\n\u00a0\u00a0<currentMemory>2097152</currentMemory>\n\u00a0\u00a0<vcpu>1</vcpu>\n\u00a0\u00a0<os>\n\u00a0\u00a0\u00a0\u00a0<type arch='x86_64' machine='pc-1.0'>hvm</type>\n\u00a0\u00a0\u00a0\u00a0<boot dev='hd'/>\n\u00a0\u00a0</os>\n\u00a0\u00a0<features>\n\u00a0\u00a0\u00a0\u00a0<acpi/>\n\u00a0\u00a0</features>\n\u00a0\u00a0<clock offset='utc'/>\n\u00a0\u00a0<on_poweroff>destroy</on_poweroff>\n\u00a0\u00a0<on_reboot>restart</on_reboot>\n\u00a0\u00a0<on_crash>destroy</on_crash>\n\u00a0\u00a0<devices>\n\u00a0\u00a0\u00a0\u00a0<emulator>/usr/bin/kvm</emulator>\n\u00a0\u00a0\u00a0\u00a0<disk type='file' device='disk'>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<driver name='qemu' type='raw'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source file='/dev/mapper/vg_main-mailer01--root'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target dev='hda' bus='ide'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='ide0-0-0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='drive' controller='0' bus='0' unit='0'/>\n\u00a0\u00a0\u00a0\u00a0</disk>\n\u00a0\u00a0\u00a0\u00a0<disk type='file' device='disk'>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<driver name='qemu' type='raw'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source file='/dev/mapper/vg_main-mailer01--swap'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target dev='hdb' bus='ide'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='ide0-0-1'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='drive' controller='0' bus='0' unit='1'/>\n\u00a0\u00a0\u00a0\u00a0</disk>\n\u00a0\u00a0\u00a0\u00a0<controller type='ide' index='0'>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='ide0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>\n\u00a0\u00a0\u00a0\u00a0</controller>\n\u00a0\u00a0\u00a0\u00a0<interface type='bridge'>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<mac address='52:54:00:d2:f7:31'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source bridge='br0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target dev='vnet0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<model type='virtio'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='net0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>\n\u00a0\u00a0\u00a0\u00a0</interface>\n\u00a0\u00a0\u00a0\u00a0<serial type='pty'>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source path='/dev/pts/0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target port='0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='serial0'/>\n\u00a0\u00a0\u00a0\u00a0</serial>\n\u00a0\u00a0\u00a0\u00a0<console type='pty' tty='/dev/pts/0'>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source path='/dev/pts/0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target type='serial' port='0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='serial0'/>\n\u00a0\u00a0\u00a0\u00a0</console>\n\u00a0\u00a0\u00a0\u00a0<input type='mouse' bus='ps2'/>\n\u00a0\u00a0\u00a0\u00a0<graphics type='vnc' port='5900' autoport='yes' listen='127.0.0.1'>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<listen type='address' address='127.0.0.1'/>\n\u00a0\u00a0\u00a0\u00a0</graphics>\n\u00a0\u00a0\u00a0\u00a0<video>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<model type='cirrus' vram='9216' heads='1'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='video0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>\n\u00a0\u00a0\u00a0\u00a0</video>\n\u00a0\u00a0\u00a0\u00a0<memballoon model='virtio'>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='balloon0'/>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>\n\u00a0\u00a0\u00a0\u00a0</memballoon>\n\u00a0\u00a0</devices>\n\u00a0\u00a0<seclabel type='dynamic' model='apparmor' relabel='yes'>\n\u00a0\u00a0\u00a0\u00a0<label>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</label>\n\u00a0\u00a0\u00a0\u00a0<imagelabel>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</imagelabel>\n\u00a0\u00a0</seclabel>\n</domain>\n\nFrom within the guest:\n# cat /etc/network/interfaces\n# The primary network interface\nauto eth0\niface eth0 inet static\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0address 212.XX.239.100\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0netmask 255.255.255.240\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0network 212.XX.239.96\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0broadcast 212.XX.239.111\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0gateway 212.XX.239.97\n\n# ifconfig\neth0      Link encap:Ethernet  HWaddr 52:54:00:d2:f7:31\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0inet addr:212.XX.239.100  Bcast:212.XX.239.111  Mask:255.255.255.240\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0inet6 addr: fe80::5054:ff:fed2:f731/64 Scope:Link\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX packets:5631830 errors:0 dropped:0 overruns:0 frame:0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TX packets:6683416 errors:0 dropped:0 overruns:0 carrier:0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0collisions:0 txqueuelen:1000\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX bytes:2027322829 (2.0 GB)  TX bytes:2076698690 (2.0 GB)\n\nA commandline which starts the KVM guest:\n/usr/bin/kvm -S -M pc-1.0 -enable-kvm -m 2048 -smp 1,sockets=1,cores=1,threads=1 -name mailer01 -uuid d41d1355-84e8-ae23-e84e-227bc0231b97 -nodefconfig -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/mailer01.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-shutdown -drive file=/dev/mapper/vg_main-mailer01--root,if=none,id=drive-ide0-0-0,format=raw -device ide-drive,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0,bootindex=1 -drive file=/dev/mapper/vg_main-mailer01--swap,if=none,id=drive-ide0-0-1,format=raw -device ide-drive,bus=ide.0,unit=1,drive=drive-ide0-0-1,id=ide0-0-1 -netdev tap,fd=18,id=hostnet0 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:d2:f7:31,bus=pci.0,addr=0x3 -chardev pty,id=charserial0 -device isa-serial,chardev=charserial0,id=serial0 -usb -vnc 127.0.0.1:0 -vga cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x4\n\nProblem:\n------------\nPeriodically (at least once a day), one or more of the guests lose network connectivity.  Ping responds with 'host unreachable', even from the dom host. Logging in via the serial console shows no problems: eth0 is up, can ping the local host, but no outside connectivity.  Restart the network (/etc/init.d/networking restart) does nothing. Reboot the machine and it comes alive again.\n\nI've verified there's no arp games going on on the primary host (the arp tables remain the same before - when it had connectivity - and after - when it doesn't.\n\nThis is a critical issue affecting production services on the latest LTS release of Ubuntu. It's similar to an issue which was 'resolved' in 10.04 but appears to have risen its ugly head again.", 
    "tags": [
        "kernel-kvm", 
        "kvm", 
        "networking", 
        "verification-done"
    ], 
    "importance": "Undecided", 
    "heat": 344, 
    "link": "https://bugs.launchpad.net/nova/+bug/997978", 
    "owner": "None", 
    "id": 997978, 
    "index": 4072, 
    "openned": "2012-08-15 14:29:10.758101+00:00", 
    "created": "2012-05-11 09:33:43.884593+00:00", 
    "title": "KVM images lose connectivity with bridged network", 
    "comments": [
        {
            "content": "System:\n-----------\nDell R410 Dual processor 2.4Ghz w/16G RAM\nDistributor ID: Ubuntu\nDescription:    Ubuntu 12.04 LTS\nRelease:        12.04\nCodename:       precise\n\nSetup:\n---------\nWe're running 3 KVM guests, all Ubuntu 12.04 LTS using bridged networking. \n\nFrom the host:\n# cat /etc/network/interfaces\nauto br0\niface br0 inet static\n        address 212.XX.239.98\n        netmask 255.255.255.240\n        gateway 212.XX.239.97\n        bridge_ports eth0\n        bridge_fd 9\n        bridge_hello 2\n        bridge_maxage 12\n        bridge_stp off\n\n# ifconfig eth0\neth0      Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a  \n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:11278363 errors:0 dropped:3128 overruns:0 frame:0\n          TX packets:14437384 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:4115980743 (4.1 GB)  TX bytes:5451961979 (5.4 GB)\n          Interrupt:36 Memory:da000000-da012800 \n\n# ifconfig br0\nbr0       Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a  \n          inet addr:212.XX.239.98  Bcast:212.XX.239.111  Mask:255.255.255.240\n          inet6 addr: fe80::d6ae:52ff:fe84:2d5a/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:1720861 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:1708622 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:210152198 (210.1 MB)  TX bytes:300858508 (300.8 MB)\n\n# brctl show\nbridge name     bridge id               STP enabled     interfaces\nbr0             8000.d4ae52842d5a       no              eth0\n\nI have no default network configured to autostart in libvirt as we're using bridged networking:\n# virsh net-list --all\nName                 State      Autostart\n-----------------------------------------\ndefault              inactive   no        \n\n# arp\nAddress                  HWtype  HWaddress           Flags Mask            Iface\nmailer03.xxxx.com       ether   52:54:00:82:5f:0f   C                     br0\nmailer01.xxxx.com       ether   52:54:00:d2:f7:31   C                     br0\nmailer02.xxxx.com       ether   52:54:00:d3:8f:91   C                     br0\ndxi-gw2.xxxx.com        ether   00:1a:30:2a:b1:c0   C                     br0\n\nFrom one of the guests:\n<domain type='kvm' id='4'>\n  <name>mailer01</name>\n  <uuid>d41d1355-84e8-ae23-e84e-227bc0231b97</uuid>\n  <memory>2097152</memory>\n  <currentMemory>2097152</currentMemory>\n  <vcpu>1</vcpu>\n  <os>\n    <type arch='x86_64' machine='pc-1.0'>hvm</type>\n    <boot dev='hd'/>\n  </os>\n  <features>\n    <acpi/>\n  </features>\n  <clock offset='utc'/>\n  <on_poweroff>destroy</on_poweroff>\n  <on_reboot>restart</on_reboot>\n  <on_crash>destroy</on_crash>\n  <devices>\n    <emulator>/usr/bin/kvm</emulator>\n    <disk type='file' device='disk'>\n      <driver name='qemu' type='raw'/>\n      <source file='/dev/mapper/vg_main-mailer01--root'/>\n      <target dev='hda' bus='ide'/>\n      <alias name='ide0-0-0'/>\n      <address type='drive' controller='0' bus='0' unit='0'/>\n    </disk>\n    <disk type='file' device='disk'>\n      <driver name='qemu' type='raw'/>\n      <source file='/dev/mapper/vg_main-mailer01--swap'/>\n      <target dev='hdb' bus='ide'/>\n      <alias name='ide0-0-1'/>\n      <address type='drive' controller='0' bus='0' unit='1'/>\n    </disk>\n    <controller type='ide' index='0'>\n      <alias name='ide0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>\n    </controller>\n    <interface type='bridge'>\n      <mac address='52:54:00:d2:f7:31'/>\n      <source bridge='br0'/>\n      <target dev='vnet0'/>\n      <model type='virtio'/>\n      <alias name='net0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>\n    </interface>\n    <serial type='pty'>\n      <source path='/dev/pts/0'/>\n      <target port='0'/>\n      <alias name='serial0'/>\n    </serial>\n    <console type='pty' tty='/dev/pts/0'>\n      <source path='/dev/pts/0'/>\n      <target type='serial' port='0'/>\n      <alias name='serial0'/>\n    </console>\n    <input type='mouse' bus='ps2'/>\n    <graphics type='vnc' port='5900' autoport='yes' listen='127.0.0.1'>\n      <listen type='address' address='127.0.0.1'/>\n    </graphics>\n    <video>\n      <model type='cirrus' vram='9216' heads='1'/>\n      <alias name='video0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>\n    </video>\n    <memballoon model='virtio'>\n      <alias name='balloon0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>\n    </memballoon>\n  </devices>\n  <seclabel type='dynamic' model='apparmor' relabel='yes'>\n    <label>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</label>\n    <imagelabel>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</imagelabel>\n  </seclabel>\n</domain>\n\nFrom within the guest:\n# cat /etc/network/interfaces \n# The primary network interface\nauto eth0\niface eth0 inet static\n        address 212.XX.239.100\n        netmask 255.255.255.240 \n        network 212.XX.239.96\n        broadcast 212.XX.239.111\n        gateway 212.XX.239.97\n\n# ifconfig\neth0      Link encap:Ethernet  HWaddr 52:54:00:d2:f7:31  \n          inet addr:212.XX.239.100  Bcast:212.XX.239.111  Mask:255.255.255.240\n          inet6 addr: fe80::5054:ff:fed2:f731/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:5631830 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:6683416 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:2027322829 (2.0 GB)  TX bytes:2076698690 (2.0 GB)\n\n\nA commandline which starts the KVM guest:\n/usr/bin/kvm -S -M pc-1.0 -enable-kvm -m 2048 -smp 1,sockets=1,cores=1,threads=1 -name mailer01 -uuid d41d1355-84e8-ae23-e84e-227bc0231b97 -nodefconfig -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/mailer01.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-shutdown -drive file=/dev/mapper/vg_main-mailer01--root,if=none,id=drive-ide0-0-0,format=raw -device ide-drive,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0,bootindex=1 -drive file=/dev/mapper/vg_main-mailer01--swap,if=none,id=drive-ide0-0-1,format=raw -device ide-drive,bus=ide.0,unit=1,drive=drive-ide0-0-1,id=ide0-0-1 -netdev tap,fd=18,id=hostnet0 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:d2:f7:31,bus=pci.0,addr=0x3 -chardev pty,id=charserial0 -device isa-serial,chardev=charserial0,id=serial0 -usb -vnc 127.0.0.1:0 -vga cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x4\n\nProblem:\n------------\nPeriodically (at least once a day), one or more of the guests lose network connectivity.  Ping responds with 'host unreachable', even from the dom host. Logging in via the serial console shows no problems: eth0 is up, can ping the local host, but no outside connectivity.  Restart the network (/etc/init.d/networking restart) does nothing. Reboot the machine and it comes alive again.\n\nI've verified there's no arp games going on on the primary host (the arp tables remain the same before - when it had connectivity - and after - when it doesn't.\n\nThis is a critical issue affecting production services on the latest LTS release of Ubuntu. It's similar to an issue which was 'resolved' in 10.04 but appears to have risen its ugly head again.", 
            "date_created": "2012-05-11 09:33:43.884593+00:00", 
            "author": "https://api.launchpad.net/1.0/~j+launchpad-net"
        }, 
        {
            "content": "Thanks for reporting this bug.  Does this also happen ifonly one of the VMs is up?  Is there any pattern to the time of day or length of a vm's uptime before this happens?  What does 'route -n' show before and after it happens?", 
            "date_created": "2012-05-11 15:36:45.979851+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "(setting status to incomplete while awaiting response)", 
            "date_created": "2012-05-11 15:37:42.563547+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "This happens to one of the VMs at any one time (on Wednesday two failed, about 2 hours apart). There's no discernible pattern in terms of time of day or length of a VMs uptime.\n\nThe next time one fails (they've been stable today), I'll do a route -n and post the output.  For record, currently (with a working VM), route -n shows:\n\n $ route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         212.XX.239.97   0.0.0.0         UG    100    0        0 eth0\n212.XX.239.96   0.0.0.0         255.255.255.240 U     0      0        0 eth0\n", 
            "date_created": "2012-05-11 15:49:58.184749+00:00", 
            "author": "https://api.launchpad.net/1.0/~j+launchpad-net"
        }, 
        {
            "content": "Thanks,\n\nIn order to check whether it is a qemu (perhaps virtio driver) bug or\na bug in the kernel or network utilities on the host, would you be\nable to try setting up a container and checking it's networking?\nThere are lighter weight ways of testing this, but the simplest way\nwould be to:\n\nsudo apt-get install lxc\n# If having lxcbr0 bothers you, since you don't need it for this test, you\n# can set LXC_AUTO=false in /etc/default/lxc and do\n# \"sudo stop lxc; sudo start lxc\".\ncat > lxc.conf << EOF\nlxc.network.type=veth\nlxc.network.link=br0\nlxc.network.flags=up\nEOF\n\nsudo lxc-create -t ubuntu -f lxc.conf -n lxc1\nsudo lxc-start -n lxc1 -d\n\nThen log into the container's console with\n\nsudo lxc-console -n lxc1\n\nand, from there, periodically check the network status.  If that also\nloses connectivity periodically, then we know the bug is happening\nbelow kvm.\n", 
            "date_created": "2012-05-11 16:19:01+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I tried building the container this morning using both your file above, and the following:\nlxc.network.type=veth\nlxc.network.link=br0\nlxc.network.flags=up\nlxc.network.ipv4=212.XX.239.103/28\nlxc.network.name=eth0\n\n\n# lxc-create -t ubuntu -f lxc.conf -n lxc1\ndebootstrap is /usr/sbin/debootstrap\nChecking cache download in /var/cache/lxc/precise/rootfs-amd64 ... \nCopy /var/cache/lxc/precise/rootfs-amd64 to /var/lib/lxc/lxc1/rootfs ... \nCopying rootfs to /var/lib/lxc/lxc1/rootfs ...\n\n##\n# The default user is 'ubuntu' with password 'ubuntu'!\n# Use the 'sudo' command to run tasks as root in the container.\n##\n\n'ubuntu' template installed\n'lxc1' created\n\nBut it fails to start:\n\n# lxc-start -n lxc1\nlxc-start: failed to spawn 'lxc1'\n\n/var/log/syslog shows:\nMay 12 09:47:12 dom0 kernel: [ 1107.903216] device vethHzjri2 entered promiscuous mode\nMay 12 09:47:12 dom0 kernel: [ 1107.905151] ADDRCONF(NETDEV_UP): vethHzjri2: link is not ready\n\nifconfig shows a load of virtual devices and brctl shows:\n\n# brctl show\nbridge name\tbridge id\t\tSTP enabled\tinterfaces\nbr0\t\t8000.0649d9be1876\tno\t\teth0\n\t\t\t\t\t\t\tveth4bkC47\n\t\t\t\t\t\t\tvethHzjri2\n\t\t\t\t\t\t\tvethNBwjzP\n\t\t\t\t\t\t\tvethZo4vwt\n\t\t\t\t\t\t\tvethhzluzM\n\t\t\t\t\t\t\tvethidQWcJ\n\t\t\t\t\t\t\tvethmtoeDY\n\t\t\t\t\t\t\tvethuPj7Qk\n\t\t\t\t\t\t\tvethuxztRp\n\t\t\t\t\t\t\tvnet1\n\n(I've tried starting the contain a few times).\n\nI'm happy to debug this with you, but lxc isn't software I'm familiar with, unfortunately. Any ideas?\n", 
            "date_created": "2012-05-12 08:49:00.498893+00:00", 
            "author": "https://api.launchpad.net/1.0/~j+launchpad-net"
        }, 
        {
            "content": "It took a few days, but we've finally had a failure of VM instance 2.  It died 2.5 hours ago. Logging into the dom0 host shows the arp table dead for that host:\n\nmailer02.xxxx.com               (incomplete)                              br0\n\nLogging into the machine itself via console:\n\nroot:~# ifconfig\neth0      Link encap:Ethernet  HWaddr 52:54:00:d3:8f:91  \n          inet addr:212.XX.239.101  Bcast:212.XX.239.111  Mask:255.255.255.240\n          inet6 addr: fe80::5054:ff:fed3:8f91/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:6893246 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:8242152 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:2290922658 (2.2 GB)  TX bytes:3314395798 (3.3 GB)\n\nroot:~# route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         212.XX.239.97   0.0.0.0         UG    100    0        0 eth0\n212.XX.239.96   0.0.0.0         255.255.255.240 U     0      0        0 eth0\n\nRestarting the network on the vm (/etc/init.d/networking restart) does nothing. Rebooting the VM brings it back to life.\n\nI'm happy to try with the container again, but using the instructions provided (even with some additional research online), I can't get it running.  Please advise.\n\nThanks.", 
            "date_created": "2012-05-15 19:12:54.435327+00:00", 
            "author": "https://api.launchpad.net/1.0/~j+launchpad-net"
        }, 
        {
            "content": "Sorry, I didn't see your update on the 12th.\n\nThe configuration file as you showed it may also work, but it should be simpler\nto use the one I posted.\n\nCan you do \n\tsudo lxc-start -n lxc1 -l DEBUG -o debugout\n\nand attach the file debugout here?\n\nDo you have cgroups mounted?  (what does 'grep cgroup /proc/self/mounts' show?)\n\nDoes the dhcp server for that network answer all requests, or only for\ncertain mac addresses?  (Lack of dhcp response shouldn't prevent the\ncontainer from starting anyway, so shouldn't explain the problem)\n", 
            "date_created": "2012-05-15 19:38:04.404988+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Hey,\n\nThere is no DHCP server for that network, which is why I set up the static IPs.\n\nThe cgroup-bin package wasn't installed, I installed that and then grep showed some output:\n\nroot:~# grep cgroup /proc/self/mounts\ncgroups /sys/fs/cgroup tmpfs rw,relatime,mode=755 0 0\ncgroup /sys/fs/cgroup/cpu cgroup rw,relatime,cpu 0 0\ncgroup /sys/fs/cgroup/cpuacct cgroup rw,relatime,cpuacct 0 0\ncgroup /sys/fs/cgroup/devices cgroup rw,relatime,devices 0 0\ncgroup /sys/fs/cgroup/memory cgroup rw,relatime,memory 0 0\ncgroup /sys/fs/cgroup/freezer cgroup rw,relatime,freezer 0 0\n\nThe container has now started.\n\nI'll configure it so it's running the same software as the other VMs and let's see what happens over the coming days.\n\nThanks for your help so far.", 
            "date_created": "2012-05-15 20:05:57.521182+00:00", 
            "author": "https://api.launchpad.net/1.0/~j+launchpad-net"
        }, 
        {
            "content": "An update: had a different KVM VM die today (same symptoms/resolution as previously); the LXC instance remains working.", 
            "date_created": "2012-05-17 15:57:39.928561+00:00", 
            "author": "https://api.launchpad.net/1.0/~j+launchpad-net"
        }, 
        {
            "content": "Another update: multiple KVM VM failures over the past couple of days, the lxc-container is working without issue.", 
            "date_created": "2012-05-21 15:42:17.832870+00:00", 
            "author": "https://api.launchpad.net/1.0/~j+launchpad-net"
        }, 
        {
            "content": "Thanks Jonathan, sounds like the issue is definately in qemu then.", 
            "date_created": "2012-05-21 15:57:15.679913+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I have the same symptoms with Ubuntu 12. The network is not reachable 3-4 times a day, for about 1-2 minutes but recovers by itself. Does not seem traffic/load related as it also happens, when there is nothing on.\n \n- No dhcp\n- bridged network with static ip's for guests\n- atm only running one VM Ubuntu 12\n- pretty bare host install with just kvm and libvirt \n- no relevant output in any log files\n\nNetwork \n\n---------------------------------------\ninterfaces file on host:\n\nauto lo\niface lo inet loopback\n\n# device: eth0\nauto  eth0\niface eth0 inet static\n  address   176.9.x.x\n  broadcast 176.9.x.x\n  netmask   255.255.255.192\n  gateway   176.9.x.x\n\n# default route to access subnet\nup route add -net 176.9.x.x netmask 255.255.255.192 gw 176.9.x.x eth0\n\nauto  br0\niface br0 inet static\n  address   176.9.x.x\n  netmask   255.255.255.255\n  gateway   176.9.x.x\n  pointopoint 176.9.x.x\n  bridge_ports eth0\n  bridge_stp off\n  bridge_fd 0\n  bridge_maxwait 0\n  up route add -host 176.9.x.x dev br0\n  up route add -host 176.9.x.x dev br0ll\n\n------------------------------------\ninterfaces in vm\n\n# The loopback network interface\nauto lo\niface lo inet loopback\n\n# The primary network interface\nauto eth0\niface eth0 inet static\n  address 176.9.x.x\n  netmask 255.255.255.192\n  gateway 176.9.x.x\n  pointopoint 176.9.x.x\n  dns-nameservers 213.133.98.98. 213.133.99.99\n\n--------------------------------\nvirsh # version\nCompiled against library: libvir 0.9.8\nUsing library: libvir 0.9.8\nUsing API: QEMU 0.9.8\nRunning hypervisor: QEMU 1.0.0\n", 
            "date_created": "2012-06-09 09:11:31.527497+00:00", 
            "author": "https://api.launchpad.net/1.0/~vespaschorsch"
        }, 
        {
            "content": "Ok, looking back over the original description, the bug poster has an eth0 mac address of d4:ae:52:84:2d:5a.  I'm quite certain that is at least a part of the problem - the bridge will always take the lowest mac address of any device on it, and the nics on the VMs have lower mac addresses.  So any time a VM goes on or offline, the bridge mac address will change, causing network traffic to pause.\n\nGeorg, please show 'ifconfig -a' output while the VMs are running", 
            "date_created": "2012-06-11 13:33:41.202032+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "If the mac address of eth0 is the cause of your problem, then a (non-ideal) workaround would be to use the stock NATed virbr0 for your VMs instead, as it won't be bridged with eth0.", 
            "date_created": "2012-06-11 13:40:29.350935+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Sorry, I had it backwards.  The bridge takes the higher address.", 
            "date_created": "2012-06-11 13:46:55.677806+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I have the same issue as stated above, but instead of rebooting the guests to bring them back, a quick ifdown, ifup does the trick.  Network is restored after this.", 
            "date_created": "2012-06-11 18:42:57.130038+00:00", 
            "author": "https://api.launchpad.net/1.0/~bradleydsmith"
        }, 
        {
            "content": "@serge, thanks for your input. here Dom0 ifconfig, with 2 machines running.\n\ni setup br0 myself because the machines are running at hetzner, with special addon IP's so the vm's can be reached from the outside. (wiki.hetzner.de/index.php/KVM_mit_Nutzung_aller_IPs_-_the_easy_way) i am also evaluating the problem with hetzner support to ensure its not one of their routers in from of the Dom0.\n\nvnet0, vnet1 are the bridges created by libvirt, but the vm have static ip entries in /network/interfaces and are bound to br0 via libvirt.\n\n------------------------------\n\nbr0       Link encap:Ethernet  HWaddr c8:60:00:e9:4a:2e  \n          inet addr:176.9.126.xx  Bcast:0.0.0.0  Mask:255.255.255.255\n          inet6 addr: fe80::ca60:ff:fee9:4a2e/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:5852477 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:4403013 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:2310013511 (2.3 GB)  TX bytes:2588138678 (2.5 GB)\n\neth0      Link encap:Ethernet  HWaddr c8:60:00:e9:4a:2e  \n          inet addr:176.9.126.xx  Bcast:176.9.126.95  Mask:255.255.255.192\n          UP BROADCAST RUNNING PROMISC MULTICAST  MTU:1500  Metric:1\n          RX packets:6623242 errors:0 dropped:35190 overruns:0 frame:0\n          TX packets:4668377 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:2484375973 (2.4 GB)  TX bytes:1715146205 (1.7 GB)\n          Interrupt:17 Memory:fe500000-fe520000 \n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:16436  Metric:1\n          RX packets:59917 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:59917 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:9106822 (9.1 MB)  TX bytes:9106822 (9.1 MB)\n\nvnet0     Link encap:Ethernet  HWaddr fe:54:00:2e:3d:0e  \n          inet6 addr: fe80::fc54:ff:fe2e:3d0e/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:2033457 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:2971987 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:500 \n          RX bytes:1023321831 (1.0 GB)  TX bytes:1482597549 (1.4 GB)\n\nvnet1     Link encap:Ethernet  HWaddr fe:54:00:3f:2a:9c  \n          inet6 addr: fe80::fc54:ff:fe3f:2a9c/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:124034 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:140178 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:500 \n          RX bytes:27970351 (27.9 MB)  TX bytes:56681695 (56.6 MB)\n------------------------------------\n", 
            "date_created": "2012-06-12 12:58:33.865805+00:00", 
            "author": "https://api.launchpad.net/1.0/~vespaschorsch"
        }, 
        {
            "content": "Got this wrong:   \nvnet0, vnet1 are the bridges created by libvirt, => are the network interface created by libvirt.\n\nI am jsut reading this bug report concerning the MAC address problems:\n\nhttps://bugzilla.redhat.com/show_bug.cgi?id=571991\nhttps://bugzilla.redhat.com/show_bug.cgi?id=583139\n\nand so far it seems ok that the br0 still has the MAC of eth0 and the VMs both start with FE::", 
            "date_created": "2012-06-12 14:59:36.861831+00:00", 
            "author": "https://api.launchpad.net/1.0/~vespaschorsch"
        }, 
        {
            "content": "Quoting Georg Leciejewski (<email address hidden>):\n> @serge, thanks for your input. here Dom0 ifconfig, with 2 machines\n> running.\n> \n> i setup br0 myself because the machines are running at hetzner, with\n> special addon IP's so the vm's can be reached from the outside.\n> (wiki.hetzner.de/index.php/KVM_mit_Nutzung_aller_IPs_-_the_easy_way) i\n> am also evaluating the problem with hetzner support to ensure its not\n> one of their routers in from of the Dom0.\n> \n> vnet0, vnet1 are the bridges created by libvirt, but the vm have static\n> ip entries in /network/interfaces and are bound to br0 via libvirt.\n> \n> ------------------------------\n> \n> br0       Link encap:Ethernet  HWaddr c8:60:00:e9:4a:2e  \n>           inet addr:176.9.126.xx  Bcast:0.0.0.0  Mask:255.255.255.255\n>           inet6 addr: fe80::ca60:ff:fee9:4a2e/64 Scope:Link\n>           UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n>           RX packets:5852477 errors:0 dropped:0 overruns:0 frame:0\n>           TX packets:4403013 errors:0 dropped:0 overruns:0 carrier:0\n>           collisions:0 txqueuelen:0 \n>           RX bytes:2310013511 (2.3 GB)  TX bytes:2588138678 (2.5 GB)\n> \n> eth0      Link encap:Ethernet  HWaddr c8:60:00:e9:4a:2e  \n>           inet addr:176.9.126.xx  Bcast:176.9.126.95  Mask:255.255.255.192\n>           UP BROADCAST RUNNING PROMISC MULTICAST  MTU:1500  Metric:1\n>           RX packets:6623242 errors:0 dropped:35190 overruns:0 frame:0\n>           TX packets:4668377 errors:0 dropped:0 overruns:0 carrier:0\n>           collisions:0 txqueuelen:1000 \n>           RX bytes:2484375973 (2.4 GB)  TX bytes:1715146205 (1.7 GB)\n>           Interrupt:17 Memory:fe500000-fe520000 \n\nOne thing I notice here is that you have an ip address on eth0, which I\nassume is bridged with br0?\n\nWhen I bridge eth0 to br0 using the following /etc/network/interfaces:\n\n=========================\nauto lo\niface lo inet loopback\n\nauto br0\niface br0 inet dhcp\n bridge_ports eth0\n\n# The primary network interface\nauto eth0\niface eth0 inet manual\n=========================\n\nI get the following ifconfig -a output:\n\n=========================\nbr0       Link encap:Ethernet  HWaddr fa:16:3e:59:27:16  \n          inet addr:10.55.60.89  Bcast:10.55.60.255  Mask:255.255.255.0\n          inet6 addr: fe80::f816:3eff:fe59:2716/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:223 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:178 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:21627 (21.6 KB)  TX bytes:19555 (19.5 KB)\n\neth0      Link encap:Ethernet  HWaddr fa:16:3e:59:27:16  \n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:259 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:178 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:26871 (26.8 KB)  TX bytes:19487 (19.4 KB)\n=========================\n\nWhat does your /etc/network/interfaces look like?\n", 
            "date_created": "2012-06-14 22:55:35+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "here it is. already posted it above with ip's xx:\n\n================================\nauto lo\niface lo inet loopback\n\n# device: eth0\nauto  eth0\niface eth0 inet static\n  address   176.9.126.79\n  broadcast 176.9.126.95\n  netmask   255.255.255.192\n  gateway   176.9.126.65\n\n# default route to access subnet\nup route add -net 176.9.126.64 netmask 255.255.255.192 gw 176.9.126.65 eth0\n\nauto  br0\niface br0 inet static\n  address   176.9.126.79\n  netmask   255.255.255.255\n  gateway   176.9.126.65\n  pointopoint 176.9.126.65\n  bridge_ports eth0\n  bridge_stp off\n  bridge_fd 0\n  bridge_maxwait 0\n  up route add -host 176.9.126.92 dev br0\n  up route add -host 176.9.126.93 dev br0\n\n======================================\nand brctl show\n======================================\nbridge name\tbridge id\t\tSTP enabled\tinterfaces\nbr0\t\t8000.c86000e94a2e\tno\t\teth0\n\t\t\t\t\t\t\t                       vnet0\nvirbr0\t\t8000.000000000000\tyes\t\t\n======================================\n\nI also did an mtr during downtimes and it shows that packages are lost on dom0 -> .79 \nI still hope it is some kind of misconfig, but as said before same network/bridge config runn without interupts in ubuntu 10.4 lts.\nThanks for your patience.\n\n\n", 
            "date_created": "2012-06-15 10:38:28.741140+00:00", 
            "author": "https://api.launchpad.net/1.0/~vespaschorsch"
        }, 
        {
            "content": "Quoting Georg Leciejewski (<email address hidden>):\n> here it is. already posted it above with ip's xx:\n> \n> ================================\n> auto lo\n> iface lo inet loopback\n> \n> # device: eth0\n> auto  eth0\n> iface eth0 inet static\n\nHi,\n\nI believe this is wrong.  Could you change the eth0 bit to simply\n\nauto eth0\niface eth0 inet manual\n\nThe fact that\n\n> I also did an mtr during downtimes and it shows that packages are lost on dom0 -> .79 \n\nSupports the idea that that might solve your problem.  (It also suggests\nthat yours is not the same as the original bug reporter's problem).\n", 
            "date_created": "2012-06-15 12:34:11+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I tried that with no difference, but i am on another path: maybe it is related to acpi ", 
            "date_created": "2012-06-19 09:25:00.270959+00:00", 
            "author": "https://api.launchpad.net/1.0/~vespaschorsch"
        }, 
        {
            "content": "I am having the same issue, and gave an in-depth inspection in my report: bug 1016848\n\nI am running version Essex 2012.1, and networking in VlanManager mode, a dedicated nova-network gateway, KVM and virt-type, Ubuntu 12.04 Precise, and run into this incident in up to every 1-2 days, yesterday even twice within 3 hours.\n\nOne symptom may be high networking traffic I/O on the given KVM instance.\n\nUntil now, I worked around by `nova reboot $instance_name`.\n\nbradleyd (bradleydsmith), what exactly did you mean by ifdown & ifup? the vnet%d interface or the bridge (e.g. br100) ? What interface did you re-up? -- for the mean time, I'd like to write a tiny daemon that runs on the hypervisor nodes, to check every N secs whether or not it can PING the KVM, and if not, it is to re-up its underlying network interface.\n\nSerge Hallyn, I'd like to assist in whatever you need to get this beast fixed, since for me this is also a very major incident, too, and I just can't add more production services until knowing the OpenStack-stack is functioning well. So please tell me what I can provide you with. :-)\n\nRegards,\nChristian.\n\n", 
            "date_created": "2012-06-25 15:06:38.773788+00:00", 
            "author": "https://api.launchpad.net/1.0/~trapni"
        }, 
        {
            "content": "i believe that we're seeing the same problem with ganeti-managed kvm instances running on 12.04 utilizing a bridged network.\n\nin an initial deployment of 8 guests (also 12.04) we had half of them drop off the network within a few hours.  there is a weak correlation between high network load in the guests and the network dropping.  in some but not all cases from the kvm instance's console i was able to ifdown/ifup its interface and bring it back online.", 
            "date_created": "2012-06-27 00:42:05.442914+00:00", 
            "author": "https://api.launchpad.net/1.0/~abezella"
        }, 
        {
            "content": "Same kind of problem here :\n\nRunning Ubuntu-servers 12.04 VMs on Ubuntu-servers 12.04 using KVM/Libvirt over bridges.\n\nPinging my gateway from a random VM and watching packets with tcpdump on the kvm host :\n\nicmp is ok on my vnet -> ok on the bridge -> ok on my bond (active-backup) -> ok on my gateway (reply) -> ok on my bond -> ok on my brigde -> No packet received on my vnet !!!!\n\nbrct showmacs mybridge seems to be ok showing my mac:addr (bridge+vm)\n\nI have to ifdown/ifup my eth0 on virtual guest to make it work again til the next time.\n", 
            "date_created": "2012-06-27 07:21:23.690119+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "Note I'm using 3.2.0-23-virtual kernel for my VMs ...", 
            "date_created": "2012-06-27 11:05:21.386751+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "So is it a bug in the VM's networking driver or in the hypervisor ?", 
            "date_created": "2012-06-27 12:56:53.666677+00:00", 
            "author": "https://api.launchpad.net/1.0/~trapni"
        }, 
        {
            "content": "@Georg,\n\nhave you found any more about the relation to acpi?\n\n@Stephane,\n\nin your case it would certainly seem to be a bug in either the guest kernel or the virtual nic driver, as with the original bug submitter.  Can you try switching to a different virtual nic type, i.e.\n\n   model type='ne2k_pci'\n\nAlso if it is possible for you to run a test on a quantal host, which has a much newer qemu-kvm, that would be interesting.  Can you tell me in numbers how heavy traffic needs to be before the VM drops out?  Is it traffic to the VM which freezes that VM, or does any traffic to the host or any VM threaten to freeze any VM.\n\n@Christian,\n\nseveral people have piped in on this bug.  I'm not certain about yours, but this bug in particular is in qemu itself (or perhaps, though unlikely, the kernel).\n", 
            "date_created": "2012-06-27 13:10:06.179505+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "@Serge\n\nI did upgrade my kernels yesterday evening both on hypervisors and guests so now I'm running 3.2.0-25-generic on hosts and the same kernel version but virtual for VMs. Same problem today morning, some VMs dropped out. I'm actually using virtio everywhere. I'll try to test another one and keep you in touch asap.\nI also tried to run a VMs with the generic kernel (not the virtual one) and I'm facing the same issue.\nSerge as I'm building this new plateform I can say they there is no traffic at all on my VMs exept 2 guys testing some java stuffs. I almost thinking that VMs drop out when there is not enough traffic on nics...\n\nI'll keep you in touch.\n", 
            "date_created": "2012-06-28 08:00:22.955210+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "Serge, \n\nne2k_pci seems to drop the link when generating some traffic (only tested on 4 VMs).\ne1000 seems have to same problem as virtio, dropping connections without traffic ...\nWhat else may I try ? Is it really a driver issue ?", 
            "date_created": "2012-06-28 11:22:38.512492+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "\nI've noticed I never had such a problem on one host running 3.2.0-24-generic ... on this one, my VMs have only 2 vnet per VM whereas on others I have at least 4 vnet per VM.\n\nIs there a tap generation limit somewhere ? (I don't think so, I do not see such a thing in sysctl -a)\nI'll try to downgrade my kernel on one buggy host while waiting for some ideas...\n\n", 
            "date_created": "2012-06-28 12:39:13.037012+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "@Stephane,\n\ncan you show your host network configuration and a VM's xml?  Are you bridging the VM nics with the host's eth0 over your own br0, or are you using the default NATed virbr0?  Does this happen even when only a single VM is up?\n\nI will try to reproduce next week.\n\n(For host network configuration,  the results of :\n   sudo ifconfig -a\n   sudo brctl show\n   netstat -nr\n   virsh net-dumpxml\nshould suffice, and 'virsh dumpxml VM1' to show the xml configuration for a guest)\n", 
            "date_created": "2012-06-28 13:10:35.017501+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Serge,\n\nI'm using bond0 (active-backup with eth0/eth4) then tagging vlans with bond0.XXXX and linking my bond0.XXXX in a bridge ... then I do the same with bond1 (eth1/eth5) etc until bond3.\n\nThen here is a dumpxml example :\n\n<domain type='kvm' id='5'>\n  <name>myguest1</name>\n  <uuid>cc31a6e0-267c-4470-bcd7-8a92755a85cd</uuid>\n  <memory>2097152</memory>\n  <currentMemory>2097152</currentMemory>\n  <vcpu>2</vcpu>\n  <os>\n    <type arch='x86_64' machine='pc-0.14'>hvm</type>\n    <boot dev='hd'/>\n    <bootmenu enable='no'/>\n  </os>\n  <features>\n    <acpi/>\n    <apic/>\n    <pae/>\n  </features>\n  <clock offset='utc'/>\n  <on_poweroff>destroy</on_poweroff>\n  <on_reboot>restart</on_reboot>\n  <on_crash>restart</on_crash>\n  <devices>\n    <emulator>/usr/bin/kvm</emulator>\n    <disk type='file' device='disk'>\n      <driver name='qemu' type='qcow2'/>\n      <source file='/vm/disques//myguest1.qcow2'/>\n      <target dev='hda' bus='ide'/>\n      <alias name='ide0-0-0'/>\n      <address type='drive' controller='0' bus='0' unit='0'/>\n    </disk>\n    <controller type='ide' index='0'>\n      <alias name='ide0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>\n    </controller>\n    <interface type='bridge'>\n      <mac address='52:54:00:a1:3d:dc'/>\n      <source bridge='bridge1'/>\n      <target dev='vnet16'/>\n      <model type='virtio'/>\n      <alias name='net0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>\n    </interface>\n    <interface type='bridge'>\n      <mac address='52:54:00:3b:81:78'/>\n      <source bridge='bridge2'/>\n      <target dev='vnet17'/>\n      <model type='virtio'/>\n      <alias name='net1'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>\n    </interface>\n    <interface type='bridge'>\n      <mac address='52:54:00:3d:96:57'/>\n      <source bridge='bridge3'/>\n      <target dev='vnet18'/>\n      <model type='virtio'/>\n      <alias name='net2'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x05' function='0x0'/>\n    </interface>\n    <interface type='bridge'>\n      <mac address='52:54:00:10:2e:f1'/>\n      <source bridge='bridge4'/>\n      <target dev='vnet19'/>\n      <model type='virtio'/>\n      <alias name='net3'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x06' function='0x0'/>\n    </interface>\n    <serial type='pty'>\n      <source path='/dev/pts/6'/>\n      <target port='0'/>\n      <alias name='serial0'/>\n    </serial>\n    <console type='pty' tty='/dev/pts/6'>\n      <source path='/dev/pts/6'/>\n      <target type='serial' port='0'/>\n      <alias name='serial0'/>\n    </console>\n    <input type='mouse' bus='ps2'/>\n    <graphics type='vnc' port='5904' autoport='yes'/>\n    <video>\n      <model type='cirrus' vram='9216' heads='1'/>\n      <alias name='video0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>\n    </video>\n    <memballoon model='virtio'>\n      <alias name='balloon0'/>\n      <address type='pci' domain='0x0000' bus='0x00' slot='0x07' function='0x0'/>\n    </memballoon>\n  </devices>\n  <seclabel type='dynamic' model='apparmor' relabel='yes'>\n    <label>libvirt-cc31a6e0-267c-4470-bcd7-8a92755a85cd</label>\n    <imagelabel>libvirt-cc31a6e0-267c-4470-bcd7-8a92755a85cd</imagelabel>\n  </seclabel>\n</domain>\n\nMay I ask you your email to send it to you directly ? ... because it's quite huge to paste it here... I do have many vlans ...", 
            "date_created": "2012-06-28 13:48:52.792718+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "This bug affects me as well, is it related to the one discussed here https://bugzilla.kernel.org/show_bug.cgi?id=42829\n\nI will try using the vhost_net driver in the host and vhost=on as a guest parameter to see if it bypasses the issue.", 
            "date_created": "2012-06-28 21:48:33.095890+00:00", 
            "author": "https://api.launchpad.net/1.0/~adioso"
        }, 
        {
            "content": "Alex,\n\nThanks for the link, I'll also try to test with :\n\n<driver name='vhost' txmode='iothread' ioeventfd='on' event_idx='off'/>\n\nDoes it work better for you with vhost_net ?\n", 
            "date_created": "2012-06-29 07:43:38.046803+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "Ok just in cas it may help...\n\nIt does work modprobing vhost_net and adding :\n<driver name='vhost' txmode='iothread' ioeventfd='on' event_idx='off'/>\non every nics definitions.\nTested on more than 100 VMs.", 
            "date_created": "2012-07-03 07:24:57.997428+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "Stephane, ya, as a workaround (not to say: the better way), modprobe'ing \"vhost_net\" driver before actually starting the VMs works perfect. no incidents since 4 days now (tested on 30+ VMs).\n\nBut is your driver-tag for? I did not need to do that, my libvirt-bin added the vhost=on parameter to qemu-kvm automatically - so what do I need this line for then?\n\nRegards,\nChristian.", 
            "date_created": "2012-07-03 07:54:36.187950+00:00", 
            "author": "https://api.launchpad.net/1.0/~trapni"
        }, 
        {
            "content": "Christian,\n\nI'm not really sure if just enabling vhost_net is enough... you may probably be right : it works well for you since 4 days ...\nLike I still do not understand where the bug is locate, I prefered to do everything to fix it quickly.\n\nReading the bugzilla : https://bugzilla.kernel.org/show_bug.cgi?id=42829 they were also talking about event_idx='off'\nIt seems to be patched now (I'm not sure basically):\nhttp://git.kernel.org/?p=linux/kernel/git/davem/net-next.git;a=commitdiff;h=4b727361f0bc7ee7378298941066d8aa15023ffb;hp=e1ac50f64691de9a095ac5d73cb8ac73d3d17dba\n\nRegards,", 
            "date_created": "2012-07-03 08:36:55.484069+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "Christian,\n\nYou are right, no need to add :\n\n<driver name='vhost' txmode='iothread' ioeventfd='on' event_idx='off'/>\n\n\nin the xml ...\n\nmodprobe vhost_net should be enough.\n", 
            "date_created": "2012-07-03 08:48:57.790663+00:00", 
            "author": "https://api.launchpad.net/1.0/~stefneveu"
        }, 
        {
            "content": "Thanks Stephane,  per comment #38 I'm marking this bug as affecting the kernel.", 
            "date_created": "2012-07-05 13:42:58.066451+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Just to confirm Stephane in #39, all we did was modprobe vhost_net (and add it to /etc/modules) then stop and start all our VMs. libvirtd detected vhost_net and added the vhost=on parameter automatically to our VMs. So far no crashes.", 
            "date_created": "2012-07-15 03:18:57.491687+00:00", 
            "author": "https://api.launchpad.net/1.0/~adioso"
        }, 
        {
            "content": "(Perhaps a test kernel should be built in ppa with the patch from comment #38)", 
            "date_created": "2012-07-17 19:51:31.448217+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "The proposed commit, 4b727361f0bc7ee7378298941066d8aa15023ffb: \"virtio_net: fix truesize underestimation\" (http://git.kernel.org/?p=linux/kernel/git/davem/net-next.git;a=commit;h=4b727361f0bc7ee7378298941066d8aa15023ffb) is in the precise kernel already.  That's unfortunately a dead end.\n\nIf someone who can reproduce this bug could either\n    1. test with a quantal image on the affected hardware, or\n    2. test with qemu compiled from git HEAD\n        a. git clone git://git.qemu.org/qemu.git\n    \tb. cd qemu\n\tc. ./configure --target-list=x86_64-softmmu\n\td. cd x86_64-softmmu\n\te. ./qemu_64-softmmu <arguments>\n\nthe result should be helpful.\n", 
            "date_created": "2012-07-23 12:53:38.232050+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I have faced with the same bug\nWhen a VM using virtio-net driver receives too much network traffic, the network interface stops working.\nSteps to reproduce -\n\nOn VM (with virtio-net):\n\n% nc -k -l 0.0.0.0 4242 > /dev/null\n\nOn another machine (baremetal or VM):\n% cat /dev/zero | nc IP 4242\n\nAfter some time, the VM network will stop working. With 2 listeners on the VM, I succeeded to reproduce this issue in about 1 hour.\n\nWhen I restart networking it working again\n\nI am using next packages:\nlinux-image_3.2.0.23.25_amd64.deb\nqemu_1.0+noroms-0ubuntu13_amd64.deb\n", 
            "date_created": "2012-07-24 08:56:24.056946+00:00", 
            "author": "https://api.launchpad.net/1.0/~enelen"
        }, 
        {
            "content": "Thanks, Eugene - that sounds like a great test case!  I will try\nthat.\n", 
            "date_created": "2012-07-24 14:06:56+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "On quantal, I can't get such a VM to run without it automatically loading vhost_net.  The following kvm command \n\nsudo kvm -hda x.img -netdev tap,ifname=tap0,id=hostnet0,vhost=on -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:d8:33:46,bus=pci.0,addr=0x3 -vnc :1\n\ncauses vhost_net to get loaded.  (The same command doesn't quite work in precise)\n\nI'll leave the testcase (with nc) running for a few hours on quantal in any case.\n\nThen I'll replace my quantal install with a precise one, and try again to reproduce there.", 
            "date_created": "2012-08-07 21:03:29.603461+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "@Eugene,\n\nI ran that test case on precise for 3.5 hours, with virtio network bridged with eth0 and without the vhost_net kernel module loaded, but network never hung.", 
            "date_created": "2012-08-09 13:07:59.832793+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Switching to eth0 slave to bond0 inside br0 does not help me to reproduce.", 
            "date_created": "2012-08-10 16:50:36.381616+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Status changed to 'Confirmed' because the bug affects multiple users.", 
            "date_created": "2012-08-13 12:44:31.023377+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }, 
        {
            "content": "Hi,\n\ncould anyone who has reproduced this without bonding please comment here?", 
            "date_created": "2012-08-13 13:25:23.524260+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I have seen this issue on 2 different servers which use bridging but not bonding.\n\nOne server was a customer system and we were forced to back-date the OS to an earlier release.  They were experiencing the issue up to once/day and quickly got impatient to have it resolved.\n\nThe other server is an internal system which runs multiple vm's.  We have only seen the issue on one of the vm's and only once every 2-3 weeks.  The vm which experiences the issue is our LTSP server.\n\nI have been testing a small cluster of 3 host machines which use both bonding and bridging.  I have not seen this issue affect them, but the usage is quite light and the vm's come & go since it's a testing environment right now.  Due to this bug, we have halted any plans to upgrade vm hosts to Precise until we can verify it's fixed.\n\nWe've seen the following when the issue has occurred:\n* Absolutely nothing in any logs, dmesg, etc.\n* Host machine cannot ping the guest\n* arp shows guest as incomplete\n* guest machine can ping its own IP, but nothing else (host, gw, etc)\n* restarting networking subsystem is successful (no errors) but has no effect on the problem\n* rebooting the guest fixes the problem until it happens again.  The reboot does not actually kill the kvm session and get a new process ID, but somehow having the guest go through the init again fixes it (until it happens again some period later).\n* This issue has occurred on one 12.04 guest and one 11.10 guest\n* Both of the servers which this occured on are Dell 2950 series machines.  I have not seen this issue on any of our HP Proliant (mostly DL360's) machines.\n\nIf there is some sort of test I can run to help debug, I'm happy to do that.\n\nThank you for trying to address this.  This is a huge bug for us.\n\nThanks,\ngary\n", 
            "date_created": "2012-08-14 18:36:29.569199+00:00", 
            "author": "https://api.launchpad.net/1.0/~ua5r"
        }, 
        {
            "content": "I'm noticing the same behavior on 12.04 hosts with 12.04 guests. No bonding. I'm currently running a test with two identical VMs, one started after modprobing vhost_net", 
            "date_created": "2012-08-15 00:37:44.593363+00:00", 
            "author": "https://api.launchpad.net/1.0/~kamador"
        }, 
        {
            "content": "I have bonding, I have seen this both with and without vhost_net module.", 
            "date_created": "2012-08-15 14:15:31.873914+00:00", 
            "author": "https://api.launchpad.net/1.0/~vachon"
        }, 
        {
            "content": "Causes nova network connectivity to freeze and be unresponsive", 
            "date_created": "2012-08-15 14:30:14.701425+00:00", 
            "author": "https://api.launchpad.net/1.0/~vachon"
        }, 
        {
            "content": "The following from comment #51:\n\nrebooting the guest fixes the problem until it happens again. The reboot does not actually kill the kvm session and get a new process ID, but somehow having the guest go through the init again fixes it (until it happens again some period later).\n\nmakes me suspect the guest OS (though it still could be virtual hw in qemu).\n\n@Kraig,\n do you have a script or recipe with which you can pretty reliably trigger this?", 
            "date_created": "2012-08-15 14:51:33.939451+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Nothing concrete or that I can distribute unfortunately. I was able to reproduce it with an infinitely long bi-direction iperf but right now I am testing our internal web services under production level loads. I've yet to reproduce the problem after loading the vhost_net module but i'll need more time before I feel confident that it works.", 
            "date_created": "2012-08-16 01:51:10.978400+00:00", 
            "author": "https://api.launchpad.net/1.0/~kamador"
        }, 
        {
            "content": "we had 12.04 vms experiencing these hangs regularly (sometimes only staying online for hours).  after enabling vhost_net there was a period of weeks without issue but a few days one of them hung again with the same (or very similar) symptoms.  an ifdown/ifup from within the guest brought it back on the network.", 
            "date_created": "2012-08-16 04:28:27.833184+00:00", 
            "author": "https://api.launchpad.net/1.0/~abezella"
        }, 
        {
            "content": "There's a quite interesting thread in the openstack mailing list. May not be related to this bug but I guess it's worth investigating in any case:\n\nhttp://markmail.org/message/xrvipkn2pvln2qty", 
            "date_created": "2012-08-16 11:22:44.154668+00:00", 
            "author": "https://api.launchpad.net/1.0/~rubiojr"
        }, 
        {
            "content": "Regarding comment #55:\nI don't believe this is a guest OS issue.  In my comment #51 I also indicate that I have had non-precise vm's (specifically 11.10) experience the same issue.\n\nI have only experienced this issue when using 12.04 precise as the host OS.  On a customer server which I back-dated by reinstalling 11.10 as the host OS, the issue went away.", 
            "date_created": "2012-08-16 11:37:09.710147+00:00", 
            "author": "https://api.launchpad.net/1.0/~ua5r"
        }, 
        {
            "content": "Quoting Gary Cuozzo (<email address hidden>):\n> Regarding comment #55:\n> I don't believe this is a guest OS issue.  In my comment #51 I also indicate that I have had non-precise vm's (specifically 11.10) experience the same issue.\n> \n> I have only experienced this issue when using 12.04 precise as the host\n> OS.  On a customer server which I back-dated by reinstalling 11.10 as\n> the host OS, the issue went away.\n\nAh, thanks for that info.\n\nIf I push an updated version of qemu-kvm to ppa:ubuntu-virt/ppa, would you\n(would anyone) be able to test it to confirm whether it fixes the issue?\nIf so then we could be sure the problem is in qemu userspace.\n", 
            "date_created": "2012-08-16 14:04:00+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I can test that today.\r\n\r\nSent from my iPhone\r\n\r\nOn Aug 16, 2012, at 7:11 AM, Serge Hallyn <email address hidden> wrote:\r\n\r\n> Quoting Gary Cuozzo (<email address hidden>):\r\n>> Regarding comment #55:\r\n>> I don't believe this is a guest OS issue.  In my comment #51 I also indicate that I have had non-precise vm's (specifically 11.10) experience the same issue.\r\n>> \r\n>> I have only experienced this issue when using 12.04 precise as the host\r\n>> OS.  On a customer server which I back-dated by reinstalling 11.10 as\r\n>> the host OS, the issue went away.\r\n> \r\n> Ah, thanks for that info.\r\n> \r\n> If I push an updated version of qemu-kvm to ppa:ubuntu-virt/ppa, would you\r\n> (would anyone) be able to test it to confirm whether it fixes the issue?\r\n> If so then we could be sure the problem is in qemu userspace.\r\n> \r\n> -- \r\n> You received this bug notification because you are subscribed to the bug\r\n> report.\r\n> https://bugs.launchpad.net/bugs/997978\r\n> \r\n> Title:\r\n>  KVM images lose connectivity with bridged network\r\n> \r\n> Status in OpenStack Compute (Nova):\r\n>  New\r\n> Status in \u201cbridge-utils\u201d package in Ubuntu:\r\n>  Invalid\r\n> Status in \u201cifenslave\u201d package in Ubuntu:\r\n>  Confirmed\r\n> Status in \u201clibvirt\u201d package in Ubuntu:\r\n>  Confirmed\r\n> Status in \u201clinux\u201d package in Ubuntu:\r\n>  Confirmed\r\n> Status in \u201cqemu-kvm\u201d package in Ubuntu:\r\n>  Confirmed\r\n> \r\n> Bug description:\r\n>  System:\r\n>  -----------\r\n>  Dell R410 Dual processor 2.4Ghz w/16G RAM\r\n>  Distributor ID: Ubuntu\r\n>  Description:    Ubuntu 12.04 LTS\r\n>  Release:        12.04\r\n>  Codename:       precise\r\n> \r\n>  Setup:\r\n>  ---------\r\n>  We're running 3 KVM guests, all Ubuntu 12.04 LTS using bridged networking. \r\n> \r\n>  From the host:\r\n>  # cat /etc/network/interfaces\r\n>  auto br0\r\n>  iface br0 inet static\r\n>          address 212.XX.239.98\r\n>          netmask 255.255.255.240\r\n>          gateway 212.XX.239.97\r\n>          bridge_ports eth0\r\n>          bridge_fd 9\r\n>          bridge_hello 2\r\n>          bridge_maxage 12\r\n>          bridge_stp off\r\n> \r\n>  # ifconfig eth0\r\n>  eth0      Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a  \r\n>            UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\r\n>            RX packets:11278363 errors:0 dropped:3128 overruns:0 frame:0\r\n>            TX packets:14437384 errors:0 dropped:0 overruns:0 carrier:0\r\n>            collisions:0 txqueuelen:1000 \r\n>            RX bytes:4115980743 (4.1 GB)  TX bytes:5451961979 (5.4 GB)\r\n>            Interrupt:36 Memory:da000000-da012800 \r\n> \r\n>  # ifconfig br0\r\n>  br0       Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a  \r\n>            inet addr:212.XX.239.98  Bcast:212.XX.239.111  Mask:255.255.255.240\r\n>            inet6 addr: fe80::d6ae:52ff:fe84:2d5a/64 Scope:Link\r\n>            UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\r\n>            RX packets:1720861 errors:0 dropped:0 overruns:0 frame:0\r\n>            TX packets:1708622 errors:0 dropped:0 overruns:0 carrier:0\r\n>            collisions:0 txqueuelen:0 \r\n>            RX bytes:210152198 (210.1 MB)  TX bytes:300858508 (300.8 MB)\r\n> \r\n>  # brctl show\r\n>  bridge name     bridge id               STP enabled     interfaces\r\n>  br0             8000.d4ae52842d5a       no              eth0\r\n> \r\n>  I have no default network configured to autostart in libvirt as we're using bridged networking:\r\n>  # virsh net-list --all\r\n>  Name                 State      Autostart\r\n>  -----------------------------------------\r\n>  default              inactive   no        \r\n> \r\n>  # arp\r\n>  Address                  HWtype  HWaddress           Flags Mask            Iface\r\n>  mailer03.xxxx.com       ether   52:54:00:82:5f:0f   C                     br0\r\n>  mailer01.xxxx.com       ether   52:54:00:d2:f7:31   C                     br0\r\n>  mailer02.xxxx.com       ether   52:54:00:d3:8f:91   C                     br0\r\n>  dxi-gw2.xxxx.com        ether   00:1a:30:2a:b1:c0   C                     br0\r\n> \r\n>  From one of the guests:\r\n>  <domain type='kvm' id='4'>\r\n>    <name>mailer01</name>\r\n>    <uuid>d41d1355-84e8-ae23-e84e-227bc0231b97</uuid>\r\n>    <memory>2097152</memory>\r\n>    <currentMemory>2097152</currentMemory>\r\n>    <vcpu>1</vcpu>\r\n>    <os>\r\n>      <type arch='x86_64' machine='pc-1.0'>hvm</type>\r\n>      <boot dev='hd'/>\r\n>    </os>\r\n>    <features>\r\n>      <acpi/>\r\n>    </features>\r\n>    <clock offset='utc'/>\r\n>    <on_poweroff>destroy</on_poweroff>\r\n>    <on_reboot>restart</on_reboot>\r\n>    <on_crash>destroy</on_crash>\r\n>    <devices>\r\n>      <emulator>/usr/bin/kvm</emulator>\r\n>      <disk type='file' device='disk'>\r\n>        <driver name='qemu' type='raw'/>\r\n>        <source file='/dev/mapper/vg_main-mailer01--root'/>\r\n>        <target dev='hda' bus='ide'/>\r\n>        <alias name='ide0-0-0'/>\r\n>        <address type='drive' controller='0' bus='0' unit='0'/>\r\n>      </disk>\r\n>      <disk type='file' device='disk'>\r\n>        <driver name='qemu' type='raw'/>\r\n>        <source file='/dev/mapper/vg_main-mailer01--swap'/>\r\n>        <target dev='hdb' bus='ide'/>\r\n>        <alias name='ide0-0-1'/>\r\n>        <address type='drive' controller='0' bus='0' unit='1'/>\r\n>      </disk>\r\n>      <controller type='ide' index='0'>\r\n>        <alias name='ide0'/>\r\n>        <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>\r\n>      </controller>\r\n>      <interface type='bridge'>\r\n>        <mac address='52:54:00:d2:f7:31'/>\r\n>        <source bridge='br0'/>\r\n>        <target dev='vnet0'/>\r\n>        <model type='virtio'/>\r\n>        <alias name='net0'/>\r\n>        <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>\r\n>      </interface>\r\n>      <serial type='pty'>\r\n>        <source path='/dev/pts/0'/>\r\n>        <target port='0'/>\r\n>        <alias name='serial0'/>\r\n>      </serial>\r\n>      <console type='pty' tty='/dev/pts/0'>\r\n>        <source path='/dev/pts/0'/>\r\n>        <target type='serial' port='0'/>\r\n>        <alias name='serial0'/>\r\n>      </console>\r\n>      <input type='mouse' bus='ps2'/>\r\n>      <graphics type='vnc' port='5900' autoport='yes' listen='127.0.0.1'>\r\n>        <listen type='address' address='127.0.0.1'/>\r\n>      </graphics>\r\n>      <video>\r\n>        <model type='cirrus' vram='9216' heads='1'/>\r\n>        <alias name='video0'/>\r\n>        <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>\r\n>      </video>\r\n>      <memballoon model='virtio'>\r\n>        <alias name='balloon0'/>\r\n>        <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>\r\n>      </memballoon>\r\n>    </devices>\r\n>    <seclabel type='dynamic' model='apparmor' relabel='yes'>\r\n>      <label>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</label>\r\n>      <imagelabel>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</imagelabel>\r\n>    </seclabel>\r\n>  </domain>\r\n> \r\n>  From within the guest:\r\n>  # cat /etc/network/interfaces \r\n>  # The primary network interface\r\n>  auto eth0\r\n>  iface eth0 inet static\r\n>          address 212.XX.239.100\r\n>          netmask 255.255.255.240 \r\n>          network 212.XX.239.96\r\n>          broadcast 212.XX.239.111\r\n>          gateway 212.XX.239.97\r\n> \r\n>  # ifconfig\r\n>  eth0      Link encap:Ethernet  HWaddr 52:54:00:d2:f7:31  \r\n>            inet addr:212.XX.239.100  Bcast:212.XX.239.111  Mask:255.255.255.240\r\n>            inet6 addr: fe80::5054:ff:fed2:f731/64 Scope:Link\r\n>            UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\r\n>            RX packets:5631830 errors:0 dropped:0 overruns:0 frame:0\r\n>            TX packets:6683416 errors:0 dropped:0 overruns:0 carrier:0\r\n>            collisions:0 txqueuelen:1000 \r\n>            RX bytes:2027322829 (2.0 GB)  TX bytes:2076698690 (2.0 GB)\r\n> \r\n> \r\n>  A commandline which starts the KVM guest:\r\n>  /usr/bin/kvm -S -M pc-1.0 -enable-kvm -m 2048 -smp 1,sockets=1,cores=1,threads=1 -name mailer01 -uuid d41d1355-84e8-ae23-e84e-227bc0231b97 -nodefconfig -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/mailer01.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-shutdown -drive file=/dev/mapper/vg_main-mailer01--root,if=none,id=drive-ide0-0-0,format=raw -device ide-drive,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0,bootindex=1 -drive file=/dev/mapper/vg_main-mailer01--swap,if=none,id=drive-ide0-0-1,format=raw -device ide-drive,bus=ide.0,unit=1,drive=drive-ide0-0-1,id=ide0-0-1 -netdev tap,fd=18,id=hostnet0 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:d2:f7:31,bus=pci.0,addr=0x3 -chardev pty,id=charserial0 -device isa-serial,chardev=charserial0,id=serial0 -usb -vnc 127.0.0.1:0 -vga cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x4\r\n> \r\n>  Problem:\r\n>  ------------\r\n>  Periodically (at least once a day), one or more of the guests lose network connectivity.  Ping responds with 'host unreachable', even from the dom host. Logging in via the serial console shows no problems: eth0 is up, can ping the local host, but no outside connectivity.  Restart the network (/etc/init.d/networking restart) does nothing. Reboot the machine and it comes alive again.\r\n> \r\n>  I've verified there's no arp games going on on the primary host (the\r\n>  arp tables remain the same before - when it had connectivity - and\r\n>  after - when it doesn't.\r\n> \r\n>  This is a critical issue affecting production services on the latest\r\n>  LTS release of Ubuntu. It's similar to an issue which was 'resolved'\r\n>  in 10.04 but appears to have risen its ugly head again.\r\n> \r\n> To manage notifications about this bug go to:\r\n> https://bugs.launchpad.net/nova/+bug/997978/+subscriptions\r\n> \r\n", 
            "date_created": "2012-08-16 14:40:16+00:00", 
            "author": "https://api.launchpad.net/1.0/~kamador"
        }, 
        {
            "content": "Hi Serge,\nI would be willing to install your ppa packages.  The only issue on my end is that this problem only occurs every 3-4 weeks for me.  So I don't think I would be able to give any sort of concrete feedback for whether it addresses the issue or not.\n\nMy customer's server was having the issue several times per week, but I had to take action pretty quickly to keep them happy and chose to backdate to 11.10.  After 9 days, they have not had the issue, which lends more evidence that it is not a guest-based issue but host-based.", 
            "date_created": "2012-08-16 15:28:09.581971+00:00", 
            "author": "https://api.launchpad.net/1.0/~ua5r"
        }, 
        {
            "content": "as a counter-example, our original deployment of eight 12.04 guests on 12.04 hosts were dropping off the network regularly.  when the guests were reinstalled as 10.04 (on the same hosts, with the same workload) the problem did not recur.", 
            "date_created": "2012-08-16 15:47:48.819694+00:00", 
            "author": "https://api.launchpad.net/1.0/~abezella"
        }, 
        {
            "content": "Thanks, Gary,   I've pushed a test package, with version0.9.13-0ubuntu7ppa1,  to ppa:ubuntu-virt/backport.  Once it builds, you can install it with\n\nsudo add-apt-repository ppa:ubuntu-virt/backport\nsudo apt-get update\nsudo apt-get -y dist-upgrade", 
            "date_created": "2012-08-16 15:50:52.530776+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Sorry.  Obviously that needs to be qemu-kvm.  I'll add that in a few minutes.", 
            "date_created": "2012-08-16 15:53:24.927057+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I will test too", 
            "date_created": "2012-08-20 14:09:44.387730+00:00", 
            "author": "https://api.launchpad.net/1.0/~vachon"
        }, 
        {
            "content": "Your ubuntu-virt ppa is actually coming up with no canidate repo.  Did this already get merged into the mainline?", 
            "date_created": "2012-08-20 14:16:21.627907+00:00", 
            "author": "https://api.launchpad.net/1.0/~vachon"
        }, 
        {
            "content": "Anecdotal evidence[1] suggests that this is a problem with the driver in the guest. It would be interesting to learn when this problem appeared and if it's gone with Quantal guests.\n\n[1]: http://lists.openstack.org/pipermail/openstack-operators/2012-August/001921.html", 
            "date_created": "2012-08-20 21:08:38.915902+00:00", 
            "author": "https://api.launchpad.net/1.0/~soren"
        }, 
        {
            "content": "@Thomas,\n\nI'm sorry, that should be 'ppa:ubuntu-virt/backports' (plural, not singular).", 
            "date_created": "2012-08-20 21:30:55.317967+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "This bug also affects me.\nI run several VMs on the same host. A mix of ubuntu 11.10 and 12.04.  The problem occurs regardless of guest OS.\nI was experiencing the problem for months, though it was occuring rarely and I didn't search for a solution.  Recently it started happening every day (sometimes twice a day), because we started using the machines in question more heavily.\n\nI can easily confirm that this happens on high network traffic machines. It never occurs on ones with lower traffic, and it always occurs after a machine's network traffic increases for some reason (services on it start being used more frequently etc.)\n\nNow I'll install Serge's PPA and we'll see what happens. Please, correct me if I'm wrong, but as far as I understood, I only need to install that on the host, right?\n\n", 
            "date_created": "2012-08-24 08:07:09.131191+00:00", 
            "author": "https://api.launchpad.net/1.0/~akat-metin"
        }, 
        {
            "content": "I think the big is in the guest code. Did you try 10.04 LTS?\n", 
            "date_created": "2012-08-24 10:42:40+00:00", 
            "author": "https://api.launchpad.net/1.0/~vachon"
        }, 
        {
            "content": "No I might try it later today (as a guest)\n\nI installed the PPA to the host. From what I can see, the situation is even worse. Had several failures in the first 2 hours since.", 
            "date_created": "2012-08-24 11:08:49.109377+00:00", 
            "author": "https://api.launchpad.net/1.0/~akat-metin"
        }, 
        {
            "content": "Quoting Metin Akat (<email address hidden>):\n> No I might try it later today (as a guest)\n> \n> I installed the PPA to the host. From what I can see, the situation is\n> even worse. Had several failures in the first 2 hours since.\n\nThanks, that's valuable information.\n\n(Yes, the ppa was to be installed on the host, not the guests)\n", 
            "date_created": "2012-08-24 15:41:43+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Today I see there is a new qemu-kvm package on the PPA. Installed. Let's se what happens.", 
            "date_created": "2012-08-25 08:34:35.513723+00:00", 
            "author": "https://api.launchpad.net/1.0/~akat-metin"
        }, 
        {
            "content": "So far no VMs have lost their network connectivity.", 
            "date_created": "2012-08-27 11:36:50.224724+00:00", 
            "author": "https://api.launchpad.net/1.0/~akat-metin"
        }, 
        {
            "content": "@Metin,\n\nstill no incidents?", 
            "date_created": "2012-08-28 15:16:25.922479+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "@Serge\nYes, still no incidents. Haven't updated the machine since.", 
            "date_created": "2012-08-29 10:06:26.039468+00:00", 
            "author": "https://api.launchpad.net/1.0/~akat-metin"
        }, 
        {
            "content": "I installed the new packages on Monday and have not had any issues.  That said, I was only experiencing failures once every 3-4 weeks.  So I don't think my data point will be valid for at least a few weeks.", 
            "date_created": "2012-08-29 14:48:09.376147+00:00", 
            "author": "https://api.launchpad.net/1.0/~ua5r"
        }, 
        {
            "content": "Quoting Gary Cuozzo (<email address hidden>):\n> I installed the new packages on Monday and have not had any issues.\n> That said, I was only experiencing failures once every 3-4 weeks.  So I\n> don't think my data point will be valid for at least a few weeks.\n\nThanks, Gary, will wait before making assumptions.\n", 
            "date_created": "2012-08-29 15:23:28+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I am absolutely sure that at least with me, this is fixed. Whole working week and not a single incident. It used to be several every day last week (before I updated to the PPA)", 
            "date_created": "2012-08-31 11:09:27.492905+00:00", 
            "author": "https://api.launchpad.net/1.0/~akat-metin"
        }, 
        {
            "content": "Thanks for the feedback.\n\nI've looked through the commit log and found no obvious single or group of commits which would solve this.\n\nWe could talk about backporting the quantal packages into precise - however the quantal packages do appear to also bring in their own regressions, for instance bug 1040033.\n\nLet's see if the packages also fix it for Gary.", 
            "date_created": "2012-08-31 20:17:59.164104+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Soren has suggested commit a281ebc11a6917fbc27e1a93bb5772cd14e241fc ('virtio: add missing mb() on notification') seems a likely candidate for a fix.", 
            "date_created": "2012-08-31 20:42:37.552070+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I am also seeing the problem on our Ganeti managed KVM under Ubuntu 12.04.  In our case on those servers with higher network load,  connectivity  to the guest is lost but may take one to two days.   The one server with low network traffic has never lost connectivity.\n\nBy the way the loss of connectivity problem does not happen with 12.04 guests running on 11.10 containers.\n\nI have patched to the current levels but still see the problem. The kvm  package installed is;\nkvm  1:84+dfsg-0ubuntu16+1.0+noroms+0ubuntu14.1\n\nIs there something else I should be looking for? \n\nThanks", 
            "date_created": "2012-09-01 00:12:28.753584+00:00", 
            "author": "https://api.launchpad.net/1.0/~gustavehellman"
        }, 
        {
            "content": "confirm the issue.\n\nif i upgrade to the ppa, can i upgrade to official package later? how long will the ppa become official package?", 
            "date_created": "2012-09-01 15:16:17.724064+00:00", 
            "author": "https://api.launchpad.net/1.0/~ppyy"
        }, 
        {
            "content": "@Peng Yong. Yes, you can. There is a package called ppa-purge in the official repositories. Install it. It will allow you to revert to official packages at will.", 
            "date_created": "2012-09-03 07:57:04.129596+00:00", 
            "author": "https://api.launchpad.net/1.0/~akat-metin"
        }, 
        {
            "content": "As Serge says, we think we've narrowed in on the set of commits that will address this problem:\n\n   a821ce5 virtio: order index/descriptor reads\n   92045d8 virtio: add missing mb() on enable notification\n   a281ebc virtio: add missing mb() on notification\n\nI'd be happy to provide a SRU candidate in a PPA with just those patches applied if anyone is willing to test?\n\nSerge, would it be ok for me to use the ubuntu-virt/backports ppa for this, or would you rather I create a new PPA?", 
            "date_created": "2012-09-03 08:12:41.301021+00:00", 
            "author": "https://api.launchpad.net/1.0/~soren"
        }, 
        {
            "content": "I can test that. I had to use the hardware to deal with a separate issue but I loaded up the backported package on Friday and I have been running a test over the weekend. No problems yet. \r\n\r\nSent from my iPhone\r\n\r\nOn Sep 3, 2012, at 1:21 AM, Soren Hansen <email address hidden> wrote:\r\n\r\n> As Serge says, we think we've narrowed in on the set of commits that\r\n> will address this problem:\r\n> \r\n>   a821ce5 virtio: order index/descriptor reads\r\n>   92045d8 virtio: add missing mb() on enable notification\r\n>   a281ebc virtio: add missing mb() on notification\r\n> \r\n> I'd be happy to provide a SRU candidate in a PPA with just those patches\r\n> applied if anyone is willing to test?\r\n> \r\n> Serge, would it be ok for me to use the ubuntu-virt/backports ppa for\r\n> this, or would you rather I create a new PPA?\r\n> \r\n> -- \r\n> You received this bug notification because you are subscribed to the bug\r\n> report.\r\n> https://bugs.launchpad.net/bugs/997978\r\n> \r\n> Title:\r\n>  KVM images lose connectivity with bridged network\r\n> \r\n> Status in OpenStack Compute (Nova):\r\n>  New\r\n> Status in \u201cbridge-utils\u201d package in Ubuntu:\r\n>  Invalid\r\n> Status in \u201cifenslave\u201d package in Ubuntu:\r\n>  Confirmed\r\n> Status in \u201clibvirt\u201d package in Ubuntu:\r\n>  Confirmed\r\n> Status in \u201clinux\u201d package in Ubuntu:\r\n>  Confirmed\r\n> Status in \u201cqemu-kvm\u201d package in Ubuntu:\r\n>  Confirmed\r\n> \r\n> Bug description:\r\n>  System:\r\n>  -----------\r\n>  Dell R410 Dual processor 2.4Ghz w/16G RAM\r\n>  Distributor ID: Ubuntu\r\n>  Description:    Ubuntu 12.04 LTS\r\n>  Release:        12.04\r\n>  Codename:       precise\r\n> \r\n>  Setup:\r\n>  ---------\r\n>  We're running 3 KVM guests, all Ubuntu 12.04 LTS using bridged networking. \r\n> \r\n>  From the host:\r\n>  # cat /etc/network/interfaces\r\n>  auto br0\r\n>  iface br0 inet static\r\n>          address 212.XX.239.98\r\n>          netmask 255.255.255.240\r\n>          gateway 212.XX.239.97\r\n>          bridge_ports eth0\r\n>          bridge_fd 9\r\n>          bridge_hello 2\r\n>          bridge_maxage 12\r\n>          bridge_stp off\r\n> \r\n>  # ifconfig eth0\r\n>  eth0      Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a  \r\n>            UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\r\n>            RX packets:11278363 errors:0 dropped:3128 overruns:0 frame:0\r\n>            TX packets:14437384 errors:0 dropped:0 overruns:0 carrier:0\r\n>            collisions:0 txqueuelen:1000 \r\n>            RX bytes:4115980743 (4.1 GB)  TX bytes:5451961979 (5.4 GB)\r\n>            Interrupt:36 Memory:da000000-da012800 \r\n> \r\n>  # ifconfig br0\r\n>  br0       Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a  \r\n>            inet addr:212.XX.239.98  Bcast:212.XX.239.111  Mask:255.255.255.240\r\n>            inet6 addr: fe80::d6ae:52ff:fe84:2d5a/64 Scope:Link\r\n>            UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\r\n>            RX packets:1720861 errors:0 dropped:0 overruns:0 frame:0\r\n>            TX packets:1708622 errors:0 dropped:0 overruns:0 carrier:0\r\n>            collisions:0 txqueuelen:0 \r\n>            RX bytes:210152198 (210.1 MB)  TX bytes:300858508 (300.8 MB)\r\n> \r\n>  # brctl show\r\n>  bridge name     bridge id               STP enabled     interfaces\r\n>  br0             8000.d4ae52842d5a       no              eth0\r\n> \r\n>  I have no default network configured to autostart in libvirt as we're using bridged networking:\r\n>  # virsh net-list --all\r\n>  Name                 State      Autostart\r\n>  -----------------------------------------\r\n>  default              inactive   no        \r\n> \r\n>  # arp\r\n>  Address                  HWtype  HWaddress           Flags Mask            Iface\r\n>  mailer03.xxxx.com       ether   52:54:00:82:5f:0f   C                     br0\r\n>  mailer01.xxxx.com       ether   52:54:00:d2:f7:31   C                     br0\r\n>  mailer02.xxxx.com       ether   52:54:00:d3:8f:91   C                     br0\r\n>  dxi-gw2.xxxx.com        ether   00:1a:30:2a:b1:c0   C                     br0\r\n> \r\n>  From one of the guests:\r\n>  <domain type='kvm' id='4'>\r\n>    <name>mailer01</name>\r\n>    <uuid>d41d1355-84e8-ae23-e84e-227bc0231b97</uuid>\r\n>    <memory>2097152</memory>\r\n>    <currentMemory>2097152</currentMemory>\r\n>    <vcpu>1</vcpu>\r\n>    <os>\r\n>      <type arch='x86_64' machine='pc-1.0'>hvm</type>\r\n>      <boot dev='hd'/>\r\n>    </os>\r\n>    <features>\r\n>      <acpi/>\r\n>    </features>\r\n>    <clock offset='utc'/>\r\n>    <on_poweroff>destroy</on_poweroff>\r\n>    <on_reboot>restart</on_reboot>\r\n>    <on_crash>destroy</on_crash>\r\n>    <devices>\r\n>      <emulator>/usr/bin/kvm</emulator>\r\n>      <disk type='file' device='disk'>\r\n>        <driver name='qemu' type='raw'/>\r\n>        <source file='/dev/mapper/vg_main-mailer01--root'/>\r\n>        <target dev='hda' bus='ide'/>\r\n>        <alias name='ide0-0-0'/>\r\n>        <address type='drive' controller='0' bus='0' unit='0'/>\r\n>      </disk>\r\n>      <disk type='file' device='disk'>\r\n>        <driver name='qemu' type='raw'/>\r\n>        <source file='/dev/mapper/vg_main-mailer01--swap'/>\r\n>        <target dev='hdb' bus='ide'/>\r\n>        <alias name='ide0-0-1'/>\r\n>        <address type='drive' controller='0' bus='0' unit='1'/>\r\n>      </disk>\r\n>      <controller type='ide' index='0'>\r\n>        <alias name='ide0'/>\r\n>        <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>\r\n>      </controller>\r\n>      <interface type='bridge'>\r\n>        <mac address='52:54:00:d2:f7:31'/>\r\n>        <source bridge='br0'/>\r\n>        <target dev='vnet0'/>\r\n>        <model type='virtio'/>\r\n>        <alias name='net0'/>\r\n>        <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>\r\n>      </interface>\r\n>      <serial type='pty'>\r\n>        <source path='/dev/pts/0'/>\r\n>        <target port='0'/>\r\n>        <alias name='serial0'/>\r\n>      </serial>\r\n>      <console type='pty' tty='/dev/pts/0'>\r\n>        <source path='/dev/pts/0'/>\r\n>        <target type='serial' port='0'/>\r\n>        <alias name='serial0'/>\r\n>      </console>\r\n>      <input type='mouse' bus='ps2'/>\r\n>      <graphics type='vnc' port='5900' autoport='yes' listen='127.0.0.1'>\r\n>        <listen type='address' address='127.0.0.1'/>\r\n>      </graphics>\r\n>      <video>\r\n>        <model type='cirrus' vram='9216' heads='1'/>\r\n>        <alias name='video0'/>\r\n>        <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>\r\n>      </video>\r\n>      <memballoon model='virtio'>\r\n>        <alias name='balloon0'/>\r\n>        <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>\r\n>      </memballoon>\r\n>    </devices>\r\n>    <seclabel type='dynamic' model='apparmor' relabel='yes'>\r\n>      <label>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</label>\r\n>      <imagelabel>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</imagelabel>\r\n>    </seclabel>\r\n>  </domain>\r\n> \r\n>  From within the guest:\r\n>  # cat /etc/network/interfaces \r\n>  # The primary network interface\r\n>  auto eth0\r\n>  iface eth0 inet static\r\n>          address 212.XX.239.100\r\n>          netmask 255.255.255.240 \r\n>          network 212.XX.239.96\r\n>          broadcast 212.XX.239.111\r\n>          gateway 212.XX.239.97\r\n> \r\n>  # ifconfig\r\n>  eth0      Link encap:Ethernet  HWaddr 52:54:00:d2:f7:31  \r\n>            inet addr:212.XX.239.100  Bcast:212.XX.239.111  Mask:255.255.255.240\r\n>            inet6 addr: fe80::5054:ff:fed2:f731/64 Scope:Link\r\n>            UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\r\n>            RX packets:5631830 errors:0 dropped:0 overruns:0 frame:0\r\n>            TX packets:6683416 errors:0 dropped:0 overruns:0 carrier:0\r\n>            collisions:0 txqueuelen:1000 \r\n>            RX bytes:2027322829 (2.0 GB)  TX bytes:2076698690 (2.0 GB)\r\n> \r\n> \r\n>  A commandline which starts the KVM guest:\r\n>  /usr/bin/kvm -S -M pc-1.0 -enable-kvm -m 2048 -smp 1,sockets=1,cores=1,threads=1 -name mailer01 -uuid d41d1355-84e8-ae23-e84e-227bc0231b97 -nodefconfig -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/mailer01.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-shutdown -drive file=/dev/mapper/vg_main-mailer01--root,if=none,id=drive-ide0-0-0,format=raw -device ide-drive,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0,bootindex=1 -drive file=/dev/mapper/vg_main-mailer01--swap,if=none,id=drive-ide0-0-1,format=raw -device ide-drive,bus=ide.0,unit=1,drive=drive-ide0-0-1,id=ide0-0-1 -netdev tap,fd=18,id=hostnet0 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:d2:f7:31,bus=pci.0,addr=0x3 -chardev pty,id=charserial0 -device isa-serial,chardev=charserial0,id=serial0 -usb -vnc 127.0.0.1:0 -vga cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x4\r\n> \r\n>  Problem:\r\n>  ------------\r\n>  Periodically (at least once a day), one or more of the guests lose network connectivity.  Ping responds with 'host unreachable', even from the dom host. Logging in via the serial console shows no problems: eth0 is up, can ping the local host, but no outside connectivity.  Restart the network (/etc/init.d/networking restart) does nothing. Reboot the machine and it comes alive again.\r\n> \r\n>  I've verified there's no arp games going on on the primary host (the\r\n>  arp tables remain the same before - when it had connectivity - and\r\n>  after - when it doesn't.\r\n> \r\n>  This is a critical issue affecting production services on the latest\r\n>  LTS release of Ubuntu. It's similar to an issue which was 'resolved'\r\n>  in 10.04 but appears to have risen its ugly head again.\r\n> \r\n> To manage notifications about this bug go to:\r\n> https://bugs.launchpad.net/nova/+bug/997978/+subscriptions\r\n> \r\n", 
            "date_created": "2012-09-03 16:58:11+00:00", 
            "author": "https://api.launchpad.net/1.0/~kamador"
        }, 
        {
            "content": "Soren,\n\nthanks very much.  It's probably best to use a new ppa, as the backports may be more generally useful, and would force unfortunate versioning games.\n\nJust using ppa:ubuntu-virt/ppa should probably be fine too.", 
            "date_created": "2012-09-04 15:10:59.210411+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Packages are ready for testing in the all new ubuntu-virt/kvm-network-hang PPA.\n\nIt has a lower version than the test package Serge posted earlier, so you'll need to first disable that other PPA and then enable this one and upgrade.\n\nThis should do the trick:\n\n# You can skip these first two commands if you didn't test Serge's packages earlier\nsudo apt-get install ppa-purge\nsudo ppa-purge -p backports ubuntu-virt\n\nsudo add-apt-repository ppa:ubuntu-virt/kvm-network-hang\nsudo apt-get update\nsudo apt-get install qemu-kvm\n\nOf course, use at your own risk, etc.", 
            "date_created": "2012-09-04 21:54:35.314134+00:00", 
            "author": "https://api.launchpad.net/1.0/~soren"
        }, 
        {
            "content": "@Metin,\n\nwill you be able to test with the kernel Soren proposed in comment #89, or is that hardware now taken?", 
            "date_created": "2012-09-07 16:38:05.589351+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Ok, this bug seems to be about KVM networking bugs in Ubuntu. I don't see anything specific for upstream OpenStack developers to debug or fix. Marking as Invalid.\n\nIf there is some specific OpenStack upstream issue diagnosed, it's probably best to file a new bug with the details of the specific issue clearly isolated from everything else going on in this bug.", 
            "date_created": "2012-09-11 14:30:10.028123+00:00", 
            "author": "https://api.launchpad.net/1.0/~markmc"
        }, 
        {
            "content": "Canonical is now aware of this issue and they are working on it", 
            "date_created": "2012-09-21 18:23:59.956401+00:00", 
            "author": "https://api.launchpad.net/1.0/~cloudbuilders-n"
        }, 
        {
            "content": "I updated qemu-kvm package from ppa:ubuntu-virt/kvm-network-hang.\nI started next test to load network on VMs -\nOn VM 1 :\n% nc -k -l 0.0.0.0 4242 > /dev/null\nOn  VM 2:\n% cat /dev/zero | nc IP 4242\nThere is no problems with this VMs from 12/Sep/2012 .\nSo qemu-kvm package from this PPA resolved this issue.\n", 
            "date_created": "2012-09-24 09:15:24.919839+00:00", 
            "author": "https://api.launchpad.net/1.0/~enelen"
        }, 
        {
            "content": "Lovely, thanks for the feedback. I've just uploaded this to precise-proposed.", 
            "date_created": "2012-09-24 20:17:32.379732+00:00", 
            "author": "https://api.launchpad.net/1.0/~soren"
        }, 
        {
            "content": "We have been testing the kvm-network-hang patch in our production setup since 9/17. We just saw our second failure. This is much improved from the multiple failure per day we were seeing,  I don't think its fixed yet.", 
            "date_created": "2012-09-24 22:26:17.720682+00:00", 
            "author": "https://api.launchpad.net/1.0/~mjhilt-x"
        }, 
        {
            "content": "Matt, are the symptoms identical? You might be experiencing a different bug entirely.", 
            "date_created": "2012-09-25 12:22:53.787834+00:00", 
            "author": "https://api.launchpad.net/1.0/~soren"
        }, 
        {
            "content": "Soren,\n\nWe have a 12.04 based OpenStack cluster with 4 host nodes running about 30 VMs currently.\nWe performed the steps to add the kvm-network-hang repo and updated to the latest version on the host machines, then rebooted the instances. My understanding is that this should catch the update, since a new KVM command is run on reboot.\n\nI caught the first failure ~12 hours after the upgrade. It had the usual symptoms: networking loss, but the VM is still up and an active VNC session was possible. I thought I just might have missed a reboot on one of the VMs, so I didn't report anything. The second failure happened yesterday, but someone else caught it and rebooted the VM. As best we can tell after the fact, it looks like the usual failure (no full harddrive, or kernel panic, or anything that got logged).\n\nAs  I mentioned before, we used to see at least one failure per day, usually much more. This patch has at least reduced the occurence to a minimal amount. These non-deterministic bugs are hard to track down.\n\n", 
            "date_created": "2012-09-25 16:07:44.648605+00:00", 
            "author": "https://api.launchpad.net/1.0/~mjhilt-x"
        }, 
        {
            "content": "I don't believe just rebooting a guest will cause a new KVM instance to load.  As a test, I just rebooted a guest VM on a system here and the pid of the kvm process did not change.  I think it may be possible that you are still running on the old software.\n\nAlso, to update my data point...  On my server which was experiencing issues, I rebooted the host just to make sure everything was fresh.  It's been about a month and I have not experienced the failure again.  I was typically going a few weeks between issues.\n\ngary\n\n\n----- Original Message -----\nFrom: \"Matt Hilt\" <email address hidden>\nTo: <email address hidden>\nSent: Tuesday, September 25, 2012 12:07:44 PM\nSubject: [Bug 997978] Re: KVM images lose connectivity with bridged network\n\nSoren,\n\nWe have a 12.04 based OpenStack cluster with 4 host nodes running about 30 VMs currently.\nWe performed the steps to add the kvm-network-hang repo and updated to the latest version on the host machines, then rebooted the instances. My understanding is that this should catch the update, since a new KVM command is run on reboot.\n\nI caught the first failure ~12 hours after the upgrade. It had the usual\nsymptoms: networking loss, but the VM is still up and an active VNC\nsession was possible. I thought I just might have missed a reboot on one\nof the VMs, so I didn't report anything. The second failure happened\nyesterday, but someone else caught it and rebooted the VM. As best we\ncan tell after the fact, it looks like the usual failure (no full\nharddrive, or kernel panic, or anything that got logged).\n\nAs  I mentioned before, we used to see at least one failure per day,\nusually much more. This patch has at least reduced the occurence to a\nminimal amount. These non-deterministic bugs are hard to track down.\n\n-- \nYou received this bug notification because you are subscribed to the bug\nreport.\nhttps://bugs.launchpad.net/bugs/997978\n\nTitle:\n  KVM images lose connectivity with bridged network\n\nStatus in OpenStack Compute (Nova):\n  Invalid\nStatus in \u201cqemu-kvm\u201d package in Ubuntu:\n  Fix Released\nStatus in \u201cqemu-kvm\u201d source package in Precise:\n  In Progress\n\nBug description:\n  =========================================\n  SRU Justification:\n  1. Impact: networking breaks after awhile in kvm guests using virtio networking\n  2. Development fix: The bug was fixed upstream and the fix picked up in a new\n     merge.\n  3. Stable fix: 3 virtio patches are cherrypicked from upstream:\n     a821ce5 virtio: order index/descriptor reads\n     92045d8 virtio: add missing mb() on enable notification\n     a281ebc virtio: add missing mb() on notification\n  4. Test case: Create a bridge enslaving the real NIC, and use that as the bridge\n     for a kvm instance with virtio networking.  See comment #44 for specific test\n     case.\n  5. Regression potential: Should be low as several people have tested the fixed\n     package under heavy load.\n  =========================================\n\n  System:\n  -----------\n  Dell R410 Dual processor 2.4Ghz w/16G RAM\n  Distributor ID: Ubuntu\n  Description:    Ubuntu 12.04 LTS\n  Release:        12.04\n  Codename:       precise\n\n  Setup:\n  ---------\n  We're running 3 KVM guests, all Ubuntu 12.04 LTS using bridged networking.\n\n  From the host:\n  # cat /etc/network/interfaces\n  auto br0\n  iface br0 inet static\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0address 212.XX.239.98\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0netmask 255.255.255.240\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0gateway 212.XX.239.97\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_ports eth0\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_fd 9\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_hello 2\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_maxage 12\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0bridge_stp off\n\n  # ifconfig eth0\n  eth0      Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX packets:11278363 errors:0 dropped:3128 overruns:0 frame:0\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TX packets:14437384 errors:0 dropped:0 overruns:0 carrier:0\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0collisions:0 txqueuelen:1000\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX bytes:4115980743 (4.1 GB)  TX bytes:5451961979 (5.4 GB)\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Interrupt:36 Memory:da000000-da012800\n\n  # ifconfig br0\n  br0       Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0inet addr:212.XX.239.98  Bcast:212.XX.239.111  Mask:255.255.255.240\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0inet6 addr: fe80::d6ae:52ff:fe84:2d5a/64 Scope:Link\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX packets:1720861 errors:0 dropped:0 overruns:0 frame:0\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TX packets:1708622 errors:0 dropped:0 overruns:0 carrier:0\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0collisions:0 txqueuelen:0\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX bytes:210152198 (210.1 MB)  TX bytes:300858508 (300.8 MB)\n\n  # brctl show\n  bridge name     bridge id               STP enabled     interfaces\n  br0             8000.d4ae52842d5a       no              eth0\n\n  I have no default network configured to autostart in libvirt as we're using bridged networking:\n  # virsh net-list --all\n  Name                 State      Autostart\n  -----------------------------------------\n  default              inactive   no\n\n  # arp\n  Address                  HWtype  HWaddress           Flags Mask            Iface\n  mailer03.xxxx.com       ether   52:54:00:82:5f:0f   C                     br0\n  mailer01.xxxx.com       ether   52:54:00:d2:f7:31   C                     br0\n  mailer02.xxxx.com       ether   52:54:00:d3:8f:91   C                     br0\n  dxi-gw2.xxxx.com        ether   00:1a:30:2a:b1:c0   C                     br0\n\n  From one of the guests:\n  <domain type='kvm' id='4'>\n  \u00a0\u00a0<name>mailer01</name>\n  \u00a0\u00a0<uuid>d41d1355-84e8-ae23-e84e-227bc0231b97</uuid>\n  \u00a0\u00a0<memory>2097152</memory>\n  \u00a0\u00a0<currentMemory>2097152</currentMemory>\n  \u00a0\u00a0<vcpu>1</vcpu>\n  \u00a0\u00a0<os>\n  \u00a0\u00a0\u00a0\u00a0<type arch='x86_64' machine='pc-1.0'>hvm</type>\n  \u00a0\u00a0\u00a0\u00a0<boot dev='hd'/>\n  \u00a0\u00a0</os>\n  \u00a0\u00a0<features>\n  \u00a0\u00a0\u00a0\u00a0<acpi/>\n  \u00a0\u00a0</features>\n  \u00a0\u00a0<clock offset='utc'/>\n  \u00a0\u00a0<on_poweroff>destroy</on_poweroff>\n  \u00a0\u00a0<on_reboot>restart</on_reboot>\n  \u00a0\u00a0<on_crash>destroy</on_crash>\n  \u00a0\u00a0<devices>\n  \u00a0\u00a0\u00a0\u00a0<emulator>/usr/bin/kvm</emulator>\n  \u00a0\u00a0\u00a0\u00a0<disk type='file' device='disk'>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<driver name='qemu' type='raw'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source file='/dev/mapper/vg_main-mailer01--root'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target dev='hda' bus='ide'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='ide0-0-0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='drive' controller='0' bus='0' unit='0'/>\n  \u00a0\u00a0\u00a0\u00a0</disk>\n  \u00a0\u00a0\u00a0\u00a0<disk type='file' device='disk'>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<driver name='qemu' type='raw'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source file='/dev/mapper/vg_main-mailer01--swap'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target dev='hdb' bus='ide'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='ide0-0-1'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='drive' controller='0' bus='0' unit='1'/>\n  \u00a0\u00a0\u00a0\u00a0</disk>\n  \u00a0\u00a0\u00a0\u00a0<controller type='ide' index='0'>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='ide0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>\n  \u00a0\u00a0\u00a0\u00a0</controller>\n  \u00a0\u00a0\u00a0\u00a0<interface type='bridge'>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<mac address='52:54:00:d2:f7:31'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source bridge='br0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target dev='vnet0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<model type='virtio'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='net0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>\n  \u00a0\u00a0\u00a0\u00a0</interface>\n  \u00a0\u00a0\u00a0\u00a0<serial type='pty'>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source path='/dev/pts/0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target port='0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='serial0'/>\n  \u00a0\u00a0\u00a0\u00a0</serial>\n  \u00a0\u00a0\u00a0\u00a0<console type='pty' tty='/dev/pts/0'>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<source path='/dev/pts/0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<target type='serial' port='0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='serial0'/>\n  \u00a0\u00a0\u00a0\u00a0</console>\n  \u00a0\u00a0\u00a0\u00a0<input type='mouse' bus='ps2'/>\n  \u00a0\u00a0\u00a0\u00a0<graphics type='vnc' port='5900' autoport='yes' listen='127.0.0.1'>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<listen type='address' address='127.0.0.1'/>\n  \u00a0\u00a0\u00a0\u00a0</graphics>\n  \u00a0\u00a0\u00a0\u00a0<video>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<model type='cirrus' vram='9216' heads='1'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='video0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>\n  \u00a0\u00a0\u00a0\u00a0</video>\n  \u00a0\u00a0\u00a0\u00a0<memballoon model='virtio'>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<alias name='balloon0'/>\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0<address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>\n  \u00a0\u00a0\u00a0\u00a0</memballoon>\n  \u00a0\u00a0</devices>\n  \u00a0\u00a0<seclabel type='dynamic' model='apparmor' relabel='yes'>\n  \u00a0\u00a0\u00a0\u00a0<label>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</label>\n  \u00a0\u00a0\u00a0\u00a0<imagelabel>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</imagelabel>\n  \u00a0\u00a0</seclabel>\n  </domain>\n\n  From within the guest:\n  # cat /etc/network/interfaces\n  # The primary network interface\n  auto eth0\n  iface eth0 inet static\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0address 212.XX.239.100\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0netmask 255.255.255.240\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0network 212.XX.239.96\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0broadcast 212.XX.239.111\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0gateway 212.XX.239.97\n\n  # ifconfig\n  eth0      Link encap:Ethernet  HWaddr 52:54:00:d2:f7:31\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0inet addr:212.XX.239.100  Bcast:212.XX.239.111  Mask:255.255.255.240\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0inet6 addr: fe80::5054:ff:fed2:f731/64 Scope:Link\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX packets:5631830 errors:0 dropped:0 overruns:0 frame:0\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TX packets:6683416 errors:0 dropped:0 overruns:0 carrier:0\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0collisions:0 txqueuelen:1000\n  \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RX bytes:2027322829 (2.0 GB)  TX bytes:2076698690 (2.0 GB)\n\n  A commandline which starts the KVM guest:\n  /usr/bin/kvm -S -M pc-1.0 -enable-kvm -m 2048 -smp 1,sockets=1,cores=1,threads=1 -name mailer01 -uuid d41d1355-84e8-ae23-e84e-227bc0231b97 -nodefconfig -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/mailer01.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-shutdown -drive file=/dev/mapper/vg_main-mailer01--root,if=none,id=drive-ide0-0-0,format=raw -device ide-drive,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0,bootindex=1 -drive file=/dev/mapper/vg_main-mailer01--swap,if=none,id=drive-ide0-0-1,format=raw -device ide-drive,bus=ide.0,unit=1,drive=drive-ide0-0-1,id=ide0-0-1 -netdev tap,fd=18,id=hostnet0 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:d2:f7:31,bus=pci.0,addr=0x3 -chardev pty,id=charserial0 -device isa-serial,chardev=charserial0,id=serial0 -usb -vnc 127.0.0.1:0 -vga cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x4\n\n  Problem:\n  ------------\n  Periodically (at least once a day), one or more of the guests lose network connectivity.  Ping responds with 'host unreachable', even from the dom host. Logging in via the serial console shows no problems: eth0 is up, can ping the local host, but no outside connectivity.  Restart the network (/etc/init.d/networking restart) does nothing. Reboot the machine and it comes alive again.\n\n  I've verified there's no arp games going on on the primary host (the\n  arp tables remain the same before - when it had connectivity - and\n  after - when it doesn't.\n\n  This is a critical issue affecting production services on the latest\n  LTS release of Ubuntu. It's similar to an issue which was 'resolved'\n  in 10.04 but appears to have risen its ugly head again.\n\nTo manage notifications about this bug go to:\nhttps://bugs.launchpad.net/nova/+bug/997978/+subscriptions\n", 
            "date_created": "2012-09-25 16:31:05+00:00", 
            "author": "https://api.launchpad.net/1.0/~ua5r"
        }, 
        {
            "content": "Running \"sudo reboot\" from the VM doesn't change the PID, but using the reboot command on the openstack dashboard does. \nIt seems like some of our VMs used the former, and some the later, with correlation between the soft reboot and the instance dying. So we'll hard reboot the vms, and profusely apologize for causing alarm.", 
            "date_created": "2012-09-25 17:33:27.634782+00:00", 
            "author": "https://api.launchpad.net/1.0/~mjhilt-x"
        }, 
        {
            "content": "Matt, no problem at all. Please be sure to report back if you encounter the issue again after the hard reboot. Thanks!", 
            "date_created": "2012-09-25 20:24:17.051195+00:00", 
            "author": "https://api.launchpad.net/1.0/~soren"
        }, 
        {
            "content": "Hello,\n\nPrior to applying the qemu package in Soren's PPA, we were able to reproduce this problem within 45 minutes (on average). We're now up to 22 hours (and climbing) without an issue.\n\nIf anyone is curious, here is the test setup that we have been using with OpenStack:\n\n---\n\nnova boot --image cfefd40f-be71-4c93-b480-c9964689f5ce --key_name sandbox --flavor 2 dhcp-1\n \ndhcp-1> sudo su\ndhcp-1> apt-get iperf\n\nnova boot --image cfefd40f-be71-4c93-b480-c9964689f5ce --key_name sandbox --flavor 2 dhcp-2\n\ndhcp-2> sudo su\ndhcp-2> apt-get iperf\ndhcp-2> iperf -s\n\ndhcp-1> iperf -c dhcp-1 -t 86400 -i 10\n\n---\n\nThanks,\nJoe", 
            "date_created": "2012-09-25 21:00:57.677553+00:00", 
            "author": "https://api.launchpad.net/1.0/~joe-topjian-v"
        }, 
        {
            "content": "Hello Jonathan, or anyone else affected,\n\nAccepted qemu-kvm into precise-proposed. The package will build now and be available at http://launchpad.net/ubuntu/+source/qemu-kvm/1.0+noroms-0ubuntu14.2 in a few hours, and then in the -proposed repository.\n\nPlease help us by testing this new package.  See https://wiki.ubuntu.com/Testing/EnableProposed for documentation how to enable and use -proposed.  Your feedback will aid us getting this update out to other Ubuntu users.\n\nIf this package fixes the bug for you, please change the bug tag from verification-needed to verification-done.  If it does not, change the tag to verification-failed.  In either case, details of your testing will help us make a better decision.\n\nFurther information regarding the verification process can be found at https://wiki.ubuntu.com/QATeam/PerformingSRUVerification .  Thank you in advance!", 
            "date_created": "2012-10-03 17:19:03.955133+00:00", 
            "author": "https://api.launchpad.net/1.0/~adconrad"
        }, 
        {
            "content": "Ignore the above automated message, the precise fix that was in the queue was superseded by a security update of the same version.", 
            "date_created": "2012-10-03 17:21:06.864136+00:00", 
            "author": "https://api.launchpad.net/1.0/~adconrad"
        }, 
        {
            "content": "Hi Adam,\n\nDoes this mean that the qemu fix for this ticket is not in -proposed yet? Or that the security update contains the fix?\n\nThanks,\nJoe", 
            "date_created": "2012-10-03 17:50:48.659727+00:00", 
            "author": "https://api.launchpad.net/1.0/~joe-topjian-v"
        }, 
        {
            "content": "As far as I can tell the fix is still not released in -proposed", 
            "date_created": "2012-10-03 23:01:52.831246+00:00", 
            "author": "https://api.launchpad.net/1.0/~ben-nerp"
        }, 
        {
            "content": "The security update doesn't contain the fix, the original proposed update needs to be rebased against the security update.  I may do that in a bit if Soren doesn't get there first.", 
            "date_created": "2012-10-04 00:22:24.396441+00:00", 
            "author": "https://api.launchpad.net/1.0/~adconrad"
        }, 
        {
            "content": "Hello Jonathan, or anyone else affected,\n\nAccepted qemu-kvm into precise-proposed. The package will build now and be available at http://launchpad.net/ubuntu/+source/qemu-kvm/1.0+noroms-0ubuntu14.3 in a few hours, and then in the -proposed repository.\n\nPlease help us by testing this new package.  See https://wiki.ubuntu.com/Testing/EnableProposed for documentation how to enable and use -proposed.  Your feedback will aid us getting this update out to other Ubuntu users.\n\nIf this package fixes the bug for you, please change the bug tag from verification-needed to verification-done.  If it does not, change the tag to verification-failed.  In either case, details of your testing will help us make a better decision.\n\nFurther information regarding the verification process can be found at https://wiki.ubuntu.com/QATeam/PerformingSRUVerification .  Thank you in advance!", 
            "date_created": "2012-10-04 00:37:47.694956+00:00", 
            "author": "https://api.launchpad.net/1.0/~adconrad"
        }, 
        {
            "content": "I have installed this package on two of my OpenStack compute nodes. I'll have an update in a day or so on if this package still fixes the issue like the package from Soren's PPA.", 
            "date_created": "2012-10-04 03:22:18.175255+00:00", 
            "author": "https://api.launchpad.net/1.0/~joe-topjian-v"
        }, 
        {
            "content": "Installed yesterday and rebooted the dom0 machine and thus all virtual machines. Will report back if there are any problems.", 
            "date_created": "2012-10-05 07:29:30.328363+00:00", 
            "author": "https://api.launchpad.net/1.0/~j+launchpad-net"
        }, 
        {
            "content": "We tested the -proposed packages yesterday and are confident that they resolve the issue. We used the test scenario described in comment #101.\n\nServers that have not had the updated package applied failed the test within an hour. Servers with the updated package did not fail the test.", 
            "date_created": "2012-10-05 17:17:48.406960+00:00", 
            "author": "https://api.launchpad.net/1.0/~joe-topjian-v"
        }, 
        {
            "content": "The verification of this Stable Release Update has completed successfully and the package has now been released to -updates.  Subsequently, the Ubuntu Stable Release Updates Team is being unsubscribed and will not receive messages about this bug report.  In the event that you encounter a regression using the package from -updates please report a new bug using ubuntu-bug and tag the bug report regression-update so we can easily find any regresssions.", 
            "date_created": "2012-10-10 18:43:50.520581+00:00", 
            "author": "https://api.launchpad.net/1.0/~adconrad"
        }, 
        {
            "content": "This bug was fixed in the package qemu-kvm - 1.0+noroms-0ubuntu14.3\n\n---------------\nqemu-kvm (1.0+noroms-0ubuntu14.3) precise-proposed; urgency=low\n\n  * Fix race condition in virtio code on multicore systems. (LP: #997978)\n    - 9001-virtio-add-missing-mb-on-notification.patch\n    - 9002-virtio-add-missing-mb-on-enable-notification.patch\n    - 9003-virtio-order-index-descriptor-reads.patch\n -- Soren Hansen <email address hidden>   Mon, 03 Sep 2012 10:15:54 +0200", 
            "date_created": "2012-10-10 18:44:19.144179+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }, 
        {
            "content": "I got the same issue, but my host OS is RHEL 6.3 (2.6.32-220.el6.x86_64), the qemu-kvm version is 0.12.1.2 , and my guest base image is Ubuntu 12.4 LTS.\nMy problem is: \nAfter I enable the libvirt_use_virtio_for_bridges = true in the nova.conf, the new instance can not get ip address and the gateway can not be added in the router table.\n\nThe router table like this:\n\n--before enable virtio\n~$ route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         172.17.33.8     0.0.0.0         UG    100    0        0 eth0\n172.17.32.0     0.0.0.0         255.255.252.0   U     0      0        0 eth0\n\n--after enable virtio\n~$ route -n\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         172.17.32.1     0.0.0.0         UG    100    0        0 eth0\n172.17.32.0     0.0.0.0         255.255.252.0   U     0      0        0 eth0\n\n\nHere is the dnsmasq process on my host server:\nroot     32034 32033  0 Oct12 ?        00:00:00 /usr/sbin/dnsmasq --strict-order --bind-interfaces --conf-file= --domain=novalocal --pid-file=/var/lib/nova/networks/nova-br100.pid --listen-address=172.17.33.8 --except-interface=lo --dhcp-range=172.17.33.3,static,120s --dhcp-lease-max=256 --dhcp-hostsfile=/var/lib/nova/networks/nova-br100.conf --dhcp-script=/usr/bin/nova-dhcpbridge --leasefile-ro\n\nSoren, \nYour solution are only for ubuntu host and should install the ppa on the host machine, right?\nIs there any solution or workaround for RHEL?", 
            "date_created": "2012-10-15 19:02:04.970118+00:00", 
            "author": "https://api.launchpad.net/1.0/~genggjh"
        }, 
        {
            "content": "This bug is considered fixed for me. Not a single network glitch since installing the package from PPA. Many thanks to the development team!", 
            "date_created": "2012-11-02 12:42:21.035355+00:00", 
            "author": "https://api.launchpad.net/1.0/~j+launchpad-net"
        }, 
        {
            "content": "Same here, thank you everyone!\n\n--  \nKraig Amador\n\n\nOn Friday, November 2, 2012 at 5:42 AM, Jonathan Tullett wrote:\n\n> This bug is considered fixed for me. Not a single network glitch since\n> installing the package from PPA. Many thanks to the development team!\n>  \n> --  \n> You received this bug notification because you are subscribed to the bug\n> report.\n> https://bugs.launchpad.net/bugs/997978\n>  \n> Title:\n> KVM images lose connectivity with bridged network\n>  \n> Status in OpenStack Compute (Nova):\n> Invalid\n> Status in \u201cqemu-kvm\u201d package in Ubuntu:\n> Fix Released\n> Status in \u201cqemu-kvm\u201d source package in Precise:\n> Fix Released\n>  \n> Bug description:\n> =========================================\n> SRU Justification:\n> 1. Impact: networking breaks after awhile in kvm guests using virtio networking\n> 2. Development fix: The bug was fixed upstream and the fix picked up in a new\n> merge.\n> 3. Stable fix: 3 virtio patches are cherrypicked from upstream:\n> a821ce5 virtio: order index/descriptor reads\n> 92045d8 virtio: add missing mb() on enable notification\n> a281ebc virtio: add missing mb() on notification\n> 4. Test case: Create a bridge enslaving the real NIC, and use that as the bridge\n> for a kvm instance with virtio networking. See comment #44 for specific test\n> case.\n> 5. Regression potential: Should be low as several people have tested the fixed\n> package under heavy load.\n> =========================================\n>  \n> System:\n> -----------\n> Dell R410 Dual processor 2.4Ghz w/16G RAM\n> Distributor ID: Ubuntu\n> Description: Ubuntu 12.04 LTS\n> Release: 12.04\n> Codename: precise\n>  \n> Setup:\n> ---------\n> We're running 3 KVM guests, all Ubuntu 12.04 LTS using bridged networking.\n>  \n> From the host:\n> # cat /etc/network/interfaces\n> auto br0\n> iface br0 inet static\n>         address 212.XX.239.98\n>         netmask 255.255.255.240\n>         gateway 212.XX.239.97\n>         bridge_ports eth0\n>         bridge_fd 9\n>         bridge_hello 2\n>         bridge_maxage 12\n>         bridge_stp off\n>  \n> # ifconfig eth0\n> eth0 Link encap:Ethernet HWaddr d4:ae:52:84:2d:5a\n>           UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1\n>           RX packets:11278363 errors:0 dropped:3128 overruns:0 frame:0\n>           TX packets:14437384 errors:0 dropped:0 overruns:0 carrier:0\n>           collisions:0 txqueuelen:1000\n>           RX bytes:4115980743 (4.1 GB) TX bytes:5451961979 (5.4 GB)\n>           Interrupt:36 Memory:da000000-da012800\n>  \n> # ifconfig br0\n> br0 Link encap:Ethernet HWaddr d4:ae:52:84:2d:5a\n>           inet addr:212.XX.239.98 Bcast:212.XX.239.111 Mask:255.255.255.240\n>           inet6 addr: fe80::d6ae:52ff:fe84:2d5a/64 Scope:Link\n>           UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1\n>           RX packets:1720861 errors:0 dropped:0 overruns:0 frame:0\n>           TX packets:1708622 errors:0 dropped:0 overruns:0 carrier:0\n>           collisions:0 txqueuelen:0\n>           RX bytes:210152198 (210.1 MB) TX bytes:300858508 (300.8 MB)\n>  \n> # brctl show\n> bridge name bridge id STP enabled interfaces\n> br0 8000.d4ae52842d5a no eth0\n>  \n> I have no default network configured to autostart in libvirt as we're using bridged networking:\n> # virsh net-list --all\n> Name State Autostart\n> -----------------------------------------\n> default inactive no\n>  \n> # arp\n> Address HWtype HWaddress Flags Mask Iface\n> mailer03.xxxx.com (http://mailer03.xxxx.com) ether 52:54:00:82:5f:0f C br0\n> mailer01.xxxx.com (http://mailer01.xxxx.com) ether 52:54:00:d2:f7:31 C br0\n> mailer02.xxxx.com (http://mailer02.xxxx.com) ether 52:54:00:d3:8f:91 C br0\n> dxi-gw2.xxxx.com (http://dxi-gw2.xxxx.com) ether 00:1a:30:2a:b1:c0 C br0\n>  \n> From one of the guests:\n> <domain type='kvm' id='4'>\n>   <name>mailer01</name>\n>   <uuid>d41d1355-84e8-ae23-e84e-227bc0231b97</uuid>\n>   <memory>2097152</memory>\n>   <currentMemory>2097152</currentMemory>\n>   <vcpu>1</vcpu>\n>   <os>\n>     <type arch='x86_64' machine='pc-1.0'>hvm</type>\n>     <boot dev='hd'/>\n>   </os>\n>   <features>\n>     <acpi/>\n>   </features>\n>   <clock offset='utc'/>\n>   <on_poweroff>destroy</on_poweroff>\n>   <on_reboot>restart</on_reboot>\n>   <on_crash>destroy</on_crash>\n>   <devices>\n>     <emulator>/usr/bin/kvm</emulator>\n>     <disk type='file' device='disk'>\n>       <driver name='qemu' type='raw'/>\n>       <source file='/dev/mapper/vg_main-mailer01--root'/>\n>       <target dev='hda' bus='ide'/>\n>       <alias name='ide0-0-0'/>\n>       <address type='drive' controller='0' bus='0' unit='0'/>\n>     </disk>\n>     <disk type='file' device='disk'>\n>       <driver name='qemu' type='raw'/>\n>       <source file='/dev/mapper/vg_main-mailer01--swap'/>\n>       <target dev='hdb' bus='ide'/>\n>       <alias name='ide0-0-1'/>\n>       <address type='drive' controller='0' bus='0' unit='1'/>\n>     </disk>\n>     <controller type='ide' index='0'>\n>       <alias name='ide0'/>\n>       <address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>\n>     </controller>\n>     <interface type='bridge'>\n>       <mac address='52:54:00:d2:f7:31'/>\n>       <source bridge='br0'/>\n>       <target dev='vnet0'/>\n>       <model type='virtio'/>\n>       <alias name='net0'/>\n>       <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>\n>     </interface>\n>     <serial type='pty'>\n>       <source path='/dev/pts/0'/>\n>       <target port='0'/>\n>       <alias name='serial0'/>\n>     </serial>\n>     <console type='pty' tty='/dev/pts/0'>\n>       <source path='/dev/pts/0'/>\n>       <target type='serial' port='0'/>\n>       <alias name='serial0'/>\n>     </console>\n>     <input type='mouse' bus='ps2'/>\n>     <graphics type='vnc' port='5900' autoport='yes' listen='127.0.0.1'>\n>       <listen type='address' address='127.0.0.1'/>\n>     </graphics>\n>     <video>\n>       <model type='cirrus' vram='9216' heads='1'/>\n>       <alias name='video0'/>\n>       <address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>\n>     </video>\n>     <memballoon model='virtio'>\n>       <alias name='balloon0'/>\n>       <address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>\n>     </memballoon>\n>   </devices>\n>   <seclabel type='dynamic' model='apparmor' relabel='yes'>\n>     <label>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</label>\n>     <imagelabel>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</imagelabel>\n>   </seclabel>\n> </domain>\n>  \n> From within the guest:\n> # cat /etc/network/interfaces\n> # The primary network interface\n> auto eth0\n> iface eth0 inet static\n>         address 212.XX.239.100\n>         netmask 255.255.255.240\n>         network 212.XX.239.96\n>         broadcast 212.XX.239.111\n>         gateway 212.XX.239.97\n>  \n> # ifconfig\n> eth0 Link encap:Ethernet HWaddr 52:54:00:d2:f7:31\n>           inet addr:212.XX.239.100 Bcast:212.XX.239.111 Mask:255.255.255.240\n>           inet6 addr: fe80::5054:ff:fed2:f731/64 Scope:Link\n>           UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1\n>           RX packets:5631830 errors:0 dropped:0 overruns:0 frame:0\n>           TX packets:6683416 errors:0 dropped:0 overruns:0 carrier:0\n>           collisions:0 txqueuelen:1000\n>           RX bytes:2027322829 (2.0 GB) TX bytes:2076698690 (2.0 GB)\n>  \n> A commandline which starts the KVM guest:\n> /usr/bin/kvm -S -M pc-1.0 -enable-kvm -m 2048 -smp 1,sockets=1,cores=1,threads=1 -name mailer01 -uuid d41d1355-84e8-ae23-e84e-227bc0231b97 -nodefconfig -nodefaults -chardev socket,id=charmonitor,path=/var/lib/libvirt/qemu/mailer01.monitor,server,nowait -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-shutdown -drive file=/dev/mapper/vg_main-mailer01--root,if=none,id=drive-ide0-0-0,format=raw -device ide-drive,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0,bootindex=1 -drive file=/dev/mapper/vg_main-mailer01--swap,if=none,id=drive-ide0-0-1,format=raw -device ide-drive,bus=ide.0,unit=1,drive=drive-ide0-0-1,id=ide0-0-1 -netdev tap,fd=18,id=hostnet0 -device virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:d2:f7:31,bus=pci.0,addr=0x3 -chardev pty,id=charserial0 -device isa-serial,chardev=charserial0,id=serial0 -usb -vnc 127.0.0.1:0 -vga cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x4\n>  \n> Problem:\n> ------------\n> Periodically (at least once a day), one or more of the guests lose network connectivity. Ping responds with 'host unreachable', even from the dom host. Logging in via the serial console shows no problems: eth0 is up, can ping the local host, but no outside connectivity. Restart the network (/etc/init.d/networking restart) does nothing. Reboot the machine and it comes alive again.\n>  \n> I've verified there's no arp games going on on the primary host (the\n> arp tables remain the same before - when it had connectivity - and\n> after - when it doesn't.\n>  \n> This is a critical issue affecting production services on the latest\n> LTS release of Ubuntu. It's similar to an issue which was 'resolved'\n> in 10.04 but appears to have risen its ugly head again.\n>  \n> To manage notifications about this bug go to:\n> https://bugs.launchpad.net/nova/+bug/997978/+subscriptions\n>  \n>  \n\n\n", 
            "date_created": "2012-11-02 15:52:21+00:00", 
            "author": "https://api.launchpad.net/1.0/~kamador"
        }, 
        {
            "content": "So I'm sorry to report that after about 50 days of uptime on qemu-kvm (1.0+noroms-0ubuntu14.3) I had 3 VMs out of ~60 in my cluster drop off the network.  It happened on different host machines, so it's not a single machine in the cluster that's a problem.\n\nTwo of the nodes were restarted (full qemu shutdown/relaunch) so I didn't have a chance to debug them.\n\nOne of them I was able to console and work on before I gave up and restarted it.  The interesting things I discovered was that the workarounds I had done in the past did not work.  Previously I was able to ifdown/ifup the virtual interface to restore networking.  Also migrating between nodes did not restore networking.", 
            "date_created": "2012-12-03 18:48:22.481739+00:00", 
            "author": "https://api.launchpad.net/1.0/~ben-nerp"
        }, 
        {
            "content": "But otherwise it sounds like it looked the same - VM still up but its network down?\n\nHad these VMs been running for 50 days, or was it that you hadn't seen the problem in 50 days?  If the latter, could these have been on a newer kernel?", 
            "date_created": "2012-12-07 14:54:33.521686+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Will there be a fix for 10.04 lucid, too?\nI think this bug affects me too: Windows SBS 2008 with virtio network driver on ubuntu 10.04 lucid host loses network connection from time to time. It's not really deterministic when this error occurs. Usually it happens when there's a large amount of traffic sent over the network. After disabling (via VNC console) the network card in Windows and re-enabling it, everything works fine again, no need to reboot the VM.\nAny help is appreciated, since it's a quite annoying bug... :-)", 
            "date_created": "2013-01-05 19:48:41.319194+00:00", 
            "author": "https://api.launchpad.net/1.0/~mk-binary-artworks"
        }, 
        {
            "content": "I'm testing this some more, and it looks like it's still easy to reproduce on my system.\n\ncc2ab6833adc73311a2407be2eb5f915  /usr/bin/qemu-system-x86_64\n\nI can cause the guest to drop VM networking with an rsync+ssh from a nearby host.", 
            "date_created": "2013-01-05 21:42:35.850381+00:00", 
            "author": "https://api.launchpad.net/1.0/~ben-nerp"
        }, 
        {
            "content": "@BenKochie,\n\ncould you please file a new bug with details?", 
            "date_created": "2013-01-07 15:49:51.751930+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "I've found this problem in my saucy installation. I just opened a bug cause I'm not sure if it's related. \n\nhttps://bugs.launchpad.net/ubuntu/+source/core-network/+bug/1255516\n\nMy problem is actually worse since host machine cannot get access to other machines on the network. Not even virtual machines but hardware machines, routers, NAS, and so on. \n\nThe only way to recover from this situation is to ifdown ifup the bridge. Then it recovers until it happens again. \n\nWhen I remove the bridge no problems. But I was not able to test it since I need the bridge up.\n\nI'm investigating macvtap instead of bridge...", 
            "date_created": "2013-11-27 20:07:30.982613+00:00", 
            "author": "https://api.launchpad.net/1.0/~gad-aguilardelgado"
        }, 
        {
            "content": "I have to clarify that I'm not sure that this has something to do with KVM, QEMU and the like. \n\nI think is more a problem of the linux bridge driver since It fails even if you don't have any vm running. Yes, it takes more time to fail but this can be because not enough traffic to make it fail. \n\n", 
            "date_created": "2013-11-28 12:32:39.986831+00:00", 
            "author": "https://api.launchpad.net/1.0/~gad-aguilardelgado"
        }, 
        {
            "content": "I think I may have the same problem running a 13.10 qemu-kvm host with 8 virtual machines.  As far as I can see only two VMs seem to have the problem. All of them use em1: macvtap as source device and a bridge as source mode. After reading many posts here, I changed from virtio to rtl8139 as a device model to see if I still lose network connection.", 
            "date_created": "2013-12-18 16:38:00.316234+00:00", 
            "author": "https://api.launchpad.net/1.0/~janowicz"
        }, 
        {
            "content": "My web search reveals this problem has been around for years and most posts conclude that the problem continues.  After solving my tap0 TX packets dropped problem, I find that my VM network has random freezes a few times each day.  Many bloggers on this subject say this VM network freeze is difficult to reproduce.  Not for me! I can cause a network freeze on my VM in a heartbeat.  Like many others, all I need to do is start a data transfer over the bridge (FTP 2Kb file or larger). When the freeze happens, ifconfig tap0 says overruns:1. This is QEMU version 1.6.2 without KVM on CentOS 6.5 version 2.6.32-431. ", 
            "date_created": "2014-03-26 00:56:36.868894+00:00", 
            "author": "https://api.launchpad.net/1.0/~dewey-w"
        }, 
        {
            "content": "After moving to 3.5 kernel I haven't seen it, even at 3x traffic which used\nto cause it\nOn Mar 25, 2014 9:06 PM, \"Dewey McDonnell\" <email address hidden> wrote:\n\n> My web search reveals this problem has been around for years and most\n> posts conclude that the problem continues.  After solving my tap0 TX\n> packets dropped problem, I find that my VM network has random freezes a\n> few times each day.  Many bloggers on this subject say this VM network\n> freeze is difficult to reproduce.  Not for me! I can cause a network\n> freeze on my VM in a heartbeat.  Like many others, all I need to do is\n> start a data transfer over the bridge (FTP 2Kb file or larger). When the\n> freeze happens, ifconfig tap0 says overruns:1. This is QEMU version\n> 1.6.2 without KVM on CentOS 6.5 version 2.6.32-431.\n>\n> --\n> You received this bug notification because you are subscribed to the bug\n> report.\n> https://bugs.launchpad.net/bugs/997978\n>\n> Title:\n>   KVM images lose connectivity with bridged network\n>\n> Status in OpenStack Compute (Nova):\n>   Invalid\n> Status in \"qemu-kvm\" package in Ubuntu:\n>   Fix Released\n> Status in \"qemu-kvm\" source package in Precise:\n>   Fix Released\n>\n> Bug description:\n>   =========================================\n>   SRU Justification:\n>   1. Impact: networking breaks after awhile in kvm guests using virtio\n> networking\n>   2. Development fix: The bug was fixed upstream and the fix picked up in\n> a new\n>      merge.\n>   3. Stable fix: 3 virtio patches are cherrypicked from upstream:\n>      a821ce5 virtio: order index/descriptor reads\n>      92045d8 virtio: add missing mb() on enable notification\n>      a281ebc virtio: add missing mb() on notification\n>   4. Test case: Create a bridge enslaving the real NIC, and use that as\n> the bridge\n>      for a kvm instance with virtio networking.  See comment #44 for\n> specific test\n>      case.\n>   5. Regression potential: Should be low as several people have tested the\n> fixed\n>      package under heavy load.\n>   =========================================\n>\n>   System:\n>   -----------\n>   Dell R410 Dual processor 2.4Ghz w/16G RAM\n>   Distributor ID: Ubuntu\n>   Description:    Ubuntu 12.04 LTS\n>   Release:        12.04\n>   Codename:       precise\n>\n>   Setup:\n>   ---------\n>   We're running 3 KVM guests, all Ubuntu 12.04 LTS using bridged\n> networking.\n>\n>   From the host:\n>   # cat /etc/network/interfaces\n>   auto br0\n>   iface br0 inet static\n>           address 212.XX.239.98\n>           netmask 255.255.255.240\n>           gateway 212.XX.239.97\n>           bridge_ports eth0\n>           bridge_fd 9\n>           bridge_hello 2\n>           bridge_maxage 12\n>           bridge_stp off\n>\n>   # ifconfig eth0\n>   eth0      Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a\n>             UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n>             RX packets:11278363 errors:0 dropped:3128 overruns:0 frame:0\n>             TX packets:14437384 errors:0 dropped:0 overruns:0 carrier:0\n>             collisions:0 txqueuelen:1000\n>             RX bytes:4115980743 (4.1 GB)  TX bytes:5451961979 (5.4 GB)\n>             Interrupt:36 Memory:da000000-da012800\n>\n>   # ifconfig br0\n>   br0       Link encap:Ethernet  HWaddr d4:ae:52:84:2d:5a\n>             inet addr:212.XX.239.98  Bcast:212.XX.239.111\n>  Mask:255.255.255.240\n>             inet6 addr: fe80::d6ae:52ff:fe84:2d5a/64 Scope:Link\n>             UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n>             RX packets:1720861 errors:0 dropped:0 overruns:0 frame:0\n>             TX packets:1708622 errors:0 dropped:0 overruns:0 carrier:0\n>             collisions:0 txqueuelen:0\n>             RX bytes:210152198 (210.1 MB)  TX bytes:300858508 (300.8 MB)\n>\n>   # brctl show\n>   bridge name     bridge id               STP enabled     interfaces\n>   br0             8000.d4ae52842d5a       no              eth0\n>\n>   I have no default network configured to autostart in libvirt as we're\n> using bridged networking:\n>   # virsh net-list --all\n>   Name                 State      Autostart\n>   -----------------------------------------\n>   default              inactive   no\n>\n>   # arp\n>   Address                  HWtype  HWaddress           Flags Mask\n>    Iface\n>   mailer03.xxxx.com       ether   52:54:00:82:5f:0f   C\n>   br0\n>   mailer01.xxxx.com       ether   52:54:00:d2:f7:31   C\n>   br0\n>   mailer02.xxxx.com       ether   52:54:00:d3:8f:91   C\n>   br0\n>   dxi-gw2.xxxx.com        ether   00:1a:30:2a:b1:c0   C\n>   br0\n>\n>   From one of the guests:\n>   <domain type='kvm' id='4'>\n>     <name>mailer01</name>\n>     <uuid>d41d1355-84e8-ae23-e84e-227bc0231b97</uuid>\n>     <memory>2097152</memory>\n>     <currentMemory>2097152</currentMemory>\n>     <vcpu>1</vcpu>\n>     <os>\n>       <type arch='x86_64' machine='pc-1.0'>hvm</type>\n>       <boot dev='hd'/>\n>     </os>\n>     <features>\n>       <acpi/>\n>     </features>\n>     <clock offset='utc'/>\n>     <on_poweroff>destroy</on_poweroff>\n>     <on_reboot>restart</on_reboot>\n>     <on_crash>destroy</on_crash>\n>     <devices>\n>       <emulator>/usr/bin/kvm</emulator>\n>       <disk type='file' device='disk'>\n>         <driver name='qemu' type='raw'/>\n>         <source file='/dev/mapper/vg_main-mailer01--root'/>\n>         <target dev='hda' bus='ide'/>\n>         <alias name='ide0-0-0'/>\n>         <address type='drive' controller='0' bus='0' unit='0'/>\n>       </disk>\n>       <disk type='file' device='disk'>\n>         <driver name='qemu' type='raw'/>\n>         <source file='/dev/mapper/vg_main-mailer01--swap'/>\n>         <target dev='hdb' bus='ide'/>\n>         <alias name='ide0-0-1'/>\n>         <address type='drive' controller='0' bus='0' unit='1'/>\n>       </disk>\n>       <controller type='ide' index='0'>\n>         <alias name='ide0'/>\n>         <address type='pci' domain='0x0000' bus='0x00' slot='0x01'\n> function='0x1'/>\n>       </controller>\n>       <interface type='bridge'>\n>         <mac address='52:54:00:d2:f7:31'/>\n>         <source bridge='br0'/>\n>         <target dev='vnet0'/>\n>         <model type='virtio'/>\n>         <alias name='net0'/>\n>         <address type='pci' domain='0x0000' bus='0x00' slot='0x03'\n> function='0x0'/>\n>       </interface>\n>       <serial type='pty'>\n>         <source path='/dev/pts/0'/>\n>         <target port='0'/>\n>         <alias name='serial0'/>\n>       </serial>\n>       <console type='pty' tty='/dev/pts/0'>\n>         <source path='/dev/pts/0'/>\n>         <target type='serial' port='0'/>\n>         <alias name='serial0'/>\n>       </console>\n>       <input type='mouse' bus='ps2'/>\n>       <graphics type='vnc' port='5900' autoport='yes' listen='127.0.0.1'>\n>         <listen type='address' address='127.0.0.1'/>\n>       </graphics>\n>       <video>\n>         <model type='cirrus' vram='9216' heads='1'/>\n>         <alias name='video0'/>\n>         <address type='pci' domain='0x0000' bus='0x00' slot='0x02'\n> function='0x0'/>\n>       </video>\n>       <memballoon model='virtio'>\n>         <alias name='balloon0'/>\n>         <address type='pci' domain='0x0000' bus='0x00' slot='0x04'\n> function='0x0'/>\n>       </memballoon>\n>     </devices>\n>     <seclabel type='dynamic' model='apparmor' relabel='yes'>\n>       <label>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</label>\n>       <imagelabel>libvirt-d41d1355-84e8-ae23-e84e-227bc0231b97</imagelabel>\n>     </seclabel>\n>   </domain>\n>\n>   From within the guest:\n>   # cat /etc/network/interfaces\n>   # The primary network interface\n>   auto eth0\n>   iface eth0 inet static\n>           address 212.XX.239.100\n>           netmask 255.255.255.240\n>           network 212.XX.239.96\n>           broadcast 212.XX.239.111\n>           gateway 212.XX.239.97\n>\n>   # ifconfig\n>   eth0      Link encap:Ethernet  HWaddr 52:54:00:d2:f7:31\n>             inet addr:212.XX.239.100  Bcast:212.XX.239.111\n>  Mask:255.255.255.240\n>             inet6 addr: fe80::5054:ff:fed2:f731/64 Scope:Link\n>             UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n>             RX packets:5631830 errors:0 dropped:0 overruns:0 frame:0\n>             TX packets:6683416 errors:0 dropped:0 overruns:0 carrier:0\n>             collisions:0 txqueuelen:1000\n>             RX bytes:2027322829 (2.0 GB)  TX bytes:2076698690 (2.0 GB)\n>\n>   A commandline which starts the KVM guest:\n>   /usr/bin/kvm -S -M pc-1.0 -enable-kvm -m 2048 -smp\n> 1,sockets=1,cores=1,threads=1 -name mailer01 -uuid\n> d41d1355-84e8-ae23-e84e-227bc0231b97 -nodefconfig -nodefaults -chardev\n> socket,id=charmonitor,path=/var/lib/libvirt/qemu/mailer01.monitor,server,nowait\n> -mon chardev=charmonitor,id=monitor,mode=control -rtc base=utc -no-shutdown\n> -drive\n> file=/dev/mapper/vg_main-mailer01--root,if=none,id=drive-ide0-0-0,format=raw\n> -device\n> ide-drive,bus=ide.0,unit=0,drive=drive-ide0-0-0,id=ide0-0-0,bootindex=1\n> -drive\n> file=/dev/mapper/vg_main-mailer01--swap,if=none,id=drive-ide0-0-1,format=raw\n> -device ide-drive,bus=ide.0,unit=1,drive=drive-ide0-0-1,id=ide0-0-1 -netdev\n> tap,fd=18,id=hostnet0 -device\n> virtio-net-pci,netdev=hostnet0,id=net0,mac=52:54:00:d2:f7:31,bus=pci.0,addr=0x3\n> -chardev pty,id=charserial0 -device\n> isa-serial,chardev=charserial0,id=serial0 -usb -vnc 127.0.0.1:0 -vga\n> cirrus -device virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x4\n>\n>   Problem:\n>   ------------\n>   Periodically (at least once a day), one or more of the guests lose\n> network connectivity.  Ping responds with 'host unreachable', even from the\n> dom host. Logging in via the serial console shows no problems: eth0 is up,\n> can ping the local host, but no outside connectivity.  Restart the network\n> (/etc/init.d/networking restart) does nothing. Reboot the machine and it\n> comes alive again.\n>\n>   I've verified there's no arp games going on on the primary host (the\n>   arp tables remain the same before - when it had connectivity - and\n>   after - when it doesn't.\n>\n>   This is a critical issue affecting production services on the latest\n>   LTS release of Ubuntu. It's similar to an issue which was 'resolved'\n>   in 10.04 but appears to have risen its ugly head again.\n>\n> To manage notifications about this bug go to:\n> https://bugs.launchpad.net/nova/+bug/997978/+subscriptions\n>\n", 
            "date_created": "2014-03-26 01:09:47+00:00", 
            "author": "https://api.launchpad.net/1.0/~vachon"
        }, 
        {
            "content": "Thanks Thomas for your speedy reply.  Now my CentOS uname -a is version 3.5.0.  My tap0 lockup problem is exactly the same as with the older kernel.  Anything else you would suggest?", 
            "date_created": "2014-03-27 03:34:46.013877+00:00", 
            "author": "https://api.launchpad.net/1.0/~dewey-w"
        }, 
        {
            "content": "We're running qemu-kvm 1.0+noroms-0ubuntu14.13 on a 12.04.4 LTS with KVM based 12.04.4 LTS virtual machines , and have observed this problem.   We have been using the regular software bridges on many machines, and have only noticed the problem on one of our newest servers.\n\nUsing virtio devices we get the discussed lockups.\n\nUsing e1000 we get no lockups, but this is a much lower performing interface and thus we have performance issues. We have NFS and other traffic between VMs and the host, so need more than the GigE that we have to external hosts.\n\nI note above that this bug was considered fixed by qemu-kvm - 1.0+noroms-0ubuntu14.3, but this appears to not be the case.", 
            "date_created": "2014-03-28 16:04:11.437445+00:00", 
            "author": "https://api.launchpad.net/1.0/~russell-flora"
        }, 
        {
            "content": "Very easily reproducible on my side. ", 
            "date_created": "2014-04-06 03:25:34.283412+00:00", 
            "author": "https://api.launchpad.net/1.0/~fawadkhaliq"
        }, 
        {
            "content": "Yes, I think it is safe to say that the bug is still around. The VM loses network connectivity under \"enough\" load. I, for example can reproduce this by running a spark job which transfers a few gigabytes of data between worker VMs. And within a minute one of the VMs lose network connectivity. If I try to reboot the VM, it goes into error state. Trying to delete makes the qemu-kvm process defunct.\n\nuname -r\n3.8.0-29-generic\n\nvirsh --version\n1.1.1\n\n", 
            "date_created": "2014-05-30 19:43:33.453341+00:00", 
            "author": "https://api.launchpad.net/1.0/~ezhaar"
        }, 
        {
            "content": "@ezhaar - please open a new bug so we can collect new information.  If you are on trusty then please file against qemu, othewise file against qemu-kvm.  Then mark it as also affecting libvirt and linux (the kernel).  Then reproduce the bug, and immediately after the crashes do 'apport-collect <bug-number>', which should collect the data for each of those packages.  Please show the host network configuration, the libvirt network config if applicable, the xml dumps for the vms, and where to get spark.", 
            "date_created": "2014-05-30 23:09:43.965552+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "Looks like I have this problem on 12.04.1 LTS with kernel  3.2.0-67-generic #101-Ubuntu SMP Tue Jul 15 17:46:11 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux on the host and Debian Wheezy on the guest (SMP Debian 3.2.60-1+deb7u3 x86_64 GNU/Linux)\n\nThe guest will occationally loose connection with other hosts on the LAN, and their entries in the arp table on the guest  are gone. \nOnly sporadic forwarding of arp replies on the host back to the guest seem to be the problem. \n\nDumping arp request (triggered by a ping from guest) on the bridge external (real) interface on the host catches both requests and replies, while the same dump on vnet0 misses replies for minutes until a reply suddeny comes through and reestablishes connection. \n\nI am using virtio interface. It makes no difference if I change to e1000. FW policy is ACCEPT on all tables.", 
            "date_created": "2014-07-31 16:35:30.040897+00:00", 
            "author": "https://api.launchpad.net/1.0/~oyvind-2"
        }, 
        {
            "content": "I faced probably the same problem installing Xen-4.3.2 with Gentoo kernel-3.12.21. \n\nDomU's interface hangs after short time under heavy network load (starting at ~10Mbyte/s). From outside it looks, like the instance would crash, but deactivating and activating the interface e.g. form the \"xl console <domU name>\" with /etc/init.d/net.eth0 stop/start, restores normal operation. \n\nAfter 3 days of testing/searching I found a workaround. Setting the following options with ethtool, I could successfully prevent my domU's interfaces from hanging:\n\nethtool --offload <network device> gso off tso off sg off gro off\n\nThis http://cloudnull.io/2012/07/xenserver-network-tuning/ leeds me to my solution.\n\nI also posted my other expirience with this bridged network configuration in the Gentoo wiki https://wiki.gentoo.org/wiki/Xen .", 
            "date_created": "2014-07-31 17:01:21.847495+00:00", 
            "author": "https://api.launchpad.net/1.0/~mpajak-r"
        }, 
        {
            "content": "My problem with missing arp replies was solved( worked around) by setting \nbridge_ageing 0\nfor the bridge in /etc/network/interfaces, making it a hub forwarding all packets to all hosts.", 
            "date_created": "2014-08-06 06:58:45.393567+00:00", 
            "author": "https://api.launchpad.net/1.0/~oyvind-2"
        }, 
        {
            "content": "I report the same situation as comment 129. \nSpark Cluster installed with Ambari 1.7, installed HDP 2.2 running Zookeeper, Ganglia, HDFS and YARN.\nUbuntu 12.04\n\nuname -r\n3.2.0-67-virtual\n\nInstances running fine until the start of a Spark of Hadoop job with YARN. The Job gets accepted but then 2 slaves of the cluster are interested by the bug and lose connectivity. They are still accessible by the openstack web page console but can't reach the network. Reboots brings the VM in a halt state. \nSolved with  ethtool -K eth0 tx off sg off tso off ufo off gso off gro off lro off\n\n", 
            "date_created": "2015-01-17 00:59:07.726965+00:00", 
            "author": "https://api.launchpad.net/1.0/~gibbo87"
        }, 
        {
            "content": "Please file a new bug against the linux package, preferably (if possible) using the command 'ubuntu-bug linux'", 
            "date_created": "2015-01-21 18:11:46.763927+00:00", 
            "author": "https://api.launchpad.net/1.0/~serge-hallyn"
        }, 
        {
            "content": "If this problem is related to this one - https://bugs.launchpad.net/ubuntu/+source/qemu-kvm/+bug/1325560?comments=all - then upgrading the kernel should fix it.\n\nIn my case I'm using Ubuntu 14.04 with kernel 3.13 and after upgrading to kernel 3.16, no more connectivity problems.", 
            "date_created": "2015-02-09 19:28:42.176323+00:00", 
            "author": "https://api.launchpad.net/1.0/~ramirovjnr"
        }, 
        {
            "content": "- Updating -\n\nThe problem came back today - the VM was running OK for more than 72 hours - and then the connectivity with the gateway was lost again.\n\nLooking Martin's post #132, I was seeing some packets being dropped by being incorrect. Applied the ethtool fix and also changed the driver to e1000 and going to monitor it.\n\nAfter applying the ethtool patch, I got no more dropped packets with incorrect checksum.", 
            "date_created": "2015-02-10 13:13:25.014206+00:00", 
            "author": "https://api.launchpad.net/1.0/~ramirovjnr"
        }, 
        {
            "content": "Still seeing this on 14.04.4 LTS under enough load, or when moving from paused state.", 
            "date_created": "2016-09-07 19:42:14.058168+00:00", 
            "author": "https://api.launchpad.net/1.0/~initialhit"
        }
    ], 
    "closed": "2012-09-11 14:40:37.673729+00:00"
}