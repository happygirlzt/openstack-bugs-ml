{
    "status": "Won't Fix", 
    "last_updated": "2016-05-13 15:10:42.704458+00:00", 
    "description": "gate-tempest-dsvm-large-ops error rate is spiking since the last 24 hours (http://goo.gl/G9Zazy) with the following stacktrace :\n\n2015-09-28 15:02:50.954 | Traceback (most recent call last):\n2015-09-28 15:02:50.954 |   File \"tempest/test.py\", line 127, in wrapper\n2015-09-28 15:02:50.954 |     return f(self, *func_args, **func_kwargs)\n2015-09-28 15:02:50.954 |   File \"tempest/scenario/test_large_ops.py\", line 138, in test_large_ops_scenario_3\n2015-09-28 15:02:50.954 |     self._large_ops_scenario()\n2015-09-28 15:02:50.954 |   File \"tempest/scenario/test_large_ops.py\", line 123, in _large_ops_scenario\n2015-09-28 15:02:50.954 |     self.nova_boot()\n2015-09-28 15:02:50.954 |   File \"tempest/scenario/test_large_ops.py\", line 119, in nova_boot\n2015-09-28 15:02:50.954 |     self._wait_for_server_status('ACTIVE')\n2015-09-28 15:02:50.954 |   File \"tempest/scenario/test_large_ops.py\", line 81, in _wait_for_server_status\n2015-09-28 15:02:50.955 |     server['id'], status)\n2015-09-28 15:02:50.955 |   File \"tempest/common/waiters.py\", line 95, in wait_for_server_status\n2015-09-28 15:02:50.955 |     raise exceptions.TimeoutException(message)\n2015-09-28 15:02:50.955 | tempest.exceptions.TimeoutException: Request timed out\n\nhttp://logs.openstack.org/23/226923/5/gate/gate-tempest-dsvm-large-ops/826845d/console.html#_2015-09-28_15_02_50_955", 
    "tags": [
        "testing"
    ], 
    "importance": "High", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1500615", 
    "owner": "None", 
    "id": 1500615, 
    "index": 1815, 
    "openned": "2015-09-28 21:00:41.459986+00:00", 
    "created": "2015-09-28 21:00:41.459986+00:00", 
    "title": "Large Ops scenario is taking too long", 
    "comments": [
        {
            "content": "gate-tempest-dsvm-large-ops error rate is spiking since the last 24 hours (http://goo.gl/G9Zazy) with the following stacktrace :\n\n2015-09-28 15:02:50.954 | Traceback (most recent call last):\n2015-09-28 15:02:50.954 |   File \"tempest/test.py\", line 127, in wrapper\n2015-09-28 15:02:50.954 |     return f(self, *func_args, **func_kwargs)\n2015-09-28 15:02:50.954 |   File \"tempest/scenario/test_large_ops.py\", line 138, in test_large_ops_scenario_3\n2015-09-28 15:02:50.954 |     self._large_ops_scenario()\n2015-09-28 15:02:50.954 |   File \"tempest/scenario/test_large_ops.py\", line 123, in _large_ops_scenario\n2015-09-28 15:02:50.954 |     self.nova_boot()\n2015-09-28 15:02:50.954 |   File \"tempest/scenario/test_large_ops.py\", line 119, in nova_boot\n2015-09-28 15:02:50.954 |     self._wait_for_server_status('ACTIVE')\n2015-09-28 15:02:50.954 |   File \"tempest/scenario/test_large_ops.py\", line 81, in _wait_for_server_status\n2015-09-28 15:02:50.955 |     server['id'], status)\n2015-09-28 15:02:50.955 |   File \"tempest/common/waiters.py\", line 95, in wait_for_server_status\n2015-09-28 15:02:50.955 |     raise exceptions.TimeoutException(message)\n2015-09-28 15:02:50.955 | tempest.exceptions.TimeoutException: Request timed out\n\nhttp://logs.openstack.org/23/226923/5/gate/gate-tempest-dsvm-large-ops/826845d/console.html#_2015-09-28_15_02_50_955", 
            "date_created": "2015-09-28 21:00:41.459986+00:00", 
            "author": "https://api.launchpad.net/1.0/~sylvain-bauza"
        }, 
        {
            "content": "https://review.openstack.org/#/c/226831/ was a devstack change that cut n-api workers from 4 to 2 and n-cond workers from 8 to 2.  That merged on 9/24 and we started spiking shortly after that, so maybe related.", 
            "date_created": "2015-09-28 21:05:07.052102+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "The test itself is creating 100 instances at once:\n\nhttp://logs.openstack.org/23/226923/5/gate/gate-tempest-dsvm-large-ops/826845d/logs/tempest_conf.txt.gz\n\nlarge_ops_number = 100", 
            "date_created": "2015-09-28 21:13:45.508414+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/228636", 
            "date_created": "2015-09-28 21:47:19.945822+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "After reading the IRC logs from when the bug was reported I noticed an observation by Matt that the time the resource semaphore was held kept increasing until it dropped - this can indeed be caused by a small number of conductor workers. COMPUTE_RESOURCE_SEMAPHORE is nova-cpu process wide, and there is a non-trivial amount of DB querying that goes on while it's held. A storm of requests would mean even more stuff going to the conductor which in turn makes ongoing requests holding the lock slow down as they are competing for the same pool of conductor workers to do their DB queries for them.\n\nIt is hard to tell without actually profiling the code (AND porobably adding even more probes like number of threads and DB requests per conductor worker), but increasing the number of conductor workers is definitely a good guess as to where the problem might be\n\n", 
            "date_created": "2015-09-29 08:34:23.807577+00:00", 
            "author": "https://api.launchpad.net/1.0/~ndipanov"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/228980", 
            "date_created": "2015-09-29 14:45:33.378033+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/228636\nCommitted: https://git.openstack.org/cgit/openstack-dev/devstack/commit/?id=c35eee5dbbb6b4dbc2901ebef4c4d88780aa74ec\nSubmitter: Jenkins\nBranch:    master\n\ncommit c35eee5dbbb6b4dbc2901ebef4c4d88780aa74ec\nAuthor: Matt Riedemann <email address hidden>\nDate:   Mon Sep 28 14:46:27 2015 -0700\n\n    use nproc/2 workers for large ops job\n    \n    Commit 1ce19ab76d67a89b04f907f1d292d013a3b699e0 dropped API_WORKERS from\n    nproc/2 to nproc/4 and also started using API_WORKERS for the number of\n    conductor workers, so in gate runs that dropped conductor workers from 8\n    to 2.  We're now seeing instance build timeouts in the large ops job.\n    \n    This change goes back to nproc/2 for the large ops job (VIRT_DRIVER=='fake').\n    \n    Closes-Bug: #1500615\n    \n    Change-Id: Ie6ef855fce0a99c930d479b7459c15b69e8de499\n", 
            "date_created": "2015-09-30 15:17:48.508775+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/229490", 
            "date_created": "2015-09-30 15:50:21.883596+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/228980\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=9bb4c07b2996aa9e3153e6d6f28e7aa600c64100\nSubmitter: Jenkins\nBranch:    master\n\ncommit 9bb4c07b2996aa9e3153e6d6f28e7aa600c64100\nAuthor: Matt Riedemann <email address hidden>\nDate:   Tue Sep 29 07:21:19 2015 -0700\n\n    Add checkpoint logging when building an instance in compute manager\n    \n    When the large ops job fails because instances timeout during the build,\n    it's hard to know what is going on for a given instance in the compute\n    manager's _do_build_and_run_instance flow since a lot of the trace\n    logging that happens is in the virt drivers.\n    \n    The large ops job uses the fake virt driver which doesn't do much\n    logging at all. Rather than add logging to the fake virt driver, it'd be\n    useful to add some logging to the compute manager when we are doing\n    sub-tasks like building networks, building bdms, and spawning the instance\n    on the hypervisor.\n    \n    Per: https://wiki.openstack.org/wiki/LoggingStandards\n    \n    The 'Starting instance' log message is changed to debug level and the\n    completed task logging unit of work messages with time spent are done at\n    info level.\n    \n    Related-Bug: #1500615\n    \n    Change-Id: I6b9e7fc7b3a14ccf8b1531fa08ce8d732e23775a\n", 
            "date_created": "2015-10-05 16:38:57.817458+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/229490\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=48a07fe48f6d45f14d711fa35d23a1a9b45e3efc\nSubmitter: Jenkins\nBranch:    master\n\ncommit 48a07fe48f6d45f14d711fa35d23a1a9b45e3efc\nAuthor: Matt Riedemann <email address hidden>\nDate:   Wed Sep 30 08:45:48 2015 -0700\n\n    Add checkpoint logging when terminating an instance\n    \n    Following I6b9e7fc7b3a14ccf8b1531fa08ce8d732e23775a for building an\n    instance, this adds some checkpoint logging for terminating an instance,\n    including destroying it on the hypervisor, deallocating the network, and\n    detaching any volumes.\n    \n    Related-Bug: #1500615\n    \n    Change-Id: I16b8879f9dad9b0283b0758c41c70233624276f9\n", 
            "date_created": "2015-10-06 17:18:51.050282+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "We dropped the large ops job.", 
            "date_created": "2016-05-13 15:10:41.961863+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }
    ], 
    "closed": "2016-05-13 15:10:26.139235+00:00"
}