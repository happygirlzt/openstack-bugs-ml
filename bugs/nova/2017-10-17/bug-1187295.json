{
    "status": "Fix Released", 
    "last_updated": "2014-01-09 06:16:18.386074+00:00", 
    "description": "I'm running based on Grizzly with quantum+OVS+vlan.\nWhen I have an active instance in the cloud, I noticed about a periodic keystone query from the compute node with the active instance. Each time, the compute node requests 4 new tokens.\nAnyone know why this happen ?\n\nI notice some logs in nova-compute.log, but not sure if it is related:\n\n2013-06-04 15:35:52.242 DEBUG nova.network.quantumv2.api [req-abe1ca6d-f282-4ec4-b696-b24006a6367e 8cbad06dd1764bae93612132ca62671d 45a521413d9b43ff888abb7de9878171] get_instance_nw_info() for aabb _get_instance_nw_info /usr/lib/python2.7/dist-packages/nova/network/quantumv2/api.py:366\n\nThanks.\n-chen", 
    "tags": [
        "network"
    ], 
    "importance": "Undecided", 
    "heat": 18, 
    "link": "https://bugs.launchpad.net/nova/+bug/1187295", 
    "owner": "None", 
    "id": 1187295, 
    "index": 4980, 
    "openned": "2013-06-04 08:30:12.845494+00:00", 
    "created": "2013-06-04 08:30:12.845494+00:00", 
    "title": "periodic keystone query for active instances", 
    "comments": [
        {
            "content": "I'm running based on Grizzly with quantum+OVS+vlan.\nWhen I have an active instance in the cloud, I noticed about a periodic keystone query from the compute node with the active instance. Each time, the compute node requests 4 new tokens.\nAnyone know why this happen ?\n\nI notice some logs in nova-compute.log, but not sure if it is related:\n\n2013-06-04 15:35:52.242 DEBUG nova.network.quantumv2.api [req-abe1ca6d-f282-4ec4-b696-b24006a6367e 8cbad06dd1764bae93612132ca62671d 45a521413d9b43ff888abb7de9878171] get_instance_nw_info() for aabb _get_instance_nw_info /usr/lib/python2.7/dist-packages/nova/network/quantumv2/api.py:366\n\nThanks.\n-chen", 
            "date_created": "2013-06-04 08:30:12.845494+00:00", 
            "author": "https://api.launchpad.net/1.0/~chen-li"
        }, 
        {
            "content": "There's a mailing list thread discussing this issue starting at http://lists.openstack.org/pipermail/openstack-dev/2013-June/009893.html", 
            "date_created": "2013-06-05 15:56:43.373825+00:00", 
            "author": "https://api.launchpad.net/1.0/~doug-hellmann"
        }, 
        {
            "content": "Thanks Doug, from the mailing list, I think I get:\n\n1. This periodic task I seem is nova computer's healer task. It is trying to get network information from quantum for an instance.\n\n2. I observed it causes 4 times keystone queries, while Mike said  \"We were seeing 5 separate calls to the quantum API to generate that structure whenever get_instance_nw_info was called.\" \n    Not sure why 5 calls end with 4 keystone access, anyway, I think it is related.\n\n3. From what I have seem, obviously, this operation is work through HTTP.\n\n4. Beside this operation, nova has no way to get network information updated, that's why you get the floating IP issue at first place.\n\n5. People agree this operation should be dropped from the nova v3 API, because nova do not need to hold network information when it is working with quantum.\n\n6. You guys are discussion about a solution before drop the operation but: \n     a, No stale caches\n     b, Reduced the number of calls going to the quantum API by 80%\n\nAm I understand correct ?\n\nThanks.\n-chen", 
            "date_created": "2013-06-06 02:50:59.931382+00:00", 
            "author": "https://api.launchpad.net/1.0/~chen-li"
        }, 
        {
            "content": "I get another answer from ask.openstack.org.\nhttps://ask.openstack.org/question/1812/periodic-keystone-query-for-active-instances/\n\nAre these designs related to each other?\n\nThanks\n-chen", 
            "date_created": "2013-06-07 01:55:43.177170+00:00", 
            "author": "https://api.launchpad.net/1.0/~chen-li"
        }, 
        {
            "content": "The patch referenced in the blueprint had to be reverted.", 
            "date_created": "2013-09-17 19:47:14.560180+00:00", 
            "author": "https://api.launchpad.net/1.0/~russellb"
        }, 
        {
            "content": "There is a much big problem than just described in the bug. We have a large scale deployment with grizzly running Neutron.\nFor us in real deployment running more than 300 VMs, neutron port-list is taking more than 90 seconds. It can increase with number of VMs.\nWith some custom optimizations in port-list handler in place, we figured out that if no API calls at all to quantum from controllers and including restrict calls from  nova-computes  - it took 6 seconds for port-list.\n\nOn our analysis, nova-compute periodically every 60 seconds calls neutron for list of networks, subnets, floating IPs, ports etc.,\n\nWe see two issues here. \n1) Neutron list API response time - which is indirectly related (assuming openstack as complete solution)\n2) Nova-Compute heal_instance_info_cache() load on neutron\n\nFor #2, I need to get nova community feedback for the need of maintaining instance network info - as that is job of neutron.\nIs nova consuming that in any scheduler job?\nIf there is need for nova to maintain this - instead of making several neutron calls, we should think of single API call and reduce number of DB queries.\n", 
            "date_created": "2013-10-10 19:08:24.900277+00:00", 
            "author": "https://api.launchpad.net/1.0/~ravivsn"
        }, 
        {
            "content": "This has been improved since the bug was opened, so I'm going to close this out", 
            "date_created": "2014-01-03 18:48:23.233213+00:00", 
            "author": "https://api.launchpad.net/1.0/~russellb"
        }, 
        {
            "content": "Hi,  Bryant\n\nCan you also provides some more information about how the issue been improved, and related patches and blueprints do that ?\n\nThanks.\n-chen\n", 
            "date_created": "2014-01-09 06:16:17.528310+00:00", 
            "author": "https://api.launchpad.net/1.0/~chen-li"
        }
    ], 
    "closed": "2014-01-03 18:48:28.987488+00:00"
}