{
    "status": "Invalid", 
    "last_updated": "2017-09-12 19:14:41.933936+00:00", 
    "description": "We hit this error in Ocata while trying to launch an arm64 instance:\n\n2017-03-16 08:01:42.329 144245 ERROR nova.virt.libvirt.guest [req-2ad2d5d9-696d-4baa-a071-756e460ca3de 8f431f83f7e44ef1a084e7e27b40a685 a904dd389c5d4817a4d95b8f3268cf4d - - -] Error launching a defined domain with XML: <domain type='kvm'>\n  <name>instance-00000001</name>\n  <uuid>220bec1b-8907-4da9-9862-9cc2354abf39</uuid>\n  <metadata>\n    <nova:instance xmlns:nova=\"http://openstack.org/xmlns/libvirt/nova/1.0\">\n      <nova:package version=\"15.0.0\"/>\n      <nova:name>guestOS-test-arm64-kvm-xenial-ci_oil_slave14_0</nova:name>\n      <nova:creationTime>2017-03-16 08:01:38</nova:creationTime>\n      <nova:flavor name=\"m1.small\">\n        <nova:memory>2048</nova:memory>\n        <nova:disk>20</nova:disk>\n        <nova:swap>0</nova:swap>\n        <nova:ephemeral>0</nova:ephemeral>\n        <nova:vcpus>1</nova:vcpus>\n      </nova:flavor>\n      <nova:owner>\n        <nova:user uuid=\"8f431f83f7e44ef1a084e7e27b40a685\">admin</nova:user>\n        <nova:project uuid=\"a904dd389c5d4817a4d95b8f3268cf4d\">admin</nova:project>\n      </nova:owner>\n      <nova:root type=\"image\" uuid=\"4e864421-efc0-4c39-8b49-d619356f72de\"/>\n    </nova:instance>\n  </metadata>\n  <memory unit='KiB'>2097152</memory>\n  <currentMemory unit='KiB'>2097152</currentMemory>\n  <vcpu placement='static'>1</vcpu>\n  <cputune>\n    <shares>1024</shares>\n  </cputune>\n  <os>\n    <type arch='aarch64' machine='virt-2.8'>hvm</type>\n    <loader readonly='yes' type='pflash'>/usr/share/AAVMF/AAVMF_CODE.fd</loader>\n    <nvram>/var/lib/libvirt/qemu/nvram/instance-00000001_VARS.fd</nvram>\n    <boot dev='hd'/>\n  </os>\n  <features>\n    <acpi/>\n    <apic/>\n    <gic version='3'/>\n  </features>\n  <cpu mode='host-model'>\n    <model fallback='allow'/>\n    <topology sockets='1' cores='1' threads='1'/>\n  </cpu>\n  <clock offset='utc'>\n    <timer name='pit' tickpolicy='delay'/>\n    <timer name='rtc' tickpolicy='catchup'/>\n  </clock>\n  <on_poweroff>destroy</on_poweroff>\n  <on_reboot>restart</on_reboot>\n  <on_crash>destroy</on_crash>\n  <devices>\n    <emulator>/usr/bin/kvm</emulator>\n    <disk type='file' device='disk'>\n      <driver name='qemu' type='qcow2' cache='none'/>\n      <source file='/var/lib/nova/instances/220bec1b-8907-4da9-9862-9cc2354abf39/disk'/>\n      <target dev='vda' bus='virtio'/>\n      <address type='virtio-mmio'/>\n    </disk>\n    <controller type='pci' index='0' model='pcie-root'/>\n    <interface type='bridge'>\n      <mac address='fa:16:3e:74:b0:97'/>\n      <source bridge='qbr9a95f1e8-d5'/>\n      <target dev='tap9a95f1e8-d5'/>\n      <model type='virtio'/>\n      <address type='virtio-mmio'/>\n    </interface>\n    <serial type='pty'>\n      <log file='/var/lib/nova/instances/220bec1b-8907-4da9-9862-9cc2354abf39/console.log' append='off'/>\n      <target port='0'/>\n    </serial>\n    <console type='pty'>\n      <log file='/var/lib/nova/instances/220bec1b-8907-4da9-9862-9cc2354abf39/console.log' append='off'/>\n      <target type='serial' port='0'/>\n    </console>\n    <memballoon model='virtio'>\n      <stats period='10'/>\n      <address type='virtio-mmio'/>\n    </memballoon>\n  </devices>\n</domain>\n             \n2017-03-16 08:01:42.333 144245 ERROR nova.virt.libvirt.driver [req-2ad2d5d9-696d-4baa-a071-756e460ca3de 8f431f83f7e44ef1a084e7e27b40a685 a904dd389c5d4817a4d95b8f3268cf4d - - -] [instance: 220bec1b-8907-4da9-9862-9cc2354abf39] Failed to start libvirt guest\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 1930, in _build_and_run_instance\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     block_device_info=block_device_info)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 2688, in spawn\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     destroy_disks_on_failure=True)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5099, in _create_domain_and_network\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     destroy_disks_on_failure)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     self.force_reraise()\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     six.reraise(self.type_, self.value, self.tb)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5071, in _create_domain_and_network\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     post_xml_callback=post_xml_callback)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4989, in _create_domain\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     guest.launch(pause=pause)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     self._encoded_xml, errors='ignore')\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     self.force_reraise()\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     six.reraise(self.type_, self.value, self.tb)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/guest.py\", line 140, in launch\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     return self._domain.createWithFlags(flags)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 186, in doit\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 144, in proxy_call\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     rv = execute(f, *args, **kwargs)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 125, in execute\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     six.reraise(c, e, tb)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 83, in tworker\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     rv = meth(*args, **kwargs)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 1065, in createWithFlags\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39] libvirtError: unsupported configuration: CPU mode 'host-model' for aarch64 kvm domain on aarch64 host is not supported by hypervisor\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]", 
    "tags": [
        "arm64", 
        "oil", 
        "openstack-version.ocata", 
        "uosci"
    ], 
    "importance": "Undecided", 
    "heat": 34, 
    "link": "https://bugs.launchpad.net/nova/+bug/1673467", 
    "owner": "None", 
    "id": 1673467, 
    "index": 8005, 
    "openned": "2017-03-16 14:16:36.964030+00:00", 
    "created": "2017-03-16 14:16:05.320594+00:00", 
    "title": "[ocata] unsupported configuration: CPU mode 'host-model' for aarch64 kvm domain on aarch64 host is not supported by hypervisor", 
    "comments": [
        {
            "content": "We hit this error in Ocata while trying to launch an arm64 instance:\n\n2017-03-16 08:01:42.329 144245 ERROR nova.virt.libvirt.guest [req-2ad2d5d9-696d-4baa-a071-756e460ca3de 8f431f83f7e44ef1a084e7e27b40a685 a904dd389c5d4817a4d95b8f3268cf4d - - -] Error launching a defined domain with XML: <domain type='kvm'>\n  <name>instance-00000001</name>\n  <uuid>220bec1b-8907-4da9-9862-9cc2354abf39</uuid>\n  <metadata>\n    <nova:instance xmlns:nova=\"http://openstack.org/xmlns/libvirt/nova/1.0\">\n      <nova:package version=\"15.0.0\"/>\n      <nova:name>guestOS-test-arm64-kvm-xenial-ci_oil_slave14_0</nova:name>\n      <nova:creationTime>2017-03-16 08:01:38</nova:creationTime>\n      <nova:flavor name=\"m1.small\">\n        <nova:memory>2048</nova:memory>\n        <nova:disk>20</nova:disk>\n        <nova:swap>0</nova:swap>\n        <nova:ephemeral>0</nova:ephemeral>\n        <nova:vcpus>1</nova:vcpus>\n      </nova:flavor>\n      <nova:owner>\n        <nova:user uuid=\"8f431f83f7e44ef1a084e7e27b40a685\">admin</nova:user>\n        <nova:project uuid=\"a904dd389c5d4817a4d95b8f3268cf4d\">admin</nova:project>\n      </nova:owner>\n      <nova:root type=\"image\" uuid=\"4e864421-efc0-4c39-8b49-d619356f72de\"/>\n    </nova:instance>\n  </metadata>\n  <memory unit='KiB'>2097152</memory>\n  <currentMemory unit='KiB'>2097152</currentMemory>\n  <vcpu placement='static'>1</vcpu>\n  <cputune>\n    <shares>1024</shares>\n  </cputune>\n  <os>\n    <type arch='aarch64' machine='virt-2.8'>hvm</type>\n    <loader readonly='yes' type='pflash'>/usr/share/AAVMF/AAVMF_CODE.fd</loader>\n    <nvram>/var/lib/libvirt/qemu/nvram/instance-00000001_VARS.fd</nvram>\n    <boot dev='hd'/>\n  </os>\n  <features>\n    <acpi/>\n    <apic/>\n    <gic version='3'/>\n  </features>\n  <cpu mode='host-model'>\n    <model fallback='allow'/>\n    <topology sockets='1' cores='1' threads='1'/>\n  </cpu>\n  <clock offset='utc'>\n    <timer name='pit' tickpolicy='delay'/>\n    <timer name='rtc' tickpolicy='catchup'/>\n  </clock>\n  <on_poweroff>destroy</on_poweroff>\n  <on_reboot>restart</on_reboot>\n  <on_crash>destroy</on_crash>\n  <devices>\n    <emulator>/usr/bin/kvm</emulator>\n    <disk type='file' device='disk'>\n      <driver name='qemu' type='qcow2' cache='none'/>\n      <source file='/var/lib/nova/instances/220bec1b-8907-4da9-9862-9cc2354abf39/disk'/>\n      <target dev='vda' bus='virtio'/>\n      <address type='virtio-mmio'/>\n    </disk>\n    <controller type='pci' index='0' model='pcie-root'/>\n    <interface type='bridge'>\n      <mac address='fa:16:3e:74:b0:97'/>\n      <source bridge='qbr9a95f1e8-d5'/>\n      <target dev='tap9a95f1e8-d5'/>\n      <model type='virtio'/>\n      <address type='virtio-mmio'/>\n    </interface>\n    <serial type='pty'>\n      <log file='/var/lib/nova/instances/220bec1b-8907-4da9-9862-9cc2354abf39/console.log' append='off'/>\n      <target port='0'/>\n    </serial>\n    <console type='pty'>\n      <log file='/var/lib/nova/instances/220bec1b-8907-4da9-9862-9cc2354abf39/console.log' append='off'/>\n      <target type='serial' port='0'/>\n    </console>\n    <memballoon model='virtio'>\n      <stats period='10'/>\n      <address type='virtio-mmio'/>\n    </memballoon>\n  </devices>\n</domain>\n             \n2017-03-16 08:01:42.333 144245 ERROR nova.virt.libvirt.driver [req-2ad2d5d9-696d-4baa-a071-756e460ca3de 8f431f83f7e44ef1a084e7e27b40a685 a904dd389c5d4817a4d95b8f3268cf4d - - -] [instance: 220bec1b-8907-4da9-9862-9cc2354abf39] Failed to start libvirt guest\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 1930, in _build_and_run_instance\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     block_device_info=block_device_info)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 2688, in spawn\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     destroy_disks_on_failure=True)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5099, in _create_domain_and_network\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     destroy_disks_on_failure)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     self.force_reraise()\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     six.reraise(self.type_, self.value, self.tb)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5071, in _create_domain_and_network\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     post_xml_callback=post_xml_callback)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 4989, in _create_domain\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     guest.launch(pause=pause)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     self._encoded_xml, errors='ignore')\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 220, in __exit__\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     self.force_reraise()\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     six.reraise(self.type_, self.value, self.tb)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/guest.py\", line 140, in launch\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     return self._domain.createWithFlags(flags)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 186, in doit\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 144, in proxy_call\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     rv = execute(f, *args, **kwargs)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 125, in execute\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     six.reraise(c, e, tb)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 83, in tworker\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     rv = meth(*args, **kwargs)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 1065, in createWithFlags\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39] libvirtError: unsupported configuration: CPU mode 'host-model' for aarch64 kvm domain on aarch64 host is not supported by hypervisor\n2017-03-16 08:01:43.522 144245 ERROR nova.compute.manager [instance: 220bec1b-8907-4da9-9862-9cc2354abf39]", 
            "date_created": "2017-03-16 14:16:05.320594+00:00", 
            "author": "https://api.launchpad.net/1.0/~lmic"
        }, 
        {
            "content": "Can you provide the versions of libvirt and QEMU on the system?", 
            "date_created": "2017-03-16 14:58:33.296800+00:00", 
            "author": "https://api.launchpad.net/1.0/~dannf"
        }, 
        {
            "content": "Hi Larry,\nI quickly tried to reproduce, but the only arm system I had around was blocking me for other reasons. Beofre I spend to much on a system being incomparable anyway I'd like to confirm what type of arm system you exactly have.\n\nAlso - assuming it is in your OS test infra - if there is any chance to log into your system please ping \"cpaelzer\" on IRC.\n\nhost-model is supposed to copy the hosts features from virsh capabilities - could you attach the output of the following:\n$ virsh capabilities\n\nFinally is this a regression of a case that worked e.g. with Newton/Yakkety but now fails on Ocata/Zesty?", 
            "date_created": "2017-03-16 15:02:48.576250+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "Also subscribing Dannf for virt-on-arm experience", 
            "date_created": "2017-03-16 15:05:34.489787+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "Hi Christian, here's the requested data below. This is with Xenial and Ocata. It has worked with Xenial and Mitaka.\n\nubuntu@phanpy:~$ virsh capabilities\n<capabilities>\n\n  <host>\n    <uuid>12ded42d-2831-44a4-b0ba-cc3af3481077</uuid>\n    <cpu>\n      <arch>aarch64</arch>\n      <topology sockets='1' cores='48' threads='1'/>\n      <pages unit='KiB' size='4'/>\n      <pages unit='KiB' size='2048'/>\n    </cpu>\n    <power_management/>\n    <migration_features>\n      <live/>\n      <uri_transports>\n        <uri_transport>tcp</uri_transport>\n        <uri_transport>rdma</uri_transport>\n      </uri_transports>\n    </migration_features>\n    <topology>\n      <cells num='1'>\n        <cell id='0'>\n          <memory unit='KiB'>131989624</memory>\n          <pages unit='KiB' size='4'>32997406</pages>\n          <pages unit='KiB' size='2048'>0</pages>\n          <distances>\n            <sibling id='0' value='10'/>\n          </distances>\n          <cpus num='48'>\n            <cpu id='0' socket_id='0' core_id='0' siblings='0'/>\n            <cpu id='1' socket_id='0' core_id='1' siblings='1'/>\n            <cpu id='2' socket_id='0' core_id='2' siblings='2'/>\n            <cpu id='3' socket_id='0' core_id='3' siblings='3'/>\n            <cpu id='4' socket_id='0' core_id='4' siblings='4'/>\n            <cpu id='5' socket_id='0' core_id='5' siblings='5'/>\n            <cpu id='6' socket_id='0' core_id='6' siblings='6'/>\n            <cpu id='7' socket_id='0' core_id='7' siblings='7'/>\n            <cpu id='8' socket_id='0' core_id='8' siblings='8'/>\n            <cpu id='9' socket_id='0' core_id='9' siblings='9'/>\n            <cpu id='10' socket_id='0' core_id='10' siblings='10'/>\n            <cpu id='11' socket_id='0' core_id='11' siblings='11'/>\n            <cpu id='12' socket_id='0' core_id='12' siblings='12'/>\n            <cpu id='13' socket_id='0' core_id='13' siblings='13'/>\n            <cpu id='14' socket_id='0' core_id='14' siblings='14'/>\n            <cpu id='15' socket_id='0' core_id='15' siblings='15'/>\n            <cpu id='16' socket_id='0' core_id='16' siblings='16'/>\n            <cpu id='17' socket_id='0' core_id='17' siblings='17'/>\n            <cpu id='18' socket_id='0' core_id='18' siblings='18'/>\n            <cpu id='19' socket_id='0' core_id='19' siblings='19'/>\n            <cpu id='20' socket_id='0' core_id='20' siblings='20'/>\n            <cpu id='21' socket_id='0' core_id='21' siblings='21'/>\n            <cpu id='22' socket_id='0' core_id='22' siblings='22'/>\n            <cpu id='23' socket_id='0' core_id='23' siblings='23'/>\n            <cpu id='24' socket_id='0' core_id='24' siblings='24'/>\n            <cpu id='25' socket_id='0' core_id='25' siblings='25'/>\n            <cpu id='26' socket_id='0' core_id='26' siblings='26'/>\n            <cpu id='27' socket_id='0' core_id='27' siblings='27'/>\n            <cpu id='28' socket_id='0' core_id='28' siblings='28'/>\n            <cpu id='29' socket_id='0' core_id='29' siblings='29'/>\n            <cpu id='30' socket_id='0' core_id='30' siblings='30'/>\n            <cpu id='31' socket_id='0' core_id='31' siblings='31'/>\n            <cpu id='32' socket_id='0' core_id='32' siblings='32'/>\n            <cpu id='33' socket_id='0' core_id='33' siblings='33'/>\n            <cpu id='34' socket_id='0' core_id='34' siblings='34'/>\n            <cpu id='35' socket_id='0' core_id='35' siblings='35'/>\n            <cpu id='36' socket_id='0' core_id='36' siblings='36'/>\n            <cpu id='37' socket_id='0' core_id='37' siblings='37'/>\n            <cpu id='38' socket_id='0' core_id='38' siblings='38'/>\n            <cpu id='39' socket_id='0' core_id='39' siblings='39'/>\n            <cpu id='40' socket_id='0' core_id='40' siblings='40'/>\n            <cpu id='41' socket_id='0' core_id='41' siblings='41'/>\n            <cpu id='42' socket_id='0' core_id='42' siblings='42'/>\n            <cpu id='43' socket_id='0' core_id='43' siblings='43'/>\n            <cpu id='44' socket_id='0' core_id='44' siblings='44'/>\n            <cpu id='45' socket_id='0' core_id='45' siblings='45'/>\n            <cpu id='46' socket_id='0' core_id='46' siblings='46'/>\n            <cpu id='47' socket_id='0' core_id='47' siblings='47'/>\n          </cpus>\n        </cell>\n      </cells>\n    </topology>\n    <secmodel>\n      <model>apparmor</model>\n      <doi>0</doi>\n    </secmodel>\n    <secmodel>\n      <model>dac</model>\n      <doi>0</doi>\n      <baselabel type='kvm'>+64055:+117</baselabel>\n      <baselabel type='qemu'>+64055:+117</baselabel>\n    </secmodel>\n  </host>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='armv7l'>\n      <wordsize>32</wordsize>\n      <emulator>/usr/bin/qemu-system-arm</emulator>\n      <machine maxCpus='1'>integratorcp</machine>\n      <machine maxCpus='2'>nuri</machine>\n      <machine maxCpus='1'>verdex</machine>\n      <machine maxCpus='1'>ast2500-evb</machine>\n      <machine maxCpus='2'>smdkc210</machine>\n      <machine maxCpus='1'>collie</machine>\n      <machine maxCpus='1'>imx25-pdk</machine>\n      <machine maxCpus='1'>spitz</machine>\n      <machine maxCpus='4'>realview-pbx-a9</machine>\n      <machine maxCpus='1'>realview-eb</machine>\n      <machine maxCpus='1'>versatilepb</machine>\n      <machine maxCpus='1'>realview-pb-a8</machine>\n      <machine maxCpus='1'>musicpal</machine>\n      <machine maxCpus='1'>z2</machine>\n      <machine maxCpus='1'>akita</machine>\n      <machine maxCpus='255'>virt-2.7</machine>\n      <machine maxCpus='1'>kzm</machine>\n      <machine maxCpus='255'>virt-2.8</machine>\n      <machine canonical='virt-2.8' maxCpus='255'>virt</machine>\n      <machine maxCpus='4'>realview-eb-mpcore</machine>\n      <machine maxCpus='1'>sx1</machine>\n      <machine maxCpus='1'>sx1-v1</machine>\n      <machine maxCpus='255'>virt-2.6</machine>\n      <machine maxCpus='1'>cubieboard</machine>\n      <machine maxCpus='4'>highbank</machine>\n      <machine maxCpus='4'>raspi2</machine>\n      <machine maxCpus='1'>netduino2</machine>\n      <machine maxCpus='1'>terrier</machine>\n      <machine maxCpus='1'>n810</machine>\n      <machine maxCpus='1'>mainstone</machine>\n      <machine maxCpus='1'>palmetto-bmc</machine>\n      <machine maxCpus='4'>sabrelite</machine>\n      <machine maxCpus='4'>midway</machine>\n      <machine maxCpus='1'>cheetah</machine>\n      <machine maxCpus='1'>tosa</machine>\n      <machine maxCpus='1'>borzoi</machine>\n      <machine maxCpus='1'>versatileab</machine>\n      <machine maxCpus='1'>lm3s6965evb</machine>\n      <machine maxCpus='1'>n800</machine>\n      <machine maxCpus='1'>connex</machine>\n      <machine maxCpus='1'>xilinx-zynq-a9</machine>\n      <machine maxCpus='4'>vexpress-a9</machine>\n      <machine maxCpus='4'>vexpress-a15</machine>\n      <machine maxCpus='1'>canon-a1100</machine>\n      <machine maxCpus='1'>lm3s811evb</machine>\n      <domain type='qemu'/>\n      <domain type='kvm'>\n        <emulator>/usr/bin/qemu-system-aarch64</emulator>\n        <machine maxCpus='1'>integratorcp</machine>\n        <machine maxCpus='2'>nuri</machine>\n        <machine maxCpus='1'>verdex</machine>\n        <machine maxCpus='1'>ast2500-evb</machine>\n        <machine maxCpus='2'>smdkc210</machine>\n        <machine maxCpus='1'>collie</machine>\n        <machine maxCpus='1'>imx25-pdk</machine>\n        <machine maxCpus='1'>spitz</machine>\n        <machine maxCpus='4'>realview-pbx-a9</machine>\n        <machine maxCpus='1'>realview-eb</machine>\n        <machine maxCpus='1'>versatilepb</machine>\n        <machine maxCpus='1'>realview-pb-a8</machine>\n        <machine maxCpus='1'>musicpal</machine>\n        <machine maxCpus='1'>z2</machine>\n        <machine maxCpus='1'>akita</machine>\n        <machine maxCpus='255'>virt-2.7</machine>\n        <machine maxCpus='1'>kzm</machine>\n        <machine maxCpus='255'>virt-2.8</machine>\n        <machine canonical='virt-2.8' maxCpus='255'>virt</machine>\n        <machine maxCpus='4'>realview-eb-mpcore</machine>\n        <machine maxCpus='1'>sx1</machine>\n        <machine maxCpus='1'>sx1-v1</machine>\n        <machine maxCpus='255'>virt-2.6</machine>\n        <machine maxCpus='1'>cubieboard</machine>\n        <machine maxCpus='4'>highbank</machine>\n        <machine maxCpus='4'>raspi2</machine>\n        <machine maxCpus='1'>netduino2</machine>\n        <machine maxCpus='1'>terrier</machine>\n        <machine maxCpus='1'>n810</machine>\n        <machine maxCpus='1'>mainstone</machine>\n        <machine maxCpus='1'>palmetto-bmc</machine>\n        <machine maxCpus='4'>sabrelite</machine>\n        <machine maxCpus='4'>midway</machine>\n        <machine maxCpus='1'>cheetah</machine>\n        <machine maxCpus='1'>tosa</machine>\n        <machine maxCpus='1'>borzoi</machine>\n        <machine maxCpus='1'>versatileab</machine>\n        <machine maxCpus='1'>lm3s6965evb</machine>\n        <machine maxCpus='1'>n800</machine>\n        <machine maxCpus='1'>connex</machine>\n        <machine maxCpus='1'>xilinx-zynq-a9</machine>\n        <machine maxCpus='1'>xlnx-ep108</machine>\n        <machine maxCpus='4'>vexpress-a9</machine>\n        <machine maxCpus='4'>vexpress-a15</machine>\n        <machine maxCpus='1'>xlnx-zcu102</machine>\n        <machine maxCpus='1'>canon-a1100</machine>\n        <machine maxCpus='1'>lm3s811evb</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n    </features>\n  </guest>\n\n  <guest>\n    <os_type>hvm</os_type>\n    <arch name='aarch64'>\n      <wordsize>64</wordsize>\n      <emulator>/usr/bin/qemu-system-aarch64</emulator>\n      <machine maxCpus='1'>integratorcp</machine>\n      <machine maxCpus='2'>nuri</machine>\n      <machine maxCpus='1'>verdex</machine>\n      <machine maxCpus='1'>ast2500-evb</machine>\n      <machine maxCpus='2'>smdkc210</machine>\n      <machine maxCpus='1'>collie</machine>\n      <machine maxCpus='1'>imx25-pdk</machine>\n      <machine maxCpus='1'>spitz</machine>\n      <machine maxCpus='4'>realview-pbx-a9</machine>\n      <machine maxCpus='1'>realview-eb</machine>\n      <machine maxCpus='1'>versatilepb</machine>\n      <machine maxCpus='1'>realview-pb-a8</machine>\n      <machine maxCpus='1'>musicpal</machine>\n      <machine maxCpus='1'>z2</machine>\n      <machine maxCpus='1'>akita</machine>\n      <machine maxCpus='255'>virt-2.7</machine>\n      <machine maxCpus='1'>kzm</machine>\n      <machine maxCpus='255'>virt-2.8</machine>\n      <machine canonical='virt-2.8' maxCpus='255'>virt</machine>\n      <machine maxCpus='4'>realview-eb-mpcore</machine>\n      <machine maxCpus='1'>sx1</machine>\n      <machine maxCpus='1'>sx1-v1</machine>\n      <machine maxCpus='255'>virt-2.6</machine>\n      <machine maxCpus='1'>cubieboard</machine>\n      <machine maxCpus='4'>highbank</machine>\n      <machine maxCpus='4'>raspi2</machine>\n      <machine maxCpus='1'>netduino2</machine>\n      <machine maxCpus='1'>terrier</machine>\n      <machine maxCpus='1'>n810</machine>\n      <machine maxCpus='1'>mainstone</machine>\n      <machine maxCpus='1'>palmetto-bmc</machine>\n      <machine maxCpus='4'>sabrelite</machine>\n      <machine maxCpus='4'>midway</machine>\n      <machine maxCpus='1'>cheetah</machine>\n      <machine maxCpus='1'>tosa</machine>\n      <machine maxCpus='1'>borzoi</machine>\n      <machine maxCpus='1'>versatileab</machine>\n      <machine maxCpus='1'>lm3s6965evb</machine>\n      <machine maxCpus='1'>n800</machine>\n      <machine maxCpus='1'>connex</machine>\n      <machine maxCpus='1'>xilinx-zynq-a9</machine>\n      <machine maxCpus='1'>xlnx-ep108</machine>\n      <machine maxCpus='4'>vexpress-a9</machine>\n      <machine maxCpus='4'>vexpress-a15</machine>\n      <machine maxCpus='1'>xlnx-zcu102</machine>\n      <machine maxCpus='1'>canon-a1100</machine>\n      <machine maxCpus='1'>lm3s811evb</machine>\n      <domain type='qemu'/>\n      <domain type='kvm'>\n        <emulator>/usr/bin/kvm</emulator>\n        <machine maxCpus='1'>integratorcp</machine>\n        <machine maxCpus='2'>nuri</machine>\n        <machine maxCpus='1'>verdex</machine>\n        <machine maxCpus='1'>ast2500-evb</machine>\n        <machine maxCpus='2'>smdkc210</machine>\n        <machine maxCpus='1'>collie</machine>\n        <machine maxCpus='1'>imx25-pdk</machine>\n        <machine maxCpus='1'>spitz</machine>\n        <machine maxCpus='4'>realview-pbx-a9</machine>\n        <machine maxCpus='1'>realview-eb</machine>\n        <machine maxCpus='1'>versatilepb</machine>\n        <machine maxCpus='1'>realview-pb-a8</machine>\n        <machine maxCpus='1'>musicpal</machine>\n        <machine maxCpus='1'>z2</machine>\n        <machine maxCpus='1'>akita</machine>\n        <machine maxCpus='255'>virt-2.7</machine>\n        <machine maxCpus='1'>kzm</machine>\n        <machine maxCpus='255'>virt-2.8</machine>\n        <machine canonical='virt-2.8' maxCpus='255'>virt</machine>\n        <machine maxCpus='4'>realview-eb-mpcore</machine>\n        <machine maxCpus='1'>sx1</machine>\n        <machine maxCpus='1'>sx1-v1</machine>\n        <machine maxCpus='255'>virt-2.6</machine>\n        <machine maxCpus='1'>cubieboard</machine>\n        <machine maxCpus='4'>highbank</machine>\n        <machine maxCpus='4'>raspi2</machine>\n        <machine maxCpus='1'>netduino2</machine>\n        <machine maxCpus='1'>terrier</machine>\n        <machine maxCpus='1'>n810</machine>\n        <machine maxCpus='1'>mainstone</machine>\n        <machine maxCpus='1'>palmetto-bmc</machine>\n        <machine maxCpus='4'>sabrelite</machine>\n        <machine maxCpus='4'>midway</machine>\n        <machine maxCpus='1'>cheetah</machine>\n        <machine maxCpus='1'>tosa</machine>\n        <machine maxCpus='1'>borzoi</machine>\n        <machine maxCpus='1'>versatileab</machine>\n        <machine maxCpus='1'>lm3s6965evb</machine>\n        <machine maxCpus='1'>n800</machine>\n        <machine maxCpus='1'>connex</machine>\n        <machine maxCpus='1'>xilinx-zynq-a9</machine>\n        <machine maxCpus='1'>xlnx-ep108</machine>\n        <machine maxCpus='4'>vexpress-a9</machine>\n        <machine maxCpus='4'>vexpress-a15</machine>\n        <machine maxCpus='1'>xlnx-zcu102</machine>\n        <machine maxCpus='1'>canon-a1100</machine>\n        <machine maxCpus='1'>lm3s811evb</machine>\n      </domain>\n    </arch>\n    <features>\n      <cpuselection/>\n      <deviceboot/>\n      <disksnapshot default='on' toggle='no'/>\n    </features>\n  </guest>\n\n</capabilities>\n\n\n", 
            "date_created": "2017-03-16 15:34:43.100262+00:00", 
            "author": "https://api.launchpad.net/1.0/~lmic"
        }, 
        {
            "content": "Hi,\nI was able to reproduce at least partially.\n\nI must admit that I never heard about host-model before, host-passthrough usually.\nChecking the doc [1] reveals that the function is broken pre libvirt 3.2/qemu2.9 - and e.g. the qemu is not even released yet.\n\nSo even if we would make host-model pass here on the initial check it will not \"do what it is supposed\".\n\nOTOH the more common host-passthrough is working - so much I could confirm.\n\nI see why host-model is nicer than passthrough, as it would be a bit more portable.\nMaybe openstack changed and on Xenial/Mitaka selected passthrough - we might want to do so again on Ocata.\n\n@Openstack Team\n1. could you check what model was passed on Mitaka/Newton, I'd assume host-passthrough but well that is only \"assuming\"\n2. if #1 is true, what would you think about fixing this by going back to host-passthrough for Ocata on aarch64?\n\n[1]: https://libvirt.org/formatdomain.html", 
            "date_created": "2017-03-16 16:09:09.347606+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "incomplete on libvirt waiting for openstack expertise on this case", 
            "date_created": "2017-03-16 16:11:22.731561+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "Simple test on the option itself without Openstack\n\n $ dd if=/dev/zero of=flash0.img bs=1M count=64\n $ dd if=/usr/share/qemu-efi/QEMU_EFI.fd of=flash0.img conv=notrunc\n $ dd if=/dev/zero of=flash1.img bs=1M count=64\n $ wget http://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-arm64-uefi1.img\n\n<domain type='kvm' xmlns:qemu='http://libvirt.org/schemas/domain/qemu/1.0'>\n        <name>testguest</name>\n        <uuid>f9c9e534-6233-482c-842d-88b8606a4604</uuid>\n        <memory unit='KiB'>1048576</memory>\n        <currentMemory unit='KiB'>1048576</currentMemory>\n        <vcpu placement='static'>1</vcpu>\n        <os>\n                <type arch='aarch64' machine='virt-2.8'>hvm</type>\n        </os>\n        <features>\n                <gic version='3'/>\n        </features>\n  <cpu mode='host-model'>\n          <model fallback='allow'/>\n  </cpu>\n<!--\n  <cpu mode='host-passthrough'>\n          <model fallback='allow'/>\n  </cpu>\n        <cpu mode='custom' match='exact'>\n                <model fallback='allow'>host</model>\n        </cpu>\n-->\n        <clock offset='utc'/>\n        <on_poweroff>destroy</on_poweroff>\n        <on_reboot>restart</on_reboot>\n        <on_crash>destroy</on_crash>\n        <devices>\n                <emulator>/usr/bin/qemu-system-aarch64</emulator>\n                <disk type='file' device='disk'>\n                        <driver name='qemu' type='raw'/>\n                        <source file='/home/ubuntu/xenial-server-cloudimg-arm64-uefi1.img'/>\n                        <target dev='hdc' bus='virtio'/>\n                        <address type='virtio-mmio'/>\n                </disk>\n                <controller type='pci' index='0' model='pcie-root'/>\n                <memballoon model='none'/>\n                <interface type='network'>                                                   \n                        <mac address='52:54:00:af:8f:2f'/>                                         \n                        <source network='default'/>                                                \n                        <model type='virtio'/>                                                     \n                </interface> \n                <serial type='pty'>                                                          \n                        <target port='0'/>                                                         \n                </serial>                                                                    \n                <console type='pty'>                                                         \n                        <target type='serial' port='0'/>                                           \n                </console>  \n        </devices>\n</domain>\n\n", 
            "date_created": "2017-03-16 16:25:58.783007+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "Larry, can you get domain xml from newton for comparison?\n\nAlso, I assume you hit this on xenial-ocata, so I think it would make sense to just use xenial-newton (vs yakkety-newton) to compare.\n\nNote that xenial-ocata has a new version of libvirt (and qemu):\nlibvirt: 2.5.0-3ubuntu3\nqemu: 1:2.8+dfsg-3ubuntu2\n\nxenial-mitaka and xenial-newton both use:\nlibvirt: 1.3.1-1ubuntu10.8\nqemu: 1:2.5+dfsg-5ubuntu10.9", 
            "date_created": "2017-03-16 16:28:50.453985+00:00", 
            "author": "https://api.launchpad.net/1.0/~corey.bryant"
        }, 
        {
            "content": "I'm not seeing any major changes in nova between newton and ocata wrt host-model. That's not to say this isn't a bug in nova.\n\nAs I noted previously, xenial-ocata is using libvirt 2.5.0 whereas xenial-mitaka and xenial-newton are using libvirt 1.3.1.  This error and the function that it comes from are new since sometime after libvirt 1.3.1: \"libvirtError: unsupported configuration: CPU mode 'host-model' for aarch64 kvm domain on aarch64 host is not supported by hypervisor\".\n\nThis is coming from the following code, pasted from libvirt 2.5.0:\n\n5020 static int\n5021 qemuProcessUpdateGuestCPU(virDomainDefPtr def,\n5022                           virQEMUCapsPtr qemuCaps,\n5023                           virCapsPtr caps,\n5024                           unsigned int flags)\n5025 {\n5026     int ret = -1;\n5027     size_t nmodels = 0;\n5028     char **models = NULL;\n5029 \n5030     if (!def->cpu)\n5031         return 0;\n5032 \n5033     /* nothing to do if only topology part of CPU def is used */\n5034     if (def->cpu->mode == VIR_CPU_MODE_CUSTOM && !def->cpu->model)\n5035         return 0;\n5036 \n5037     /* Old libvirt added host CPU model to host-model CPUs for migrations,\n5038      * while new libvirt just turns host-model into custom mode. We need\n5039      * to fix the mode to maintain backward compatibility and to avoid\n5040      * the CPU model to be replaced in virCPUUpdate.\n5041      */\n5042     if (!(flags & VIR_QEMU_PROCESS_START_NEW) &&\n5043         ARCH_IS_X86(def->os.arch) &&\n5044         def->cpu->mode == VIR_CPU_MODE_HOST_MODEL &&\n5045         def->cpu->model) {\n5046         def->cpu->mode = VIR_CPU_MODE_CUSTOM;\n5047     }\n5048 \n5049     if (!virQEMUCapsIsCPUModeSupported(qemuCaps, caps, def->virtType,\n5050                                        def->cpu->mode)) {\n5051         virReportError(VIR_ERR_CONFIG_UNSUPPORTED,\n5052                        _(\"CPU mode '%s' for %s %s domain on %s host is not \"\n5053                          \"supported by hypervisor\"),\n5054                        virCPUModeTypeToString(def->cpu->mode),\n5055                        virArchToString(def->os.arch),\n5056                        virDomainVirtTypeToString(def->virtType),\n5057                        virArchToString(caps->host.arch));\n5058         return -1;\n5059     }\n\nThis code was introduced by the following commit:\n\ncommit 7ce711a30eaf882ccd0217b2528362b563b6d670\nAuthor: Jiri Denemark <email address hidden>\nDate:   Wed Jun 22 15:53:48 2016 +0200\n\n    qemu: Update guest CPU def in live XML\n\n    Storing the updated CPU definition in the live domain definition saves\n    us from having to update it over and over when we need it. Not to\n    mention that we will soon further update the CPU definition according to\n    QEMU once it's started.\n\n    A highly wanted side effect of this patch, libvirt will pass all CPU\n    features explicitly specified in domain XML to QEMU, even those that are\n    already included in the host model.\n\n    This patch should fix the following bugs:\n        https://bugzilla.redhat.com/show_bug.cgi?id=1207095\n        https://bugzilla.redhat.com/show_bug.cgi?id=1339680\n        https://bugzilla.redhat.com/show_bug.cgi?id=1371039\n        https://bugzilla.redhat.com/show_bug.cgi?id=1373849\n        https://bugzilla.redhat.com/show_bug.cgi?id=1375524\n        https://bugzilla.redhat.com/show_bug.cgi?id=1377913\n\n    Signed-off-by: Jiri Denemark <email address hidden>\n", 
            "date_created": "2017-03-16 17:38:01.844759+00:00", 
            "author": "https://api.launchpad.net/1.0/~corey.bryant"
        }, 
        {
            "content": "Thanks Corey!\nAlso for pulling out the code.\n\nIt still smells like \"was never working well, but now it tells you\".\n\nTo be sure it was specified that way before @Larry would you add a domain xml from Newton to round up the picture so we can continue thinking on where a fix would be appropriate.", 
            "date_created": "2017-03-17 09:50:27.432783+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "This looks like an upstream libvirt/qemu issue that got exposed with the version bump in Ubuntu. Closing the upstream Nova side. ", 
            "date_created": "2017-03-17 20:42:20.266106+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "Here's the requested xml from an arm64 newton instance:\n\nhttps://pastebin.ubuntu.com/24230654/", 
            "date_created": "2017-03-22 20:30:11.582019+00:00", 
            "author": "https://api.launchpad.net/1.0/~jason-hobbs"
        }, 
        {
            "content": "@Corey @Christian the xml in comm#12 from Jason is Xenial-Newton.  ", 
            "date_created": "2017-03-22 21:56:29.006084+00:00", 
            "author": "https://api.launchpad.net/1.0/~rkota"
        }, 
        {
            "content": "Snipping the interesting parts:\n\n    <type arch='aarch64' machine='virt'>hvm</type>\n[...]\n  <features>\n    <gic version='3'/>\n[...]\n  <cpu mode='host-model'>\n    <model fallback='allow'/>\n[...]\n\nThat means on Xenial-Newton that worked for you.\nYet as outlined before \"worked\" is a bit special here as it meant more \"passed but didn't work\" as outlined in comment #5 - I don't know the details of this.\n\nWith that in mind for now lets simplify the Test and try to get Openstack out of the equation for now (although it might eventually be the best place for a solution).\n\nWill update after some tests ...", 
            "date_created": "2017-03-23 07:59:36.571540+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "# Similar to my test in comment #7, but with slighly modified XML as in [1]\nStart on Xenial, upgrade one by one\n\nAt the spot of xx CPU xx I had one of the following:\n\nhm - host model\n  <cpu mode='host-model'>\n    <model fallback='allow'/>\n  </cpu>\nhp - host passthrough\n  <cpu mode='host-passthrough'>\n     <model fallback='allow'/>\n  </cpu>\nmaf - match allow fallback\n  <cpu mode='custom' match='exact'>\n     <model fallback='allow'>host</model>\n  </cpu>\nmff - match forbid fallback\n  <cpu mode='custom' match='exact'>\n     <model fallback='forbid'>host</model>\n  </cpu>\n\nThose four modes to some extend mean the same \"make it as close to the host cpu as possible\" with slight differences, see [2]. And the \"bonus\" that host-model was broken until soon to be released qemu/libvirt versions.\n\nAdding next release in sources and using \"apt-get install -t\" I was able to test qemu/libvirt upgrades one by one.\n\nTesting:                  hm       hp       maf     mff\nLV 1.3.1 / Qemu 2.5       ok       ok        ok      ok\nLV 1.3.1 / Qemu 2.6.1     fails by LV 1.3.1 not able to handle virt-2.6\nLV 2.1   / Qemu 2.6.1     ok       ok        ok      ok\nLV 2.1   / Qemu 2.8       ok       ok        ok      ok\nLV 2.5   / Qemu 2.8       fail     ok        ok      ok\n\nAll of the rest of the system is still as on Xenial, so we can exclude other packages.\n\nWe can see that \"only\" host-model regressed, certainly due to the mentioned changes that it was broken so far.\n\nBy that we get to the libvirt code that corey already posted.\nThat code changed a lot 2.1-2.5.\nTo some extend it comes down to the check in virQEMUCapsIsCPUModeSupported, but I need to find the changes that lead to add the \"host-model doesn't work\" statement in the xml doc to get more background.\n\nThe whole call to qemuProcessUpdateGuestCPU did not exist in 2.1, to some extend the old check was \"qemuProcessStartValidateGuestCPU\".\nThe introduction of the check that now breaks was in 803497a8 that added virQEMUCapsIsCPUModeSupported which checks against \"!!qemuCaps->hostCPUModel\".\nThat in turn \nRelated changes:\n- http://libvirt.org/git/?p=libvirt.git;a=commit;h=7ce711a30eaf882ccd0217b2528362b563b6d670 (2.3)\n- http://libvirt.org/git/?p=libvirt.git;a=commit;h=803497a8acdc76b9b229bd27d595ec89beed2f3e (2.3)\n\nI checked that on x86 host-model works with libvirt 2.5.\nThat means there the qemuCaps hold this flag.\n\nAfter confirming that known it was \"easy\" to have a much simpler check.\nThe capabilities this is checked is like \"the guest wants X can the emulator run X\".\nNot that is as easy as:\n$ virsh domcapabilities --emulatorbin /usr/bin/qemu-system-aarch64 | grep host-model\n    <mode name='host-model' supported='no'/>\nWhile\n$ virsh domcapabilities --emulatorbin /usr/bin/qemu-system-x86_64 | grep host-model\n    <mode name='host-model' supported='yes'>\n\nWith that I went back to\nlibvirt 2.1 on arm and there the whole cpu section was not populated (and as outlined libvirt did not check against it even if it would be).\n\nI want to check how this is populated and also the commits that lead to the doc in the xml stating that host-model was flawed before L3.2/Q2.9.\n\nBut before knowing better I'd say libvirt is right to reject it if the emulator bin is not supporting it. I'll update when I have more in a bit.\n\n[1]: http://paste.ubuntu.com/24233826/\n[2]: https://libvirt.org/formatdomain.html#elementsCPU\n", 
            "date_created": "2017-03-23 10:14:34.194509+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "On x86 due to a compat fix host-model effectively is CUSTOM see qemuProcessUpdateGuestCPU (in coreys post).\n\nI also checked where this gets populated but didn't find a sweet sport to see if is now different.\nBut qemuBuildCpuModelArgStr was interesting.\n\nOn 2.5 and master stripped of unimportant to aarch64 it is:\n- host-passthrough -> add \"host\"\n- host-model -> fail\n  (remember x86 converts host-model to custom)\n- custom -> add \"whatever was given\"\n\nSo that won't work even if we would let it pass the check.\n\nAnd while the code changed the semantics did not - yet there it handled host-model \"like\" passthrough not in the construction but due to a fallback in detection.\n\nThat known I checked the qemu command strings it constructed in the past, it was: \"-cpu host\".\nAha, no specials due to host-model (as it didn't work), so on aarch64 host-model was equal to host-passthrough with the failure that the \"advertised\" extra that host-model has over host-passthrough did not work.\n\nNow libvirt changed to know that and tells you that host-model is not working, but that is actually correct - even it seemed so in the first place I'd not consider this a regression in the usual sense.\n\n- Regression: sometihng that worked now fails\n- This: something that you thought works, but didn't now fails telling you so\n\nSummarizing in next comment to catch everybody and sync with the openstack Team on this.", 
            "date_created": "2017-03-23 11:13:42.183567+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "I know it is a lot of text, but not all of you have to read everything, so here my TL;DR: (IMHO)\n\n- no libvirt regression; host-model never worked, just no one noticed so far\n- Openstack should change (at least for that arch) to host-passthrough\n  - if the \"feature\" of host-model is really wanted it can be reenabled on a version check on qemu/libvirt > 2.9/3.2 (or later depending how things work out)", 
            "date_created": "2017-03-23 11:14:24.572893+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "Switching the status back to New for upstream nova since there may be a need to switch from host-model to host-passthrough in nova.", 
            "date_created": "2017-03-23 12:13:44.800900+00:00", 
            "author": "https://api.launchpad.net/1.0/~corey.bryant"
        }, 
        {
            "content": "FYI - On the Libvirt side the new 3.2 release has the following statement which is - at least -\n related to the semantics of a host-* cpu specification. That is really a major change which we will unlikely SRU, but pick up naturally when we move to this or a later libvirt version - likely on aa-relase. On top this change still is x86_64 only for now, I'd expect further changes for other architectures down the road (CPU Feat detection is very different per arch anyway, so other arches might go different routes - but this sheds some light on some of the insufficiencies of the old detection at least).\n\nSo far just FYI:\n\n- qemu: Detect host CPU model by asking QEMU on x86_64\nPreviously, libvirt detected the host CPU model using CPUID\ninstruction, which caused libvirt to detect a lot of CPU features that\nare not supported by QEMU/KVM. Asking QEMU makes sure we don't start it\nwith unsupported features.\n\n\n", 
            "date_created": "2017-04-03 05:54:45.682435+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "The plan is to implement an arch specific charm change  to pass in the \"host-passthrough\" as  CPU mode until a newer libvirt with functional \"host-model\" parameter is available in a future Ubuntu release. ", 
            "date_created": "2017-04-03 15:28:23.360411+00:00", 
            "author": "https://api.launchpad.net/1.0/~rkota"
        }, 
        {
            "content": "I've tried cpu modes: none, host-model, and host-passthrough.  I'm not able to create nova instances on Ocata arm64 with any of these modes.\n\nApr 03 17:46:03 juju-b15153-15 libvirtd[25804]: unsupported configuration: logfile not supported in this QEMU binary\nApr 03 17:55:31 juju-b15153-15 libvirtd[25804]: End of file while reading data: Input/output error\nApr 03 17:55:48 juju-b15153-15 libvirtd[25804]: this function is not supported by the connection driver: cannot get node CPU data for aarch64 architecture\nApr 03 17:55:48 juju-b15153-15 libvirtd[25804]: Failed to get host CPU\nApr 03 17:55:49 juju-b15153-15 libvirtd[25804]: End of file while reading data: Input/output error\nApr 03 17:56:06 juju-b15153-15 libvirtd[25804]: this function is not supported by the connection driver: cannot get node CPU data for aarch64 architecture\nApr 03 17:56:06 juju-b15153-15 libvirtd[25804]: Failed to get host CPU\nApr 03 17:56:07 juju-b15153-15 libvirtd[25804]: End of file while reading data: Input/output error\nApr 03 17:56:25 juju-b15153-15 libvirtd[25804]: this function is not supported by the connection driver: cannot get node CPU data for aarch64 architecture\nApr 03 17:56:25 juju-b15153-15 libvirtd[25804]: Failed to get host CPU\n", 
            "date_created": "2017-04-04 18:35:21.928322+00:00", 
            "author": "https://api.launchpad.net/1.0/~1chb1n"
        }, 
        {
            "content": "Hi Ryan, that is most disturbing as we proved that working in the lower layers (just switching in the guest xml) with only libvirt/qemu.\nCan you provide the Guest XMLs it tries to deploy in these cases?", 
            "date_created": "2017-04-05 05:45:15.322449+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "I hit this problem with yakkety-newton as well today, seems nested kvm doesn't work on yakkety (mitaka doesn't have this problem), it said:\n\n2017-04-11 12:12:21.047 19019 ERROR nova.compute.manager [instance: 4912dc24-fb89-4b83-9b59-d139547b7c28] libvirtError: invalid argument: could not find capabilities for domaintype=kvm\n\nroot@juju-5e1208-basic-yakkety-newton-7:~# kvm-ok \nINFO: /dev/kvm does not exist\nHINT:   sudo modprobe kvm_intel\nINFO: Your CPU supports KVM extensions\nKVM acceleration can be used\n\nroot@juju-5e1208-basic-yakkety-newton-7:~# modprobe kvm_intel\nmodprobe: ERROR: could not insert 'kvm_intel': Input/output error\n\nthen cause we see openstack's errors above, more info can refer the link http://paste.ubuntu.com/24364083/", 
            "date_created": "2017-04-12 00:38:35.342210+00:00", 
            "author": "https://api.launchpad.net/1.0/~zhhuabj"
        }, 
        {
            "content": "Hi Hua, this is a different issue - forked that into 1683670", 
            "date_created": "2017-04-18 08:44:47.234544+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "Got this today via Mail, linking here:\n\nnone:\n\nhttps://pastebin.canonical.com/190574/\n\nhost-model:\n\nhttps://pastebin.canonical.com/190578/\n\nhost-passthrough\n\nhttps://pastebin.canonical.com/190579/", 
            "date_created": "2017-06-13 05:51:47.937783+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "The former came down to the difference of\nnone:\n  <cpu>\n    <topology sockets='1' cores='1' threads='1'/>\n  </cpu>\n\nhost-model:\n  <cpu mode='host-model'>\n    <model fallback='allow'/>\n    <topology sockets='1' cores='1' threads='1'/>\n  </cpu>\n\nhost-passthrough:\n  <cpu mode='host-passthrough'>\n    <topology sockets='1' cores='1' threads='1'/>\n  </cpu>", 
            "date_created": "2017-06-13 05:52:56.166814+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "@Andrew McLeod\nTo clarify - your Data is a follow on to Ryan in Comment #21 tight?\nAnd I assume you still see that all of them fail for not getting CPU Data.\n\nWhich is odd, as I stated in #22 as it worked before and we were on my and Ryans system only about tweaking host-model to host-passthrough to get things working in regard to the initial bug report.\n\nThanks for the full XMLs, I'm now testing with these if I can reproduce any of these new/related issues.", 
            "date_created": "2017-06-13 06:01:03.377371+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "@admcleod - While my system is preparing to test this I think the logs you added are already kind of proving that the issue this bug was reported about is kind of solved.\n\nIn regard to your logs - the related error:\nnone:\n-> Passes the initialization but then breaks on logfile\n\nhost-model:\n-> Fails due to host-model being broken\n\nhost-passthrough\n-> Passes the initialization but then breaks on logfile\n\nThat might be an issue, but a different one - so I forked off bug 1697610\n\nIn regard to the cpu-types here I got it working with host-passthrough as stated before.\nKeeping this bug incomplete.", 
            "date_created": "2017-06-13 07:08:18.269192+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "BTW - if you want to teach the charm to check such things FYI:\n\n$ virsh domcapabilities | grep host-model\n    <mode name='host-model' supported='no'/>", 
            "date_created": "2017-06-13 07:30:27.986562+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "@paelzer #27 - yes the data was a follow up to #21", 
            "date_created": "2017-06-14 13:29:39.221424+00:00", 
            "author": "https://api.launchpad.net/1.0/~admcleod"
        }, 
        {
            "content": "Automatically discovered version ocata in description. If this is incorrect, please update the description to include 'nova version: ...'", 
            "date_created": "2017-06-27 16:04:11.147853+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "I managed to get around this issue:\n\nlibvirtError: unsupported configuration: logfile not supported in this QEMU binary\n\nBy modifying the domain xml and removing the child nodes for serial and console. \n\nSo now there are more reasonable errors for cpu-modes none and host-model\n\nnone:\n\nhttps://pastebin.canonical.com/192075/\n\nhost-model:\n\nhttps://pastebin.canonical.com/192074/\n\nhowever, host-passthrough also does not work:\n\nhttps://pastebin.canonical.com/192073/", 
            "date_created": "2017-06-28 12:15:34.647741+00:00", 
            "author": "https://api.launchpad.net/1.0/~admcleod"
        }, 
        {
            "content": "A general description of the workaround for 'logfile not supported in this QEMU binary' on arm64 with ocata is:\n\nin nova/virt/libvirt/guest.py:115, in the create function, added:\n\n        xml = etree.fromstring(xml)\n        for bad in xml.xpath(\"//log\"):\n                bad.getparent().remove(bad)\n        #for item in xml.findall('console'):\n        #       xml.remove(item)\n        #for item in xml.findall('serial'):\n        #       xml.remove(item)\n        xml = etree.tostring(xml)\n\n        # for debugging...\n        txt_file = open(\"/tmp/xml_out.xml\", \"w\")\n        txt_file.write(xml)\n        txt_file.close()\n\nIt appears removing just the 'log' element should be sufficient as this was the specific error, but i tested more thoroughly with removing console and serial elements entirely.\n\nThe workaround for the error 'libvirtError: Requested operation is not valid: domain is already running' was to modify dist-packages/libvirt.py:1097, and completely pass the resume function- seems like the check of whether the domain is already running or not is faulty?\n\nOnce these changes were made I could launch an instance with host-passthrough, give it a floating IP and ssh into it.\n\n", 
            "date_created": "2017-06-28 12:57:47.664987+00:00", 
            "author": "https://api.launchpad.net/1.0/~admcleod"
        }, 
        {
            "content": "It seems like two possible fixes are:\n\n1) Update libvirt's qemuProcessUpdateGuestCPU() to not limit the the switch of cpu mode from host-model->custom to ARCH_IS_X86(). Would there be side-effects if we also switch host-model->custom when ARCH_IS_ARM()? Perhaps we can check with upstream libvirt devs about this if someone hasn't already.\n\n2) In nova, it looks like host-model is set in _get_guest_cpu_model_config(). Could we update that to set mode = \"host-passthrough\" if AARCH64, where it currently sets mode = \"host-model\"? If I understand Christian's comments above correctly, this should result in the same behavior we had prior to ocata as host-model was switched to host-passthrough.", 
            "date_created": "2017-06-28 19:22:54.392525+00:00", 
            "author": "https://api.launchpad.net/1.0/~corey.bryant"
        }, 
        {
            "content": "Hi Andrew and Corey,\nfirst of all thanks for the re-checks.\n- None is usually not supported on arm, as there are too different cpus and you have to select one.\n- Host-passthrough fails for \"domain is already running\" that seems unrelated to the types and actually means it might be running after all :-)\n- Host-model, as I said is known broken so the refuse via \"'host-model' for aarch64 kvm domain on aarch64 host is not supported by hypervisor\" seems correct still\n\nAbout Coreys suggestions:\nI'm pretty sure there were reasons for the \"ARCH_IS_X86\" in [1] - especially on a platform as diverse in cpu models as arm just turning it to custom might have side effects we don't see.\nI haven't discussed #1 with upstream and at least I didn't see anyone else doing it.\nTherefore #2 might be the much safer solution if you want it to work on arm for now.\n\nIt might be worth to check the host-passthrough case to work before that, but as I said above \"domain already running\" sounds like an unrelated issue.\n\n[1]: http://libvirt.org/git/?p=libvirt.git;a=commit;h=7ce711a30", 
            "date_created": "2017-06-29 06:36:24.600074+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "Hi trying to get the status right here.\nAFAIK these things are changed in libvirt 3.2 to be good - at least for x86, not sure if/how arm followed but since there were major changes we should consider it fixed and re-analyze from there for the development release.\nSo the coming merge of a newer libvirt will fix it for current Ubuntu-dev.\n\nSince it is a \"known behavior\" on zesty's version I added a task on won't fix as so far - as I understood - we thought to better fix it in Openstack creating the xml's.\n\nFurthermore adding a qemu task which will need to be >=2.9 to let the code in libvirt >=3.2 really work correctly.\n\nRead [1] for the version references.\n\n[1]: https://libvirt.org/formatdomain.html#elementsCPU\n", 
            "date_created": "2017-07-05 07:43:52.153591+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "Update: we've got a rough diff patch as a work-around for nova, using host-passthrough.  That patch is likely not exactly what we will propose upstream to Nova.  Next steps will be to revise and minimize that patch, and propose a fix upstream in nova master.  Once that lands, we can propose a cherry pick back to Ocata, etc.\n\nIn parallel to that, we will need to reproduce and triage the \"domain is already running\" issue, if it is indeed persistent and present.", 
            "date_created": "2017-07-10 19:08:07.957142+00:00", 
            "author": "https://api.launchpad.net/1.0/~1chb1n"
        }, 
        {
            "content": "We are working to re-confirm this issue exists on Pike-B3, since that is where any upstream nova patches will be initially proposed.", 
            "date_created": "2017-07-12 18:59:55.215103+00:00", 
            "author": "https://api.launchpad.net/1.0/~1chb1n"
        }, 
        {
            "content": "This bug was fixed in the package libvirt - 3.5.0-1ubuntu1\n\n---------------\nlibvirt (3.5.0-1ubuntu1) artful; urgency=medium\n\n  * Merged with Debian unstable (3.5)\n    This closes several bugs:\n    - improved handling of host-model since libvirt 3.2 (LP: #1673467)\n    - Adding POWER9 cpu model to cpu_map.xml (LP: #1690209)\n  * Remaining changes:\n    - Disable sheepdog (universe dependency)\n    - Disable libssh2 support (universe dependency)\n    - Disable firewalld support (universe dependency)\n    - Disable selinux\n    - Enable esx support\n      + Add build-dep to libcurl4-gnutls-dev (required for esx)\n    - Set qemu-group to kvm (for compat with older ubuntu)\n    - Regularly clear AppArmor profiles for vms that no longer exist\n    - Additional apport package-hook\n    - Modifications to adapt for our delayed switch away from libvirt-bin (can\n      be dropped >18.04).\n      + d/p/ubuntu/libvirtd-service-add-bin-alias.patch: systemd: define alias\n        to old service name so that old references work\n      + d/p/ubuntu/libvirtd-init-add-bin-alias.patch: sysv init: define alias\n        to old service name so that old references work\n      + d/control: transitional package with the old name and maintainer\n        scripts to handle the transition\n    - Backwards compatible handling of group rename (can be dropped >18.04).\n    - config details and autostart of default bridged network. Creating that is\n      now the default in general, yet our solution provides the following on\n      top as of today:\n      + nat only on some ports <port start='1024' end='65535'/>\n      + autostart the default network by default\n      + do not autostart if 192.168.122.0 is already taken (e.g. in containers)\n    - d/p/ubuntu/Allow-libvirt-group-to-access-the-socket.patch: This is\n      the group based access to libvirt functions as it was used in Ubuntu\n      for quite long.\n      + d/p/ubuntu/daemon-augeas-fix-expected.patch fix some related tests\n        due to the group access change.\n    - ubuntu/parallel-shutdown.patch: set parallel shutdown by default.\n    - d/p/ubuntu/enable-kvm-spice.patch: compat with older Ubuntu qemu/kvm\n      which provided a separate kvm-spice.\n    - d/p/ubuntu/storage-disable-gluster-test: gluster not enabled, skip test\n    - d/p/ubuntu/ubuntu-libxl-qemu-path.patch: this change was split. The\n      section that adapts the path of the emulator to the Debian/Ubuntu\n      packaging is kept.\n    - d/p/ubuntu/ubuntu-libxl-Fix-up-VRAM-to-minimum-requirements.patch: auto\n      set VRAM to minimum requirements\n    - d/p/ubuntu/xen-default-uri.patch: set default URI on xen hosts\n    - Add libxl log directory\n    - libvirt-uri.sh: Automatically switch default libvirt URI for users on\n      Xen dom0 via user profile (was missing on changelogs before)\n    - d/p/ubuntu/apibuild-skip-libvirt-common.h: drop libvirt-common.h from\n      included_files to avoid build failures due to duplicate definitions.\n    - Update README.Debian with Ubuntu changes\n    - Convert libvirt0, libnss_libvirt and libvirt-dev to multi-arch.\n    - Enable some additional features on ppc64el and s390x (for arch parity)\n      + systemtap, zfs, numa and numad on s390x.\n      + systemtap on ppc64el.\n    - fix conffile upgrade handling to avoid obsolete files\n      and inactive duplicates (LP 1694159)\n    - d/t/control, d/t/smoke-qemu-session: fixup smoke-qemu-session by making\n      vmlinuz available and accessible (Debian bug 848314)\n    - d/t/control, d/t/smoke-lxc: fix up lxc smoke test (Debian bug 848317)\n    - Extended handling of apparmor profiles - clear lost profiles via cron\n    - Add dnsmasq configuration to work with system wide dnsmasq (drop >18.04,\n      no more UCA onto Xenial then which has global dnsmasq by default).\n    - Reworked apparmor Delta, especially the more complex delta is dropped\n      now, also our former delta is now split into logical pieces, has\n      improved comments and is part of a continuous upstreaming effort.\n      Listing related remaining changes:\n      + d/p/0001-apparmor-Allow-pygrub-to-run-on-Debian-Ubuntu.patch: apparmor:\n        Allow pygrub to run on Debian/Ubuntu\n      + d/p/0002-apparmor-libvirt-qemu-Allow-macvtap-access.patch: apparmor,\n        libvirt-qemu: Allow macvtap access\n      + d/p/0003-apparmor-libvirt-qemu-Allow-read-access-to-overcommi.patch:\n        apparmor, libvirt-qemu: Allow read access to overcommit_memory\n      + d/p/0004-apparmor-Explicit-deny-for-setpcap.patch: apparmor: Explicit\n        deny for setpcap\n      + d/p/0005-apparmor-libvirt-qemu-Allow-use-of-sgabios.patch: apparmor,\n        libvirt-qemu: Allow use of sgabios\n      + d/p/0006-apparmor-libvirt-qemu-Silence-lttng-related-deny-mes.patch:\n        apparmor, libvirt-qemu: Silence lttng related deny messages\n      + d/p/0007-apparmor-libvirt-qemu-Allow-owner-read-access-to-PRO.patch:\n        apparmor, libvirt-qemu: Allow owner read access to @{PROC}/*/auxv\n      + d/p/0008-apparmor-libvirt-qemu-Allow-read-access-to-sysfs-sys.patch:\n        apparmor, libvirt-qemu: Allow read access to sysfs system info\n      + d/p/0009-apparmor-libvirt-qemu-Allow-read-access-to-max_mem_r.patch:\n        apparmor, libvirt-qemu: Allow read access to max_mem_regions\n      + d/p/0010-apparmor-libvirt-qemu-Allow-qemu-block-extra-librari.patch:\n        apparmor, libvirt-qemu: Allow qemu-block-extra libraries\n      + d/p/0011-apparmor-libvirt-qemu-Allow-access-to-hugepage-mount.patch:\n        apparmor, libvirt-qemu: Allow access to hugepage mounts\n      + d/p/0012-apparmor-libvirtd-Allow-access-to-netlink-sockets.patch:\n        apparmor, libvirtd: Allow access to netlink sockets\n      + d/p/0013-apparmor-Add-rules-for-mediation-support.patch:\n        apparmor: Add rules for mediation support\n      + d/p/0014-apparmor-virt-aa-helper-Improve-comment-about-backin.patch:\n        apparmor, virt-aa-helper: Improve comment about backing store\n      + d/p/0015-apparmor-virt-aa-helper-Allow-access-to-ecryptfs-fil.patch:\n        apparmor, virt-aa-helper: Allow access to ecryptfs files\n      + d/p/0016-apparmor-libvirtd-Allow-ixr-to-var-lib-libvirt-virtd.patch:\n        apparmor, libvirtd: Allow ixr to /var/lib/libvirt/virtd*\n      + d/p/0017-apparmor-virt-aa-helper-Allow-access-to-tmp-director.patch:\n        apparmor, virt-aa-helper: Allow access to tmp directories\n      + d/p/0018-apparmor-virt-aa-helper-Add-ipv6-network-policy.patch:\n        apparmor, virt-aa-helper: Add ipv6 network policy\n      + d/p/0019-apparmor-virt-aa-helper-Allow-access-to-sys-bus-usb-.patch:\n        apparmor, virt-aa-helper: Allow access to /sys/bus/usb/devices\n      + d/p/0020-apparmor-virt-aa-helper-Allow-various-storage-pools-.patch:\n        apparmor, virt-aa-helper: Allow various storage pools and image\n        locations\n      + d/p/0021-apparmor-virt-aa-helper-Add-openvswitch-support.patch:\n        apparmor, virt-aa-helper: Add openvswitch support\n      + d/p/0022-apparmor-drop-references-to-qemu-kvm.patch: apparmor: drop\n        references to qemu-kvm\n      + d/p/0023-apparmor-qemu-won-t-call-qemu-nbd.patch: apparmor: qemu\n        won't call qemu-nbd\n      + d/p/0024-apparmor-virt-aa-helper-Allow-access-to-name-service.patch:\n        apparmor, virt-aa-helper: Allow access to name services\n      + d/p/0025-apparmor-fix-newer-virt-manager-1.4.0.patch: Add Apparmor\n        permissions so virt-manager 1.4.0 viewing works (LP 1668681).\n      + d/p/0026-apparmor-add-generic-base-vfio-device.patch: apparmor: add\n        /dev/vfio for vf (hot) attach (LP 1680384).\n      + d/p/0027-apparmor-allow-reading-cmdline-of-shutdown-signal.patch:\n        apparmor: allow to parse cmdline of the pid that send the shutdown\n        signal (LP 1680384).\n      + (28 is a new patch, listed in added changes)\n      + d/p/0029-appmor-libvirt-qemu-Add-9p-support.patch: appmor,\n        libvirt-qemu: Add 9p support\n      + d/p/0030-virt-aa-helper-Complete-9p-support.patch: virt-aa-helper:\n        add l to 9p file options.\n      + d/p/0031-virt-aa-helper-Ask-for-no-deny-rule-for-readonly-dis.patch:\n        virt-aa-helper: Ask for no deny rule for readonly disk (renamed and\n        reworded, was virt-aa-helper-no-explicity-deny-for-basefiles.patch)\n      + d/p/0032-apparmor-libvirt-qemu-Allow-reading-charm-specific-c.patch:\n        apparmor, libvirt-qemu: Allow reading charm-specific ceph config\n      + d/p/0033-UBUNTU-only-apparmor-for-kvm.powerpc-LP-1680384.patch: allow\n        commands executed by ubuntu only kvm wrapper on ppc64el (LP 1686621).\n      + d/p/0034-apparmor-virt-aa-helper-access-for-snapped-nova.patch:\n        apparmor, virt-aa-helper: access for snapped nova\n    - remaining but updated to match the latest release\n      + d/p/Disable-use-of-namespaces-by-default.patch (Debian change)\n      + d/p/Reduce-udevadm-settle-timeout-to-10-seconds.patch (Debian change)\n      + d/p/debian/apparmor_profiles_local_include.patch Include local\n        apparmor profile (Debian change)\n      + d/p/ubuntu/ubuntu_machine_type.patch: accept ubuntu types as pci440fx\n      + d/test/smoke-lxc workaround for debbug 848317/867379\n  * Dropped Changes (Upstream):\n    - Add missing apparmor rule for debug-threads feature (LP 1615550).\n    - Add new block device types to virt-aa-helpers profile (LP 1641618)\n    - d/p/ubuntu/storage-default-permission-mode-to-0711: safer default perms\n      for storage dirs like /var/lib/libvirt/images.\n    - d/p/ubuntu/libvirtd-service-nolimit.patch: remove proc/file/task limits\n      to support huge systems.\n    - d/p/ubuntu/libvirtd-service-set-notifyaccess.patch: set NotifyAccess=all\n      in libvirtd.service (-d not allowed to be specified, everything else\n      upstream so drop delta; LP 1574566).\n    - d/p/ubuntu/qemu_process-spice-don-t-release-used-port.patch: qemu_process\n      spice: don't release used port (LP 1697729).\n    - d/p/ubuntu/virsh-maxvcpu-fall-back-to-old-command.patch: virsh: maxvcpus:\n      Always fall back to the old command if domain caps fail (LP 1674298)\n    - d/p/ubuntu/qemu-Allow-empty-script-path-to-interface.patch: in the past\n      it was possible to have <script path=''/> which now fails - fix to match\n      the old behavior (LP 1665698)\n    - Reworked apparmor Delta and started upstreaming, listing related\n      changes dropped:\n      + Apparmor feature parsing to depend on new apparmor features which\n        appear in different versions across distributions (no more needed\n        >=Xenial, allows to now separate changes and upstream more easily).\n      + d/p/ubuntu/Ensure-disk-names-follow-the-disk-name-regex.patch:\n        guarantee disk spec is following the defined regex (LP 1665410).\n      + d/p/ubuntu/virt-aa-helper-add-guest-agent-rule.patch: add\n        virt-aa-helper rule allowing all private channel access.\n      + d/p/ubuntu/virt-aa-helper-apparmor-allow-usr-share-AAVMF-too.patch:\n        virt-aa-helper to allow access to aarch64 UEFI images.\n      + d/rules, apparmor: include and install local apparmor profiles (This\n        is now done by dh_apparmor automatically)\n      + add local apparmor override templates (provided by dh_apparmor now)\n      + Fix name resolution calls from virt-aa-helper profile (LP 1546674).\n      + virt-aa-helper, apparmor: allow /usr/share/OVMF/ too\n      + virt-aa-helper: Generalize test for firmware paths\n      + apparmor, virt-aa-helper: Allow aarch64 UEFI.\n      + apparmor, libvirt-qemu: Add ppc64el related changes\n      + apparmor, libvirtd: Allow libxl-save-helper to run on Debian/Ubuntu\n      + apparmor, libvirt-qemu: Allow access to ceph config\n      + apparmor, libvirt-qemu: Allow access to certificates used by libvirt-vnc\n      + apparmor, virt-aa-helper: Explicit denies for host devices\n      + apparmor, virt-aa-helper: Allow access to libnl-3 config files\n      + apparmor, libvirt-qemu: allow access to pt_chown for pty consoles\n  * Dropped Changes (In Debian):\n    - d/rules: debhelper start virtlogd.socket\n    - d/p/ubuntu/Debianize-virtlogd-service.patch: Adapt config file location\n      for Debian based systems.\n    - Additional debian/bug-presubj\n    - Extended handling of apparmor profiles - reload and remove in maintainer\n      scripts (dh_apparmor* now generate these snippets)\n  * Dropped Changes (no SysV anymore):\n    - Add sysvinit script for virtlockd\n    - Wait on socket in sysvinit script\n    - d/rules: dh_installinit virtlockd (was part of \"Cleanup systemd\n      debhelper\"\n    - d/p/ubuntu/Debianize-virtlockd-init.patch: Fix default config path in\n      virtlockd.init for Debian based systems.\n  * Dropped Changes (other reasons):\n    - d/p/ubuntu/dnsmasq-as-priv-user: configuration to run as extra user\n      This used group libvirt instead of nobody which makes it worse; Needs\n      to be fixed upstream (LP: #1690729).\n      + d/p/ubuntu/disable-network-test.patch: disable test failing due to\n        dnsmasq changes.\n    - Add .gitignore for .pc\n    - we keep lxc support as Debian does, but stop adding delta. It feels\n      somewhat less maintained than e.g. libvirt for qemu. Also for secure\n      and comfortable container management lxd is clearly preferred. The\n      delta caused more issues than it solved so deliver libvirt-lxc as-is\n      and drop the related delta.\n      + d/p/ubuntu/9031-enable-lxc-apparmor: enable apparmor confinement of\n        containers by default.\n      + d/p/ubuntu/9032-lxc-allow-no-security-driver: allow empty sec driver\n        for libvirt-lxc.\n    - The following xen changes are no more required with current versions\n      + d/p/ubuntu/ubuntu-libxl-hvmloader-path.patch: Fallback for libxl\n        xen paths (LP 1459603)\n      + d/p/ubuntu/ubuntu-libxl-qemu-path.patch: this change was split. The\n        section about compat to the very old qemu-dm name is no more needed.\n      + d/p/ubuntu/libxl-fix-test-data.patch and\n        d/p/ubuntu/fix-xen-xml-in-tests.patch: updated and unified into the\n        former one + also updated the maintainer notes to ease updating.\n      + d/p/ubuntu/libxl-no-dm-check.patch: Stop calling emulator to identify\n        device-model\n  * Added Changes:\n    - d/p/0028-apparmor-add-default-pki-path-of-lbvirt-spice.patch:\n      apparmor: add default pki path of lbvirt-spice (LP: #1690140)\n    - conffile handling of files dropped in 3.5 (can be dropped >18.04)\n      + /etc/init.d/virtlockd was sysv init only\n      + /etc/apparmor.d/local/usr.sbin.libvirtd and\n        /etc/apparmor.d/local/usr.lib.libvirt.virt-aa-helper are now generated\n        by dh_apparmor as needed\n    - d/p/ubuntu/fix-libxl-default-driver-name.patch: avoid an issue with\n      default driver entries missing name='qemu'.\n\n -- Christian Ehrhardt <email address hidden>  Thu, 06 Jul 2017 15:43:17 +0200", 
            "date_created": "2017-07-14 12:12:13.537646+00:00", 
            "author": "https://api.launchpad.net/1.0/~janitor"
        }, 
        {
            "content": "We need this fix in Ocata, which is delivered via Zesty versions.  I see that it is triaged as wont-fix for Zesty.  Can we revisit that decision?  Is the fix something that can be picked back to the libvirt in Zesty?", 
            "date_created": "2017-07-20 09:25:06.010977+00:00", 
            "author": "https://api.launchpad.net/1.0/~1chb1n"
        }, 
        {
            "content": "Hi Ryan,\nthe \"fix\" on the libvirt side is to actually understand host-model on x86.\nAs outlined before that doesn't mean anything for arm yet.\nThe changes are too huge in libvirt and also need a much newer qemu to work (2.9) - so they make no sense for zesty which is why it is won't fix.\n\nThe fix for Ocata has to be done in openstack (as discussed before) to send host-passthrough instead of host-model - the fix mentioned by you in comment #37, that is the fix that will be the one for UCA-O.\n\nAnd even for UCA-P based on Artful we will have to test if the final combination of libvirt/qemu in Artful is enough to get it working on arm as well (as most development around this feature-fix was driven by x86 only).", 
            "date_created": "2017-07-20 10:09:39.811409+00:00", 
            "author": "https://api.launchpad.net/1.0/~paelzer"
        }, 
        {
            "content": "OK - some updates\n\nI've tested with 2.5.0 and 3.5.0 of libvirt using OpenStack Ocata.\n\n2.5.0 libvirt/qemu does not support host-model - only host-passthrough so I agree that we should just being doing the right thing either in the charm (as we've done for other non-x86 arch) or the nova codebase - my preference is for the first as we avoid to much magic behaviour.\n\n3.5.0 has the same limitation; I'm actually bumping into a different issue for which I'll raise another bug for arm64 instances using that libvirt stack.\n\ntl;dr - lets just use host-passthrough and move on.\n\n", 
            "date_created": "2017-07-26 13:30:34.546296+00:00", 
            "author": "https://api.launchpad.net/1.0/~james-page"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/487422", 
            "date_created": "2017-07-26 13:37:24.495497+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/487422\nCommitted: https://git.openstack.org/cgit/openstack/charm-nova-compute/commit/?id=b5d9b18c0afd06b721d78bced96b4c6c19f77834\nSubmitter: Jenkins\nBranch:    master\n\ncommit b5d9b18c0afd06b721d78bced96b4c6c19f77834\nAuthor: James Page <email address hidden>\nDate:   Wed Jul 26 14:35:33 2017 +0100\n\n    aarch64: set default cpu_mode to host-passthrough\n    \n    Unless explicit configuration is supplied by the charm user, set\n    the cpu_mode configuration on the aarch64 architecture to\n    host-passthrough; host-model is not supported by the underlying\n    hypervisor.\n    \n    Change-Id: I6df2d70e7b5fed7e614ca981864f6f737a1a90eb\n    Closes-Bug: 1673467\n", 
            "date_created": "2017-07-27 09:23:16.700898+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "FYI: The charm fix component of this is slated to be fix-released along with the OpenStack Charms release on Sept 7 2018.  Do bear in mind that there may still be some package changes in flight at that time, as the Charms release doesn't align to the Ubuntu distro release in all cases.", 
            "date_created": "2017-08-16 18:21:19.284272+00:00", 
            "author": "https://api.launchpad.net/1.0/~1chb1n"
        }, 
        {
            "content": "Typo in previous comment.  Sept 7 2017 is the correct date.\n\nFYI: The charm fix component of this is slated to be fix-released along with the OpenStack Charms release on Sept 7 2017. Do bear in mind that there may still be some package changes in flight at that time, as the Charms release doesn't align to the Ubuntu distro release in all cases.", 
            "date_created": "2017-08-16 18:22:50.248089+00:00", 
            "author": "https://api.launchpad.net/1.0/~1chb1n"
        }
    ], 
    "closed": "2017-07-26 13:32:50.587931+00:00"
}