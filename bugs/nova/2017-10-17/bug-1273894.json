{
    "status": "Expired", 
    "last_updated": "2016-09-28 01:33:36.811994+00:00", 
    "description": "Currently, when Cinder sends a snapshot create or delete job to Nova for the GlusterFS driver, it has a fixed timeout window, and if the job takes longer than that, the snapshot operation is failed.  (The assumption is that Nova has somehow failed.)\n\nThis is problematic because it fails operations that are still active but running very slowly.\n\nThe fix proposed here is to use the same update_snapshot_status API which is used to finalize these operations to send periodic updates while the operation is in progress, so that Cinder knows that Nova is still active, and that the job does not need to be timed out.\n\nThis is backward compatible for both Havana Cinder and Havana Nova.", 
    "tags": [
        "cinder-nova", 
        "drivers", 
        "glusterfs", 
        "libvirt"
    ], 
    "importance": "Undecided", 
    "heat": 12, 
    "link": "https://bugs.launchpad.net/nova/+bug/1273894", 
    "owner": "None", 
    "id": 1273894, 
    "index": 5777, 
    "openned": "2014-01-28 23:45:49.968731+00:00", 
    "created": "2014-01-28 23:45:35.849435+00:00", 
    "title": "GlusterFS: Do not time out long-running volume snapshot operations", 
    "comments": [
        {
            "content": "Currently, when Cinder sends a snapshot create or delete job to Nova for the GlusterFS driver, it has a fixed timeout window, and if the job takes longer than that, the snapshot operation is failed.  (The assumption is that Nova has somehow failed.)\n\nThis is problematic because it fails operations that are still active but running very slowly.\n\nThe fix proposed here is to use the same update_snapshot_status API which is used to finalize these operations to send periodic updates while the operation is in progress, so that Cinder knows that Nova is still active, and that the job does not need to be timed out.\n\nThis is backward compatible for both Havana Cinder and Havana Nova.", 
            "date_created": "2014-01-28 23:45:35.849435+00:00", 
            "author": "https://api.launchpad.net/1.0/~eharney"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/69759", 
            "date_created": "2014-01-29 00:38:14.620017+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/69761", 
            "date_created": "2014-01-29 00:41:14.499697+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/76587", 
            "date_created": "2014-02-26 17:21:12.839934+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/76587\nCommitted: https://git.openstack.org/cgit/openstack/cinder/commit/?id=5c79c08f7bb88484a96427d30244057f7cd7cdfc\nSubmitter: Jenkins\nBranch:    master\n\ncommit 5c79c08f7bb88484a96427d30244057f7cd7cdfc\nAuthor: Eric Harney <email address hidden>\nDate:   Wed Feb 26 11:38:29 2014 -0500\n\n    GlusterFS: Increase snapshot delete job timeout to two hours\n    \n    Increase the timeout for Nova snapshot delete operations from ten\n    minutes to two hours.  This helps prevent Cinder from terminating\n    operations prematurely that are still being processed by Nova.\n    \n    It is not uncommon for snapshot delete jobs to run for longer than\n    ten minutes depending on the size of the snapshot and speed of the\n    storage backend.\n    \n    This will be followed up with a more robust mechanism to keep track\n    of snapshot job progress as a later effort.\n    \n    Related-Bug: 1273894\n    \n    Change-Id: I1ad52568aed1ce1bf593e71704e481b6fe5f44fb\n", 
            "date_created": "2014-02-27 02:25:27.442182+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Nothing really in shape here for I-3.  Moving to RC1 in hopes of finding some decent solution.", 
            "date_created": "2014-03-04 20:24:55.968177+00:00", 
            "author": "https://api.launchpad.net/1.0/~eharney"
        }, 
        {
            "content": " Nova patch is abandoned, this clearly isn't in progress anymore", 
            "date_created": "2014-12-03 14:59:23.964549+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "This appears to still need a fix.", 
            "date_created": "2015-06-23 14:18:52.178940+00:00", 
            "author": "https://api.launchpad.net/1.0/~eharney"
        }, 
        {
            "content": "@Eric Harney,\n  I read up the history of this bug, looked at the prev patches.\n\nIIUC, overloading 'progress' field isn't a good idea, so the recent work to introduce new fields in Nova\n(See https://review.openstack.org/#/c/172813/) should address the overloading 'progress' field part.\n\nBut we still need to have a loop on the Cinder side with _some_ timeout as we wouldn't know\nif the Nova/Compute node crashed/stopped responding for some reason, so we don't hang forever on the Cinder side\n\nDo you intend to have some mechanism wherein we wouldn't need a loop on the Cinder side ?\nIIUC thats only possible if Nova sends _real_ progress data for the blockjob. Do you have any other solution in mind ?", 
            "date_created": "2015-07-07 06:27:15.305560+00:00", 
            "author": "https://api.launchpad.net/1.0/~dpkshetty"
        }, 
        {
            "content": "Automatically unassigning due to inactivity.", 
            "date_created": "2015-11-24 19:08:30.160733+00:00", 
            "author": "https://api.launchpad.net/1.0/~sean-mcginnis"
        }, 
        {
            "content": "Do we still have this issue?", 
            "date_created": "2016-03-13 20:26:02.380059+00:00", 
            "author": "https://api.launchpad.net/1.0/~sean-mcginnis"
        }, 
        {
            "content": "Yes, operations will still fail if they take longer than X minutes/hours due to a slow I/O path.", 
            "date_created": "2016-04-05 18:46:03.361576+00:00", 
            "author": "https://api.launchpad.net/1.0/~eharney"
        }, 
        {
            "content": "\nThis is an automated cleanup. This bug report has been closed because it\nis older than 18 months and there is no open code change to fix this.\nAfter this time it is unlikely that the circumstances which lead to\nthe observed issue can be reproduced.\n\nIf you can reproduce the bug, please:\n* reopen the bug report (set to status \"New\")\n* AND add the detailed steps to reproduce the issue (if applicable)\n* AND leave a comment \"CONFIRMED FOR: <RELEASE_NAME>\"\n  Only still supported release names are valid (LIBERTY, MITAKA, OCATA, NEWTON).\n  Valid example: CONFIRMED FOR: LIBERTY\n", 
            "date_created": "2016-07-05 09:45:56.165541+00:00", 
            "author": "https://api.launchpad.net/1.0/~mzoeller"
        }, 
        {
            "content": "GlusterFS driver is now being removed, so marking as Won't Fix.\n\nhttps://review.openstack.org/#/c/377028/", 
            "date_created": "2016-09-28 01:33:19.934193+00:00", 
            "author": "https://api.launchpad.net/1.0/~sean-mcginnis"
        }
    ], 
    "closed": "2016-07-05 09:45:53.007914+00:00"
}