{
    "status": "Invalid", 
    "last_updated": "2015-04-01 12:42:53.495040+00:00", 
    "description": "I want configured the PCI pass-through to assign the physical NIC to instance.\n\nI have two NICs with same type:\n04:00.0 Ethernet controller [0200]: Intel Corporation 82599EB 10-Gigabit SFP+ Network Connection [8086:154d] (rev 01)\n04:00.1 Ethernet controller [0200]: Intel Corporation 82599EB 10-Gigabit SFP+ Network Connection [8086:154d] (rev 01)\n\nI add below configuration into nova.conf on compute node:\npci_passthrough_whitelist=[{\"vendor_id\":\"8086\", \"product_id\":\"154d\"}]\n\nand add below configuration into nova.conf on controller node:\npci_alias={\"vendor_id\":\"8086\", \"product_id\":\"154d\", \"name\":\"a1\"}\n\nthen create flavor and set the extra spec:\nnova flavor-key test_flavor set \"pci_passthrough:alias\"=\"a1:1\"\n\nAfter that, I launch the first instance using the test_flavor, it succeed.\n\nHowever, I launch the second instance also using the test_flavor, but it failed.\n\nThere is error log from scheduler.log, it said that the device is already in use.\nI found that when launch the second instance, nova still assign the first NIC which has been already assigned to the first instance to the second instance. So it failed...\n\nI suppose this maybe a bug of nova, or could be resolved by configuration. ---Anyway, need your confirmation!\n\nBelow is the error log for reference:\n2013-12-05 05:21:10.522 6109 ERROR nova.scheduler.filter_scheduler [req-6abe0403-36fe-4d24-9852-9436fbf75331 c7095324d1fe439e8c9f350a71690388 92a596418bac4d3a901f1956fbed4463] [instance: 8dcb7465-080b-4bb6-bcd6-d228ca17e5fd] Error from last host: lng-compute-1 (node lng-compute-1): [u'Traceback (most recent call last):\\n', u' File \"/usr/lib/python2.6/site-packages/nova/compute/manager.py\", line 1037, in _build_instance\\n set_access_ip=set_access_ip)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/compute/manager.py\", line 1410, in _spawn\\n LOG.exception(_(\\'Instance failed to spawn\\'), instance=instance)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/compute/manager.py\", line 1407, in _spawn\\n block_device_info)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/virt/libvirt/driver.py\", line 2070, in spawn\\n block_device_info, context=context)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/virt/libvirt/driver.py\", line 3205, in _create_domain_and_network\\n domain = self._create_domain(xml, instance=instance, power_on=power_on)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/virt/libvirt/driver.py\", line 3148, in _create_domain\\n domain.XMLDesc(0))\\n', u' File \"/usr/lib/python2.6/site-packages/nova/virt/libvirt/driver.py\", line 3143, in _create_domain\\n domain.createWithFlags(launch_flags)\\n', u' File \"/usr/lib/python2.6/site-packages/eventlet/tpool.py\", line 187, in doit\\n result = proxy_call(self._autowrap, f, *args, **kwargs)\\n', u' File \"/usr/lib/python2.6/site-packages/eventlet/tpool.py\", line 147, in proxy_call\\n rv = execute(f,*args,**kwargs)\\n', u' File \"/usr/lib/python2.6/site-packages/eventlet/tpool.py\", line 76, in tworker\\n rv = meth(*args,**kwargs)\\n', u' File \"/usr/lib64/python2.6/site-packages/libvirt.py\", line 708, in createWithFlags\\n if ret == -1: raise libvirtError (\\'virDomainCreateWithFlags() failed\\', dom=self)\\n', u'libvirtError: Requested operation is not valid: PCI device 0000:04:00.0 is in use by domain instance-00000010\\n']", 
    "tags": [
        "libvirt", 
        "pci-passthrough"
    ], 
    "importance": "Undecided", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1261256", 
    "owner": "None", 
    "id": 1261256, 
    "index": 5652, 
    "openned": "2013-12-16 02:47:28.770646+00:00", 
    "created": "2013-12-16 02:47:28.770646+00:00", 
    "title": "Cannot assign 2 same type PCI passthrough devices to 2 instances separately", 
    "comments": [
        {
            "content": "I want configured the PCI pass-through to assign the physical NIC to instance.\n\nI have two NICs with same type:\n04:00.0 Ethernet controller [0200]: Intel Corporation 82599EB 10-Gigabit SFP+ Network Connection [8086:154d] (rev 01)\n04:00.1 Ethernet controller [0200]: Intel Corporation 82599EB 10-Gigabit SFP+ Network Connection [8086:154d] (rev 01)\n\nI add below configuration into nova.conf on compute node:\npci_passthrough_whitelist=[{\"vendor_id\":\"8086\", \"product_id\":\"154d\"}]\n\nand add below configuration into nova.conf on controller node:\npci_alias={\"vendor_id\":\"8086\", \"product_id\":\"154d\", \"name\":\"a1\"}\n\nthen create flavor and set the extra spec:\nnova flavor-key test_flavor set \"pci_passthrough:alias\"=\"a1:1\"\n\nAfter that, I launch the first instance using the test_flavor, it succeed.\n\nHowever, I launch the second instance also using the test_flavor, but it failed.\n\nThere is error log from scheduler.log, it said that the device is already in use.\nI found that when launch the second instance, nova still assign the first NIC which has been already assigned to the first instance to the second instance. So it failed...\n\nI suppose this maybe a bug of nova, or could be resolved by configuration. ---Anyway, need your confirmation!\n\nBelow is the error log for reference:\n2013-12-05 05:21:10.522 6109 ERROR nova.scheduler.filter_scheduler [req-6abe0403-36fe-4d24-9852-9436fbf75331 c7095324d1fe439e8c9f350a71690388 92a596418bac4d3a901f1956fbed4463] [instance: 8dcb7465-080b-4bb6-bcd6-d228ca17e5fd] Error from last host: lng-compute-1 (node lng-compute-1): [u'Traceback (most recent call last):\\n', u' File \"/usr/lib/python2.6/site-packages/nova/compute/manager.py\", line 1037, in _build_instance\\n set_access_ip=set_access_ip)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/compute/manager.py\", line 1410, in _spawn\\n LOG.exception(_(\\'Instance failed to spawn\\'), instance=instance)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/compute/manager.py\", line 1407, in _spawn\\n block_device_info)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/virt/libvirt/driver.py\", line 2070, in spawn\\n block_device_info, context=context)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/virt/libvirt/driver.py\", line 3205, in _create_domain_and_network\\n domain = self._create_domain(xml, instance=instance, power_on=power_on)\\n', u' File \"/usr/lib/python2.6/site-packages/nova/virt/libvirt/driver.py\", line 3148, in _create_domain\\n domain.XMLDesc(0))\\n', u' File \"/usr/lib/python2.6/site-packages/nova/virt/libvirt/driver.py\", line 3143, in _create_domain\\n domain.createWithFlags(launch_flags)\\n', u' File \"/usr/lib/python2.6/site-packages/eventlet/tpool.py\", line 187, in doit\\n result = proxy_call(self._autowrap, f, *args, **kwargs)\\n', u' File \"/usr/lib/python2.6/site-packages/eventlet/tpool.py\", line 147, in proxy_call\\n rv = execute(f,*args,**kwargs)\\n', u' File \"/usr/lib/python2.6/site-packages/eventlet/tpool.py\", line 76, in tworker\\n rv = meth(*args,**kwargs)\\n', u' File \"/usr/lib64/python2.6/site-packages/libvirt.py\", line 708, in createWithFlags\\n if ret == -1: raise libvirtError (\\'virDomainCreateWithFlags() failed\\', dom=self)\\n', u'libvirtError: Requested operation is not valid: PCI device 0000:04:00.0 is in use by domain instance-00000010\\n']", 
            "date_created": "2013-12-16 02:47:28.770646+00:00", 
            "author": "https://api.launchpad.net/1.0/~ryan-yi-liu"
        }, 
        {
            "content": "I think this should be a bug.\nBecause after I started the first instance, I found the 'status'  value of table pci_devices in mysql nova was not correct. It was still 'available', it should be 'allocated' ! --- I think that's why when start the second instance, nova still assign the same device.\n", 
            "date_created": "2013-12-17 09:53:50.172156+00:00", 
            "author": "https://api.launchpad.net/1.0/~ryan-yi-liu"
        }, 
        {
            "content": "Hi, Yi liu\ncan you give more details, for example : if the stats in DB is \" allocated\" ?  \nyou can use the api patch:  https://review.openstack.org/#/q/status:open+project:openstack/nova+branch:master+topic:bp/pci-api-support,n,z", 
            "date_created": "2014-01-02 08:28:35.784602+00:00", 
            "author": "https://api.launchpad.net/1.0/~shuangtai-tian"
        }, 
        {
            "content": "Hi Shuangtai,\nThank you for your reply.\nHowever, I have reinstalled my environment, then the issue didn't reproduced...\nIf I met the problem again, I will provide you more information.", 
            "date_created": "2014-01-10 08:45:47.897760+00:00", 
            "author": "https://api.launchpad.net/1.0/~ryan-yi-liu"
        }, 
        {
            "content": "sounds like we need some digging to work out what is going on here, incomplete", 
            "date_created": "2014-02-07 19:01:26.646979+00:00", 
            "author": "https://api.launchpad.net/1.0/~johngarbutt"
        }, 
        {
            "content": "currently set to non reproducable, closing for now. Please reopen if this problem happens again.", 
            "date_created": "2015-04-01 12:42:52.900693+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }
    ], 
    "closed": "2015-04-01 12:42:35.319053+00:00"
}