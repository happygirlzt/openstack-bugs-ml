{
    "status": "In Progress", 
    "last_updated": "2017-06-29 11:47:25.746519+00:00", 
    "description": "Description\n===========\nI resize an instance and revert it, it works correctly, but when I resize this instance again, the instance set to error, and I check the compute log like below.\nI use the rbd backend, I think the reason should be like this, If instance use shared storage, revert resize will not delete the instance dir and files on destination host, this files owner is root, if resize the instance again and migrate to the same destination host, the IOError exception will be thrown.\n\nLogs\n==============\nTraceback (most recent call last):\n   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 3950, in finish_resize\n     disk_info, image_meta)\n   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 3915, in _finish_resize\n     old_instance_type)\n   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\n     self.force_reraise()\n   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n     six.reraise(self.type_, self.value, self.tb)\n   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 3910, in _finish_resize\n     block_device_info, power_on)\n   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 7223, in finish_migration\n     self._ensure_console_log_for_instance(instance)\n   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 2867, in _ensure_console_log_for_instance\n     libvirt_utils.file_open(console_file, 'a').close()\n   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/utils.py\", line 313, in file_open\n     return open(*args, **kwargs)\n IOError: [Errno 13] Permission denied: '/var/lib/nova/instances/c1c4847d-0470-4fae-9060-6511a8e2c056/console.log'", 
    "tags": [
        "ceph", 
        "live-migration", 
        "resize"
    ], 
    "importance": "Undecided", 
    "heat": 6, 
    "link": "https://bugs.launchpad.net/nova/+bug/1694913", 
    "owner": "https://api.launchpad.net/1.0/~falseuser", 
    "id": 1694913, 
    "index": 8141, 
    "openned": "2017-06-01 07:23:16.138980+00:00", 
    "created": "2017-06-01 07:23:16.138980+00:00", 
    "title": "revert a resize task and resize again or live migration will fail when use rbd", 
    "comments": [
        {
            "content": "Description\n===========\nI resize an instance and revert it, it works correctly, but when I resize this instance again, the instance set to error, and I check the compute log like below.\nI use the rbd backend, I think the reason should be like this, If instance use shared storage, revert resize will not delete the instance dir and files on destination host, this files owner is root, if resize the instance again and migrate to the same destination host, the IOError exception will be thrown.\n\nLogs\n==============\nTraceback (most recent call last):\n   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 3950, in finish_resize\n     disk_info, image_meta)\n   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 3915, in _finish_resize\n     old_instance_type)\n   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\n     self.force_reraise()\n   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\n     six.reraise(self.type_, self.value, self.tb)\n   File \"/usr/lib/python2.7/site-packages/nova/compute/manager.py\", line 3910, in _finish_resize\n     block_device_info, power_on)\n   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 7223, in finish_migration\n     self._ensure_console_log_for_instance(instance)\n   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/driver.py\", line 2867, in _ensure_console_log_for_instance\n     libvirt_utils.file_open(console_file, 'a').close()\n   File \"/usr/lib/python2.7/site-packages/nova/virt/libvirt/utils.py\", line 313, in file_open\n     return open(*args, **kwargs)\n IOError: [Errno 13] Permission denied: '/var/lib/nova/instances/c1c4847d-0470-4fae-9060-6511a8e2c056/console.log'", 
            "date_created": "2017-06-01 07:23:16.138980+00:00", 
            "author": "https://api.launchpad.net/1.0/~falseuser"
        }, 
        {
            "content": "On which release is this happening? I believe the console.log ownership issue has been fixed in newer releases.", 
            "date_created": "2017-06-01 13:16:43.373590+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "See https://review.openstack.org/#/c/392643/ and https://review.openstack.org/#/c/466088/ - do you have those fixes?", 
            "date_created": "2017-06-01 13:18:07.711658+00:00", 
            "author": "https://api.launchpad.net/1.0/~mriedem"
        }, 
        {
            "content": "Thanks, I found this in Newton, those above commits can solve my problem, and why we do not directly delete the instance files and path on destination host after revert a resize task?\n", 
            "date_created": "2017-06-02 10:24:31.163712+00:00", 
            "author": "https://api.launchpad.net/1.0/~falseuser"
        }, 
        {
            "content": "It is need to delete the instance files and path on destination host after revert a resize task, I try a live migration after revert a resize task when use rbd, and I see the error log like below\n\n\n\nLogs\n=====================================\nERROR oslo_messaging.rpc.server [None req-77b787e3-f885-4783-a4bc-f60a1491d1cc admin admin] Exception during message handling: DestinationDiskExists: The supplied disk path (/opt/stack/data/nova/instances/44721008-5a73-43e6-8c91-3d31d88f93d2) already exists, it is expected not to exist.\nERROR oslo_messaging.rpc.server Traceback (most recent call last):\nERROR oslo_messaging.rpc.server   File \"/usr/lib/python2.7/site-packages/oslo_messaging/rpc/server.py\", line 157, in _process_incoming\nERROR oslo_messaging.rpc.server     res = self.dispatcher.dispatch(message)\nERROR oslo_messaging.rpc.server   File \"/usr/lib/python2.7/site-packages/oslo_messaging/rpc/dispatcher.py\", line 213, in dispatch\nERROR oslo_messaging.rpc.server     return self._do_dispatch(endpoint, method, ctxt, args)\nERROR oslo_messaging.rpc.server   File \"/usr/lib/python2.7/site-packages/oslo_messaging/rpc/dispatcher.py\", line 183, in _do_dispatch\nERROR oslo_messaging.rpc.server     result = func(ctxt, **new_args)\nERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/exception_wrapper.py\", line 77, in wrapped\nERROR oslo_messaging.rpc.server     function_name, call_dict, binary)\nERROR oslo_messaging.rpc.server   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\nERROR oslo_messaging.rpc.server     self.force_reraise()\nERROR oslo_messaging.rpc.server   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\nERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\nERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/exception_wrapper.py\", line 68, in wrapped\nERROR oslo_messaging.rpc.server     return f(self, context, *args, **kw)\nERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/utils.py\", line 690, in decorated_function\nERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)\nERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 214, in decorated_function\nERROR oslo_messaging.rpc.server     kwargs['instance'], e, sys.exc_info())\nERROR oslo_messaging.rpc.server   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 220, in __exit__\nERROR oslo_messaging.rpc.server     self.force_reraise()\nERROR oslo_messaging.rpc.server   File \"/usr/lib/python2.7/site-packages/oslo_utils/excutils.py\", line 196, in force_reraise\nERROR oslo_messaging.rpc.server     six.reraise(self.type_, self.value, self.tb)\nERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 202, in decorated_function\nERROR oslo_messaging.rpc.server     return function(self, context, *args, **kwargs)\nERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/compute/manager.py\", line 5362, in pre_live_migration\nERROR oslo_messaging.rpc.server     migrate_data)\nERROR oslo_messaging.rpc.server   File \"/opt/stack/nova/nova/virt/libvirt/driver.py\", line 6791, in pre_live_migration\nERROR oslo_messaging.rpc.server     raise exception.DestinationDiskExists(path=instance_dir)\nERROR oslo_messaging.rpc.server DestinationDiskExists: The supplied disk path (/opt/stack/data/nova/instances/44721008-5a73-43e6-8c91-3d31d88f93d2) already exists, it is expected not to exist.\nERROR oslo_messaging.rpc.server ", 
            "date_created": "2017-06-05 09:17:00.024759+00:00", 
            "author": "https://api.launchpad.net/1.0/~falseuser"
        }, 
        {
            "content": "I found this in Pike (devstack-master), and do live migration again will succeed", 
            "date_created": "2017-06-05 09:18:34.859449+00:00", 
            "author": "https://api.launchpad.net/1.0/~falseuser"
        }, 
        {
            "content": "There are no currently open reviews on this bug, changing the status back to the previous state and unassigning. If there are active reviews related to this bug, please include links in comments. ", 
            "date_created": "2017-06-27 19:27:55.486181+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }, 
        {
            "content": "Found open reviews for this bug in gerrit, setting to In Progress. \n\nreview: https://review.openstack.org/469814 in branch: master\n", 
            "date_created": "2017-06-29 11:47:25.164778+00:00", 
            "author": "https://api.launchpad.net/1.0/~sdague"
        }
    ]
}