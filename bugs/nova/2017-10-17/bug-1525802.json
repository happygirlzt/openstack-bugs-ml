{
    "status": "Invalid", 
    "last_updated": "2016-02-22 09:33:04.366955+00:00", 
    "description": "Hello,\n\nWhen issuing a live migration between kvm nodes having multipath cinder volume it sometimes hangs and causes qemu-kvm to crash, the only solution is a restart of the kvm node.\n\nSometimes when live migrating you get stuck when it tries to migrate the active RAM, you will see something like this in the nova-compute.log:\nhttp://paste.openstack.org/show/481773/\n\nAs you can see it get's nowhere.\nWhat is happening in the backgroun is that for some reason the multipath volumes when viewing with 'multipath -ll' they go into a 'faulty running' state and causes issues with the block device causing the qemu-kvm process to hang, the kvm node also tries to run blkid and kpart but all of those hang, which means you can get 100+ load just for those stuck processes.\n\n[1015086.978188] end_request: I/O error, dev sdg, sector 41942912\n[1015086.978398] device-mapper: multipath: Failing path 8:96.\n[1015088.547034] qbr8eff45f7-ed: port 1(qvb8eff45f7-ed) entered disabled state\n[1015088.791695] INFO: task qemu-system-x86:19383 blocked for more than 120 seconds.\n[1015088.791940]       Tainted: P           OX 3.13.0-68-generic #111-Ubuntu\n[1015088.792147] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\n[1015088.792396] qemu-system-x86 D ffff88301f2f3180     0 19383      1 0x00000000\n[1015088.792404]  ffff8817440ada88 0000000000000086 ffff8817fa574800 ffff8817440adfd8\n[1015088.792414]  0000000000013180 0000000000013180 ffff8817fa574800 ffff88301f2f3a18\n[1015088.792420]  0000000000000000 ffff882ff7ab5280 0000000000000000 ffff8817fa574800\n[1015088.792426] Call Trace:\n[1015088.792440]  [<ffffffff8172880d>] io_schedule+0x9d/0x140\n[1015088.792449]  [<ffffffff811fc304>] do_blockdev_direct_IO+0x1ce4/0x2910\n[1015088.792456]  [<ffffffff811f7170>] ? I_BDEV+0x10/0x10\n[1015088.792462]  [<ffffffff811fcf85>] __blockdev_direct_IO+0x55/0x60\n[1015088.792467]  [<ffffffff811f7170>] ? I_BDEV+0x10/0x10\n[1015088.792472]  [<ffffffff811f7866>] blkdev_direct_IO+0x56/0x60\n[1015088.792476]  [<ffffffff811f7170>] ? I_BDEV+0x10/0x10\n[1015088.792482]  [<ffffffff81150ce1>] generic_file_direct_write+0xc1/0x180\n[1015088.792487]  [<ffffffff811510a5>] __generic_file_aio_write+0x305/0x3d0\n[1015088.792492]  [<ffffffff811f8146>] blkdev_aio_write+0x46/0x90\n[1015088.792501]  [<ffffffff811bdc2a>] do_sync_write+0x5a/0x90\n[1015088.792507]  [<ffffffff811be3b4>] vfs_write+0xb4/0x1f0\n[1015088.792512]  [<ffffffff811bef62>] SyS_pwrite64+0x72/0xb0\n[1015088.792519]  [<ffffffff81734cdd>] system_call_fastpath+0x1a/0x1f\n\nroot     19410  0.0  0.0      0     0 ?        D    08:12   0:00 [blkid]\nroot     19575  0.0  0.0      0     0 ?        D    08:13   0:00 [blkid]\nroot     19584  0.0  0.0  28276  1076 ?        S    08:13   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     21734  0.0  0.0  28276  1080 ?        D    08:15   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     21735  0.0  0.0  28276  1076 ?        S    08:15   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000ed\nroot     22419  0.0  0.0  28276  1076 ?        D    08:16   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000ed\nroot     22420  0.0  0.0  28276  1076 ?        D    08:16   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     22864  0.0  0.0  28276  1076 ?        D    08:16   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000ed\nroot     22865  0.0  0.0  28276  1076 ?        D    08:16   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     23316  0.0  0.0  28276  1076 ?        D    08:17   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     23317  0.0  0.0  28276  1072 ?        D    08:17   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000ed\nroot     23756  0.0  0.0  28276  1076 ?        D    08:17   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     24200  0.0  0.0  28276  1076 ?        D    08:18   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     24637  0.0  0.0  28276  1072 ?        D    08:18   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     25058  0.0  0.0  28276  1076 ?        D    08:19   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot@kvm3:~# \n\nUltimately this will cause so much issues on your kvm node that the only fix is a restart because of all the libvirt locks you won't be able to stop, restart or destroy the qemu-kvm process and issuing a kill -9 won't help you either, the only solution is a restart.\n\nWhat will happen is that your live migration will fail with something like this.\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [req-99771cf6-d17e-49f7-a01d-38201afbce69 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Live migration failed.\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Traceback (most recent call last):\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 5108, in _do_live_migration\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     block_migration, migrate_data)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5431, in live_migration\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     migrate_data)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6071, in _live_migration\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     dom, finish_event)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5919, in _live_migration_monitor\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     dom.abortJob()\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 183, in doit\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 141, in proxy_call\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     rv = execute(f, *args, **kwargs)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 122, in execute\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     six.reraise(c, e, tb)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 80, in tworker\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     rv = meth(*args, **kwargs)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 482, in abortJob\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     if ret == -1: raise libvirtError ('virDomainAbortJob() failed', dom=self)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] libvirtError: Timed out during operation: cannot acquire state change lock (held by remoteDispatchDomainMigratePerform3)\n\nI'm not sure if this is the same bug as https://bugs.launchpad.net/nova/+bug/1419577 but I want to make sure to bring some light into this area since this affect our operations very much.\n\nBest regards", 
    "tags": [
        "cinder", 
        "live-migration", 
        "multipath"
    ], 
    "importance": "Undecided", 
    "heat": 16, 
    "link": "https://bugs.launchpad.net/nova/+bug/1525802", 
    "owner": "None", 
    "id": 1525802, 
    "index": 7174, 
    "openned": "2015-12-14 07:37:58.261175+00:00", 
    "created": "2015-12-14 07:37:58.261175+00:00", 
    "title": "live migration with multipath cinder volumes crashes node", 
    "comments": [
        {
            "content": "Hello,\n\nWhen issuing a live migration between kvm nodes having multipath cinder volume it sometimes hangs and causes qemu-kvm to crash, the only solution is a restart of the kvm node.\n\nSometimes when live migrating you get stuck when it tries to migrate the active RAM, you will see something like this in the nova-compute.log:\nhttp://paste.openstack.org/show/481773/\n\nAs you can see it get's nowhere.\nWhat is happening in the backgroun is that for some reason the multipath volumes when viewing with 'multipath -ll' they go into a 'faulty running' state and causes issues with the block device causing the qemu-kvm process to hang, the kvm node also tries to run blkid and kpart but all of those hang, which means you can get 100+ load just for those stuck processes.\n\n[1015086.978188] end_request: I/O error, dev sdg, sector 41942912\n[1015086.978398] device-mapper: multipath: Failing path 8:96.\n[1015088.547034] qbr8eff45f7-ed: port 1(qvb8eff45f7-ed) entered disabled state\n[1015088.791695] INFO: task qemu-system-x86:19383 blocked for more than 120 seconds.\n[1015088.791940]       Tainted: P           OX 3.13.0-68-generic #111-Ubuntu\n[1015088.792147] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\n[1015088.792396] qemu-system-x86 D ffff88301f2f3180     0 19383      1 0x00000000\n[1015088.792404]  ffff8817440ada88 0000000000000086 ffff8817fa574800 ffff8817440adfd8\n[1015088.792414]  0000000000013180 0000000000013180 ffff8817fa574800 ffff88301f2f3a18\n[1015088.792420]  0000000000000000 ffff882ff7ab5280 0000000000000000 ffff8817fa574800\n[1015088.792426] Call Trace:\n[1015088.792440]  [<ffffffff8172880d>] io_schedule+0x9d/0x140\n[1015088.792449]  [<ffffffff811fc304>] do_blockdev_direct_IO+0x1ce4/0x2910\n[1015088.792456]  [<ffffffff811f7170>] ? I_BDEV+0x10/0x10\n[1015088.792462]  [<ffffffff811fcf85>] __blockdev_direct_IO+0x55/0x60\n[1015088.792467]  [<ffffffff811f7170>] ? I_BDEV+0x10/0x10\n[1015088.792472]  [<ffffffff811f7866>] blkdev_direct_IO+0x56/0x60\n[1015088.792476]  [<ffffffff811f7170>] ? I_BDEV+0x10/0x10\n[1015088.792482]  [<ffffffff81150ce1>] generic_file_direct_write+0xc1/0x180\n[1015088.792487]  [<ffffffff811510a5>] __generic_file_aio_write+0x305/0x3d0\n[1015088.792492]  [<ffffffff811f8146>] blkdev_aio_write+0x46/0x90\n[1015088.792501]  [<ffffffff811bdc2a>] do_sync_write+0x5a/0x90\n[1015088.792507]  [<ffffffff811be3b4>] vfs_write+0xb4/0x1f0\n[1015088.792512]  [<ffffffff811bef62>] SyS_pwrite64+0x72/0xb0\n[1015088.792519]  [<ffffffff81734cdd>] system_call_fastpath+0x1a/0x1f\n\nroot     19410  0.0  0.0      0     0 ?        D    08:12   0:00 [blkid]\nroot     19575  0.0  0.0      0     0 ?        D    08:13   0:00 [blkid]\nroot     19584  0.0  0.0  28276  1076 ?        S    08:13   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     21734  0.0  0.0  28276  1080 ?        D    08:15   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     21735  0.0  0.0  28276  1076 ?        S    08:15   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000ed\nroot     22419  0.0  0.0  28276  1076 ?        D    08:16   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000ed\nroot     22420  0.0  0.0  28276  1076 ?        D    08:16   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     22864  0.0  0.0  28276  1076 ?        D    08:16   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000ed\nroot     22865  0.0  0.0  28276  1076 ?        D    08:16   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     23316  0.0  0.0  28276  1076 ?        D    08:17   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     23317  0.0  0.0  28276  1072 ?        D    08:17   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000ed\nroot     23756  0.0  0.0  28276  1076 ?        D    08:17   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     24200  0.0  0.0  28276  1076 ?        D    08:18   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     24637  0.0  0.0  28276  1072 ?        D    08:18   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     25058  0.0  0.0  28276  1076 ?        D    08:19   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot@kvm3:~# \n\nUltimately this will cause so much issues on your kvm node that the only fix is a restart because of all the libvirt locks you won't be able to stop, restart or destroy the qemu-kvm process and issuing a kill -9 won't help you either, the only solution is a restart.\n\nWhat will happen is that your live migration will fail with something like this.\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [req-99771cf6-d17e-49f7-a01d-38201afbce69 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Live migration failed.\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Traceback (most recent call last):\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 5108, in _do_live_migration\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     block_migration, migrate_data)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5431, in live_migration\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     migrate_data)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6071, in _live_migration\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     dom, finish_event)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5919, in _live_migration_monitor\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     dom.abortJob()\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 183, in doit\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 141, in proxy_call\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     rv = execute(f, *args, **kwargs)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 122, in execute\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     six.reraise(c, e, tb)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 80, in tworker\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     rv = meth(*args, **kwargs)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 482, in abortJob\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2]     if ret == -1: raise libvirtError ('virDomainAbortJob() failed', dom=self)\n2015-12-14 08:19:51.577 23821 ERROR nova.compute.manager [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] libvirtError: Timed out during operation: cannot acquire state change lock (held by remoteDispatchDomainMigratePerform3)\n\nI'm not sure if this is the same bug as https://bugs.launchpad.net/nova/+bug/1419577 but I want to make sure to bring some light into this area since this affect our operations very much.\n\nBest regards", 
            "date_created": "2015-12-14 07:37:58.261175+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "Looks like this is happening after the instance has been migrated the paths for the multipath mapping goes down. Perhaps the devices is gone but the multipath device is still not cleaned?\n\nHere is when it's created and afterwards you can see it fail after a migration.\nThis happens on the source node after a migration so the migration can be successfull and the instance is running on another node but then the source node gets this problem.\n\nDec 14 10:51:51 kvm4 kernel: [244029.700264] sd 8:0:0:4: [sdi] 41943040 512-byte logical blocks: (21.4 GB/20.0 GiB)\nDec 14 10:51:51 kvm4 kernel: [244029.700270] sd 8:0:0:4: [sdi] 4096-byte physical blocks\nDec 14 10:51:51 kvm4 kernel: [244029.701240] sd 8:0:0:4: [sdi] Write Protect is off\nDec 14 10:51:51 kvm4 kernel: [244029.701247] sd 8:0:0:4: [sdi] Mode Sense: 8f 00 00 08\nDec 14 10:51:51 kvm4 kernel: [244029.701479] sd 8:0:0:4: [sdi] Write cache: disabled, read cache: enabled, doesn't support DPO or FUA\nDec 14 10:51:51 kvm4 kernel: [244029.704149]  sdi: sdi1\nDec 14 10:51:51 kvm4 kernel: [244029.706264] sd 8:0:0:4: [sdi] Attached SCSI disk\nDec 14 10:51:51 kvm4 multipathd: sdi: add path (uevent)\nDec 14 10:51:51 kvm4 multipathd: sdi: rport id not found\nDec 14 10:51:51 kvm4 multipathd: sdi path added to devmap 36000d31000a6500000000000000000c6\n\nDec 14 11:19:47 kvm4 multipathd: 36000d31000a6500000000000000000c6: sdh - tur checker reports path is down\nDec 14 11:19:47 kvm4 multipathd: 36000d31000a6500000000000000000c6: sdi - tur checker reports path is down\nDec 14 11:19:52 kvm4 multipathd: 36000d31000a6500000000000000000c6: sdh - tur checker reports path is down\nDec 14 11:19:52 kvm4 multipathd: 36000d31000a6500000000000000000c6: sdi - tur checker reports path is down\nDec 14 11:19:57 kvm4 multipathd: 36000d31000a6500000000000000000c6: sdh - tur checker reports path is down\nDec 14 11:19:57 kvm4 multipathd: 36000d31000a6500000000000000000c6: sdi - tur checker reports path is down\nDec 14 11:20:02 kvm4 multipathd: 36000d31000a6500000000000000000c6: sdh - tur checker reports path is down\nDec 14 11:20:02 kvm4 multipathd: 36000d31000a6500000000000000000c6: sdi - tur checker reports path is down\n\n36000d31000a6500000000000000000c6 dm-14 COMPELNT,Compellent Vol  \nsize=20G features='1 queue_if_no_path' hwhandler='0' wp=rw\n`-+- policy='round-robin 0' prio=0 status=enabled\n  |- 7:0:0:4 sdh   8:112  failed faulty running\n  `- 8:0:0:4 sdi   8:128  failed faulty running\n\n36000d31000a6500000000000000000ec dm-2 ,\nsize=20G features='1 queue_if_no_path' hwhandler='0' wp=rw\n`-+- policy='round-robin 0' prio=0 status=enabled\n  `- #:#:#:# -     #:#    failed faulty running\n\nI can't really do much troubleshooting since the nodes get 100+ load so a restart is required like before.\n\nroot     11196  0.0  0.0      0     0 ?        D    11:04   0:00 [blkid]\nroot     11204  0.0  0.0  28276  1076 ?        S    11:04   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000c6\nroot     11382  0.0  0.0      0     0 ?        D    11:04   0:00 [blkid]\nroot     11404  0.0  0.0      0     0 ?        D    11:04   0:00 [blkid]\nroot     11411  0.0  0.0      0     0 ?        D    11:04   0:00 [blkid]\nroot     11422  0.0  0.0      0     0 ?        D    11:04   0:00 [blkid]\nroot     11426  0.0  0.0      0     0 ?        D    11:04   0:00 [blkid]\nroot     11429  0.0  0.0      0     0 ?        D    11:04   0:00 [blkid]\nroot     11433  0.0  0.0      0     0 ?        D    11:04   0:00 [blkid]\n\n[244798.903420] sd 7:0:0:3: Warning! Received an indication that the LUN assignments on this target have changed. The Linux SCSI layer does not automatically remap LUN assignments.\n[244801.537704] device-mapper: multipath: Failing path 8:112.\n[244801.538281] device-mapper: multipath: Failing path 8:128.\n[244811.858193] device-mapper: multipath: Failing path 8:32.\n[245035.457529] INFO: task qemu-system-x86:11340 blocked for more than 120 seconds.\n[245035.457775]       Tainted: P           OX 3.13.0-71-generic #114-Ubuntu\n[245035.457982] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\n[245035.458230] qemu-system-x86 D ffff88301f2f3180     0 11340      1 0x00000000\n[245035.458238]  ffff881563643a88 0000000000000082 ffff8817df7f8000 ffff881563643fd8\n[245035.458248]  0000000000013180 0000000000013180 ffff8817df7f8000 ffff88301f2f3a18\n[245035.458254]  0000000000000000 ffff882ff7a60c80 0000000000000000 ffff8817df7f8000\n[245035.458260] Call Trace:\n[245035.458274]  [<ffffffff81728f8d>] io_schedule+0x9d/0x140\n[245035.458282]  [<ffffffff811fc364>] do_blockdev_direct_IO+0x1ce4/0x2910\n[245035.458289]  [<ffffffff811f71d0>] ? I_BDEV+0x10/0x10\n[245035.458295]  [<ffffffff811fcfe5>] __blockdev_direct_IO+0x55/0x60\n[245035.458300]  [<ffffffff811f71d0>] ? I_BDEV+0x10/0x10\n[245035.458305]  [<ffffffff811f78c6>] blkdev_direct_IO+0x56/0x60\n[245035.458309]  [<ffffffff811f71d0>] ? I_BDEV+0x10/0x10\n[245035.458316]  [<ffffffff81150db1>] generic_file_direct_write+0xc1/0x180\n[245035.458321]  [<ffffffff81151175>] __generic_file_aio_write+0x305/0x3d0\n[245035.458326]  [<ffffffff811f81a6>] blkdev_aio_write+0x46/0x90\n[245035.458335]  [<ffffffff811bdcea>] do_sync_write+0x5a/0x90\n[245035.458340]  [<ffffffff811be474>] vfs_write+0xb4/0x1f0\n[245035.458346]  [<ffffffff811bf022>] SyS_pwrite64+0x72/0xb0\n[245035.458353]  [<ffffffff8173545d>] system_call_fastpath+0x1a/0x1f\n", 
            "date_created": "2015-12-14 10:27:22.478375+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "OpenStack Liberty on Ubuntu 14.04.2 LTS\n\nroot@kvm1:~# dpkg -l | grep -Ei \"qemu|kvm|cinder|nova|libvirt|virt\"\nii  cinder-common                       2:7.0.0-0ubuntu1~cloud0               all          Cinder storage service - common files\nii  cinder-volume                       2:7.0.0-0ubuntu1~cloud0               all          Cinder storage service - Volume server\nii  ipxe-qemu                           1.0.0+git-20131111.c3d1e78-2ubuntu1.1 all          PXE boot firmware - ROM images for qemu\nii  libvirt-bin                         1.2.16-2ubuntu11~cloud0               amd64        programs for the libvirt library\nii  libvirt0                            1.2.16-2ubuntu11~cloud0               amd64        library for interfacing with different virtualization systems\nii  neutron-common                      2:7.0.0-0ubuntu1~cloud0               all          Neutron is a virtual network service for Openstack - common\nii  neutron-plugin-ml2                  2:7.0.0-0ubuntu1~cloud0               all          Neutron is a virtual network service for Openstack - ML2 plugin\nii  neutron-plugin-openvswitch-agent    2:7.0.0-0ubuntu1~cloud0               all          Neutron is a virtual network service for Openstack - Open vSwitch plugin agent\nii  nova-common                         2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute - common files\nii  nova-compute                        2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute - compute node base\nii  nova-compute-kvm                    2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute - compute node (KVM)\nii  nova-compute-libvirt                2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute - compute node libvirt support\nii  python-cinder                       2:7.0.0-0ubuntu1~cloud0               all          Cinder Python libraries\nii  python-cinderclient                 1:1.4.0-2~cloud0                      all          Python bindings to the OpenStack Volume API - Python 2.x\nii  python-libvirt                      1.2.2-0ubuntu2                        amd64        libvirt Python bindings\nii  python-neutron                      2:7.0.0-0ubuntu1~cloud0               all          Neutron is a virtual network service for Openstack - Python library\nii  python-nova                         2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute Python libraries\nii  python-novaclient                   2:2.30.1-1~cloud0                     all          client library for OpenStack Compute API\nii  qemu-block-extra:amd64              1:2.3+dfsg-5ubuntu9~cloud0            amd64        extra block backend modules for qemu-system and qemu-utils\nii  qemu-slof                           20140630+dfsg-1ubuntu1~14.04          all          Slimline Open Firmware -- QEMU PowerPC version\nii  qemu-system                         1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries\nii  qemu-system-arm                     1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (arm)\nii  qemu-system-common                  1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (common files)\nii  qemu-system-mips                    1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (mips)\nii  qemu-system-misc                    1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (miscelaneous)\nii  qemu-system-ppc                     1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (ppc)\nii  qemu-system-sparc                   1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (sparc)\nii  qemu-system-x86                     1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (x86)\nii  qemu-utils                          1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU utilities\nii  virt-top                            1.0.7-1                               amd64        show stats of virtualized domains", 
            "date_created": "2015-12-14 14:53:47.547813+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "Better format: http://paste.openstack.org/show/481815/", 
            "date_created": "2015-12-14 14:54:24.194783+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "Sorry forgot libvirt... http://paste.openstack.org/show/481816/", 
            "date_created": "2015-12-14 14:55:16.676400+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "Posting the pastebin content (from description and comment #3, as they expire.)\n\nPastebin content from comment#1:\n----------------------------------------\n2015-12-14 08:17:22.404 23821 INFO nova.virt.libvirt.driver [req-99771cf6-d17e-49f7-a01d-38201afbce69 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Data remaining 19734528 bytes, low watermark 0 bytes 30 seconds ago\n2015-12-14 08:17:53.509 23821 INFO nova.virt.libvirt.driver [req-99771cf6-d17e-49f7-a01d-38201afbce69 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Migration running for 60 secs, memory 0% remaining; (bytes processed=2014039380, remaining=19734528, total=2156732416)\n2015-12-14 08:17:53.510 23821 INFO nova.virt.libvirt.driver [req-99771cf6-d17e-49f7-a01d-38201afbce69 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Data remaining 19734528 bytes, low watermark 0 bytes 62 seconds ago\n2015-12-14 08:18:24.704 23821 INFO nova.virt.libvirt.driver [req-99771cf6-d17e-49f7-a01d-38201afbce69 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Migration running for 90 secs, memory 0% remaining; (bytes processed=2014039380, remaining=19734528, total=2156732416)\n2015-12-14 08:18:24.705 23821 INFO nova.virt.libvirt.driver [req-99771cf6-d17e-49f7-a01d-38201afbce69 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Data remaining 19734528 bytes, low watermark 0 bytes 93 seconds ago\n2015-12-14 08:18:55.772 23821 INFO nova.virt.libvirt.driver [req-99771cf6-d17e-49f7-a01d-38201afbce69 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Migration running for 120 secs, memory 0% remaining; (bytes processed=2014039380, remaining=19734528, total=2156732416)\n2015-12-14 08:18:55.773 23821 INFO nova.virt.libvirt.driver [req-99771cf6-d17e-49f7-a01d-38201afbce69 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: babf696c-55d1-4bde-be83-3124be2ac7f2] Data remaining 19734528 bytes, low watermark 0 bytes 124 seconds ago\n----------------------------------------\n\nPastebin content from comment #3:\n----------------------------------------\nroot@kvm1:~# dpkg -l | grep -Ei \"qemu|kvm|cinder|nova\"\nii  cinder-common                       2:7.0.0-0ubuntu1~cloud0               all          Cinder storage service - common files\nii  cinder-volume                       2:7.0.0-0ubuntu1~cloud0               all          Cinder storage service - Volume server\nii  ipxe-qemu                           1.0.0+git-20131111.c3d1e78-2ubuntu1.1 all          PXE boot firmware - ROM images for qemu\nii  nova-common                         2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute - common files\nii  nova-compute                        2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute - compute node base\nii  nova-compute-kvm                    2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute - compute node (KVM)\nii  nova-compute-libvirt                2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute - compute node libvirt support\nii  python-cinder                       2:7.0.0-0ubuntu1~cloud0               all          Cinder Python libraries\nii  python-cinderclient                 1:1.4.0-2~cloud0                      all          Python bindings to the OpenStack Volume API - Python 2.x\nii  python-nova                         2:12.0.0-0ubuntu2~cloud0              all          OpenStack Compute Python libraries\nii  python-novaclient                   2:2.30.1-1~cloud0                     all          client library for OpenStack Compute API\nii  qemu-block-extra:amd64              1:2.3+dfsg-5ubuntu9~cloud0            amd64        extra block backend modules for qemu-system and qemu-utils\nii  qemu-slof                           20140630+dfsg-1ubuntu1~14.04          all          Slimline Open Firmware -- QEMU PowerPC version\nii  qemu-system                         1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries\nii  qemu-system-arm                     1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (arm)\nii  qemu-system-common                  1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (common files)\nii  qemu-system-mips                    1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (mips)\nii  qemu-system-misc                    1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (miscelaneous)\nii  qemu-system-ppc                     1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (ppc)\nii  qemu-system-sparc                   1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (sparc)\nii  qemu-system-x86                     1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU full system emulation binaries (x86)\nii  qemu-utils                          1:2.3+dfsg-5ubuntu9~cloud0            amd64        QEMU utilities\n----------------------------------------", 
            "date_created": "2015-12-14 14:57:30.706077+00:00", 
            "author": "https://api.launchpad.net/1.0/~kashyapc"
        }, 
        {
            "content": "From /var/log/libvirtd.log when this happended this morning\n2015-12-14 09:09:49.182+0000: 4875: error : virProcessKillPainfully:398 : Failed to terminate process 42798 with SIGKILL: Device or resource busy\n2015-12-14 09:09:49.224+0000: 4875: error : libxlConnectOpen:718 : internal error: libxenlight state driver is not active", 
            "date_created": "2015-12-14 15:10:14.677403+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "Had another one just now when trying to live migrate.\nThe below is from the source KVM host when trying to migrate to another one, now it complains about the paths.\n\n\n2015-12-15 08:07:57.404 35247 ERROR os_brick.initiator.connector [req-4ddb8cbf-d398-4abc-b8e3-4e12799b0f49 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] No accessible volume device: [u'/dev/disk/by-path/ip-192.168.101.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501f-lun-4', u'/dev/disk/by-path/ip-192.168.101.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501f-lun-2', u'/dev/disk/by-path/ip-192.168.102.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501e-lun-2', u'/dev/disk/by-path/ip-192.168.102.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501e-lun-4']\n2015-12-15 08:07:57.494 35247 WARNING nova.virt.libvirt.driver [req-4ddb8cbf-d398-4abc-b8e3-4e12799b0f49 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7] Error monitoring migration: Volume device not found at [u'/dev/disk/by-path/ip-192.168.101.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501f-lun-4', u'/dev/disk/by-path/ip-192.168.101.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501f-lun-2', u'/dev/disk/by-path/ip-192.168.102.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501e-lun-2', u'/dev/disk/by-path/ip-192.168.102.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501e-lun-4'].\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7] Traceback (most recent call last):\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6071, in _live_migration\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     dom, finish_event)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5996, in _live_migration_monitor\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     migrate_data)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 89, in wrapped\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     payload)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 195, in __exit__\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     six.reraise(self.type_, self.value, self.tb)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 72, in wrapped\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     return f(self, context, *args, **kw)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 378, in decorated_function\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     kwargs['instance'], e, sys.exc_info())\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 195, in __exit__\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     six.reraise(self.type_, self.value, self.tb)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 366, in decorated_function\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     return function(self, context, *args, **kwargs)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 5212, in _post_live_migration\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     migrate_data)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6392, in post_live_migration\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     self._disconnect_volume(connection_info, disk_dev)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 1049, in _disconnect_volume\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     driver.disconnect_volume(connection_info, disk_dev)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/volume/iscsi.py\", line 93, in disconnect_volume\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     self.connector.disconnect_volume(connection_info['data'], None)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py\", line 254, in inner\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     return f(*args, **kwargs)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/os_brick/initiator/connector.py\", line 565, in disconnect_volume\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     raise exception.VolumeDeviceNotFound(device=host_devices)\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7] VolumeDeviceNotFound: Volume device not found at [u'/dev/disk/by-path/ip-192.168.101.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501f-lun-4', u'/dev/disk/by-path/ip-192.168.101.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501f-lun-2', u'/dev/disk/by-path/ip-192.168.102.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501e-lun-2', u'/dev/disk/by-path/ip-192.168.102.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501e-lun-4'].\n2015-12-15 08:07:57.494 35247 ERROR nova.virt.libvirt.driver [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7] \n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [req-4ddb8cbf-d398-4abc-b8e3-4e12799b0f49 212f451de64b4ae89c853f1430510037 e47ebdf3f3934025b37df3b85bdfd565 - - -] [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7] Live migration failed.\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7] Traceback (most recent call last):\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 5108, in _do_live_migration\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     block_migration, migrate_data)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5431, in live_migration\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     migrate_data)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6071, in _live_migration\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     dom, finish_event)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5996, in _live_migration_monitor\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     migrate_data)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 89, in wrapped\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     payload)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 195, in __exit__\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     six.reraise(self.type_, self.value, self.tb)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 72, in wrapped\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     return f(self, context, *args, **kw)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 378, in decorated_function\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     kwargs['instance'], e, sys.exc_info())\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/oslo_utils/excutils.py\", line 195, in __exit__\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     six.reraise(self.type_, self.value, self.tb)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 366, in decorated_function\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     return function(self, context, *args, **kwargs)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 5212, in _post_live_migration\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     migrate_data)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6392, in post_live_migration\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     self._disconnect_volume(connection_info, disk_dev)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 1049, in _disconnect_volume\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     driver.disconnect_volume(connection_info, disk_dev)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/volume/iscsi.py\", line 93, in disconnect_volume\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     self.connector.disconnect_volume(connection_info['data'], None)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py\", line 254, in inner\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     return f(*args, **kwargs)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]   File \"/usr/lib/python2.7/dist-packages/os_brick/initiator/connector.py\", line 565, in disconnect_volume\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7]     raise exception.VolumeDeviceNotFound(device=host_devices)\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7] VolumeDeviceNotFound: Volume device not found at [u'/dev/disk/by-path/ip-192.168.101.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501f-lun-4', u'/dev/disk/by-path/ip-192.168.101.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501f-lun-2', u'/dev/disk/by-path/ip-192.168.102.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501e-lun-2', u'/dev/disk/by-path/ip-192.168.102.190:3260-iscsi-iqn.2002-03.com.compellent:5000d31000a6501e-lun-4'].\n2015-12-15 08:07:57.508 35247 ERROR nova.compute.manager [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7] \n2015-12-15 08:08:10.404 35247 INFO nova.compute.manager [-] [instance: 16ae0eb4-83fa-46c9-83da-88720af1bcf7] VM Stopped (Lifecycle Event)\n\n\nI can see this also:\n36000d31000a6500000000000000000cf dm-2 COMPELNT,Compellent Vol  \nsize=20G features='1 queue_if_no_path' hwhandler='0' wp=rw\n`-+- policy='round-robin 0' prio=0 status=enabled\n  |- 7:0:0:1 sdb   8:16   failed faulty running\n  `- 8:0:0:1 sdc   8:32   failed faulty running\n\nAnd some stuck processes:\n\nroot      2571  0.0  0.0      0     0 ?        D    08:07   0:00 [blkid]\nroot      2578  0.0  0.0  28276  1072 ?        S    08:07   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000cf\nroot      3148  0.0  0.0  28276  1076 ?        D    08:08   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000cf\nroot      3591  0.0  0.0  28276  1076 ?        D    08:08   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000cf\nroot      4161  0.0  0.0  28276  1072 ?        D    08:09   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000cf\nroot      4632  0.0  0.0  28276  1072 ?        D    08:09   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000cf\nroot      7992  0.0  0.0  28276  1076 ?        D    08:13   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000cf\nroot      8760  0.0  0.0  28276  1072 ?        D    08:13   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000cf\nroot      9215  0.0  0.0  28276  1080 ?        D    08:14   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000cf\nroot      9713  0.0  0.0  28276  1076 ?        D    08:14   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a6500000000000000000cf\n\n\nNothing special in the libvirt log except from some weird warnings I don't have a clue about.\n2015-12-15 06:37:09.891+0000: 4919: warning : AppArmorSetFDLabel:966 : could not find path for descriptor /proc/self/fd/27, skipping\n2015-12-15 06:38:08.630+0000: 4917: warning : AppArmorSetFDLabel:966 : could not find path for descriptor /proc/self/fd/27, skipping\n2015-12-15 07:07:18.581+0000: 4917: warning : AppArmorSetFDLabel:966 : could not find path for descriptor /proc/self/fd/32, skipping\n2015-12-15 07:07:51.610+0000: 4918: warning : AppArmorSetFDLabel:966 : could not find path for descriptor /proc/self/fd/32, skipping\n\ndmesg you can see that the kpart processes is stuck because it tries to use a mapper which is in the faulty running state.\n[70989.085387] INFO: task blkid:2571 blocked for more than 120 seconds.\n[70989.090582]       Tainted: P           OX 3.13.0-71-generic #114-Ubuntu\n[70989.095630] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\n[70989.105618] blkid           D ffff88301f2f3180     0  2571      1 0x00000006\n[70989.105627]  ffff882fa9255a48 0000000000000046 ffff882ff4620000 ffff882fa9255fd8\n[70989.105636]  0000000000013180 0000000000013180 ffff882ff4620000 ffff88301f2f3a18\n[70989.105642]  ffff88307ffe15e8 ffff882fa9255ad0 0000000000000002 ffffffff8114f540\n[70989.105648] Call Trace:\n[70989.105663]  [<ffffffff8114f540>] ? wait_on_page_read+0x60/0x60\n[70989.105670]  [<ffffffff81728f8d>] io_schedule+0x9d/0x140\n[70989.105677]  [<ffffffff8114f54e>] sleep_on_page+0xe/0x20\n[70989.105681]  [<ffffffff81729518>] __wait_on_bit_lock+0x48/0xb0\n[70989.105687]  [<ffffffff8114f65a>] __lock_page+0x6a/0x70\n[70989.105697]  [<ffffffff810ab420>] ? autoremove_wake_function+0x40/0x40\n[70989.105704]  [<ffffffff8115ede8>] truncate_inode_pages_range+0x348/0x5a0\n[70989.105713]  [<ffffffff811efd30>] ? mark_buffer_async_write+0x20/0x20\n[70989.105720]  [<ffffffff810dcc24>] ? on_each_cpu_cond+0xb4/0xe0\n[70989.105727]  [<ffffffff811f0ad0>] ? __brelse+0x40/0x40\n[70989.105733]  [<ffffffff8115f055>] truncate_inode_pages+0x15/0x20\n[70989.105739]  [<ffffffff811f7258>] kill_bdev+0x28/0x30\n[70989.105745]  [<ffffffff811f8844>] __blkdev_put+0x64/0x1a0\n[70989.105750]  [<ffffffff811f929e>] blkdev_put+0x4e/0x140\n[70989.105755]  [<ffffffff811f9445>] blkdev_close+0x25/0x30\n[70989.105763]  [<ffffffff811bffe4>] __fput+0xe4/0x260\n[70989.105769]  [<ffffffff811c01ae>] ____fput+0xe/0x10\n[70989.105777]  [<ffffffff810885bc>] task_work_run+0xac/0xd0\n[70989.105784]  [<ffffffff81069e28>] do_exit+0x2b8/0xa50\n[70989.105789]  [<ffffffff8106a63f>] do_group_exit+0x3f/0xa0\n[70989.105796]  [<ffffffff8107a3a0>] get_signal_to_deliver+0x1d0/0x6f0\n[70989.105806]  [<ffffffff81013458>] do_signal+0x48/0xa30\n[70989.105811]  [<ffffffff811f7d4b>] ? blkdev_aio_read+0x4b/0x70\n[70989.105817]  [<ffffffff81013ea9>] do_notify_resume+0x69/0xb0\n[70989.105823]  [<ffffffff8173571a>] int_signal+0x12/0x17\n\nIn the syslog it complains about the paths being down.\n\nDec 15 08:13:17 kvm4 multipathd: uevent trigger error\nDec 15 08:13:17 kvm4 kernel: [70953.747398] type=1400 audit(1450163597.767:46): apparmor=\"STATUS\" operation=\"profile_load\" profile=\"unconfined\" name=\"libvirt-16ae0eb4-83fa-46c9-83da-88720af1bcf7\" pid=8114 comm=\"apparmor_parser\"\nDec 15 08:13:17 kvm4 kernel: [70953.747787] type=1400 audit(1450163597.767:47): apparmor=\"STATUS\" operation=\"profile_load\" profile=\"unconfined\" name=\"qemu_bridge_helper\" pid=8114 comm=\"apparmor_parser\"\nDec 15 08:13:17 kvm4 kernel: [70953.819049] device tap21a4795a-9c entered promiscuous mode\nDec 15 08:13:17 kvm4 kernel: [70953.847217] qbr21a4795a-9c: port 2(tap21a4795a-9c) entered forwarding state\nDec 15 08:13:17 kvm4 kernel: [70953.847227] qbr21a4795a-9c: port 2(tap21a4795a-9c) entered forwarding state\nDec 15 08:13:17 kvm4 multipathd: message repeated 7 times: [ uevent trigger error]\nDec 15 08:13:17 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdb - tur checker reports path is down\nDec 15 08:13:17 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdc - tur checker reports path is down\nDec 15 08:13:16 kvm4 snmpd[5029]: message repeated 7085 times: [ error on subcontainer 'ia_addr' insert (-1)]\nDec 15 08:13:18 kvm4 snmpd[5029]: IfIndex of an interface changed. Such interfaces will appear multiple times in IF-MIB.\nDec 15 08:13:18 kvm4 kernel: [70954.529074] type=1400 audit(1450163598.547:48): apparmor=\"STATUS\" operation=\"profile_replace\" profile=\"unconfined\" name=\"libvirt-16ae0eb4-83fa-46c9-83da-88720af1bcf7\" pid=8239 comm=\"apparmor_parser\"\nDec 15 08:13:18 kvm4 kernel: [70954.544133] type=1400 audit(1450163598.563:49): apparmor=\"STATUS\" operation=\"profile_replace\" profile=\"unconfined\" name=\"qemu_bridge_helper\" pid=8239 comm=\"apparmor_parser\"\nDec 15 08:13:19 kvm4 kernel: [70955.238758] kvm: zapping shadow pages for mmio generation wraparound\nDec 15 08:13:22 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdb - tur checker reports path is down\nDec 15 08:13:22 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdc - tur checker reports path is down\nDec 15 08:13:27 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdb - tur checker reports path is down\nDec 15 08:13:27 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdc - tur checker reports path is down\nDec 15 08:13:32 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdb - tur checker reports path is down\nDec 15 08:13:32 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdc - tur checker reports path is down\nDec 15 08:13:37 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdb - tur checker reports path is down\nDec 15 08:13:37 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdc - tur checker reports path is down\nDec 15 08:13:42 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdb - tur checker reports path is down\nDec 15 08:13:42 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdc - tur checker reports path is down\nDec 15 08:13:47 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdb - tur checker reports path is down\nDec 15 08:13:47 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdc - tur checker reports path is down\nDec 15 08:13:52 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdb - tur checker reports path is down\nDec 15 08:13:52 kvm4 multipathd: 36000d31000a6500000000000000000cf: sdc - tur checker reports path is down\n\n", 
            "date_created": "2015-12-15 07:21:10.702934+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "Cant be removed manually, a restart of the node is required to resolve the stuck kpartx and blkid processes.\n\nmultipathd> del multipath 36000d31000a6500000000000000000cf\nfail\nmultipathd> remove multipath 36000d31000a6500000000000000000cf\nfail\n\n\n36000d31000a6500000000000000000cf dm-2 COMPELNT,Compellent Vol  \nsize=20G features='1 queue_if_no_path' hwhandler='0' wp=rw\n`-+- policy='round-robin 0' prio=0 status=enabled\n  |- 7:0:0:1 sdb   8:16   failed faulty running\n  `- 8:0:0:1 sdc   8:32   failed faulty running\n", 
            "date_created": "2015-12-15 07:24:44.078958+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "Would be useful to see the interactions between libvirt and QEMU by re-running your test by setting these log filters on both, source and destination Compute nodes:\n\nIn /etc/libvirt/libvirtd.conf\n\n     log_filters=\"3:event 3:file 1:util 1:security 1:qemu 1:libvirt\"\n     log_outputs=\"1:file:/var/log/libvirt/libvirtd.log\"\n\nRestart libvirt daemon (both Compute nodes).\n\nRepeat your test, capture libvirtd.log from src and dst and attach to this bug as plain text.", 
            "date_created": "2015-12-17 12:03:37.095333+00:00", 
            "author": "https://api.launchpad.net/1.0/~kashyapc"
        }, 
        {
            "content": "@Tobias \nit seems this issue is no related with OpenStack Nova but  multipathd.\nI wonder if you can test it by doing live-migration by qemu command line(or virsh)\n\nEli.", 
            "date_created": "2016-01-05 06:43:20.620149+00:00", 
            "author": "https://api.launchpad.net/1.0/~taget-9"
        }, 
        {
            "content": "I had some time to sit down and investigate this today and I think I'm a little bit closer to the problem this time.\n\nA little bit of information before I continue:\n* I run this in our test environment which is running Liberty\n* We are running Cinder with a 3rd party (Dell) ISCSI driver\n* We have enabled multipath option for Nova to make sure nova uses our two ISCSI controllers instead of one.\n\nWhen starting a live migration everything works fine for about 2-4 live migrations (we have 2 test compute nodes).\nThen something happens which causes the source host to not cleanup the multipath device properly and it fails to flush (-f) that multipath device and it enters a \"faulty running\" state on the source host, however since this is only the cleanup process the instance is actually live migrated and working on the destination host.\n\nHere is from the nova-compute logs (debug mode enabled) when the cleanup process (on the source host) removes the ISCSI devices and tries to delete the multipath device:\n\n2016-02-11 13:20:47.069 24254 DEBUG nova.virt.libvirt.volume.iscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] calling os-brick to detach iSCSI Volume disconnect_volume /usr/lib/python2.7/dist-packages/nova/virt/libvirt/volume/iscsi.py:92\n2016-02-11 13:20:47.070 24254 DEBUG oslo_concurrency.lockutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Lock \"connect_volume\" acquired by \"os_brick.initiator.connector.disconnect_volume\" :: waited 0.000s inner /usr/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py:253\n2016-02-11 13:20:47.071 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -r execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.171 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -r\" returned: 0 in 0.100s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.173 24254 DEBUG os_brick.initiator.connector [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] multipath ['-r']: stdout=Feb 11 13:20:47 | sdb: rport id not found\nFeb 11 13:20:47 | sdc: rport id not found\nreload: 36000d31000a650000000000000000168 undef COMPELNT,Compellent Vol  \nsize=1.0G features='0' hwhandler='0' wp=undef\n`-+- policy='round-robin 0' prio=1 status=undef\n  |- 8:0:0:1 sdb 8:16 active ready running\n  `- 9:0:0:1 sdc 8:32 active ready running\nFeb 11 13:20:47 | sdd: rport id not found\nFeb 11 13:20:47 | sde: rport id not found\nreload: 36000d31000a650000000000000000167 undef COMPELNT,Compellent Vol  \nsize=1.0G features='0' hwhandler='0' wp=undef\n`-+- policy='round-robin 0' prio=1 status=undef\n  |- 8:0:0:2 sdd 8:48 active ready running\n  `- 9:0:0:2 sde 8:64 active ready running\n stderr= _run_multipath /usr/lib/python2.7/dist-packages/os_brick/initiator/connector.py:901\n2016-02-11 13:20:47.174 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -ll /dev/sdc execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.251 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -ll /dev/sdc\" returned: 0 in 0.077s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.253 24254 DEBUG os_brick.initiator.connector [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] multipath ['-ll', u'/dev/sdc']: stdout=36000d31000a650000000000000000168 dm-2 COMPELNT,Compellent Vol  \nsize=1.0G features='1 queue_if_no_path' hwhandler='0' wp=rw\n`-+- policy='round-robin 0' prio=1 status=active\n  |- 8:0:0:1 sdb 8:16 active ready running\n  `- 9:0:0:1 sdc 8:32 active ready running\n stderr= _run_multipath /usr/lib/python2.7/dist-packages/os_brick/initiator/connector.py:901\n2016-02-11 13:20:47.254 24254 DEBUG os_brick.initiator.linuxscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] remove multipath device /dev/sdc remove_multipath_device /usr/lib/python2.7/dist-packages/os_brick/initiator/linuxscsi.py:119\n2016-02-11 13:20:47.254 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -l /dev/sdc execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.320 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -l /dev/sdc\" returned: 0 in 0.066s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.322 24254 DEBUG os_brick.initiator.linuxscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Found multipath device = /dev/mapper/36000d31000a650000000000000000168 find_multipath_device /usr/lib/python2.7/dist-packages/os_brick/initiator/linuxscsi.py:257\n2016-02-11 13:20:47.323 24254 DEBUG os_brick.initiator.linuxscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] multipath LUNs to remove [{'device': '/dev/sdb', 'host': '8', 'id': '0', 'channel': '0', 'lun': '1'}, {'device': '/dev/sdc', 'host': '9', 'id': '0', 'channel': '0', 'lun': '1'}] remove_multipath_device /usr/lib/python2.7/dist-packages/os_brick/initiator/linuxscsi.py:123\n2016-02-11 13:20:47.324 24254 DEBUG os_brick.initiator.linuxscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Flushing IO for device /dev/sdb flush_device_io /usr/lib/python2.7/dist-packages/os_brick/initiator/linuxscsi.py:131\n2016-02-11 13:20:47.324 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf blockdev --flushbufs /dev/sdb execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.372 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf blockdev --flushbufs /dev/sdb\" returned: 0 in 0.047s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.373 24254 DEBUG os_brick.initiator.linuxscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Remove SCSI device /dev/sdb with /sys/block/sdb/device/delete remove_scsi_device /usr/lib/python2.7/dist-packages/os_brick/initiator/linuxscsi.py:70\n2016-02-11 13:20:47.374 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf tee -a /sys/block/sdb/device/delete execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.428 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf tee -a /sys/block/sdb/device/delete\" returned: 0 in 0.055s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.429 24254 DEBUG os_brick.initiator.linuxscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Flushing IO for device /dev/sdc flush_device_io /usr/lib/python2.7/dist-packages/os_brick/initiator/linuxscsi.py:131\n2016-02-11 13:20:47.430 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf blockdev --flushbufs /dev/sdc execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.487 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf blockdev --flushbufs /dev/sdc\" returned: 0 in 0.057s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.488 24254 DEBUG os_brick.initiator.linuxscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Remove SCSI device /dev/sdc with /sys/block/sdc/device/delete remove_scsi_device /usr/lib/python2.7/dist-packages/os_brick/initiator/linuxscsi.py:70\n2016-02-11 13:20:47.488 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf tee -a /sys/block/sdc/device/delete execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.541 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf tee -a /sys/block/sdc/device/delete\" returned: 0 in 0.053s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.542 24254 DEBUG os_brick.initiator.linuxscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Flush multipath device 36000d31000a650000000000000000168 flush_multipath_device /usr/lib/python2.7/dist-packages/os_brick/initiator/linuxscsi.py:140\n2016-02-11 13:20:47.543 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -f 36000d31000a650000000000000000168 execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.602 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -f 36000d31000a650000000000000000168\" returned: 1 in 0.059s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.604 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] u'sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -f 36000d31000a650000000000000000168' failed. Not Retrying. execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:308\n2016-02-11 13:20:47.606 24254 WARNING os_brick.initiator.linuxscsi [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] multipath call failed exit 1\n2016-02-11 13:20:47.607 24254 DEBUG os_brick.initiator.connector [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Disconnect multipath device /dev/mapper/36000d31000a650000000000000000168 _disconnect_volume_multipath_iscsi /usr/lib/python2.7/dist-packages/os_brick/initiator/connector.py:684\n2016-02-11 13:20:47.609 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -ll execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.721 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -ll\" returned: 0 in 0.112s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.725 24254 DEBUG os_brick.initiator.connector [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] multipath ['-ll']: stdout=36000d31000a650000000000000000167 dm-4 COMPELNT,Compellent Vol  \nsize=1.0G features='1 queue_if_no_path' hwhandler='0' wp=rw\n`-+- policy='round-robin 0' prio=1 status=active\n  |- 8:0:0:2 sdd 8:48 active ready running\n  `- 9:0:0:2 sde 8:64 active ready running\n36000d31000a650000000000000000168 dm-2 ##,##\nsize=1.0G features='1 queue_if_no_path' hwhandler='0' wp=rw\n`-+- policy='round-robin 0' prio=0 status=active\n  `- #:#:#:# -   #:#  active faulty running\n stderr= _run_multipath /usr/lib/python2.7/dist-packages/os_brick/initiator/connector.py:901\n2016-02-11 13:20:47.730 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Running cmd (subprocess): sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -r execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:230\n2016-02-11 13:20:47.887 24254 DEBUG oslo_concurrency.processutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -r\" returned: 0 in 0.157s execute /usr/lib/python2.7/dist-packages/oslo_concurrency/processutils.py:260\n2016-02-11 13:20:47.890 24254 DEBUG os_brick.initiator.connector [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] multipath ['-r']: stdout=Feb 11 13:20:47 | sdd: rport id not found\nFeb 11 13:20:47 | sde: rport id not found\nreload: 36000d31000a650000000000000000167 undef COMPELNT,Compellent Vol  \nsize=1.0G features='0' hwhandler='0' wp=undef\n`-+- policy='round-robin 0' prio=1 status=undef\n  |- 8:0:0:2 sdd 8:48 active ready running\n  `- 9:0:0:2 sde 8:64 active ready running\n stderr= _run_multipath /usr/lib/python2.7/dist-packages/os_brick/initiator/connector.py:901\n2016-02-11 13:20:47.893 24254 DEBUG oslo_concurrency.lockutils [req-a6acbc4b-1def-43af-9fc3-c009281b2f57 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] Lock \"connect_volume\" released by \"os_brick.initiator.connector.disconnect_volume\" :: held 0.823s inner /usr/lib/python2.7/dist-packages/oslo_concurrency/lockutils.py:265\n\nNow the interesting part is that something happens which causes the multipath flush to fail (removal of the multipath device)\n CMD \"sudo nova-rootwrap /etc/nova/rootwrap.conf multipath -f 36000d31000a650000000000000000168\" returned: 1 in 0.059s\n\nCausing it to enter a faulty running state (remember this is still on the source host after a \"successfull\" live-migration has been performed).\n\n36000d31000a650000000000000000168 dm-2 ##,##\nsize=1.0G features='1 queue_if_no_path' hwhandler='0' wp=rw\n`-+- policy='round-robin 0' prio=0 status=active\n  `- #:#:#:# -   #:#  active faulty running\n\nNow you will also get some stuck processes because of this, for example blkid and kpartx will hang because of this faulty multipath device, for example when blkid tries to show the ID of all devices it will hang because of this.\nroot     19144  0.0  0.0      0     0 ?        D    13:20   0:00 [blkid]\nroot     19153  0.0  0.0  28284  2400 ?        S    13:20   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a650000000000000000167\n\nAfter a while, since some part of openstack or any other software is regularly trying to query using blkid you will after a while get a lot of blkid processes and all of them is stuck and cannot be deleted with \"kill -9\" for example.\n\nroot     19144  0.0  0.0      0     0 ?        D    13:20   0:00 [blkid]\nroot     19153  0.0  0.0  28284  2400 ?        S    13:20   0:00 /sbin/kpartx -a -p -part /dev/mapper/36000d31000a650000000000000000167\nroot     17702  0.0  0.0      0     0 ?        D    14:03   0:00 [blkid]\n\n[101898.379966] INFO: task blkid:19144 blocked for more than 120 seconds.\n[101898.380013]       Not tainted 3.16.0-60-generic #80~14.04.1-Ubuntu\n[101898.380041] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\n[101898.380076] blkid           D ffff88023fc130c0     0 19144      1 0x00000006\n[101898.380081]  ffff880217b679c8 0000000000000046 ffff8800bb3e65e0 ffff880217b67fd8\n[101898.380091]  00000000000130c0 00000000000130c0 ffff880231040a30 ffff88023fc139c0\n[101898.380093]  ffff88023ffc2ee8 ffff880217b67a50 0000000000000002 ffffffff81162bd0\n\nThe result of these stuck processes is that any live-migration that will be performed from or to this host in the future will hang on the first step where libvirt copies the active memory pages i.e this line:\n(Migration running for 0 secs, memory 100% remaining; (bytes processed=0, remaining=0, total=0)\n\nThis line will however not have any progress, this is turn will crash qemu-kvm and you won't be able to kill, start, stop or migrate that instance anywhere. The only solution when this happens is a remote of the compute node which is catastrophic to those instances being hosted there.\n\nThis is how it will look in the nova-compute.log when this happens and you try to live migrate. You will get stuck in this migration loop until it reaches the timeout.\n\n2016-02-11 14:30:01.539 24254 DEBUG nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Migration running for 50 secs, memory 4% remaining; (bytes processed=53019620, remaining=23564288, total=546119680) _live_migration_monitor /usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py:6052\n2016-02-11 14:30:01.541 24254 DEBUG nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Data remaining 23564288 bytes, low watermark 0 bytes 52 seconds ago _live_migration_monitor /usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py:6059\n2016-02-11 14:30:06.792 24254 DEBUG nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Migration running for 55 secs, memory 4% remaining; (bytes processed=53019620, remaining=23564288, total=546119680) _live_migration_monitor /usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py:6052\n2016-02-11 14:30:06.793 24254 DEBUG nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Data remaining 23564288 bytes, low watermark 0 bytes 58 seconds ago _live_migration_monitor /usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py:6059\n2016-02-11 14:30:12.032 24254 INFO nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Migration running for 60 secs, memory 4% remaining; (bytes processed=53019620, remaining=23564288, total=546119680)\n2016-02-11 14:30:12.034 24254 INFO nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Data remaining 23564288 bytes, low watermark 0 bytes 63 seconds ago\n\n\n\n2016-02-11 14:31:38.445 24254 WARNING nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Live migration stuck for 150 sec\n\n2016-02-11 14:32:08.448 24254 WARNING nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Failed to abort migration Timed out during operation: cannot acquire state change lock (held by remoteDispatchDomainMigratePerform3)\n2016-02-11 14:32:08.450 24254 WARNING nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Error monitoring migration: Timed out during operation: cannot acquire state change lock (held by remoteDispatchDomainMigratePerform3)\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Traceback (most recent call last):\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6142, in _live_migration\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     dom, finish_event)\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5990, in _live_migration_monitor\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     dom.abortJob()\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 183, in doit\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 141, in proxy_call\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     rv = execute(f, *args, **kwargs)\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 122, in execute\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     six.reraise(c, e, tb)\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 80, in tworker\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     rv = meth(*args, **kwargs)\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 482, in abortJob\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     if ret == -1: raise libvirtError ('virDomainAbortJob() failed', dom=self)\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] libvirtError: Timed out during operation: cannot acquire state change lock (held by remoteDispatchDomainMigratePerform3)\n2016-02-11 14:32:08.450 24254 ERROR nova.virt.libvirt.driver [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] \n2016-02-11 14:32:08.482 24254 DEBUG nova.virt.libvirt.driver [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Live migration monitoring is all done _live_migration /usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py:6149\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [req-6d197ff3-17a8-4ad9-8519-837f088553e5 3219c68625644b5598705862cb1287da 6c74ff68d7534d3990ea96331fcfa90a - - -] [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Live migration failed.\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] Traceback (most recent call last):\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 5124, in _do_live_migration\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     block_migration, migrate_data)\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5502, in live_migration\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     migrate_data)\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 6142, in _live_migration\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     dom, finish_event)\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/driver.py\", line 5990, in _live_migration_monitor\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     dom.abortJob()\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 183, in doit\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     result = proxy_call(self._autowrap, f, *args, **kwargs)\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 141, in proxy_call\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     rv = execute(f, *args, **kwargs)\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 122, in execute\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     six.reraise(c, e, tb)\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/eventlet/tpool.py\", line 80, in tworker\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     rv = meth(*args, **kwargs)\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 482, in abortJob\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6]     if ret == -1: raise libvirtError ('virDomainAbortJob() failed', dom=self)\n2016-02-11 14:32:08.484 24254 ERROR nova.compute.manager [instance: b2eceb4f-d997-4f5e-bb29-54552f29beb6] libvirtError: Timed out during operation: cannot acquire state change lock (held by remoteDispatchDomainMigratePerform3)\n\nYou will also get a lot of error messages in the syslog from multipath regarding the devices in the multipath.\nFeb 11 14:02:50 test-sto1-compute multipathd: 36000d31000a650000000000000000167: sdd - tur checker reports path is down\nFeb 11 14:02:55 test-sto1-compute multipathd: 36000d31000a650000000000000000167: sde - tur checker reports path is down\nFeb 11 14:02:55 test-sto1-compute multipathd: 36000d31000a650000000000000000167: sdd - tur checker reports path is down\nFeb 11 14:03:00 test-sto1-compute multipathd: 36000d31000a650000000000000000167: sde - tur checker reports path is down\nFeb 11 14:03:00 test-sto1-compute multipathd: 36000d31000a650000000000000000167: sdd - tur checker reports path is down\nFeb 11 14:03:05 test-sto1-compute multipathd: 36000d31000a650000000000000000167: sde - tur checker reports path is down\nFeb 11 14:03:05 test-sto1-compute multipathd: 36000d31000a650000000000000000167: sdd - tur checker reports path is down\n\nFeb 11 14:03:36 test-sto1-compute multipathd: 8:32: mark as failed\nFeb 11 14:03:36 test-sto1-compute kernel: [103143.649758] device-mapper: multipath: Failing path 8:32.\n\n\nNow here is the logs from the first migration when the multipath device cleanup fails and causes these stuck processes.\nIt's looks to me like this issue is because it removed the \"sdb\" device from the multipath device but then failed to remove the \"sdc\" device and that's the reason why the \"multipath -f\" flush of the device fails because it's \"in-use\" as said in the syslog.\nFeb 11 13:20:47 test-sto1-compute multipathd: 36000d31000a650000000000000000168: map in use\nFeb 11 13:20:47 test-sto1-compute multipathd: 36000d31000a650000000000000000168: can't flush\nFeb 11 13:20:47 test-sto1-compute multipathd: 36000d31000a650000000000000000168: failed in domap for removal of path sdc\n\nSyslog: http://pastebin.com/0VfevmJH\nLibvirtd: nothing interesting in the log\nnova-compute: http://pastebin.com/2TCmNHJp\nkern.log http://pastebin.com/PZGb4V6M\n\nThanksful for any help :)\n\nBest regards\nTobias", 
            "date_created": "2016-02-11 13:49:20.315680+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "I have not been able to reproduce this issue with cold migration (the \"Migrate\" button in Horizon).\nSo this bug is properly tagged with live-migration as it seems the same issue does not arise with cold migrations.\n\nI should also include the live-migration config we have in nova.conf\n[libvirt]\nvirt_type=kvm\ninject_password=true\ninject_key=true\ninject_partition=-1\nlive_migration_flag=VIR_MIGRATE_UNDEFINE_SOURCE,VIR_MIGRATE_PEER2PEER,VIR_MIGRATE_LIVE, VIR_MIGRATE_TUNNELLED\niscsi_use_multipath = True", 
            "date_created": "2016-02-11 16:28:19.388897+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "I have narrowed the issue down further.\nThe issue is that a race condition appears where we try to remove all SCSI devices and then flush (=removing) the multipath device but if the removal of the SCSI devices is delayed the call to flush the multipath device will fail because one of the SCSI devices is still a member of the multipath device.\n\nThis can be seen in the syslog when this occurs.\nFeb 11 13:20:47 test-sto1-compute multipathd: sdb: remove path (uevent)\nFeb 11 13:20:47 test-sto1-compute multipathd: sdc: rport id not found\nFeb 11 13:20:47 test-sto1-compute multipathd: 36000d31000a650000000000000000168: load table [0 2097152 multipath 0 0 1 1 round-robin 0 1 1 8:32 1000]\nFeb 11 13:20:47 test-sto1-compute multipathd: sdb: path removed from map 36000d31000a650000000000000000168\nFeb 11 13:20:47 test-sto1-compute multipathd: sdc: remove path (uevent)\nFeb 11 13:20:47 test-sto1-compute multipathd: 36000d31000a650000000000000000168: map in use\nFeb 11 13:20:47 test-sto1-compute multipathd: 36000d31000a650000000000000000168: can't flush\nFeb 11 13:20:47 test-sto1-compute multipathd: 36000d31000a650000000000000000168: failed in domap for removal of path sdc\n\nAs you can see the \"map in use can't flush\" messages. It's because the sdc was not removed in time from the multipath device before the flush was tried.\n\nThe issue is here: https://github.com/openstack/os-brick/blob/master/os_brick/initiator/linuxscsi.py#L118\nThis remove_multipath_device() is called by the disconnect_volume() function in the libvirt ISCSI driver which in turn is called in the post_live_migration() function in the libvirt driver on cleanup for the source host after a live migration.\n\nI'm thinking about possible solutions, one would be adding some kind of verification (and perhaps a delay) that checks the multipath device members before flushing it to make sure they are all unmapped before flushing. I would assume this would be an improvement that has to be made to os-brick which isn't really related directly to Nova making this bug perhaps invalid for Nova.", 
            "date_created": "2016-02-12 06:44:31.685593+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "This Debian bug seems very relevant and gives the same hickups as this bug.\nhttps://bugs.debian.org/cgi-bin/bugreport.cgi?bug=623613\n\nLooks like the kpartx and blkid processes I have been talking about previously is actually spawned by udev.\nI will do some tests setting no_path_retry to 0 in multipath.conf instead of having \"queue\".\n\nAlso setting flush_on_last_del might perhaps be good since multipath -f (for flushing) return 0 even if the multipath doesn't exist.\nBest regards", 
            "date_created": "2016-02-12 07:00:18.384047+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "Resolved by changing the no_path_retry option in multipath.conf from \"queue\" to \"0\".\nThe issue was that that when IO was queued and the path was about to be removed it was blocked and was never removed, so the flushing of the multipath device failed because the multipath device was in-use by this stuck device.\n\nI also changed removed the VIR_MIGRATE_TUNNELLED value from the  live_migration_flag option in nova.conf by recommendation from Kashyap Chamarthy (kashyapc).\n\nTo reload the multipath.conf while multipathd is running (won't stop or break your multipath devices).\nmultipathd -k\nreconfigure\n\nResolved with good help from these links:\nhttps://bugs.debian.org/cgi-bin/bugreport.cgi?bug=623613\nhttp://linux.die.net/man/5/multipath.conf\nhttp://christophe.varoqui.free.fr/refbook.html\n\nRight now, 26 live migrations and counting without any issues.\nBest regards", 
            "date_created": "2016-02-12 08:12:21.102285+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }, 
        {
            "content": "Very cool!\n\nThanks for reporting your debug progress. \ncan I know the reason your remove VIR_MIGRATE_TUNNELLED flag from libvirt?\n\nEli.\n", 
            "date_created": "2016-02-22 09:19:34.294598+00:00", 
            "author": "https://api.launchpad.net/1.0/~taget-9"
        }, 
        {
            "content": "Hello Eli,\n\nThe VIR_MIGRATE_TUNNELLED is use for security which I don't really need on a internal network between my compute nodes.\nSearch for it on https://wiki.openstack.org/wiki/OSSN/OSSN-0007 and you'll read more.\n\nI removed it by recommendation from Kashyap Chamarthy (kashyap). See IRC logs below.\n\n17:23 < kashyap> tobasco: Heh, \"lot of insight\", don't get tricked too easily :-)\n17:23 < kashyap> tobasco: Will look in 10 mins, in the middle of something\n17:24 < tobasco> kashyap: hehe, well you beat me by some lengths atleast ;) thanks\n17:25 < tobasco> kashyap: might be leaving in a while so if gone just shoot a comment and i'll check it out asap and get back\n17:26 < kashyap> tobasco: Okay, quick note - remove this VIR_MIGRATE_TUNNELLED when doing live block migration\n17:26 < kashyap> tobasco: Also a note for future releases of Nova: Both the flags 'live_migration_flag' and 'block_migration_flag' are now deprecated\n17:27 < kashyap> Mandatory flags are handled by default - https://review.openstack.org/#/c/263433/\n17:28 < kashyap> Instead the tunnelling will be handled (by upcoming versions) with a single flag.  (See here for more info: https://review.openstack.org/#/c/263434/)\n17:30 < tobasco> kashyap: ok thanks, i will try the changes, seems like the issue with the bug is because of multipath cleanup so was not really related but wanted some good input on that config :)\n17:31 < tobasco> kashyap: so if i understand it correctly in the future all needed flags would be determined by nova(?) and since I don't need tunneling I would just remove the live_migration_flag config\n17:32 < kashyap> tobasco: Just remove the VIR_MIGRATE_TUNNELLED option from block_migration_flag.  (There are no multiple changes (you say \"the changes\"), as you're using Liberty or below & not Git (I assume), just that one flag I mentioned.)\n17:33 < kashyap> tobasco: Yes, on your last point.\n17:34 < tobasco> kashyap: Cool thanks\n", 
            "date_created": "2016-02-22 09:33:03.851867+00:00", 
            "author": "https://api.launchpad.net/1.0/~tobias-urdin"
        }
    ], 
    "closed": "2016-02-12 08:15:35.234209+00:00"
}