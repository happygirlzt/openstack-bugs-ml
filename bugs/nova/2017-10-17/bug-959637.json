{
    "status": "Fix Released", 
    "last_updated": "2013-06-19 18:36:28.624012+00:00", 
    "description": "I just upgraded all my Ubuntu and Essex packages to the latest for Ubuntu 12.04:\n\nroot@spcnode1:/var/log/nova# dpkg -l libvirt-bin\nii  libvirt-bin                          0.9.8-2ubuntu13                      programs for the libvirt library\nroot@spcnode1:/var/log/nova# dpkg -l nova-compute\nii  nova-compute                         2012.1~rc1~20120316.13416-0ubuntu1   OpenStack Compute - compute node\n\nNow VMs are refusing to start, with this error:\n\n2012-03-19 12:14:03 ERROR nova.compute.manager [req-58618bbb-ee6c-4a98-adb0-dfb8b0856ada novaadmin proj] [instance: 6f81e765-c349-4493-bc49-bea964a76ff5] Instance failed to spawn\n(nova.compute.manager): TRACE: Traceback (most recent call last):\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 592, in _spawn\n(nova.compute.manager): TRACE:     self._legacy_nw_info(network_info), block_device_info)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 114, in wrapped\n(nova.compute.manager): TRACE:     return f(*args, **kw)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/connection.py\", line 936, in spawn\n(nova.compute.manager): TRACE:     self._create_new_domain(xml)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/connection.py\", line 1577, in _create_new_domain\n(nova.compute.manager): TRACE:     domain.createWithFlags(launch_flags)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 581, in createWithFlags(nova.compute.manager): TRACE:     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n(nova.compute.manager): TRACE: libvirtError: internal error process exited while connecting to monitor: char device redirected to /dev/pts/2\n(nova.compute.manager): TRACE: kvm: -drive file=/mnt/vmstore/instances/instance-0000001a/disk,if=none,id=drive-virtio-disk0,format=qcow2,cache=none: could not open disk image /mnt/vmstore/instances/instance-0000001a/disk: Invalid argument\n\n\nLooking through libvirt logs in /var/log/libvirt and /var/log/libvirt/qemu, I was able to see what was different about the -disk line to kvm, the addition of \"cache=none\"\n\nI found the addition merged in a few days ago here:  https://bazaar.launchpad.net/~nova-core/nova/github/revision/2855\n\nIf I edit my libvirt.xml.template file to remove \"cache=none\", everything boots up happily again.", 
    "tags": [], 
    "importance": "High", 
    "heat": 16, 
    "link": "https://bugs.launchpad.net/nova/+bug/959637", 
    "owner": "https://api.launchpad.net/1.0/~berrange", 
    "id": 959637, 
    "index": 639, 
    "openned": "2012-03-19 19:31:47.314329+00:00", 
    "created": "2012-03-19 19:31:47.314329+00:00", 
    "title": "libvirt disk option 'cache=none' prevents VM from booting on GlusterFS/FUSE", 
    "comments": [
        {
            "content": "I just upgraded all my Ubuntu and Essex packages to the latest for Ubuntu 12.04:\n\nroot@spcnode1:/var/log/nova# dpkg -l libvirt-bin\nii  libvirt-bin                          0.9.8-2ubuntu13                      programs for the libvirt library\nroot@spcnode1:/var/log/nova# dpkg -l nova-compute\nii  nova-compute                         2012.1~rc1~20120316.13416-0ubuntu1   OpenStack Compute - compute node\n\nNow VMs are refusing to start, with this error:\n\n2012-03-19 12:14:03 ERROR nova.compute.manager [req-58618bbb-ee6c-4a98-adb0-dfb8b0856ada novaadmin proj] [instance: 6f81e765-c349-4493-bc49-bea964a76ff5] Instance failed to spawn\n(nova.compute.manager): TRACE: Traceback (most recent call last):\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/compute/manager.py\", line 592, in _spawn\n(nova.compute.manager): TRACE:     self._legacy_nw_info(network_info), block_device_info)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/exception.py\", line 114, in wrapped\n(nova.compute.manager): TRACE:     return f(*args, **kw)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/connection.py\", line 936, in spawn\n(nova.compute.manager): TRACE:     self._create_new_domain(xml)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/nova/virt/libvirt/connection.py\", line 1577, in _create_new_domain\n(nova.compute.manager): TRACE:     domain.createWithFlags(launch_flags)\n(nova.compute.manager): TRACE:   File \"/usr/lib/python2.7/dist-packages/libvirt.py\", line 581, in createWithFlags(nova.compute.manager): TRACE:     if ret == -1: raise libvirtError ('virDomainCreateWithFlags() failed', dom=self)\n(nova.compute.manager): TRACE: libvirtError: internal error process exited while connecting to monitor: char device redirected to /dev/pts/2\n(nova.compute.manager): TRACE: kvm: -drive file=/mnt/vmstore/instances/instance-0000001a/disk,if=none,id=drive-virtio-disk0,format=qcow2,cache=none: could not open disk image /mnt/vmstore/instances/instance-0000001a/disk: Invalid argument\n\n\nLooking through libvirt logs in /var/log/libvirt and /var/log/libvirt/qemu, I was able to see what was different about the -disk line to kvm, the addition of \"cache=none\"\n\nI found the addition merged in a few days ago here:  https://bazaar.launchpad.net/~nova-core/nova/github/revision/2855\n\nIf I edit my libvirt.xml.template file to remove \"cache=none\", everything boots up happily again.", 
            "date_created": "2012-03-19 19:31:47.314329+00:00", 
            "author": "https://api.launchpad.net/1.0/~trhoden"
        }, 
        {
            "content": "After a bit more testing, this only happens when I am using GlusterFS as my VM store.  In the above report, /mnt/vmstore is a GlusterFS mount (running Gluster 3.3beta).  If I edit my nova.conf to remove \"--instances_path\", so that the default instance directofy of /var/lib/nova/instances is used instead, cache=\"None\" seems to be accepted fine.\n\nThat begs the question of whether specifying \"cache=none\" across the board is really ideal.\n\nI'm not sure what the correct setting should be for user with GlusterFS.  Perhaps documenting this potential tripping point is sufficient.  ", 
            "date_created": "2012-03-19 19:56:22.113703+00:00", 
            "author": "https://api.launchpad.net/1.0/~trhoden"
        }, 
        {
            "content": "Added Daniel Berrange, who was the author of the patch that added \"cache=none\".", 
            "date_created": "2012-03-19 22:26:38.979076+00:00", 
            "author": "https://api.launchpad.net/1.0/~russellb"
        }, 
        {
            "content": "Hmm, this message\n\n> could not open disk image /mnt/vmstore/instances/instance-0000001a/disk: Invalid argument\n\nprobably means that the filesystem does not support Direct IO. AFAIK, all filesystems except tmpfs should support this, so I'll investigate what the score is wrt GlusterFS.", 
            "date_created": "2012-03-20 10:39:27.957082+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "Can you say what kernel version you have, what glusterfs version you have and show the /proc/mounts  line for the glusterfs volume", 
            "date_created": "2012-03-20 10:52:07.578034+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "You are correct that it is Direct IO.  My Gluster mount is using FUSE, and FUSE does not support Direct IO.  I see this topic come up every few weeks on the Gluster mailing list.  It is a limitation of FUSE, not Gluster.  Supposedly patches have been submitted to FUSE to add support for Direct IO, but those have not been accepted.  Here is a recent mailing list thread about it: http://<email address hidden>/msg08353.html\n\nSo, in that sense It's hard to say that you are doing anything wrong.  Perhaps this isn't a bug.  Or perhaps the cache option needs to be configurable somehow.  It's never been clear to me whether editing the libvirt XML template is an expected/normal thing to do in an OpenStack deployment.\n\nFor completeness, here is the info you asked for:\nroot@spcnode2:~# uname -a\nLinux spcnode2 3.2.0-19-generic #30-Ubuntu SMP Fri Mar 16 16:27:15 UTC 2012 x86_64 x86_64 x86_64 GNU/Linux\nroot@spcnode2:~# lsb_release -a\nNo LSB modules are available.\nDistributor ID:\tUbuntu\nDescription:\tUbuntu precise (development branch)\nRelease:\t12.04\nCodename:\tprecise\n\nroot@spcnode2:~# glusterfs --version\nglusterfs 3.3beta2 built on Mar  6 2012 09:36:03\n\nFrom /proc/mounts:\nlocalhost:/vmstore /mnt/vmstore fuse.glusterfs rw,relatime,user_id=0,group_id=0,default_permissions,allow_other,max_read=131072 0 0\n\nWhich is achieved by:\nmount -t glusterfs localhost:/vmstore /mnt/vmstore", 
            "date_created": "2012-03-20 13:41:26.585194+00:00", 
            "author": "https://api.launchpad.net/1.0/~trhoden"
        }, 
        {
            "content": "So what we'll want todo then, is to have Nova do a check whether the storage volume supports Direct IO. If it does, then use cache=none, otherwise fallback to cache=writethrough which does not use Direct I/O, but is still crash safe.\n", 
            "date_created": "2012-03-20 13:57:32.720063+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "That sounds like a good plan, Daniel.  That way if FUSE ever does support O_DIRECT, it will switch to cache=none without any code changes.", 
            "date_created": "2012-03-21 03:16:07.626272+00:00", 
            "author": "https://api.launchpad.net/1.0/~trhoden"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/5606", 
            "date_created": "2012-03-21 11:39:54.940083+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "@travis the patch I posted to Gerrit implements the dynamic checking of O_DIRECT support. While I don't have GlusterFS, I did test this by pointing the 'instances_path' config param to a tmpfs filesystem which similarly lacks O_DIRECT. I could reproduce the error you saw, and after applying my patch guests successfully start again", 
            "date_created": "2012-03-21 11:42:09.258700+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "With regard to the 'essex-rc-potential' tag:  This looks like a new feature to me, so this should only target folsom", 
            "date_created": "2012-03-21 17:28:34.924704+00:00", 
            "author": "https://api.launchpad.net/1.0/~jogo"
        }, 
        {
            "content": "This isn't a new feature - this is fixing the regression I caused in GIT commit 9f9402693a4465346e2b901055f798ba139c130b", 
            "date_created": "2012-03-21 17:46:01.575196+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/5606\nCommitted: http://github.com/openstack/nova/commit/78f3e76d695898aaf846efb9c420e146a982e689\nSubmitter: Jenkins\nBranch:    master\n\ncommit 78f3e76d695898aaf846efb9c420e146a982e689\nAuthor: Daniel P. Berrange <email address hidden>\nDate:   Wed Mar 21 11:35:43 2012 +0000\n\n    Fix launching of guests where instances_path is on GlusterFS\n    \n    The FUSE module does not (currentl) support O_DIRECT on files.\n    This prevents QEMU from starting guests using 'cache=none' for\n    their disks located on a GlusterFS filesystem. The same also\n    applies for a handful of other filesystems (notably tmpfs, or\n    any other FUSE filesystem).\n    \n    This patch introduces a startup check in Nova compute service\n    which tries to create a file $instances_path/.direct_io.test\n    using the O_DIRECT flag. If this succeeds, then cache=none\n    will be used for all disks, otherwise it will fallback to\n    using cache=writethrough. While the latter does not have\n    performance which is as consistent as cache=none, it is still\n    host-crash safe and preserves data integrity with migration,\n    if the filesystem is cache coherant (cluster filesystems like\n    GlusterFS are, NFS by constrast is not).\n    \n    By doing the dynamic check for O_DIRECT, we ensure that if\n    future FUSE modules gain O_DIRECT support, Nova will automatically\n    do the right thing.\n    \n    * nova/tests/test_libvirt.py: Stub out os.open in\n      the _check_xml_and_disk_driver() to enable testing of\n      both O_DIRECT and non-O_DIRECT code paths\n    * nova/tests/test_virt_drivers.py: Set instances_path to\n      the current directory\n    * nova/virt/libvirt.xml.template: Replace hardcoded 'none'\n      string with the '$cachemode' variable for all disks.\n      Add missing 'cache' attribute for the config disk\n    * nova/virt/libvirt/connection.py: Check whether O_DIRECT\n      is supported on the \"FLAGS.instances_path\" directory\n      and use 'none' for cachemode if it is, 'writethrough'\n      otherwise\n    \n    Bug: 959637\n    Change-Id: I60cbff1c3ad8299fe2aa37099390f9235f6724d0\n    Signed-off-by: Daniel P. Berrange <email address hidden>\n", 
            "date_created": "2012-03-23 19:09:06.851663+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: milestone-proposed\nReview: https://review.openstack.org/5769", 
            "date_created": "2012-03-25 02:01:50.438478+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/5769\nCommitted: http://github.com/openstack/nova/commit/01e090963f75c2d97c42004a3df515ae5f6e652d\nSubmitter: Jenkins\nBranch:    milestone-proposed\n\ncommit 01e090963f75c2d97c42004a3df515ae5f6e652d\nAuthor: Daniel P. Berrange <email address hidden>\nDate:   Wed Mar 21 11:35:43 2012 +0000\n\n    Fix launching of guests where instances_path is on GlusterFS\n    \n    The FUSE module does not (currentl) support O_DIRECT on files.\n    This prevents QEMU from starting guests using 'cache=none' for\n    their disks located on a GlusterFS filesystem. The same also\n    applies for a handful of other filesystems (notably tmpfs, or\n    any other FUSE filesystem).\n    \n    This patch introduces a startup check in Nova compute service\n    which tries to create a file $instances_path/.direct_io.test\n    using the O_DIRECT flag. If this succeeds, then cache=none\n    will be used for all disks, otherwise it will fallback to\n    using cache=writethrough. While the latter does not have\n    performance which is as consistent as cache=none, it is still\n    host-crash safe and preserves data integrity with migration,\n    if the filesystem is cache coherant (cluster filesystems like\n    GlusterFS are, NFS by constrast is not).\n    \n    By doing the dynamic check for O_DIRECT, we ensure that if\n    future FUSE modules gain O_DIRECT support, Nova will automatically\n    do the right thing.\n    \n    * nova/tests/test_libvirt.py: Stub out os.open in\n      the _check_xml_and_disk_driver() to enable testing of\n      both O_DIRECT and non-O_DIRECT code paths\n    * nova/tests/test_virt_drivers.py: Set instances_path to\n      the current directory\n    * nova/virt/libvirt.xml.template: Replace hardcoded 'none'\n      string with the '$cachemode' variable for all disks.\n      Add missing 'cache' attribute for the config disk\n    * nova/virt/libvirt/connection.py: Check whether O_DIRECT\n      is supported on the \"FLAGS.instances_path\" directory\n      and use 'none' for cachemode if it is, 'writethrough'\n      otherwise\n    \n    Bug: 959637\n    Change-Id: I60cbff1c3ad8299fe2aa37099390f9235f6724d0\n    Signed-off-by: Daniel P. Berrange <email address hidden>\n", 
            "date_created": "2012-03-26 18:30:50.083368+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "FWIW: ZFS on Linux also apparently does not support Direct I/O, because I had the same problem with inability to start VMs with disks set to cache=none.  I thought it was a bug in KVM causing the option to completely fail, until finding this bug while looking to file my own bug - but when I tested moving my .qcow2 file to an ext4 partition, sure enough, cache=none worked fine then.\n\nI propose a more informative error dialog should be thrown when this occurs - \"filesystem [path] does not support Direct I/O, cache=none not supported\" would be a tremendous improvement over the generic \"failed to connect to monitor\" that's thrown now.", 
            "date_created": "2013-05-11 03:05:34.161820+00:00", 
            "author": "https://api.launchpad.net/1.0/~jrssnet"
        }, 
        {
            "content": "Actually, crap - I might need to re-file this bug anyway; I just noticed this is filed against openstack and really this is a problem with KVM itself.  (You don't get a helpful message when trying to start your guest with virsh or with virt-manager either.)", 
            "date_created": "2013-05-11 03:06:44.309734+00:00", 
            "author": "https://api.launchpad.net/1.0/~jrssnet"
        }, 
        {
            "content": "I ran into this as well with an iSCSI mount point from a FreeNAS 8.3.1 on a CentOS 6.4 and Ubuntu 12.04.2 LTS client systems. If the raw or qcow2 files are created on an iSCSI volume they fail with cache=none being the default.\n\nThe error message from qemu-kvm kept mentioning a bad parameter. You have to replace the cache=none with the cache=passthrough and it just starts working.\n\nRAW files fail late when they are most of the way through the install of the OS.\nQCOW2 files fail immediate when the file is created by qemu-kvm.\n\nThis was hugely frustrating since if the files were created before the volume was converted to an iSCSI mountpoint, they appeared to work fine. It was when I tried to create my next image that it failed.\n\nHope this helps someone else.", 
            "date_created": "2013-06-19 18:36:27.173208+00:00", 
            "author": "https://api.launchpad.net/1.0/~mcgarrah"
        }
    ], 
    "closed": "2012-03-26 18:30:48.590472+00:00"
}