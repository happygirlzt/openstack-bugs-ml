{
    "status": "Fix Released", 
    "last_updated": "2015-10-15 08:56:58.165970+00:00", 
    "description": "Currently the libvirt driver's approach to live migration is bested characterized as \"launch & pray\".  It starts the live migration operation and then just unconditionally waits for it to finish. It never makes any attempt to tune its behaviour (for example changing max downtime), nor does it look at the data transfer statistics to check if it is making any progress, nor does it have any overall timeout.\n\nIt is not uncommon for guests to have workloads that will preclude live migration from completing. Basically they can be dirtying guest RAM (or block devices) faster than the network is able to transfer it to the destination host. In such a case Nova will just leave the migration running, burning up host CPU cycles and trashing network bandwidth until the end of the universe.\n\nThere are many features exposed by libvirt, that Nova could be using to do a better job, but the question is obviously ...which features and how should they be used. Fortunately Nova is not the first project to come across this problem. The oVirt data center mgmt project has the exact same problem. So rather than trying to invent some new logic for Nova, we should, as an immediate bug fix task, just copy the oVirt logic from VDSM\n\nhttps://github.com/oVirt/vdsm/blob/master/vdsm/virt/migration.py#L430\n\nIf we get this out to users and then get real world feedback on how it operates, we will have an idea of how/where to focus future ongoing efforts.", 
    "tags": [
        "live-migrate"
    ], 
    "importance": "High", 
    "heat": 14, 
    "link": "https://bugs.launchpad.net/nova/+bug/1429220", 
    "owner": "https://api.launchpad.net/1.0/~mikal", 
    "id": 1429220, 
    "index": 1694, 
    "openned": "2015-03-06 17:50:46.455107+00:00", 
    "created": "2015-03-06 17:50:46.455107+00:00", 
    "title": "libvirt does ensure live migration will eventually complete (or abort)", 
    "comments": [
        {
            "content": "Currently the libvirt driver's approach to live migration is bested characterized as \"launch & pray\".  It starts the live migration operation and then just unconditionally waits for it to finish. It never makes any attempt to tune its behaviour (for example changing max downtime), nor does it look at the data transfer statistics to check if it is making any progress, nor does it have any overall timeout.\n\nIt is not uncommon for guests to have workloads that will preclude live migration from completing. Basically they can be dirtying guest RAM (or block devices) faster than the network is able to transfer it to the destination host. In such a case Nova will just leave the migration running, burning up host CPU cycles and trashing network bandwidth until the end of the universe.\n\nThere are many features exposed by libvirt, that Nova could be using to do a better job, but the question is obviously ...which features and how should they be used. Fortunately Nova is not the first project to come across this problem. The oVirt data center mgmt project has the exact same problem. So rather than trying to invent some new logic for Nova, we should, as an immediate bug fix task, just copy the oVirt logic from VDSM\n\nhttps://github.com/oVirt/vdsm/blob/master/vdsm/virt/migration.py#L430\n\nIf we get this out to users and then get real world feedback on how it operates, we will have an idea of how/where to focus future ongoing efforts.", 
            "date_created": "2015-03-06 17:50:46.455107+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/162253", 
            "date_created": "2015-03-06 17:52:42.943916+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/162254", 
            "date_created": "2015-03-06 17:52:54.913548+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "\"copy the logic\" right? Hate to bring this up as code referred seems to be GPL :(", 
            "date_created": "2015-03-07 22:15:25.491501+00:00", 
            "author": "https://api.launchpad.net/1.0/~dims-v"
        }, 
        {
            "content": "I'm not literally copying the source code into openstack as it has completely different structure to what we need. As you can see from the proposed patch I'm just applying the logic at a conceptual level. In any case, the code in question was written by Red Hat employees, so it is copyright is Red Hat owned and as a Red Hat employee myself I'm free to relicense it", 
            "date_created": "2015-03-09 09:33:34.205094+00:00", 
            "author": "https://api.launchpad.net/1.0/~berrange"
        }, 
        {
            "content": "Thanks Daniel", 
            "date_created": "2015-03-09 11:11:12.521545+00:00", 
            "author": "https://api.launchpad.net/1.0/~dims-v"
        }, 
        {
            "content": "Change abandoned by Joe Gordon (<email address hidden>) on branch: master\nReview: https://review.openstack.org/162254\nReason: This review is > 4 weeks without comment, and failed Jenkins the last time it was checked. We are abandoning this for now. Feel free to reactivate the review by pressing the restore button and leaving a 'recheck' comment to get fresh test results.", 
            "date_created": "2015-05-13 17:23:33.409453+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/206630", 
            "date_created": "2015-07-28 17:14:37.861358+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Related fix proposed to branch: master\nReview: https://review.openstack.org/206631", 
            "date_created": "2015-07-28 17:14:45.782196+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Fix proposed to branch: master\nReview: https://review.openstack.org/206632", 
            "date_created": "2015-07-28 17:14:53.265478+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/162253\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=07c7e5caf2819d96809af1b9a19c046b9fd09851\nSubmitter: Jenkins\nBranch:    master\n\ncommit 07c7e5caf2819d96809af1b9a19c046b9fd09851\nAuthor: Daniel P. Berrange <email address hidden>\nDate:   Fri Mar 6 16:12:28 2015 +0000\n\n    libvirt: support management of downtime during migration\n    \n    Currently live migration runs with the default maximum downtime\n    setting defined by QEMU. This is often inadequate to allow\n    migration of large VMs to ever complete. Rather than trying to\n    invent a new policy for changing downtime in OpenStack, copy\n    the existing logic that is successfully battle tested by the\n    oVirt project in VDSM.\n    \n    Note that setting the downtime step delay based on guest RAM size\n    is an inexact science, as RAM size is only one factor influencing\n    success of migration. Just as important is the rate of dirtying\n    data in the guest, but this is based on guest workload which is\n    not something Nova has visibility into. The bottleneck is the\n    network which needs to be able to keep up with the dirtying of\n    data in the guest. The greater the overall RAM size, the more\n    time is required to transfer the total guest memory. So for\n    larger guest sizes, we need to allow greater time for the guest\n    to attempt to successfully migrate before increasing the max\n    downtime. Scaling downtime step delay according to the overall\n    guest RAM size is a reasonable, albeit not foolproof, way to\n    tune migration to increase chances of success.\n    \n    This adds three host level config parameters which admins can\n    use to control the base downtime value and the rate at which\n    downtime is allowed to be increased during migration.\n    \n    Related-bug: #1429220\n    DocImpact: three new libvirt configuration parameters in\n               nova.conf allow the administrator to control\n               the maximum permitted downtime for migration\n               making migration more likely to complete for\n               large VMs.\n    Change-Id: I1992ffe9d3b2ff8d436cf1c419af9a238a8fecd8\n", 
            "date_created": "2015-08-11 07:58:06.994190+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/162254\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=da33ab4f7be6fab4b5f0e5a5d276b186c0fb0d93\nSubmitter: Jenkins\nBranch:    master\n\ncommit da33ab4f7be6fab4b5f0e5a5d276b186c0fb0d93\nAuthor: Daniel P. Berrange <email address hidden>\nDate:   Fri Mar 6 17:34:16 2015 +0000\n\n    libvirt: set caps on maximum live migration time\n    \n    Currently Nova launches live migration and then just leaves it\n    to run, assuming it'll eventually finish. If the guest is\n    dirtying memory quicker than the network can transfer it, it\n    is entirely possible that a migration will never complete. In\n    such a case it is highly undesirable to leave it running\n    forever since it wastes valuable CPU and network resources\n    Rather than trying to come up with a new policy for aborting\n    migration in OpenStack, copy the existing logic that is\n    successfully battle tested by the oVirt project in VDSM.\n    \n    This introduces two new host level configuration parameters\n    that cloud administrators can use to ensure migrations which\n    don't appear likely to complete will be aborted. First is\n    an overall cap on the total running time of migration. The\n    configured value is scaled by the number of GB of guest RAM,\n    since larger guests will obviously take proportionally longer\n    to migrate. The second is a timeout that is applied when Nova\n    detects that memory is being dirtied faster than it can be\n    transferred. It tracks a low watermark of data remaining and\n    if that low watermark doesn't decrease in the given time,\n    it assumes the VM is stuck and aborts migration\n    \n    NB with the default values for the config parameters, the code\n    for detecting stuck migrations is only going to kick in for\n    guests which have more than 2 GB of RAM allocated, as for\n    smaller guests the overall time limit will abort migration\n    before this happens. This is reasonable as small guests are\n    less likely to get stuck during migration, as the network\n    will generally be able to keep up with dirtying data well\n    enough to get to a point where the final switchover can be\n    performed.\n    \n    Related-bug: #1429220\n    DocImpact: two new libvirt configuration parameters in\n               nova.conf allow the administrator to control\n               length of migration before aborting it\n    Change-Id: I461affe6c85aaf2a6bf6e8749586bfbfe0ebc146\n", 
            "date_created": "2015-08-11 07:58:49.458889+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/206630\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=f67b8fd5ce23917221a5126b16db39afcb8f7710\nSubmitter: Jenkins\nBranch:    master\n\ncommit f67b8fd5ce23917221a5126b16db39afcb8f7710\nAuthor: Daniel P. Berrange <email address hidden>\nDate:   Tue Jul 28 16:58:01 2015 +0100\n\n    libvirt: ensure LibvirtConfigGuestDisk parses readonly/shareable flags\n    \n    The LibvirtConfigGuestDisk class did not handle parsing of the\n    readonly flag and was missing support for the shareable flag\n    entirely. Add support for dealing with both.\n    \n    Related-bug: #1429220\n    Change-Id: I69df232951c99f6c79f2c2c0ee95327ca872624e\n", 
            "date_created": "2015-08-13 23:51:21.434348+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/206631\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=2f6cf7cba883c594e14aea05a85bb36b9f5209b0\nSubmitter: Jenkins\nBranch:    master\n\ncommit 2f6cf7cba883c594e14aea05a85bb36b9f5209b0\nAuthor: Daniel P. Berrange <email address hidden>\nDate:   Tue Jul 28 17:39:33 2015 +0100\n\n    libvirt: add helper methods for getting guest devices/disks\n    \n    Add get_all_devices and get_all_disks methods to the libvirt\n    Guest object.\n    \n    Related-bug: #1429220\n    Change-Id: I97ee786c5cc603aec1695929f58aa127063db439\n", 
            "date_created": "2015-08-20 23:30:02.158120+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }, 
        {
            "content": "Reviewed:  https://review.openstack.org/206632\nCommitted: https://git.openstack.org/cgit/openstack/nova/commit/?id=9d353e59ec4b8653738bc93b62a30c0888f6c3e5\nSubmitter: Jenkins\nBranch:    master\n\ncommit 9d353e59ec4b8653738bc93b62a30c0888f6c3e5\nAuthor: Daniel P. Berrange <email address hidden>\nDate:   Tue Jul 28 13:18:25 2015 +0100\n\n    libvirt: take account of disks in migration data size\n    \n    Currently migration is tuned based on the guest RAM size\n    alone, but when doing block migration we must also look\n    at the guest disk size to determine total data transfer.\n    \n    This change currently follows the (stupid) libvirt logic\n    for deciding which disks are copied. In the future when\n    we can use new libvirt which lets us specify a desired\n    list of disks we'll update this logic.\n    \n    DocImpact: the amount of time a live migration can take\n    is now configurable for the libvirt driver, and is\n    based on a number of seconds per gigabyte of RAM and\n    local disk.\n    \n    Closes-bug: #1429220\n    Change-Id: I3d525e62c6686277c6a05f2a91edefad3230c73f\n", 
            "date_created": "2015-08-27 22:15:10.094407+00:00", 
            "author": "https://api.launchpad.net/1.0/~hudson-openstack"
        }
    ], 
    "closed": "2015-09-03 11:43:24.135992+00:00"
}